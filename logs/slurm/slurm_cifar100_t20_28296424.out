logs/cifar100/5_5_sip/InfLoRA/adam/10/0.95_1.0-0.0005/42
2025-12-11 14:31:13,150 [trainer.py] => config: configs/cifar100_20tasks_inflora_seed42.json
2025-12-11 14:31:13,151 [trainer.py] => device: [device(type='cuda', index=0)]
2025-12-11 14:31:13,151 [trainer.py] => prefix: reproduce
2025-12-11 14:31:13,151 [trainer.py] => dataset: cifar100
2025-12-11 14:31:13,151 [trainer.py] => data_path: data/
2025-12-11 14:31:13,151 [trainer.py] => memory_size: 0
2025-12-11 14:31:13,151 [trainer.py] => memory_per_class: 0
2025-12-11 14:31:13,151 [trainer.py] => fixed_memory: True
2025-12-11 14:31:13,151 [trainer.py] => shuffle: False
2025-12-11 14:31:13,151 [trainer.py] => init_cls: 5
2025-12-11 14:31:13,151 [trainer.py] => increment: 5
2025-12-11 14:31:13,151 [trainer.py] => model_name: InfLoRA
2025-12-11 14:31:13,151 [trainer.py] => net_type: sip
2025-12-11 14:31:13,151 [trainer.py] => embd_dim: 768
2025-12-11 14:31:13,151 [trainer.py] => num_heads: 12
2025-12-11 14:31:13,151 [trainer.py] => total_sessions: 20
2025-12-11 14:31:13,151 [trainer.py] => seed: 42
2025-12-11 14:31:13,152 [trainer.py] => EPSILON: 1e-08
2025-12-11 14:31:13,152 [trainer.py] => init_epoch: 20
2025-12-11 14:31:13,152 [trainer.py] => optim: adam
2025-12-11 14:31:13,152 [trainer.py] => init_lr: 0.0005
2025-12-11 14:31:13,152 [trainer.py] => init_lr_decay: 0.1
2025-12-11 14:31:13,152 [trainer.py] => init_weight_decay: 0.0
2025-12-11 14:31:13,152 [trainer.py] => epochs: 20
2025-12-11 14:31:13,152 [trainer.py] => lrate: 0.0005
2025-12-11 14:31:13,152 [trainer.py] => lrate_decay: 0.1
2025-12-11 14:31:13,152 [trainer.py] => batch_size: 128
2025-12-11 14:31:13,152 [trainer.py] => weight_decay: 0.0
2025-12-11 14:31:13,152 [trainer.py] => rank: 10
2025-12-11 14:31:13,152 [trainer.py] => lamb: 0.95
2025-12-11 14:31:13,152 [trainer.py] => lame: 1.0
2025-12-11 14:31:13,152 [trainer.py] => num_workers: 8
2025-12-11 14:31:13,152 [trainer.py] => use_wncm: True
2025-12-11 14:31:13,152 [trainer.py] => wncm_lambda: 0.07
2025-12-11 14:31:15,217 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
Loading ViT weights from local checkpoint: /leonardo/home/userexternal/lli00001/vit_b16_in21k.pth
Loaded 152 keys, missing 962, unexpected 0
2025-12-11 14:31:17,450 [whitened_ncm_head.py] => WhitenedNCM: Using CPU
2025-12-11 14:31:17,454 [trainer.py] => All params: 114881051
2025-12-11 14:31:17,458 [trainer.py] => Trainable params: 114881051
2025-12-11 14:31:17,458 [inflora.py] => Learning on 0-5
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight'}
2025-12-11 14:36:15,225 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.086, Train_accy 96.96
Threshold:  0.95
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 6/768 type remove
Layer 2 : 9/768 type remove
Layer 3 : 11/768 type remove
Layer 4 : 10/768 type remove
Layer 5 : 12/768 type remove
Layer 6 : 13/768 type remove
Layer 7 : 12/768 type remove
Layer 8 : 16/768 type remove
Layer 9 : 19/768 type remove
Layer 10 : 13/768 type remove
Layer 11 : 5/768 type remove
Layer 12 : 5/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:36:32,083 [trainer.py] => Time:314.6244122982025
500 500
500 500
2025-12-11 14:36:34,050 [trainer.py] => Time:1.966606616973877
2025-12-11 14:36:34,050 [inflora.py] => Exemplar size: 0
2025-12-11 14:36:34,050 [trainer.py] => CNN: {'total': np.float64(99.6), '00-04': np.float64(99.6), 'old': 0, 'new': np.float64(99.6)}
2025-12-11 14:36:34,050 [trainer.py] => CNN top1 curve: [np.float64(99.6)]
2025-12-11 14:36:34,050 [trainer.py] => CNN top1 with task curve: [np.float64(99.6)]
2025-12-11 14:36:34,050 [trainer.py] => CNN top1 task curve: [1.0]
2025-12-11 14:36:43,222 [trainer.py] => W-NCM: {'00-04': 99.8}
2025-12-11 14:36:43,222 [trainer.py] => Ave Acc (W-NCM): 99.80%
2025-12-11 14:36:43,222 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.80% (best 99.80%)
2025-12-11 14:36:43,222 [trainer.py] => Average forgetting (W-NCM): 0.00% | Max forgetting (W-NCM): 0.00%
2025-12-11 14:36:43,859 [trainer.py] => All params: 114881051
2025-12-11 14:36:43,862 [trainer.py] => Trainable params: 188165
2025-12-11 14:36:43,863 [inflora.py] => Learning on 5-10
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.15.weight', 'image_encoder.blocks.8.attn.lora_B_k.12.weight', 'image_encoder.blocks.1.attn.lora_B_k.12.weight', 'image_encoder.blocks.1.attn.lora_B_k.17.weight', 'image_encoder.blocks.8.attn.lora_B_k.10.weight', 'image_encoder.blocks.2.attn.lora_B_v.11.weight', 'image_encoder.blocks.11.attn.lora_B_v.15.weight', 'image_encoder.blocks.5.attn.lora_B_v.12.weight', 'classifier_pool.19.bias', 'image_encoder.blocks.0.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_v.12.weight', 'image_encoder.blocks.4.attn.lora_B_k.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.13.weight', 'image_encoder.blocks.2.attn.lora_B_v.12.weight', 'image_encoder.blocks.11.attn.lora_B_k.12.weight', 'image_encoder.blocks.9.attn.lora_B_k.16.weight', 'image_encoder.blocks.9.attn.lora_B_v.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.15.weight', 'classifier_pool.14.weight', 'image_encoder.blocks.2.attn.lora_B_k.16.weight', 'image_encoder.blocks.2.attn.lora_B_k.17.weight', 'image_encoder.blocks.8.attn.lora_B_k.13.weight', 'image_encoder.blocks.7.attn.lora_B_v.11.weight', 'image_encoder.blocks.4.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_v.17.weight', 'image_encoder.blocks.10.attn.lora_B_k.16.weight', 'image_encoder.blocks.2.attn.lora_B_k.10.weight', 'image_encoder.blocks.9.attn.lora_B_v.12.weight', 'image_encoder.blocks.5.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_v.17.weight', 'image_encoder.blocks.9.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_v.10.weight', 'classifier_pool.15.bias', 'image_encoder.blocks.11.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_k.10.weight', 'classifier_pool.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.18.weight', 'image_encoder.blocks.5.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.15.weight', 'image_encoder.blocks.5.attn.lora_B_v.10.weight', 'image_encoder.blocks.7.attn.lora_B_k.17.weight', 'image_encoder.blocks.0.attn.lora_B_v.17.weight', 'image_encoder.blocks.1.attn.lora_B_k.18.weight', 'image_encoder.blocks.4.attn.lora_B_k.18.weight', 'classifier_pool.17.bias', 'image_encoder.blocks.1.attn.lora_B_v.10.weight', 'image_encoder.blocks.7.attn.lora_B_k.15.weight', 'image_encoder.blocks.4.attn.lora_B_v.13.weight', 'image_encoder.blocks.5.attn.lora_B_k.13.weight', 'image_encoder.blocks.5.attn.lora_B_k.11.weight', 'image_encoder.blocks.6.attn.lora_B_k.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.13.weight', 'image_encoder.blocks.7.attn.lora_B_v.16.weight', 'image_encoder.blocks.9.attn.lora_B_v.11.weight', 'image_encoder.blocks.3.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_k.10.weight', 'image_encoder.blocks.8.attn.lora_B_v.17.weight', 'image_encoder.blocks.9.attn.lora_B_k.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.12.weight', 'image_encoder.blocks.3.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_v.15.weight', 'image_encoder.blocks.5.attn.lora_B_v.15.weight', 'image_encoder.blocks.11.attn.lora_B_k.14.weight', 'image_encoder.blocks.4.attn.lora_B_k.17.weight', 'classifier_pool.19.weight', 'image_encoder.blocks.1.attn.lora_B_k.11.weight', 'image_encoder.blocks.8.attn.lora_B_v.12.weight', 'image_encoder.blocks.1.attn.lora_B_v.16.weight', 'image_encoder.blocks.8.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_v.1.weight', 'image_encoder.blocks.0.attn.lora_B_v.18.weight', 'image_encoder.blocks.0.attn.lora_B_k.11.weight', 'image_encoder.blocks.6.attn.lora_B_v.11.weight', 'image_encoder.blocks.11.attn.lora_B_v.13.weight', 'image_encoder.blocks.2.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_v.1.weight', 'image_encoder.blocks.4.attn.lora_B_k.11.weight', 'image_encoder.blocks.10.attn.lora_B_v.18.weight', 'image_encoder.blocks.2.attn.lora_B_v.13.weight', 'image_encoder.blocks.3.attn.lora_B_k.14.weight', 'image_encoder.blocks.0.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_v.19.weight', 'image_encoder.blocks.11.attn.lora_B_v.19.weight', 'image_encoder.blocks.4.attn.lora_B_v.14.weight', 'image_encoder.blocks.3.attn.lora_B_k.10.weight', 'image_encoder.blocks.1.attn.lora_B_v.14.weight', 'image_encoder.blocks.0.attn.lora_B_k.14.weight', 'image_encoder.blocks.10.attn.lora_B_v.17.weight', 'image_encoder.blocks.3.attn.lora_B_v.14.weight', 'classifier_pool.1.bias', 'classifier_pool.10.weight', 'classifier_pool.10.bias', 'image_encoder.blocks.9.attn.lora_B_v.18.weight', 'image_encoder.blocks.2.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.17.weight', 'classifier_pool.12.bias', 'image_encoder.blocks.6.attn.lora_B_k.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.15.weight', 'image_encoder.blocks.1.attn.lora_B_k.19.weight', 'image_encoder.blocks.7.attn.lora_B_v.13.weight', 'image_encoder.blocks.0.attn.lora_B_k.10.weight', 'image_encoder.blocks.6.attn.lora_B_k.13.weight', 'image_encoder.blocks.0.attn.lora_B_k.12.weight', 'image_encoder.blocks.8.attn.lora_B_v.11.weight', 'image_encoder.blocks.11.attn.lora_B_k.13.weight', 'image_encoder.blocks.10.attn.lora_B_k.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.1.weight', 'image_encoder.blocks.9.attn.lora_B_v.10.weight', 'image_encoder.blocks.7.attn.lora_B_k.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.19.weight', 'image_encoder.blocks.1.attn.lora_B_k.1.weight', 'image_encoder.blocks.8.attn.lora_B_v.14.weight', 'image_encoder.blocks.0.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_k.13.weight', 'image_encoder.blocks.8.attn.lora_B_v.10.weight', 'image_encoder.blocks.3.attn.lora_B_v.10.weight', 'image_encoder.blocks.2.attn.lora_B_v.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.1.weight', 'image_encoder.blocks.8.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_k.15.weight', 'image_encoder.blocks.7.attn.lora_B_k.10.weight', 'image_encoder.blocks.8.attn.lora_B_v.18.weight', 'image_encoder.blocks.10.attn.lora_B_v.13.weight', 'image_encoder.blocks.4.attn.lora_B_k.14.weight', 'image_encoder.blocks.9.attn.lora_B_k.15.weight', 'image_encoder.blocks.11.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.12.weight', 'image_encoder.blocks.10.attn.lora_B_v.10.weight', 'image_encoder.blocks.1.attn.lora_B_k.15.weight', 'image_encoder.blocks.7.attn.lora_B_k.1.weight', 'classifier_pool.13.bias', 'image_encoder.blocks.1.attn.lora_B_k.16.weight', 'image_encoder.blocks.1.attn.lora_B_v.19.weight', 'image_encoder.blocks.9.attn.lora_B_k.18.weight', 'image_encoder.blocks.8.attn.lora_B_k.19.weight', 'image_encoder.blocks.4.attn.lora_B_k.12.weight', 'image_encoder.blocks.11.attn.lora_B_k.1.weight', 'image_encoder.blocks.8.attn.lora_B_v.19.weight', 'image_encoder.blocks.10.attn.lora_B_v.11.weight', 'classifier_pool.14.bias', 'image_encoder.blocks.2.attn.lora_B_v.16.weight', 'image_encoder.blocks.5.attn.lora_B_k.17.weight', 'image_encoder.blocks.6.attn.lora_B_v.16.weight', 'image_encoder.blocks.5.attn.lora_B_k.12.weight', 'image_encoder.blocks.4.attn.lora_B_k.10.weight', 'image_encoder.blocks.10.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.16.weight', 'classifier_pool.16.weight', 'image_encoder.blocks.6.attn.lora_B_v.10.weight', 'classifier_pool.11.weight', 'image_encoder.blocks.3.attn.lora_B_k.1.weight', 'image_encoder.blocks.1.attn.lora_B_v.17.weight', 'classifier_pool.16.bias', 'image_encoder.blocks.2.attn.lora_B_v.18.weight', 'image_encoder.blocks.3.attn.lora_B_v.16.weight', 'image_encoder.blocks.7.attn.lora_B_v.12.weight', 'image_encoder.blocks.10.attn.lora_B_k.12.weight', 'image_encoder.blocks.1.attn.lora_B_v.18.weight', 'image_encoder.blocks.9.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_v.19.weight', 'image_encoder.blocks.1.attn.lora_B_k.13.weight', 'image_encoder.blocks.9.attn.lora_B_v.16.weight', 'image_encoder.blocks.10.attn.lora_B_k.18.weight', 'image_encoder.blocks.3.attn.lora_B_k.12.weight', 'image_encoder.blocks.11.attn.lora_B_v.12.weight', 'image_encoder.blocks.11.attn.lora_B_k.17.weight', 'image_encoder.blocks.0.attn.lora_B_v.12.weight', 'image_encoder.blocks.5.attn.lora_B_v.16.weight', 'image_encoder.blocks.9.attn.lora_B_k.12.weight', 'image_encoder.blocks.0.attn.lora_B_v.13.weight', 'image_encoder.blocks.8.attn.lora_B_k.15.weight', 'image_encoder.blocks.6.attn.lora_B_v.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.13.weight', 'image_encoder.blocks.9.attn.lora_B_k.19.weight', 'classifier_pool.17.weight', 'image_encoder.blocks.7.attn.lora_B_k.11.weight', 'classifier_pool.18.bias', 'image_encoder.blocks.0.attn.lora_B_v.11.weight', 'image_encoder.blocks.10.attn.lora_B_v.14.weight', 'image_encoder.blocks.7.attn.lora_B_v.14.weight', 'image_encoder.blocks.6.attn.lora_B_k.12.weight', 'image_encoder.blocks.11.attn.lora_B_k.11.weight', 'image_encoder.blocks.7.attn.lora_B_v.19.weight', 'image_encoder.blocks.1.attn.lora_B_k.14.weight', 'image_encoder.blocks.0.attn.lora_B_v.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.17.weight', 'image_encoder.blocks.5.attn.lora_B_k.14.weight', 'image_encoder.blocks.7.attn.lora_B_k.14.weight', 'image_encoder.blocks.2.attn.lora_B_v.19.weight', 'image_encoder.blocks.3.attn.lora_B_v.13.weight', 'image_encoder.blocks.1.attn.lora_B_v.15.weight', 'image_encoder.blocks.1.attn.lora_B_v.11.weight', 'image_encoder.blocks.7.attn.lora_B_k.18.weight', 'image_encoder.blocks.7.attn.lora_B_v.15.weight', 'classifier_pool.11.bias', 'image_encoder.blocks.10.attn.lora_B_k.17.weight', 'image_encoder.blocks.3.attn.lora_B_k.18.weight', 'image_encoder.blocks.11.attn.lora_B_v.14.weight', 'image_encoder.blocks.9.attn.lora_B_v.15.weight', 'image_encoder.blocks.5.attn.lora_B_k.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.14.weight', 'image_encoder.blocks.3.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_k.11.weight', 'image_encoder.blocks.2.attn.lora_B_k.11.weight', 'image_encoder.blocks.5.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_v.18.weight', 'image_encoder.blocks.6.attn.lora_B_k.16.weight', 'image_encoder.blocks.4.attn.lora_B_k.15.weight', 'image_encoder.blocks.8.attn.lora_B_v.15.weight', 'image_encoder.blocks.2.attn.lora_B_k.15.weight', 'image_encoder.blocks.8.attn.lora_B_k.18.weight', 'image_encoder.blocks.4.attn.lora_B_v.18.weight', 'image_encoder.blocks.9.attn.lora_B_k.10.weight', 'classifier_pool.12.weight', 'image_encoder.blocks.4.attn.lora_B_v.10.weight', 'image_encoder.blocks.5.attn.lora_B_k.18.weight', 'image_encoder.blocks.4.attn.lora_B_v.12.weight', 'image_encoder.blocks.5.attn.lora_B_k.16.weight', 'image_encoder.blocks.9.attn.lora_B_v.19.weight', 'image_encoder.blocks.11.attn.lora_B_v.11.weight', 'image_encoder.blocks.0.attn.lora_B_k.13.weight', 'image_encoder.blocks.6.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.11.weight', 'image_encoder.blocks.8.attn.lora_B_v.13.weight', 'image_encoder.blocks.1.attn.lora_B_k.10.weight', 'classifier_pool.1.weight', 'image_encoder.blocks.1.attn.lora_B_v.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.14.weight', 'image_encoder.blocks.6.attn.lora_B_v.12.weight', 'image_encoder.blocks.7.attn.lora_B_k.16.weight', 'image_encoder.blocks.9.attn.lora_B_k.17.weight', 'image_encoder.blocks.10.attn.lora_B_k.14.weight', 'image_encoder.blocks.3.attn.lora_B_k.19.weight', 'image_encoder.blocks.9.attn.lora_B_k.13.weight', 'image_encoder.blocks.11.attn.lora_B_v.16.weight', 'image_encoder.blocks.11.attn.lora_B_v.18.weight', 'image_encoder.blocks.4.attn.lora_B_v.11.weight', 'classifier_pool.18.weight', 'image_encoder.blocks.6.attn.lora_B_k.18.weight', 'image_encoder.blocks.2.attn.lora_B_v.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.16.weight', 'image_encoder.blocks.2.attn.lora_B_k.1.weight', 'image_encoder.blocks.2.attn.lora_B_v.14.weight', 'image_encoder.blocks.5.attn.lora_B_v.18.weight', 'image_encoder.blocks.5.attn.lora_B_k.15.weight', 'image_encoder.blocks.10.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_v.17.weight', 'image_encoder.blocks.10.attn.lora_B_k.11.weight', 'image_encoder.blocks.7.attn.lora_B_k.19.weight', 'image_encoder.blocks.1.attn.lora_B_v.13.weight', 'image_encoder.blocks.6.attn.lora_B_k.17.weight', 'image_encoder.blocks.8.attn.lora_B_k.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.19.weight', 'image_encoder.blocks.0.attn.lora_B_v.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.19.weight', 'image_encoder.blocks.2.attn.lora_B_v.15.weight', 'image_encoder.blocks.9.attn.lora_B_v.17.weight', 'image_encoder.blocks.6.attn.lora_B_k.15.weight', 'image_encoder.blocks.3.attn.lora_B_v.18.weight', 'image_encoder.blocks.10.attn.lora_B_v.15.weight', 'image_encoder.blocks.2.attn.lora_B_k.14.weight', 'image_encoder.blocks.5.attn.lora_B_k.10.weight', 'image_encoder.blocks.6.attn.lora_B_v.14.weight', 'image_encoder.blocks.10.attn.lora_B_k.13.weight', 'image_encoder.blocks.4.attn.lora_B_k.19.weight', 'image_encoder.blocks.5.attn.lora_B_v.13.weight', 'image_encoder.blocks.6.attn.lora_B_v.18.weight', 'image_encoder.blocks.6.attn.lora_B_k.14.weight', 'image_encoder.blocks.8.attn.lora_B_k.11.weight', 'image_encoder.blocks.8.attn.lora_B_v.16.weight', 'image_encoder.blocks.10.attn.lora_B_k.15.weight', 'image_encoder.blocks.11.attn.lora_B_v.10.weight', 'classifier_pool.15.weight', 'image_encoder.blocks.0.attn.lora_B_k.18.weight', 'image_encoder.blocks.9.attn.lora_B_k.11.weight', 'image_encoder.blocks.2.attn.lora_B_k.18.weight', 'image_encoder.blocks.4.attn.lora_B_k.16.weight', 'image_encoder.blocks.4.attn.lora_B_v.15.weight', 'image_encoder.blocks.4.attn.lora_B_v.16.weight', 'image_encoder.blocks.5.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.12.weight', 'image_encoder.blocks.9.attn.lora_B_k.14.weight', 'image_encoder.blocks.1.attn.lora_B_v.12.weight', 'image_encoder.blocks.8.attn.lora_B_k.16.weight', 'image_encoder.blocks.5.attn.lora_B_v.19.weight'}
2025-12-11 14:41:39,839 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.074, Train_accy 97.56
Threshold:  0.9524999999999999
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 13/768 type remove
Layer 4 : 13/768 type remove
Layer 5 : 16/768 type remove
Layer 6 : 17/768 type remove
Layer 7 : 18/768 type remove
Layer 8 : 25/768 type remove
Layer 9 : 30/768 type remove
Layer 10 : 26/768 type remove
Layer 11 : 12/768 type remove
Layer 12 : 13/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:41:58,419 [trainer.py] => Time:314.55693078041077
1000 1000
1000 1000
2025-12-11 14:42:01,694 [trainer.py] => Time:3.2737319469451904
2025-12-11 14:42:01,694 [inflora.py] => Exemplar size: 0
2025-12-11 14:42:01,694 [trainer.py] => CNN: {'total': np.float64(99.2), '00-04': np.float64(99.0), '05-09': np.float64(99.4), 'old': np.float64(99.0), 'new': np.float64(99.4)}
2025-12-11 14:42:01,694 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2)]
2025-12-11 14:42:01,694 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5)]
2025-12-11 14:42:01,694 [trainer.py] => CNN top1 task curve: [1.0, 0.997]
2025-12-11 14:42:12,257 [trainer.py] => W-NCM: {'00-04': 99.4, '05-09': 99.6}
2025-12-11 14:42:12,257 [trainer.py] => Ave Acc (W-NCM): 99.50%
2025-12-11 14:42:12,257 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.40% (best 99.80%); T2: W-NCM 99.60% (best 99.60%)
2025-12-11 14:42:12,257 [trainer.py] => Average forgetting (W-NCM): 0.40% | Max forgetting (W-NCM): 0.40%
2025-12-11 14:42:12,909 [trainer.py] => All params: 114881051
2025-12-11 14:42:12,912 [trainer.py] => Trainable params: 2069815
2025-12-11 14:42:12,912 [inflora.py] => Learning on 10-15
Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_v.2.weight', 'image_encoder.blocks.7.attn.lora_B_k.2.weight', 'image_encoder.blocks.3.attn.lora_B_k.2.weight', 'image_encoder.blocks.5.attn.lora_B_v.2.weight', 'image_encoder.blocks.5.attn.lora_B_k.2.weight', 'image_encoder.blocks.11.attn.lora_B_k.2.weight', 'image_encoder.blocks.10.attn.lora_B_k.2.weight', 'classifier_pool.2.bias', 'image_encoder.blocks.4.attn.lora_B_k.2.weight', 'image_encoder.blocks.9.attn.lora_B_v.2.weight', 'image_encoder.blocks.8.attn.lora_B_v.2.weight', 'image_encoder.blocks.3.attn.lora_B_v.2.weight', 'image_encoder.blocks.4.attn.lora_B_v.2.weight', 'classifier_pool.2.weight', 'image_encoder.blocks.1.attn.lora_B_k.2.weight', 'image_encoder.blocks.6.attn.lora_B_v.2.weight', 'image_encoder.blocks.8.attn.lora_B_k.2.weight', 'image_encoder.blocks.0.attn.lora_B_k.2.weight', 'image_encoder.blocks.2.attn.lora_B_v.2.weight', 'image_encoder.blocks.7.attn.lora_B_v.2.weight', 'image_encoder.blocks.9.attn.lora_B_k.2.weight', 'image_encoder.blocks.2.attn.lora_B_k.2.weight', 'image_encoder.blocks.0.attn.lora_B_v.2.weight', 'image_encoder.blocks.1.attn.lora_B_v.2.weight', 'image_encoder.blocks.11.attn.lora_B_v.2.weight', 'image_encoder.blocks.6.attn.lora_B_k.2.weight'}
2025-12-11 14:47:09,132 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.095, Train_accy 96.88
Threshold:  0.955
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 15/768 type remove
Layer 4 : 14/768 type remove
Layer 5 : 18/768 type remove
Layer 6 : 20/768 type remove
Layer 7 : 21/768 type remove
Layer 8 : 29/768 type remove
Layer 9 : 43/768 type remove
Layer 10 : 42/768 type remove
Layer 11 : 20/768 type remove
Layer 12 : 27/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:47:27,797 [trainer.py] => Time:314.8849093914032
1500 1500
1500 1500
2025-12-11 14:47:32,349 [trainer.py] => Time:4.551263809204102
2025-12-11 14:47:32,349 [inflora.py] => Exemplar size: 0
2025-12-11 14:47:32,349 [trainer.py] => CNN: {'total': np.float64(96.0), '00-04': np.float64(97.4), '05-09': np.float64(98.4), '10-14': np.float64(92.2), 'old': np.float64(97.9), 'new': np.float64(92.2)}
2025-12-11 14:47:32,349 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0)]
2025-12-11 14:47:32,349 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47)]
2025-12-11 14:47:32,349 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964]
2025-12-11 14:47:44,207 [trainer.py] => W-NCM: {'00-04': 87.4, '05-09': 99.4, '10-14': 99.4}
2025-12-11 14:47:44,207 [trainer.py] => Ave Acc (W-NCM): 95.40%
2025-12-11 14:47:44,207 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 87.40% (best 99.80%); T2: W-NCM 99.40% (best 99.60%); T3: W-NCM 99.40% (best 99.40%)
2025-12-11 14:47:44,207 [trainer.py] => Average forgetting (W-NCM): 6.30% | Max forgetting (W-NCM): 12.40%
2025-12-11 14:47:44,848 [trainer.py] => All params: 114881051
2025-12-11 14:47:44,851 [trainer.py] => Trainable params: 188165
2025-12-11 14:47:44,851 [inflora.py] => Learning on 15-20
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_v.3.weight', 'image_encoder.blocks.6.attn.lora_B_k.3.weight', 'image_encoder.blocks.1.attn.lora_B_k.3.weight', 'image_encoder.blocks.0.attn.lora_B_v.3.weight', 'classifier_pool.3.bias', 'classifier_pool.3.weight', 'image_encoder.blocks.9.attn.lora_B_k.3.weight', 'image_encoder.blocks.1.attn.lora_B_v.3.weight', 'image_encoder.blocks.2.attn.lora_B_k.3.weight', 'image_encoder.blocks.11.attn.lora_B_k.3.weight', 'image_encoder.blocks.7.attn.lora_B_k.3.weight', 'image_encoder.blocks.8.attn.lora_B_v.3.weight', 'image_encoder.blocks.10.attn.lora_B_v.3.weight', 'image_encoder.blocks.7.attn.lora_B_v.3.weight', 'image_encoder.blocks.6.attn.lora_B_v.3.weight', 'image_encoder.blocks.9.attn.lora_B_v.3.weight', 'image_encoder.blocks.11.attn.lora_B_v.3.weight', 'image_encoder.blocks.5.attn.lora_B_v.3.weight', 'image_encoder.blocks.10.attn.lora_B_k.3.weight', 'image_encoder.blocks.4.attn.lora_B_k.3.weight', 'image_encoder.blocks.0.attn.lora_B_k.3.weight', 'image_encoder.blocks.5.attn.lora_B_k.3.weight', 'image_encoder.blocks.3.attn.lora_B_v.3.weight', 'image_encoder.blocks.8.attn.lora_B_k.3.weight', 'image_encoder.blocks.4.attn.lora_B_v.3.weight', 'image_encoder.blocks.3.attn.lora_B_k.3.weight'}
2025-12-11 14:52:40,975 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.077, Train_accy 97.08
Threshold:  0.9575
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 16/768 type remove
Layer 4 : 16/768 type remove
Layer 5 : 20/768 type remove
Layer 6 : 24/768 type remove
Layer 7 : 25/768 type remove
Layer 8 : 36/768 type remove
Layer 9 : 54/768 type remove
Layer 10 : 53/768 type remove
Layer 11 : 25/768 type remove
Layer 12 : 32/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:52:59,732 [trainer.py] => Time:314.88049578666687
2000 2000
2000 2000
2025-12-11 14:53:05,573 [trainer.py] => Time:5.840838432312012
2025-12-11 14:53:05,573 [inflora.py] => Exemplar size: 0
2025-12-11 14:53:05,573 [trainer.py] => CNN: {'total': np.float64(96.05), '00-04': np.float64(97.4), '05-09': np.float64(97.4), '10-14': np.float64(93.4), '15-19': np.float64(96.0), 'old': np.float64(96.07), 'new': np.float64(96.0)}
2025-12-11 14:53:05,573 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05)]
2025-12-11 14:53:05,574 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45)]
2025-12-11 14:53:05,574 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963]
2025-12-11 14:53:18,625 [trainer.py] => W-NCM: {'00-04': 91.4, '05-09': 98.8, '10-14': 98.2, '15-19': 98.2}
2025-12-11 14:53:18,625 [trainer.py] => Ave Acc (W-NCM): 96.65%
2025-12-11 14:53:18,625 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 91.40% (best 99.80%); T2: W-NCM 98.80% (best 99.60%); T3: W-NCM 98.20% (best 99.40%); T4: W-NCM 98.20% (best 98.20%)
2025-12-11 14:53:18,625 [trainer.py] => Average forgetting (W-NCM): 3.47% | Max forgetting (W-NCM): 8.40%
2025-12-11 14:53:19,254 [trainer.py] => All params: 114881051
2025-12-11 14:53:19,257 [trainer.py] => Trainable params: 188165
2025-12-11 14:53:19,258 [inflora.py] => Learning on 20-25
Parameters to be updated: {'classifier_pool.4.weight', 'image_encoder.blocks.3.attn.lora_B_v.4.weight', 'image_encoder.blocks.9.attn.lora_B_v.4.weight', 'image_encoder.blocks.4.attn.lora_B_v.4.weight', 'image_encoder.blocks.1.attn.lora_B_k.4.weight', 'image_encoder.blocks.3.attn.lora_B_k.4.weight', 'image_encoder.blocks.7.attn.lora_B_v.4.weight', 'image_encoder.blocks.2.attn.lora_B_v.4.weight', 'image_encoder.blocks.0.attn.lora_B_v.4.weight', 'image_encoder.blocks.5.attn.lora_B_v.4.weight', 'image_encoder.blocks.10.attn.lora_B_k.4.weight', 'image_encoder.blocks.7.attn.lora_B_k.4.weight', 'classifier_pool.4.bias', 'image_encoder.blocks.6.attn.lora_B_v.4.weight', 'image_encoder.blocks.11.attn.lora_B_v.4.weight', 'image_encoder.blocks.8.attn.lora_B_v.4.weight', 'image_encoder.blocks.6.attn.lora_B_k.4.weight', 'image_encoder.blocks.5.attn.lora_B_k.4.weight', 'image_encoder.blocks.4.attn.lora_B_k.4.weight', 'image_encoder.blocks.11.attn.lora_B_k.4.weight', 'image_encoder.blocks.10.attn.lora_B_v.4.weight', 'image_encoder.blocks.8.attn.lora_B_k.4.weight', 'image_encoder.blocks.1.attn.lora_B_v.4.weight', 'image_encoder.blocks.0.attn.lora_B_k.4.weight', 'image_encoder.blocks.9.attn.lora_B_k.4.weight', 'image_encoder.blocks.2.attn.lora_B_k.4.weight'}
2025-12-11 14:58:15,234 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.027, Train_accy 99.16
Threshold:  0.96
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 17/768 type remove
Layer 4 : 17/768 type remove
Layer 5 : 23/768 type remove
Layer 6 : 27/768 type remove
Layer 7 : 30/768 type remove
Layer 8 : 43/768 type remove
Layer 9 : 63/768 type remove
Layer 10 : 58/768 type remove
Layer 11 : 30/768 type remove
Layer 12 : 37/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:58:33,666 [trainer.py] => Time:314.4085330963135
2500 2500
2500 2500
2025-12-11 14:58:40,808 [trainer.py] => Time:7.141180992126465
2025-12-11 14:58:40,808 [inflora.py] => Exemplar size: 0
2025-12-11 14:58:40,808 [trainer.py] => CNN: {'total': np.float64(94.48), '00-04': np.float64(96.0), '05-09': np.float64(96.0), '10-14': np.float64(90.0), '15-19': np.float64(95.4), '20-24': np.float64(95.0), 'old': np.float64(94.35), 'new': np.float64(95.0)}
2025-12-11 14:58:40,808 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48)]
2025-12-11 14:58:40,808 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52)]
2025-12-11 14:58:40,808 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468]
2025-12-11 14:58:55,079 [trainer.py] => W-NCM: {'00-04': 93.0, '05-09': 96.39999999999999, '10-14': 96.6, '15-19': 97.2, '20-24': 99.2}
2025-12-11 14:58:55,080 [trainer.py] => Ave Acc (W-NCM): 96.48%
2025-12-11 14:58:55,080 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 93.00% (best 99.80%); T2: W-NCM 96.40% (best 99.60%); T3: W-NCM 96.60% (best 99.40%); T4: W-NCM 97.20% (best 98.20%); T5: W-NCM 99.20% (best 99.20%)
2025-12-11 14:58:55,080 [trainer.py] => Average forgetting (W-NCM): 3.45% | Max forgetting (W-NCM): 6.80%
2025-12-11 14:58:55,707 [trainer.py] => All params: 114881051
2025-12-11 14:58:55,710 [trainer.py] => Trainable params: 188165
2025-12-11 14:58:55,710 [inflora.py] => Learning on 25-30
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.5.weight', 'image_encoder.blocks.4.attn.lora_B_k.5.weight', 'image_encoder.blocks.6.attn.lora_B_v.5.weight', 'image_encoder.blocks.8.attn.lora_B_k.5.weight', 'image_encoder.blocks.1.attn.lora_B_v.5.weight', 'image_encoder.blocks.11.attn.lora_B_v.5.weight', 'image_encoder.blocks.10.attn.lora_B_v.5.weight', 'classifier_pool.5.weight', 'classifier_pool.5.bias', 'image_encoder.blocks.10.attn.lora_B_k.5.weight', 'image_encoder.blocks.8.attn.lora_B_v.5.weight', 'image_encoder.blocks.2.attn.lora_B_v.5.weight', 'image_encoder.blocks.3.attn.lora_B_v.5.weight', 'image_encoder.blocks.1.attn.lora_B_k.5.weight', 'image_encoder.blocks.6.attn.lora_B_k.5.weight', 'image_encoder.blocks.7.attn.lora_B_k.5.weight', 'image_encoder.blocks.11.attn.lora_B_k.5.weight', 'image_encoder.blocks.2.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_v.5.weight', 'image_encoder.blocks.5.attn.lora_B_k.5.weight', 'image_encoder.blocks.5.attn.lora_B_v.5.weight', 'image_encoder.blocks.9.attn.lora_B_k.5.weight', 'image_encoder.blocks.3.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_k.5.weight', 'image_encoder.blocks.7.attn.lora_B_v.5.weight', 'image_encoder.blocks.9.attn.lora_B_v.5.weight'}
2025-12-11 15:03:51,903 [inflora.py] => Task 5, Epoch 20/20 => Loss 0.113, Train_accy 95.80
Threshold:  0.9624999999999999
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 19/768 type remove
Layer 4 : 19/768 type remove
Layer 5 : 26/768 type remove
Layer 6 : 30/768 type remove
Layer 7 : 32/768 type remove
Layer 8 : 46/768 type remove
Layer 9 : 70/768 type remove
Layer 10 : 66/768 type remove
Layer 11 : 35/768 type remove
Layer 12 : 42/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:04:10,687 [trainer.py] => Time:314.976402759552
3000 3000
3000 3000
2025-12-11 15:04:19,130 [trainer.py] => Time:8.442669868469238
2025-12-11 15:04:19,130 [inflora.py] => Exemplar size: 0
2025-12-11 15:04:19,130 [trainer.py] => CNN: {'total': np.float64(92.8), '00-04': np.float64(95.6), '05-09': np.float64(94.8), '10-14': np.float64(91.8), '15-19': np.float64(94.4), '20-24': np.float64(91.8), '25-29': np.float64(88.4), 'old': np.float64(93.68), 'new': np.float64(88.4)}
2025-12-11 15:04:19,130 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8)]
2025-12-11 15:04:19,130 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47)]
2025-12-11 15:04:19,130 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931]
2025-12-11 15:04:34,627 [trainer.py] => W-NCM: {'00-04': 93.2, '05-09': 97.2, '10-14': 93.2, '15-19': 96.8, '20-24': 95.8, '25-29': 96.8}
2025-12-11 15:04:34,627 [trainer.py] => Ave Acc (W-NCM): 95.50%
2025-12-11 15:04:34,627 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 93.20% (best 99.80%); T2: W-NCM 97.20% (best 99.60%); T3: W-NCM 93.20% (best 99.40%); T4: W-NCM 96.80% (best 98.20%); T5: W-NCM 95.80% (best 99.20%); T6: W-NCM 96.80% (best 96.80%)
2025-12-11 15:04:34,627 [trainer.py] => Average forgetting (W-NCM): 4.00% | Max forgetting (W-NCM): 6.60%
2025-12-11 15:04:35,252 [trainer.py] => All params: 114881051
2025-12-11 15:04:35,255 [trainer.py] => Trainable params: 188165
2025-12-11 15:04:35,256 [inflora.py] => Learning on 30-35
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_v.6.weight', 'image_encoder.blocks.1.attn.lora_B_k.6.weight', 'image_encoder.blocks.8.attn.lora_B_v.6.weight', 'classifier_pool.6.bias', 'image_encoder.blocks.8.attn.lora_B_k.6.weight', 'image_encoder.blocks.6.attn.lora_B_k.6.weight', 'image_encoder.blocks.4.attn.lora_B_v.6.weight', 'image_encoder.blocks.9.attn.lora_B_v.6.weight', 'image_encoder.blocks.1.attn.lora_B_v.6.weight', 'image_encoder.blocks.2.attn.lora_B_k.6.weight', 'image_encoder.blocks.3.attn.lora_B_k.6.weight', 'image_encoder.blocks.10.attn.lora_B_k.6.weight', 'image_encoder.blocks.7.attn.lora_B_v.6.weight', 'image_encoder.blocks.5.attn.lora_B_v.6.weight', 'classifier_pool.6.weight', 'image_encoder.blocks.10.attn.lora_B_v.6.weight', 'image_encoder.blocks.6.attn.lora_B_v.6.weight', 'image_encoder.blocks.0.attn.lora_B_v.6.weight', 'image_encoder.blocks.11.attn.lora_B_k.6.weight', 'image_encoder.blocks.0.attn.lora_B_k.6.weight', 'image_encoder.blocks.7.attn.lora_B_k.6.weight', 'image_encoder.blocks.3.attn.lora_B_v.6.weight', 'image_encoder.blocks.11.attn.lora_B_v.6.weight', 'image_encoder.blocks.5.attn.lora_B_k.6.weight', 'image_encoder.blocks.4.attn.lora_B_k.6.weight', 'image_encoder.blocks.9.attn.lora_B_k.6.weight'}
2025-12-11 15:09:31,140 [inflora.py] => Task 6, Epoch 20/20 => Loss 0.064, Train_accy 97.68
Threshold:  0.965
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 20/768 type remove
Layer 4 : 21/768 type remove
Layer 5 : 28/768 type remove
Layer 6 : 35/768 type remove
Layer 7 : 38/768 type remove
Layer 8 : 54/768 type remove
Layer 9 : 82/768 type remove
Layer 10 : 78/768 type remove
Layer 11 : 40/768 type remove
Layer 12 : 47/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:09:49,741 [trainer.py] => Time:314.4856059551239
3500 3500
3500 3500
2025-12-11 15:09:59,449 [trainer.py] => Time:9.707706689834595
2025-12-11 15:09:59,449 [inflora.py] => Exemplar size: 0
2025-12-11 15:09:59,449 [trainer.py] => CNN: {'total': np.float64(92.34), '00-04': np.float64(95.0), '05-09': np.float64(94.8), '10-14': np.float64(89.0), '15-19': np.float64(93.6), '20-24': np.float64(90.0), '25-29': np.float64(88.8), '30-34': np.float64(95.2), 'old': np.float64(91.87), 'new': np.float64(95.2)}
2025-12-11 15:09:59,450 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34)]
2025-12-11 15:09:59,450 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37)]
2025-12-11 15:09:59,450 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926]
2025-12-11 15:10:16,125 [trainer.py] => W-NCM: {'00-04': 90.4, '05-09': 97.6, '10-14': 94.19999999999999, '15-19': 95.39999999999999, '20-24': 94.6, '25-29': 94.8, '30-34': 97.8}
2025-12-11 15:10:16,126 [trainer.py] => Ave Acc (W-NCM): 94.97%
2025-12-11 15:10:16,126 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 90.40% (best 99.80%); T2: W-NCM 97.60% (best 99.60%); T3: W-NCM 94.20% (best 99.40%); T4: W-NCM 95.40% (best 98.20%); T5: W-NCM 94.60% (best 99.20%); T6: W-NCM 94.80% (best 96.80%); T7: W-NCM 97.80% (best 97.80%)
2025-12-11 15:10:16,126 [trainer.py] => Average forgetting (W-NCM): 4.33% | Max forgetting (W-NCM): 9.40%
2025-12-11 15:10:16,749 [trainer.py] => All params: 114881051
2025-12-11 15:10:16,753 [trainer.py] => Trainable params: 188165
2025-12-11 15:10:16,753 [inflora.py] => Learning on 35-40
Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_k.7.weight', 'image_encoder.blocks.6.attn.lora_B_k.7.weight', 'image_encoder.blocks.10.attn.lora_B_v.7.weight', 'image_encoder.blocks.8.attn.lora_B_v.7.weight', 'image_encoder.blocks.5.attn.lora_B_v.7.weight', 'image_encoder.blocks.3.attn.lora_B_v.7.weight', 'image_encoder.blocks.11.attn.lora_B_v.7.weight', 'image_encoder.blocks.9.attn.lora_B_k.7.weight', 'image_encoder.blocks.9.attn.lora_B_v.7.weight', 'image_encoder.blocks.1.attn.lora_B_k.7.weight', 'image_encoder.blocks.0.attn.lora_B_k.7.weight', 'image_encoder.blocks.7.attn.lora_B_k.7.weight', 'image_encoder.blocks.2.attn.lora_B_v.7.weight', 'image_encoder.blocks.0.attn.lora_B_v.7.weight', 'image_encoder.blocks.6.attn.lora_B_v.7.weight', 'image_encoder.blocks.4.attn.lora_B_v.7.weight', 'classifier_pool.7.bias', 'image_encoder.blocks.2.attn.lora_B_k.7.weight', 'image_encoder.blocks.10.attn.lora_B_k.7.weight', 'image_encoder.blocks.4.attn.lora_B_k.7.weight', 'image_encoder.blocks.5.attn.lora_B_k.7.weight', 'image_encoder.blocks.11.attn.lora_B_k.7.weight', 'image_encoder.blocks.8.attn.lora_B_k.7.weight', 'image_encoder.blocks.1.attn.lora_B_v.7.weight', 'classifier_pool.7.weight', 'image_encoder.blocks.7.attn.lora_B_v.7.weight'}
2025-12-11 15:15:13,458 [inflora.py] => Task 7, Epoch 20/20 => Loss 0.053, Train_accy 98.08
Threshold:  0.9675
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 22/768 type remove
Layer 4 : 24/768 type remove
Layer 5 : 33/768 type remove
Layer 6 : 42/768 type remove
Layer 7 : 46/768 type remove
Layer 8 : 66/768 type remove
Layer 9 : 102/768 type remove
Layer 10 : 96/768 type remove
Layer 11 : 49/768 type remove
Layer 12 : 52/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:15:32,241 [trainer.py] => Time:315.48844623565674
4000 4000
4000 4000
2025-12-11 15:15:43,234 [trainer.py] => Time:10.99243974685669
2025-12-11 15:15:43,234 [inflora.py] => Exemplar size: 0
2025-12-11 15:15:43,234 [trainer.py] => CNN: {'total': np.float64(90.82), '00-04': np.float64(94.6), '05-09': np.float64(93.2), '10-14': np.float64(86.4), '15-19': np.float64(90.2), '20-24': np.float64(90.6), '25-29': np.float64(87.8), '30-34': np.float64(94.8), '35-39': np.float64(89.0), 'old': np.float64(91.09), 'new': np.float64(89.0)}
2025-12-11 15:15:43,234 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82)]
2025-12-11 15:15:43,235 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35)]
2025-12-11 15:15:43,235 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025]
2025-12-11 15:16:01,403 [trainer.py] => W-NCM: {'00-04': 89.4, '05-09': 97.0, '10-14': 80.0, '15-19': 93.8, '20-24': 93.8, '25-29': 94.19999999999999, '30-34': 97.0, '35-39': 98.2}
2025-12-11 15:16:01,403 [trainer.py] => Ave Acc (W-NCM): 92.93%
2025-12-11 15:16:01,403 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 89.40% (best 99.80%); T2: W-NCM 97.00% (best 99.60%); T3: W-NCM 80.00% (best 99.40%); T4: W-NCM 93.80% (best 98.20%); T5: W-NCM 93.80% (best 99.20%); T6: W-NCM 94.20% (best 96.80%); T7: W-NCM 97.00% (best 97.80%); T8: W-NCM 98.20% (best 98.20%)
2025-12-11 15:16:01,403 [trainer.py] => Average forgetting (W-NCM): 6.51% | Max forgetting (W-NCM): 19.40%
2025-12-11 15:16:02,021 [trainer.py] => All params: 114881051
2025-12-11 15:16:02,025 [trainer.py] => Trainable params: 188165
2025-12-11 15:16:02,025 [inflora.py] => Learning on 40-45
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_v.8.weight', 'image_encoder.blocks.10.attn.lora_B_v.8.weight', 'classifier_pool.8.weight', 'image_encoder.blocks.3.attn.lora_B_k.8.weight', 'image_encoder.blocks.1.attn.lora_B_v.8.weight', 'image_encoder.blocks.6.attn.lora_B_v.8.weight', 'image_encoder.blocks.7.attn.lora_B_k.8.weight', 'image_encoder.blocks.1.attn.lora_B_k.8.weight', 'image_encoder.blocks.9.attn.lora_B_k.8.weight', 'image_encoder.blocks.3.attn.lora_B_v.8.weight', 'classifier_pool.8.bias', 'image_encoder.blocks.9.attn.lora_B_v.8.weight', 'image_encoder.blocks.6.attn.lora_B_k.8.weight', 'image_encoder.blocks.7.attn.lora_B_v.8.weight', 'image_encoder.blocks.4.attn.lora_B_v.8.weight', 'image_encoder.blocks.8.attn.lora_B_k.8.weight', 'image_encoder.blocks.2.attn.lora_B_v.8.weight', 'image_encoder.blocks.5.attn.lora_B_k.8.weight', 'image_encoder.blocks.0.attn.lora_B_k.8.weight', 'image_encoder.blocks.5.attn.lora_B_v.8.weight', 'image_encoder.blocks.11.attn.lora_B_v.8.weight', 'image_encoder.blocks.8.attn.lora_B_v.8.weight', 'image_encoder.blocks.11.attn.lora_B_k.8.weight', 'image_encoder.blocks.4.attn.lora_B_k.8.weight', 'image_encoder.blocks.10.attn.lora_B_k.8.weight', 'image_encoder.blocks.2.attn.lora_B_k.8.weight'}
2025-12-11 15:20:58,370 [inflora.py] => Task 8, Epoch 20/20 => Loss 0.093, Train_accy 96.72
Threshold:  0.97
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 23/768 type remove
Layer 4 : 26/768 type remove
Layer 5 : 35/768 type remove
Layer 6 : 44/768 type remove
Layer 7 : 47/768 type remove
Layer 8 : 68/768 type remove
Layer 9 : 106/768 type remove
Layer 10 : 104/768 type remove
Layer 11 : 55/768 type remove
Layer 12 : 57/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:21:17,227 [trainer.py] => Time:315.20212388038635
4500 4500
4500 4500
2025-12-11 15:21:29,653 [trainer.py] => Time:12.425770282745361
2025-12-11 15:21:29,654 [inflora.py] => Exemplar size: 0
2025-12-11 15:21:29,654 [trainer.py] => CNN: {'total': np.float64(90.13), '00-04': np.float64(93.0), '05-09': np.float64(91.2), '10-14': np.float64(84.2), '15-19': np.float64(91.4), '20-24': np.float64(88.4), '25-29': np.float64(88.2), '30-34': np.float64(93.8), '35-39': np.float64(88.6), '40-44': np.float64(92.4), 'old': np.float64(89.85), 'new': np.float64(92.4)}
2025-12-11 15:21:29,654 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13)]
2025-12-11 15:21:29,654 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29)]
2025-12-11 15:21:29,654 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666]
2025-12-11 15:21:49,244 [trainer.py] => W-NCM: {'00-04': 87.6, '05-09': 96.6, '10-14': 83.0, '15-19': 93.4, '20-24': 93.60000000000001, '25-29': 92.2, '30-34': 96.2, '35-39': 97.6, '40-44': 97.2}
2025-12-11 15:21:49,244 [trainer.py] => Ave Acc (W-NCM): 93.04%
2025-12-11 15:21:49,244 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 87.60% (best 99.80%); T2: W-NCM 96.60% (best 99.60%); T3: W-NCM 83.00% (best 99.40%); T4: W-NCM 93.40% (best 98.20%); T5: W-NCM 93.60% (best 99.20%); T6: W-NCM 92.20% (best 96.80%); T7: W-NCM 96.20% (best 97.80%); T8: W-NCM 97.60% (best 98.20%); T9: W-NCM 97.20% (best 97.20%)
2025-12-11 15:21:49,244 [trainer.py] => Average forgetting (W-NCM): 6.10% | Max forgetting (W-NCM): 16.40%
2025-12-11 15:21:49,869 [trainer.py] => All params: 114881051
2025-12-11 15:21:49,872 [trainer.py] => Trainable params: 188165
2025-12-11 15:21:49,872 [inflora.py] => Learning on 45-50
Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_k.9.weight', 'image_encoder.blocks.9.attn.lora_B_k.9.weight', 'image_encoder.blocks.6.attn.lora_B_v.9.weight', 'image_encoder.blocks.2.attn.lora_B_k.9.weight', 'image_encoder.blocks.0.attn.lora_B_k.9.weight', 'image_encoder.blocks.10.attn.lora_B_k.9.weight', 'image_encoder.blocks.1.attn.lora_B_v.9.weight', 'image_encoder.blocks.7.attn.lora_B_v.9.weight', 'image_encoder.blocks.8.attn.lora_B_k.9.weight', 'image_encoder.blocks.9.attn.lora_B_v.9.weight', 'image_encoder.blocks.8.attn.lora_B_v.9.weight', 'image_encoder.blocks.2.attn.lora_B_v.9.weight', 'classifier_pool.9.bias', 'image_encoder.blocks.6.attn.lora_B_k.9.weight', 'image_encoder.blocks.0.attn.lora_B_v.9.weight', 'image_encoder.blocks.10.attn.lora_B_v.9.weight', 'image_encoder.blocks.7.attn.lora_B_k.9.weight', 'image_encoder.blocks.4.attn.lora_B_v.9.weight', 'image_encoder.blocks.4.attn.lora_B_k.9.weight', 'image_encoder.blocks.11.attn.lora_B_k.9.weight', 'image_encoder.blocks.5.attn.lora_B_v.9.weight', 'image_encoder.blocks.1.attn.lora_B_k.9.weight', 'image_encoder.blocks.3.attn.lora_B_v.9.weight', 'image_encoder.blocks.11.attn.lora_B_v.9.weight', 'image_encoder.blocks.5.attn.lora_B_k.9.weight', 'classifier_pool.9.weight'}
2025-12-11 15:26:46,620 [inflora.py] => Task 9, Epoch 20/20 => Loss 0.061, Train_accy 98.00
Threshold:  0.9724999999999999
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 24/768 type remove
Layer 4 : 28/768 type remove
Layer 5 : 38/768 type remove
Layer 6 : 48/768 type remove
Layer 7 : 53/768 type remove
Layer 8 : 74/768 type remove
Layer 9 : 113/768 type remove
Layer 10 : 112/768 type remove
Layer 11 : 61/768 type remove
Layer 12 : 62/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:27:05,059 [trainer.py] => Time:315.18732213974
5000 5000
5000 5000
2025-12-11 15:27:18,654 [trainer.py] => Time:13.594145059585571
2025-12-11 15:27:18,654 [inflora.py] => Exemplar size: 0
2025-12-11 15:27:18,654 [trainer.py] => CNN: {'total': np.float64(89.58), '00-04': np.float64(91.8), '05-09': np.float64(91.2), '10-14': np.float64(80.0), '15-19': np.float64(90.6), '20-24': np.float64(88.8), '25-29': np.float64(86.2), '30-34': np.float64(92.2), '35-39': np.float64(90.8), '40-44': np.float64(93.2), '45-49': np.float64(91.0), 'old': np.float64(89.42), 'new': np.float64(91.0)}
2025-12-11 15:27:18,654 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58)]
2025-12-11 15:27:18,654 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32)]
2025-12-11 15:27:18,654 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968]
2025-12-11 15:27:39,229 [trainer.py] => W-NCM: {'00-04': 88.4, '05-09': 95.19999999999999, '10-14': 78.60000000000001, '15-19': 94.0, '20-24': 90.8, '25-29': 90.4, '30-34': 90.60000000000001, '35-39': 94.8, '40-44': 96.6, '45-49': 98.4}
2025-12-11 15:27:39,229 [trainer.py] => Ave Acc (W-NCM): 91.78%
2025-12-11 15:27:39,229 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 88.40% (best 99.80%); T2: W-NCM 95.20% (best 99.60%); T3: W-NCM 78.60% (best 99.40%); T4: W-NCM 94.00% (best 98.20%); T5: W-NCM 90.80% (best 99.20%); T6: W-NCM 90.40% (best 96.80%); T7: W-NCM 90.60% (best 97.80%); T8: W-NCM 94.80% (best 98.20%); T9: W-NCM 96.60% (best 97.20%); T10: W-NCM 98.40% (best 98.40%)
2025-12-11 15:27:39,229 [trainer.py] => Average forgetting (W-NCM): 7.42% | Max forgetting (W-NCM): 20.80%
2025-12-11 15:27:39,842 [trainer.py] => All params: 114881051
2025-12-11 15:27:39,845 [trainer.py] => Trainable params: 188165
2025-12-11 15:27:39,845 [inflora.py] => Learning on 50-55
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.10.weight', 'image_encoder.blocks.8.attn.lora_B_k.10.weight', 'image_encoder.blocks.3.attn.lora_B_k.10.weight', 'classifier_pool.10.weight', 'image_encoder.blocks.9.attn.lora_B_k.10.weight', 'classifier_pool.10.bias', 'image_encoder.blocks.4.attn.lora_B_v.10.weight', 'image_encoder.blocks.6.attn.lora_B_k.10.weight', 'image_encoder.blocks.1.attn.lora_B_k.10.weight', 'image_encoder.blocks.0.attn.lora_B_k.10.weight', 'image_encoder.blocks.2.attn.lora_B_k.10.weight', 'image_encoder.blocks.9.attn.lora_B_v.10.weight', 'image_encoder.blocks.7.attn.lora_B_v.10.weight', 'image_encoder.blocks.2.attn.lora_B_v.10.weight', 'image_encoder.blocks.11.attn.lora_B_k.10.weight', 'image_encoder.blocks.8.attn.lora_B_v.10.weight', 'image_encoder.blocks.3.attn.lora_B_v.10.weight', 'image_encoder.blocks.5.attn.lora_B_v.10.weight', 'image_encoder.blocks.1.attn.lora_B_v.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.10.weight', 'image_encoder.blocks.7.attn.lora_B_k.10.weight', 'image_encoder.blocks.5.attn.lora_B_k.10.weight', 'image_encoder.blocks.10.attn.lora_B_v.10.weight', 'image_encoder.blocks.10.attn.lora_B_k.10.weight', 'image_encoder.blocks.11.attn.lora_B_v.10.weight', 'image_encoder.blocks.4.attn.lora_B_k.10.weight'}
2025-12-11 15:32:36,436 [inflora.py] => Task 10, Epoch 20/20 => Loss 0.035, Train_accy 98.84
Threshold:  0.975
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 17/768 type remove
Layer 3 : 25/768 type remove
Layer 4 : 31/768 type remove
Layer 5 : 41/768 type remove
Layer 6 : 53/768 type remove
Layer 7 : 60/768 type remove
Layer 8 : 87/768 type remove
Layer 9 : 125/768 type remove
Layer 10 : 122/768 type remove
Layer 11 : 69/768 type remove
Layer 12 : 68/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:32:55,130 [trainer.py] => Time:315.2842252254486
5500 5500
5500 5500
2025-12-11 15:33:10,124 [trainer.py] => Time:14.993862867355347
2025-12-11 15:33:10,124 [inflora.py] => Exemplar size: 0
2025-12-11 15:33:10,124 [trainer.py] => CNN: {'total': np.float64(87.96), '00-04': np.float64(89.2), '05-09': np.float64(88.4), '10-14': np.float64(78.2), '15-19': np.float64(89.6), '20-24': np.float64(87.8), '25-29': np.float64(87.0), '30-34': np.float64(91.4), '35-39': np.float64(88.2), '40-44': np.float64(93.0), '45-49': np.float64(87.4), '50-54': np.float64(87.4), 'old': np.float64(88.02), 'new': np.float64(87.4)}
2025-12-11 15:33:10,124 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96)]
2025-12-11 15:33:10,124 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49)]
2025-12-11 15:33:10,124 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545]
2025-12-11 15:33:31,970 [trainer.py] => W-NCM: {'00-04': 87.2, '05-09': 94.39999999999999, '10-14': 77.2, '15-19': 93.2, '20-24': 92.0, '25-29': 91.60000000000001, '30-34': 89.4, '35-39': 92.2, '40-44': 95.6, '45-49': 88.8, '50-54': 98.4}
2025-12-11 15:33:31,971 [trainer.py] => Ave Acc (W-NCM): 90.91%
2025-12-11 15:33:31,971 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 87.20% (best 99.80%); T2: W-NCM 94.40% (best 99.60%); T3: W-NCM 77.20% (best 99.40%); T4: W-NCM 93.20% (best 98.20%); T5: W-NCM 92.00% (best 99.20%); T6: W-NCM 91.60% (best 96.80%); T7: W-NCM 89.40% (best 97.80%); T8: W-NCM 92.20% (best 98.20%); T9: W-NCM 95.60% (best 97.20%); T10: W-NCM 88.80% (best 98.40%); T11: W-NCM 98.40% (best 98.40%)
2025-12-11 15:33:31,971 [trainer.py] => Average forgetting (W-NCM): 8.30% | Max forgetting (W-NCM): 22.20%
2025-12-11 15:33:32,583 [trainer.py] => All params: 114881051
2025-12-11 15:33:32,586 [trainer.py] => Trainable params: 188165
2025-12-11 15:33:32,586 [inflora.py] => Learning on 55-60
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_v.11.weight', 'classifier_pool.11.weight', 'image_encoder.blocks.3.attn.lora_B_v.11.weight', 'image_encoder.blocks.11.attn.lora_B_v.11.weight', 'image_encoder.blocks.3.attn.lora_B_k.11.weight', 'image_encoder.blocks.7.attn.lora_B_v.11.weight', 'image_encoder.blocks.8.attn.lora_B_v.11.weight', 'image_encoder.blocks.5.attn.lora_B_v.11.weight', 'image_encoder.blocks.4.attn.lora_B_v.11.weight', 'image_encoder.blocks.7.attn.lora_B_k.11.weight', 'image_encoder.blocks.10.attn.lora_B_k.11.weight', 'image_encoder.blocks.0.attn.lora_B_v.11.weight', 'image_encoder.blocks.11.attn.lora_B_k.11.weight', 'image_encoder.blocks.5.attn.lora_B_k.11.weight', 'image_encoder.blocks.9.attn.lora_B_v.11.weight', 'image_encoder.blocks.8.attn.lora_B_k.11.weight', 'image_encoder.blocks.9.attn.lora_B_k.11.weight', 'image_encoder.blocks.10.attn.lora_B_v.11.weight', 'image_encoder.blocks.1.attn.lora_B_v.11.weight', 'image_encoder.blocks.1.attn.lora_B_k.11.weight', 'classifier_pool.11.bias', 'image_encoder.blocks.0.attn.lora_B_k.11.weight', 'image_encoder.blocks.6.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_k.11.weight', 'image_encoder.blocks.4.attn.lora_B_k.11.weight', 'image_encoder.blocks.2.attn.lora_B_k.11.weight'}
2025-12-11 15:38:29,699 [inflora.py] => Task 11, Epoch 20/20 => Loss 0.078, Train_accy 97.24
Threshold:  0.9775
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 18/768 type remove
Layer 3 : 27/768 type remove
Layer 4 : 34/768 type remove
Layer 5 : 45/768 type remove
Layer 6 : 59/768 type remove
Layer 7 : 67/768 type remove
Layer 8 : 97/768 type remove
Layer 9 : 137/768 type remove
Layer 10 : 132/768 type remove
Layer 11 : 75/768 type remove
Layer 12 : 74/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:38:48,577 [trainer.py] => Time:315.99128007888794
6000 6000
6000 6000
2025-12-11 15:39:04,849 [trainer.py] => Time:16.271114587783813
2025-12-11 15:39:04,849 [inflora.py] => Exemplar size: 0
2025-12-11 15:39:04,849 [trainer.py] => CNN: {'total': np.float64(86.18), '00-04': np.float64(90.2), '05-09': np.float64(89.6), '10-14': np.float64(79.2), '15-19': np.float64(89.0), '20-24': np.float64(86.8), '25-29': np.float64(84.2), '30-34': np.float64(90.6), '35-39': np.float64(86.4), '40-44': np.float64(91.8), '45-49': np.float64(85.2), '50-54': np.float64(88.4), '55-59': np.float64(72.8), 'old': np.float64(87.4), 'new': np.float64(72.8)}
2025-12-11 15:39:04,849 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96), np.float64(86.18)]
2025-12-11 15:39:04,849 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49), np.float64(99.42)]
2025-12-11 15:39:04,849 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545, 0.8625]
2025-12-11 15:39:28,140 [trainer.py] => W-NCM: {'00-04': 81.0, '05-09': 95.8, '10-14': 78.60000000000001, '15-19': 92.60000000000001, '20-24': 90.8, '25-29': 89.8, '30-34': 85.2, '35-39': 91.60000000000001, '40-44': 96.0, '45-49': 88.4, '50-54': 93.4, '55-59': 96.0}
2025-12-11 15:39:28,141 [trainer.py] => Ave Acc (W-NCM): 89.93%
2025-12-11 15:39:28,141 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 81.00% (best 99.80%); T2: W-NCM 95.80% (best 99.60%); T3: W-NCM 78.60% (best 99.40%); T4: W-NCM 92.60% (best 98.20%); T5: W-NCM 90.80% (best 99.20%); T6: W-NCM 89.80% (best 96.80%); T7: W-NCM 85.20% (best 97.80%); T8: W-NCM 91.60% (best 98.20%); T9: W-NCM 96.00% (best 97.20%); T10: W-NCM 88.40% (best 98.40%); T11: W-NCM 93.40% (best 98.40%); T12: W-NCM 96.00% (best 96.00%)
2025-12-11 15:39:28,141 [trainer.py] => Average forgetting (W-NCM): 9.07% | Max forgetting (W-NCM): 20.80%
2025-12-11 15:39:28,762 [trainer.py] => All params: 114881051
2025-12-11 15:39:28,765 [trainer.py] => Trainable params: 188165
2025-12-11 15:39:28,765 [inflora.py] => Learning on 60-65
Parameters to be updated: {'image_encoder.blocks.8.attn.lora_B_k.12.weight', 'image_encoder.blocks.1.attn.lora_B_k.12.weight', 'image_encoder.blocks.5.attn.lora_B_v.12.weight', 'image_encoder.blocks.3.attn.lora_B_v.12.weight', 'image_encoder.blocks.11.attn.lora_B_k.12.weight', 'image_encoder.blocks.2.attn.lora_B_v.12.weight', 'classifier_pool.12.weight', 'classifier_pool.12.bias', 'image_encoder.blocks.4.attn.lora_B_v.12.weight', 'image_encoder.blocks.7.attn.lora_B_v.12.weight', 'image_encoder.blocks.10.attn.lora_B_k.12.weight', 'image_encoder.blocks.0.attn.lora_B_k.12.weight', 'image_encoder.blocks.3.attn.lora_B_k.12.weight', 'image_encoder.blocks.11.attn.lora_B_v.12.weight', 'image_encoder.blocks.0.attn.lora_B_v.12.weight', 'image_encoder.blocks.6.attn.lora_B_v.12.weight', 'image_encoder.blocks.9.attn.lora_B_k.12.weight', 'image_encoder.blocks.9.attn.lora_B_v.12.weight', 'image_encoder.blocks.6.attn.lora_B_k.12.weight', 'image_encoder.blocks.2.attn.lora_B_k.12.weight', 'image_encoder.blocks.7.attn.lora_B_k.12.weight', 'image_encoder.blocks.4.attn.lora_B_k.12.weight', 'image_encoder.blocks.8.attn.lora_B_v.12.weight', 'image_encoder.blocks.10.attn.lora_B_v.12.weight', 'image_encoder.blocks.5.attn.lora_B_k.12.weight', 'image_encoder.blocks.1.attn.lora_B_v.12.weight'}
2025-12-11 15:44:25,977 [inflora.py] => Task 12, Epoch 20/20 => Loss 0.063, Train_accy 97.64
Threshold:  0.98
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 19/768 type remove
Layer 3 : 28/768 type remove
Layer 4 : 38/768 type remove
Layer 5 : 50/768 type remove
Layer 6 : 66/768 type remove
Layer 7 : 79/768 type remove
Layer 8 : 113/768 type remove
Layer 9 : 159/768 type remove
Layer 10 : 154/768 type remove
Layer 11 : 90/768 type remove
Layer 12 : 92/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:44:44,631 [trainer.py] => Time:315.86544847488403
6500 6500
6500 6500
2025-12-11 15:45:02,169 [trainer.py] => Time:17.538123846054077
2025-12-11 15:45:02,169 [inflora.py] => Exemplar size: 0
2025-12-11 15:45:02,170 [trainer.py] => CNN: {'total': np.float64(85.97), '00-04': np.float64(90.6), '05-09': np.float64(91.6), '10-14': np.float64(76.8), '15-19': np.float64(89.2), '20-24': np.float64(82.2), '25-29': np.float64(87.4), '30-34': np.float64(91.0), '35-39': np.float64(90.2), '40-44': np.float64(91.4), '45-49': np.float64(83.4), '50-54': np.float64(88.0), '55-59': np.float64(70.6), '60-64': np.float64(85.2), 'old': np.float64(86.03), 'new': np.float64(85.2)}
2025-12-11 15:45:02,170 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96), np.float64(86.18), np.float64(85.97)]
2025-12-11 15:45:02,170 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49), np.float64(99.42), np.float64(99.28)]
2025-12-11 15:45:02,170 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545, 0.8625, 0.8606153846153846]
2025-12-11 15:45:26,772 [trainer.py] => W-NCM: {'00-04': 83.8, '05-09': 95.39999999999999, '10-14': 73.6, '15-19': 93.2, '20-24': 86.0, '25-29': 90.8, '30-34': 87.6, '35-39': 94.0, '40-44': 94.39999999999999, '45-49': 86.8, '50-54': 91.60000000000001, '55-59': 94.19999999999999, '60-64': 95.8}
2025-12-11 15:45:26,772 [trainer.py] => Ave Acc (W-NCM): 89.78%
2025-12-11 15:45:26,772 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 83.80% (best 99.80%); T2: W-NCM 95.40% (best 99.60%); T3: W-NCM 73.60% (best 99.40%); T4: W-NCM 93.20% (best 98.20%); T5: W-NCM 86.00% (best 99.20%); T6: W-NCM 90.80% (best 96.80%); T7: W-NCM 87.60% (best 97.80%); T8: W-NCM 94.00% (best 98.20%); T9: W-NCM 94.40% (best 97.20%); T10: W-NCM 86.80% (best 98.40%); T11: W-NCM 91.60% (best 98.40%); T12: W-NCM 94.20% (best 96.00%); T13: W-NCM 95.80% (best 95.80%)
2025-12-11 15:45:26,772 [trainer.py] => Average forgetting (W-NCM): 8.97% | Max forgetting (W-NCM): 25.80%
2025-12-11 15:45:27,396 [trainer.py] => All params: 114881051
2025-12-11 15:45:27,399 [trainer.py] => Trainable params: 188165
2025-12-11 15:45:27,400 [inflora.py] => Learning on 65-70
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_k.13.weight', 'image_encoder.blocks.0.attn.lora_B_k.13.weight', 'image_encoder.blocks.8.attn.lora_B_v.13.weight', 'image_encoder.blocks.7.attn.lora_B_v.13.weight', 'image_encoder.blocks.6.attn.lora_B_k.13.weight', 'image_encoder.blocks.1.attn.lora_B_k.13.weight', 'image_encoder.blocks.8.attn.lora_B_k.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.13.weight', 'image_encoder.blocks.0.attn.lora_B_v.13.weight', 'image_encoder.blocks.9.attn.lora_B_v.13.weight', 'image_encoder.blocks.7.attn.lora_B_k.13.weight', 'image_encoder.blocks.9.attn.lora_B_k.13.weight', 'image_encoder.blocks.3.attn.lora_B_k.13.weight', 'classifier_pool.13.weight', 'image_encoder.blocks.4.attn.lora_B_k.13.weight', 'image_encoder.blocks.1.attn.lora_B_v.13.weight', 'image_encoder.blocks.4.attn.lora_B_v.13.weight', 'image_encoder.blocks.10.attn.lora_B_v.13.weight', 'image_encoder.blocks.5.attn.lora_B_k.13.weight', 'image_encoder.blocks.6.attn.lora_B_v.13.weight', 'image_encoder.blocks.10.attn.lora_B_k.13.weight', 'image_encoder.blocks.5.attn.lora_B_v.13.weight', 'classifier_pool.13.bias', 'image_encoder.blocks.3.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_v.13.weight', 'image_encoder.blocks.2.attn.lora_B_v.13.weight'}
2025-12-11 15:50:24,958 [inflora.py] => Task 13, Epoch 20/20 => Loss 0.083, Train_accy 96.68
Threshold:  0.9824999999999999
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 20/768 type remove
Layer 3 : 30/768 type remove
Layer 4 : 41/768 type remove
Layer 5 : 54/768 type remove
Layer 6 : 72/768 type remove
Layer 7 : 88/768 type remove
Layer 8 : 127/768 type remove
Layer 9 : 179/768 type remove
Layer 10 : 172/768 type remove
Layer 11 : 99/768 type remove
Layer 12 : 98/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:50:44,095 [trainer.py] => Time:316.6959080696106
7000 7000
7000 7000
2025-12-11 15:51:02,981 [trainer.py] => Time:18.884947061538696
2025-12-11 15:51:02,981 [inflora.py] => Exemplar size: 0
2025-12-11 15:51:02,981 [trainer.py] => CNN: {'total': np.float64(85.07), '00-04': np.float64(89.6), '05-09': np.float64(89.2), '10-14': np.float64(74.8), '15-19': np.float64(88.8), '20-24': np.float64(81.0), '25-29': np.float64(85.4), '30-34': np.float64(89.4), '35-39': np.float64(88.6), '40-44': np.float64(91.6), '45-49': np.float64(81.2), '50-54': np.float64(86.8), '55-59': np.float64(70.4), '60-64': np.float64(83.8), '65-69': np.float64(90.4), 'old': np.float64(84.66), 'new': np.float64(90.4)}
2025-12-11 15:51:02,981 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96), np.float64(86.18), np.float64(85.97), np.float64(85.07)]
2025-12-11 15:51:02,981 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49), np.float64(99.42), np.float64(99.28), np.float64(99.29)]
2025-12-11 15:51:02,981 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545, 0.8625, 0.8606153846153846, 0.8511428571428571]
2025-12-11 15:51:28,755 [trainer.py] => W-NCM: {'00-04': 84.0, '05-09': 96.0, '10-14': 74.6, '15-19': 92.4, '20-24': 86.4, '25-29': 89.8, '30-34': 84.39999999999999, '35-39': 93.60000000000001, '40-44': 95.19999999999999, '45-49': 86.0, '50-54': 92.0, '55-59': 95.0, '60-64': 93.0, '65-69': 98.4}
2025-12-11 15:51:28,755 [trainer.py] => Ave Acc (W-NCM): 90.06%
2025-12-11 15:51:28,755 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 84.00% (best 99.80%); T2: W-NCM 96.00% (best 99.60%); T3: W-NCM 74.60% (best 99.40%); T4: W-NCM 92.40% (best 98.20%); T5: W-NCM 86.40% (best 99.20%); T6: W-NCM 89.80% (best 96.80%); T7: W-NCM 84.40% (best 97.80%); T8: W-NCM 93.60% (best 98.20%); T9: W-NCM 95.20% (best 97.20%); T10: W-NCM 86.00% (best 98.40%); T11: W-NCM 92.00% (best 98.40%); T12: W-NCM 95.00% (best 96.00%); T13: W-NCM 93.00% (best 95.80%); T14: W-NCM 98.40% (best 98.40%)
2025-12-11 15:51:28,755 [trainer.py] => Average forgetting (W-NCM): 8.65% | Max forgetting (W-NCM): 24.80%
2025-12-11 15:51:29,375 [trainer.py] => All params: 114881051
2025-12-11 15:51:29,379 [trainer.py] => Trainable params: 188165
2025-12-11 15:51:29,379 [inflora.py] => Learning on 70-75
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.14.weight', 'image_encoder.blocks.1.attn.lora_B_v.14.weight', 'image_encoder.blocks.0.attn.lora_B_k.14.weight', 'image_encoder.blocks.3.attn.lora_B_v.14.weight', 'image_encoder.blocks.9.attn.lora_B_v.14.weight', 'classifier_pool.14.weight', 'image_encoder.blocks.8.attn.lora_B_k.14.weight', 'image_encoder.blocks.10.attn.lora_B_k.14.weight', 'image_encoder.blocks.2.attn.lora_B_v.14.weight', 'image_encoder.blocks.8.attn.lora_B_v.14.weight', 'image_encoder.blocks.0.attn.lora_B_v.14.weight', 'image_encoder.blocks.10.attn.lora_B_v.14.weight', 'image_encoder.blocks.7.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_k.14.weight', 'image_encoder.blocks.2.attn.lora_B_k.14.weight', 'image_encoder.blocks.1.attn.lora_B_k.14.weight', 'image_encoder.blocks.6.attn.lora_B_v.14.weight', 'image_encoder.blocks.6.attn.lora_B_k.14.weight', 'image_encoder.blocks.5.attn.lora_B_k.14.weight', 'image_encoder.blocks.11.attn.lora_B_k.14.weight', 'image_encoder.blocks.7.attn.lora_B_k.14.weight', 'classifier_pool.14.bias', 'image_encoder.blocks.11.attn.lora_B_v.14.weight', 'image_encoder.blocks.9.attn.lora_B_k.14.weight', 'image_encoder.blocks.5.attn.lora_B_v.14.weight', 'image_encoder.blocks.3.attn.lora_B_k.14.weight'}
2025-12-11 15:56:26,466 [inflora.py] => Task 14, Epoch 20/20 => Loss 0.082, Train_accy 97.04
Threshold:  0.985
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 22/768 type remove
Layer 3 : 32/768 type remove
Layer 4 : 44/768 type remove
Layer 5 : 59/768 type remove
Layer 6 : 81/768 type remove
Layer 7 : 97/768 type remove
Layer 8 : 138/768 type remove
Layer 9 : 194/768 type remove
Layer 10 : 188/768 type remove
Layer 11 : 111/768 type remove
Layer 12 : 110/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:56:45,147 [trainer.py] => Time:315.7685444355011
7500 7500
7500 7500
2025-12-11 15:57:05,371 [trainer.py] => Time:20.222950220108032
2025-12-11 15:57:05,371 [inflora.py] => Exemplar size: 0
2025-12-11 15:57:05,371 [trainer.py] => CNN: {'total': np.float64(83.56), '00-04': np.float64(90.0), '05-09': np.float64(90.6), '10-14': np.float64(76.2), '15-19': np.float64(89.4), '20-24': np.float64(76.6), '25-29': np.float64(84.8), '30-34': np.float64(89.6), '35-39': np.float64(88.2), '40-44': np.float64(92.6), '45-49': np.float64(81.4), '50-54': np.float64(86.6), '55-59': np.float64(69.8), '60-64': np.float64(80.2), '65-69': np.float64(89.6), '70-74': np.float64(67.8), 'old': np.float64(84.69), 'new': np.float64(67.8)}
2025-12-11 15:57:05,371 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96), np.float64(86.18), np.float64(85.97), np.float64(85.07), np.float64(83.56)]
2025-12-11 15:57:05,371 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49), np.float64(99.42), np.float64(99.28), np.float64(99.29), np.float64(99.19)]
2025-12-11 15:57:05,371 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545, 0.8625, 0.8606153846153846, 0.8511428571428571, 0.836]
2025-12-11 15:57:32,588 [trainer.py] => W-NCM: {'00-04': 83.0, '05-09': 95.39999999999999, '10-14': 76.2, '15-19': 92.2, '20-24': 82.8, '25-29': 90.2, '30-34': 84.0, '35-39': 95.0, '40-44': 95.19999999999999, '45-49': 84.39999999999999, '50-54': 90.2, '55-59': 90.8, '60-64': 87.2, '65-69': 96.2, '70-74': 94.19999999999999}
2025-12-11 15:57:32,588 [trainer.py] => Ave Acc (W-NCM): 89.13%
2025-12-11 15:57:32,588 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 83.00% (best 99.80%); T2: W-NCM 95.40% (best 99.60%); T3: W-NCM 76.20% (best 99.40%); T4: W-NCM 92.20% (best 98.20%); T5: W-NCM 82.80% (best 99.20%); T6: W-NCM 90.20% (best 96.80%); T7: W-NCM 84.00% (best 97.80%); T8: W-NCM 95.00% (best 98.20%); T9: W-NCM 95.20% (best 97.20%); T10: W-NCM 84.40% (best 98.40%); T11: W-NCM 90.20% (best 98.40%); T12: W-NCM 90.80% (best 96.00%); T13: W-NCM 87.20% (best 95.80%); T14: W-NCM 96.20% (best 98.40%); T15: W-NCM 94.20% (best 94.20%)
2025-12-11 15:57:32,588 [trainer.py] => Average forgetting (W-NCM): 9.31% | Max forgetting (W-NCM): 23.20%
2025-12-11 15:57:33,297 [trainer.py] => All params: 114881051
2025-12-11 15:57:33,301 [trainer.py] => Trainable params: 188165
2025-12-11 15:57:33,301 [inflora.py] => Learning on 75-80
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.15.weight', 'image_encoder.blocks.4.attn.lora_B_k.15.weight', 'image_encoder.blocks.8.attn.lora_B_v.15.weight', 'image_encoder.blocks.2.attn.lora_B_k.15.weight', 'image_encoder.blocks.11.attn.lora_B_v.15.weight', 'image_encoder.blocks.0.attn.lora_B_v.15.weight', 'image_encoder.blocks.6.attn.lora_B_v.15.weight', 'image_encoder.blocks.8.attn.lora_B_k.15.weight', 'classifier_pool.15.bias', 'image_encoder.blocks.5.attn.lora_B_k.15.weight', 'image_encoder.blocks.3.attn.lora_B_k.15.weight', 'image_encoder.blocks.11.attn.lora_B_k.15.weight', 'image_encoder.blocks.2.attn.lora_B_v.15.weight', 'image_encoder.blocks.7.attn.lora_B_k.15.weight', 'image_encoder.blocks.10.attn.lora_B_v.15.weight', 'image_encoder.blocks.6.attn.lora_B_k.15.weight', 'image_encoder.blocks.9.attn.lora_B_k.15.weight', 'classifier_pool.15.weight', 'image_encoder.blocks.1.attn.lora_B_k.15.weight', 'image_encoder.blocks.10.attn.lora_B_k.15.weight', 'image_encoder.blocks.3.attn.lora_B_v.15.weight', 'image_encoder.blocks.5.attn.lora_B_v.15.weight', 'image_encoder.blocks.1.attn.lora_B_v.15.weight', 'image_encoder.blocks.7.attn.lora_B_v.15.weight', 'image_encoder.blocks.4.attn.lora_B_v.15.weight', 'image_encoder.blocks.9.attn.lora_B_v.15.weight'}
2025-12-11 16:02:30,951 [inflora.py] => Task 15, Epoch 20/20 => Loss 0.075, Train_accy 97.16
Threshold:  0.9875
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 24/768 type remove
Layer 3 : 37/768 type remove
Layer 4 : 52/768 type remove
Layer 5 : 70/768 type remove
Layer 6 : 97/768 type remove
Layer 7 : 116/768 type remove
Layer 8 : 172/768 type remove
Layer 9 : 242/768 type remove
Layer 10 : 242/768 type remove
Layer 11 : 132/768 type remove
Layer 12 : 116/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:02:49,791 [trainer.py] => Time:316.49047231674194
8000 8000
8000 8000
2025-12-11 16:03:11,244 [trainer.py] => Time:21.45198154449463
2025-12-11 16:03:11,244 [inflora.py] => Exemplar size: 0
2025-12-11 16:03:11,244 [trainer.py] => CNN: {'total': np.float64(83.99), '00-04': np.float64(88.4), '05-09': np.float64(93.4), '10-14': np.float64(76.8), '15-19': np.float64(90.0), '20-24': np.float64(78.4), '25-29': np.float64(83.6), '30-34': np.float64(89.0), '35-39': np.float64(85.8), '40-44': np.float64(91.8), '45-49': np.float64(81.2), '50-54': np.float64(83.8), '55-59': np.float64(69.0), '60-64': np.float64(79.2), '65-69': np.float64(89.4), '70-74': np.float64(66.0), '75-79': np.float64(98.0), 'old': np.float64(83.05), 'new': np.float64(98.0)}
2025-12-11 16:03:11,244 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96), np.float64(86.18), np.float64(85.97), np.float64(85.07), np.float64(83.56), np.float64(83.99)]
2025-12-11 16:03:11,244 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49), np.float64(99.42), np.float64(99.28), np.float64(99.29), np.float64(99.19), np.float64(99.18)]
2025-12-11 16:03:11,244 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545, 0.8625, 0.8606153846153846, 0.8511428571428571, 0.836, 0.840375]
2025-12-11 16:03:39,710 [trainer.py] => W-NCM: {'00-04': 84.6, '05-09': 95.6, '10-14': 78.8, '15-19': 91.4, '20-24': 84.8, '25-29': 89.0, '30-34': 83.8, '35-39': 93.8, '40-44': 95.0, '45-49': 84.6, '50-54': 89.60000000000001, '55-59': 90.4, '60-64': 87.2, '65-69': 94.6, '70-74': 93.60000000000001, '75-79': 99.4}
2025-12-11 16:03:39,710 [trainer.py] => Ave Acc (W-NCM): 89.76%
2025-12-11 16:03:39,710 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 84.60% (best 99.80%); T2: W-NCM 95.60% (best 99.60%); T3: W-NCM 78.80% (best 99.40%); T4: W-NCM 91.40% (best 98.20%); T5: W-NCM 84.80% (best 99.20%); T6: W-NCM 89.00% (best 96.80%); T7: W-NCM 83.80% (best 97.80%); T8: W-NCM 93.80% (best 98.20%); T9: W-NCM 95.00% (best 97.20%); T10: W-NCM 84.60% (best 98.40%); T11: W-NCM 89.60% (best 98.40%); T12: W-NCM 90.40% (best 96.00%); T13: W-NCM 87.20% (best 95.80%); T14: W-NCM 94.60% (best 98.40%); T15: W-NCM 93.60% (best 94.20%); T16: W-NCM 99.40% (best 99.40%)
2025-12-11 16:03:39,711 [trainer.py] => Average forgetting (W-NCM): 8.71% | Max forgetting (W-NCM): 20.60%
2025-12-11 16:03:40,339 [trainer.py] => All params: 114881051
2025-12-11 16:03:40,343 [trainer.py] => Trainable params: 188165
2025-12-11 16:03:40,343 [inflora.py] => Learning on 80-85
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.16.weight', 'image_encoder.blocks.6.attn.lora_B_k.16.weight', 'classifier_pool.16.bias', 'image_encoder.blocks.5.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_v.16.weight', 'image_encoder.blocks.9.attn.lora_B_k.16.weight', 'image_encoder.blocks.9.attn.lora_B_v.16.weight', 'image_encoder.blocks.2.attn.lora_B_k.16.weight', 'image_encoder.blocks.5.attn.lora_B_v.16.weight', 'image_encoder.blocks.10.attn.lora_B_k.16.weight', 'image_encoder.blocks.7.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_v.16.weight', 'image_encoder.blocks.0.attn.lora_B_v.16.weight', 'image_encoder.blocks.11.attn.lora_B_k.16.weight', 'image_encoder.blocks.7.attn.lora_B_v.16.weight', 'image_encoder.blocks.8.attn.lora_B_v.16.weight', 'image_encoder.blocks.1.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_k.16.weight', 'image_encoder.blocks.2.attn.lora_B_v.16.weight', 'image_encoder.blocks.1.attn.lora_B_v.16.weight', 'image_encoder.blocks.4.attn.lora_B_k.16.weight', 'image_encoder.blocks.4.attn.lora_B_v.16.weight', 'image_encoder.blocks.6.attn.lora_B_v.16.weight', 'image_encoder.blocks.8.attn.lora_B_k.16.weight', 'image_encoder.blocks.10.attn.lora_B_v.16.weight', 'classifier_pool.16.weight'}
2025-12-11 16:08:37,729 [inflora.py] => Task 16, Epoch 20/20 => Loss 0.051, Train_accy 98.32
Threshold:  0.99
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 25/768 type remove
Layer 3 : 43/768 type remove
Layer 4 : 58/768 type remove
Layer 5 : 81/768 type remove
Layer 6 : 117/768 type remove
Layer 7 : 137/768 type remove
Layer 8 : 201/768 type remove
Layer 9 : 275/768 type remove
Layer 10 : 284/768 type remove
Layer 11 : 181/768 type remove
Layer 12 : 145/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:08:56,629 [trainer.py] => Time:316.2862603664398
8500 8500
8500 8500
2025-12-11 16:09:19,536 [trainer.py] => Time:22.906195402145386
2025-12-11 16:09:19,536 [inflora.py] => Exemplar size: 0
2025-12-11 16:09:19,536 [trainer.py] => CNN: {'total': np.float64(83.24), '00-04': np.float64(88.6), '05-09': np.float64(93.0), '10-14': np.float64(74.8), '15-19': np.float64(90.0), '20-24': np.float64(78.0), '25-29': np.float64(83.8), '30-34': np.float64(88.8), '35-39': np.float64(83.6), '40-44': np.float64(91.0), '45-49': np.float64(82.2), '50-54': np.float64(85.0), '55-59': np.float64(66.4), '60-64': np.float64(77.0), '65-69': np.float64(90.0), '70-74': np.float64(66.4), '75-79': np.float64(97.0), '80-84': np.float64(79.4), 'old': np.float64(83.48), 'new': np.float64(79.4)}
2025-12-11 16:09:19,536 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96), np.float64(86.18), np.float64(85.97), np.float64(85.07), np.float64(83.56), np.float64(83.99), np.float64(83.24)]
2025-12-11 16:09:19,536 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49), np.float64(99.42), np.float64(99.28), np.float64(99.29), np.float64(99.19), np.float64(99.18), np.float64(99.27)]
2025-12-11 16:09:19,536 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545, 0.8625, 0.8606153846153846, 0.8511428571428571, 0.836, 0.840375, 0.8329411764705882]
2025-12-11 16:09:49,149 [trainer.py] => W-NCM: {'00-04': 85.2, '05-09': 95.39999999999999, '10-14': 76.0, '15-19': 90.8, '20-24': 85.6, '25-29': 89.2, '30-34': 86.2, '35-39': 91.8, '40-44': 94.19999999999999, '45-49': 84.8, '50-54': 88.8, '55-59': 89.60000000000001, '60-64': 86.0, '65-69': 94.39999999999999, '70-74': 92.4, '75-79': 98.6, '80-84': 96.6}
2025-12-11 16:09:49,149 [trainer.py] => Ave Acc (W-NCM): 89.74%
2025-12-11 16:09:49,149 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 85.20% (best 99.80%); T2: W-NCM 95.40% (best 99.60%); T3: W-NCM 76.00% (best 99.40%); T4: W-NCM 90.80% (best 98.20%); T5: W-NCM 85.60% (best 99.20%); T6: W-NCM 89.20% (best 96.80%); T7: W-NCM 86.20% (best 97.80%); T8: W-NCM 91.80% (best 98.20%); T9: W-NCM 94.20% (best 97.20%); T10: W-NCM 84.80% (best 98.40%); T11: W-NCM 88.80% (best 98.40%); T12: W-NCM 89.60% (best 96.00%); T13: W-NCM 86.00% (best 95.80%); T14: W-NCM 94.40% (best 98.40%); T15: W-NCM 92.40% (best 94.20%); T16: W-NCM 98.60% (best 99.40%); T17: W-NCM 96.60% (best 96.60%)
2025-12-11 16:09:49,149 [trainer.py] => Average forgetting (W-NCM): 8.61% | Max forgetting (W-NCM): 23.40%
2025-12-11 16:09:49,832 [trainer.py] => All params: 114881051
2025-12-11 16:09:49,835 [trainer.py] => Trainable params: 188165
2025-12-11 16:09:49,835 [inflora.py] => Learning on 85-90
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_k.17.weight', 'image_encoder.blocks.10.attn.lora_B_v.17.weight', 'image_encoder.blocks.1.attn.lora_B_v.17.weight', 'image_encoder.blocks.3.attn.lora_B_k.17.weight', 'image_encoder.blocks.2.attn.lora_B_k.17.weight', 'image_encoder.blocks.11.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_v.17.weight', 'image_encoder.blocks.11.attn.lora_B_v.17.weight', 'image_encoder.blocks.9.attn.lora_B_k.17.weight', 'image_encoder.blocks.6.attn.lora_B_v.17.weight', 'image_encoder.blocks.3.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_k.17.weight', 'image_encoder.blocks.0.attn.lora_B_v.17.weight', 'image_encoder.blocks.6.attn.lora_B_k.17.weight', 'classifier_pool.17.bias', 'image_encoder.blocks.9.attn.lora_B_v.17.weight', 'classifier_pool.17.weight', 'image_encoder.blocks.8.attn.lora_B_v.17.weight', 'image_encoder.blocks.0.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_k.17.weight', 'image_encoder.blocks.5.attn.lora_B_k.17.weight', 'image_encoder.blocks.8.attn.lora_B_k.17.weight', 'image_encoder.blocks.10.attn.lora_B_k.17.weight', 'image_encoder.blocks.2.attn.lora_B_v.17.weight', 'image_encoder.blocks.5.attn.lora_B_v.17.weight'}
2025-12-11 16:14:48,046 [inflora.py] => Task 17, Epoch 20/20 => Loss 0.083, Train_accy 97.12
Threshold:  0.9924999999999999
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 27/768 type remove
Layer 3 : 49/768 type remove
Layer 4 : 68/768 type remove
Layer 5 : 94/768 type remove
Layer 6 : 139/768 type remove
Layer 7 : 164/768 type remove
Layer 8 : 228/768 type remove
Layer 9 : 312/768 type remove
Layer 10 : 334/768 type remove
Layer 11 : 236/768 type remove
Layer 12 : 174/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:15:06,943 [trainer.py] => Time:317.10829305648804
9000 9000
9000 9000
2025-12-11 16:15:31,073 [trainer.py] => Time:24.12962245941162
2025-12-11 16:15:31,074 [inflora.py] => Exemplar size: 0
2025-12-11 16:15:31,074 [trainer.py] => CNN: {'total': np.float64(83.53), '00-04': np.float64(89.2), '05-09': np.float64(93.2), '10-14': np.float64(77.6), '15-19': np.float64(90.4), '20-24': np.float64(81.2), '25-29': np.float64(81.4), '30-34': np.float64(89.2), '35-39': np.float64(83.2), '40-44': np.float64(90.8), '45-49': np.float64(79.0), '50-54': np.float64(84.8), '55-59': np.float64(66.0), '60-64': np.float64(77.2), '65-69': np.float64(89.4), '70-74': np.float64(67.0), '75-79': np.float64(95.6), '80-84': np.float64(77.4), '85-89': np.float64(91.0), 'old': np.float64(83.09), 'new': np.float64(91.0)}
2025-12-11 16:15:31,074 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96), np.float64(86.18), np.float64(85.97), np.float64(85.07), np.float64(83.56), np.float64(83.99), np.float64(83.24), np.float64(83.53)]
2025-12-11 16:15:31,074 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49), np.float64(99.42), np.float64(99.28), np.float64(99.29), np.float64(99.19), np.float64(99.18), np.float64(99.27), np.float64(99.22)]
2025-12-11 16:15:31,074 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545, 0.8625, 0.8606153846153846, 0.8511428571428571, 0.836, 0.840375, 0.8329411764705882, 0.8362222222222222]
2025-12-11 16:16:01,970 [trainer.py] => W-NCM: {'00-04': 86.4, '05-09': 95.0, '10-14': 76.8, '15-19': 91.4, '20-24': 87.2, '25-29': 89.0, '30-34': 86.2, '35-39': 91.60000000000001, '40-44': 91.0, '45-49': 84.6, '50-54': 89.0, '55-59': 90.2, '60-64': 86.6, '65-69': 94.0, '70-74': 89.0, '75-79': 98.0, '80-84': 95.39999999999999, '85-89': 97.39999999999999}
2025-12-11 16:16:01,971 [trainer.py] => Ave Acc (W-NCM): 89.93%
2025-12-11 16:16:01,971 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 86.40% (best 99.80%); T2: W-NCM 95.00% (best 99.60%); T3: W-NCM 76.80% (best 99.40%); T4: W-NCM 91.40% (best 98.20%); T5: W-NCM 87.20% (best 99.20%); T6: W-NCM 89.00% (best 96.80%); T7: W-NCM 86.20% (best 97.80%); T8: W-NCM 91.60% (best 98.20%); T9: W-NCM 91.00% (best 97.20%); T10: W-NCM 84.60% (best 98.40%); T11: W-NCM 89.00% (best 98.40%); T12: W-NCM 90.20% (best 96.00%); T13: W-NCM 86.60% (best 95.80%); T14: W-NCM 94.00% (best 98.40%); T15: W-NCM 89.00% (best 94.20%); T16: W-NCM 98.00% (best 99.40%); T17: W-NCM 95.40% (best 96.60%); T18: W-NCM 97.40% (best 97.40%)
2025-12-11 16:16:01,971 [trainer.py] => Average forgetting (W-NCM): 8.35% | Max forgetting (W-NCM): 22.60%
2025-12-11 16:16:02,684 [trainer.py] => All params: 114881051
2025-12-11 16:16:02,688 [trainer.py] => Trainable params: 188165
2025-12-11 16:16:02,688 [inflora.py] => Learning on 90-95
Parameters to be updated: {'image_encoder.blocks.8.attn.lora_B_k.18.weight', 'image_encoder.blocks.4.attn.lora_B_v.18.weight', 'image_encoder.blocks.5.attn.lora_B_k.18.weight', 'image_encoder.blocks.9.attn.lora_B_v.18.weight', 'image_encoder.blocks.2.attn.lora_B_v.18.weight', 'image_encoder.blocks.1.attn.lora_B_v.18.weight', 'image_encoder.blocks.10.attn.lora_B_k.18.weight', 'image_encoder.blocks.11.attn.lora_B_v.18.weight', 'classifier_pool.18.weight', 'image_encoder.blocks.6.attn.lora_B_k.18.weight', 'image_encoder.blocks.5.attn.lora_B_v.18.weight', 'image_encoder.blocks.11.attn.lora_B_k.18.weight', 'classifier_pool.18.bias', 'image_encoder.blocks.1.attn.lora_B_k.18.weight', 'image_encoder.blocks.4.attn.lora_B_k.18.weight', 'image_encoder.blocks.8.attn.lora_B_v.18.weight', 'image_encoder.blocks.3.attn.lora_B_v.18.weight', 'image_encoder.blocks.6.attn.lora_B_v.18.weight', 'image_encoder.blocks.9.attn.lora_B_k.18.weight', 'image_encoder.blocks.0.attn.lora_B_k.18.weight', 'image_encoder.blocks.7.attn.lora_B_k.18.weight', 'image_encoder.blocks.2.attn.lora_B_k.18.weight', 'image_encoder.blocks.0.attn.lora_B_v.18.weight', 'image_encoder.blocks.3.attn.lora_B_k.18.weight', 'image_encoder.blocks.10.attn.lora_B_v.18.weight', 'image_encoder.blocks.7.attn.lora_B_v.18.weight'}
2025-12-11 16:21:00,213 [inflora.py] => Task 18, Epoch 20/20 => Loss 0.047, Train_accy 98.36
Threshold:  0.995
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 11/768 type remove
Layer 2 : 30/768 type remove
Layer 3 : 55/768 type remove
Layer 4 : 81/768 type remove
Layer 5 : 114/768 type remove
Layer 6 : 165/768 type remove
Layer 7 : 196/768 type remove
Layer 8 : 272/768 type remove
Layer 9 : 361/768 type remove
Layer 10 : 381/768 type retain
Layer 11 : 286/768 type remove
Layer 12 : 246/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:21:18,400 [trainer.py] => Time:315.7123727798462
9500 9500
9500 9500
2025-12-11 16:21:43,619 [trainer.py] => Time:25.21907067298889
2025-12-11 16:21:43,620 [inflora.py] => Exemplar size: 0
2025-12-11 16:21:43,620 [trainer.py] => CNN: {'total': np.float64(82.93), '00-04': np.float64(86.8), '05-09': np.float64(90.8), '10-14': np.float64(76.2), '15-19': np.float64(88.6), '20-24': np.float64(79.8), '25-29': np.float64(81.4), '30-34': np.float64(88.6), '35-39': np.float64(82.6), '40-44': np.float64(90.6), '45-49': np.float64(82.0), '50-54': np.float64(84.0), '55-59': np.float64(66.8), '60-64': np.float64(72.6), '65-69': np.float64(88.4), '70-74': np.float64(64.2), '75-79': np.float64(95.8), '80-84': np.float64(78.6), '85-89': np.float64(88.6), '90-94': np.float64(89.2), 'old': np.float64(82.58), 'new': np.float64(89.2)}
2025-12-11 16:21:43,620 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96), np.float64(86.18), np.float64(85.97), np.float64(85.07), np.float64(83.56), np.float64(83.99), np.float64(83.24), np.float64(83.53), np.float64(82.93)]
2025-12-11 16:21:43,620 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49), np.float64(99.42), np.float64(99.28), np.float64(99.29), np.float64(99.19), np.float64(99.18), np.float64(99.27), np.float64(99.22), np.float64(99.33)]
2025-12-11 16:21:43,620 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545, 0.8625, 0.8606153846153846, 0.8511428571428571, 0.836, 0.840375, 0.8329411764705882, 0.8362222222222222, 0.8302105263157895]
2025-12-11 16:22:15,640 [trainer.py] => W-NCM: {'00-04': 84.8, '05-09': 94.39999999999999, '10-14': 75.4, '15-19': 92.0, '20-24': 86.0, '25-29': 88.2, '30-34': 83.39999999999999, '35-39': 91.4, '40-44': 91.4, '45-49': 84.6, '50-54': 88.4, '55-59': 90.8, '60-64': 85.2, '65-69': 92.60000000000001, '70-74': 89.60000000000001, '75-79': 97.6, '80-84': 93.2, '85-89': 97.6, '90-94': 96.8}
2025-12-11 16:22:15,640 [trainer.py] => Ave Acc (W-NCM): 89.65%
2025-12-11 16:22:15,640 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 84.80% (best 99.80%); T2: W-NCM 94.40% (best 99.60%); T3: W-NCM 75.40% (best 99.40%); T4: W-NCM 92.00% (best 98.20%); T5: W-NCM 86.00% (best 99.20%); T6: W-NCM 88.20% (best 96.80%); T7: W-NCM 83.40% (best 97.80%); T8: W-NCM 91.40% (best 98.20%); T9: W-NCM 91.40% (best 97.20%); T10: W-NCM 84.60% (best 98.40%); T11: W-NCM 88.40% (best 98.40%); T12: W-NCM 90.80% (best 96.00%); T13: W-NCM 85.20% (best 95.80%); T14: W-NCM 92.60% (best 98.40%); T15: W-NCM 89.60% (best 94.20%); T16: W-NCM 97.60% (best 99.40%); T17: W-NCM 93.20% (best 96.60%); T18: W-NCM 97.60% (best 97.60%); T19: W-NCM 96.80% (best 96.80%)
2025-12-11 16:22:15,640 [trainer.py] => Average forgetting (W-NCM): 8.58% | Max forgetting (W-NCM): 24.00%
2025-12-11 16:22:16,193 [trainer.py] => All params: 114881051
2025-12-11 16:22:16,196 [trainer.py] => Trainable params: 188165
2025-12-11 16:22:16,196 [inflora.py] => Learning on 95-100
Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_v.19.weight', 'image_encoder.blocks.11.attn.lora_B_v.19.weight', 'classifier_pool.19.bias', 'image_encoder.blocks.0.attn.lora_B_k.19.weight', 'image_encoder.blocks.2.attn.lora_B_k.19.weight', 'image_encoder.blocks.9.attn.lora_B_v.19.weight', 'image_encoder.blocks.6.attn.lora_B_k.19.weight', 'image_encoder.blocks.1.attn.lora_B_k.19.weight', 'image_encoder.blocks.4.attn.lora_B_v.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.19.weight', 'image_encoder.blocks.11.attn.lora_B_k.19.weight', 'image_encoder.blocks.6.attn.lora_B_v.19.weight', 'image_encoder.blocks.9.attn.lora_B_k.19.weight', 'image_encoder.blocks.10.attn.lora_B_k.19.weight', 'image_encoder.blocks.5.attn.lora_B_k.19.weight', 'image_encoder.blocks.7.attn.lora_B_k.19.weight', 'image_encoder.blocks.10.attn.lora_B_v.19.weight', 'image_encoder.blocks.0.attn.lora_B_v.19.weight', 'image_encoder.blocks.7.attn.lora_B_v.19.weight', 'image_encoder.blocks.4.attn.lora_B_k.19.weight', 'image_encoder.blocks.1.attn.lora_B_v.19.weight', 'image_encoder.blocks.8.attn.lora_B_k.19.weight', 'image_encoder.blocks.2.attn.lora_B_v.19.weight', 'image_encoder.blocks.8.attn.lora_B_v.19.weight', 'classifier_pool.19.weight', 'image_encoder.blocks.5.attn.lora_B_v.19.weight'}
2025-12-11 16:27:10,787 [inflora.py] => Task 19, Epoch 20/20 => Loss 0.036, Train_accy 98.76
Threshold:  0.9975
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 35/768 type remove
Layer 3 : 67/768 type remove
Layer 4 : 106/768 type remove
Layer 5 : 159/768 type remove
Layer 6 : 224/768 type remove
Layer 7 : 272/768 type remove
Layer 8 : 363/768 type remove
Layer 9 : 318/768 type retain
Layer 10 : 289/768 type retain
Layer 11 : 382/768 type retain
Layer 12 : 367/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:27:29,272 [trainer.py] => Time:313.07617688179016
10000 10000
10000 10000
2025-12-11 16:27:55,751 [trainer.py] => Time:26.478553295135498
2025-12-11 16:27:55,751 [inflora.py] => Exemplar size: 0
2025-12-11 16:27:55,751 [trainer.py] => CNN: {'total': np.float64(81.09), '00-04': np.float64(87.2), '05-09': np.float64(91.0), '10-14': np.float64(71.8), '15-19': np.float64(89.2), '20-24': np.float64(77.2), '25-29': np.float64(79.0), '30-34': np.float64(88.2), '35-39': np.float64(83.4), '40-44': np.float64(89.6), '45-49': np.float64(78.4), '50-54': np.float64(85.0), '55-59': np.float64(68.8), '60-64': np.float64(74.4), '65-69': np.float64(87.8), '70-74': np.float64(60.8), '75-79': np.float64(94.2), '80-84': np.float64(80.4), '85-89': np.float64(87.6), '90-94': np.float64(88.6), '95-99': np.float64(59.2), 'old': np.float64(82.24), 'new': np.float64(59.2)}
2025-12-11 16:27:55,751 [trainer.py] => CNN top1 curve: [np.float64(99.6), np.float64(99.2), np.float64(96.0), np.float64(96.05), np.float64(94.48), np.float64(92.8), np.float64(92.34), np.float64(90.82), np.float64(90.13), np.float64(89.58), np.float64(87.96), np.float64(86.18), np.float64(85.97), np.float64(85.07), np.float64(83.56), np.float64(83.99), np.float64(83.24), np.float64(83.53), np.float64(82.93), np.float64(81.09)]
2025-12-11 16:27:55,751 [trainer.py] => CNN top1 with task curve: [np.float64(99.6), np.float64(99.5), np.float64(99.47), np.float64(99.45), np.float64(99.52), np.float64(99.47), np.float64(99.37), np.float64(99.35), np.float64(99.29), np.float64(99.32), np.float64(99.49), np.float64(99.42), np.float64(99.28), np.float64(99.29), np.float64(99.19), np.float64(99.18), np.float64(99.27), np.float64(99.22), np.float64(99.33), np.float64(99.36)]
2025-12-11 16:27:55,752 [trainer.py] => CNN top1 task curve: [1.0, 0.997, 0.964, 0.963, 0.9468, 0.931, 0.926, 0.91025, 0.9026666666666666, 0.8968, 0.8805454545454545, 0.8625, 0.8606153846153846, 0.8511428571428571, 0.836, 0.840375, 0.8329411764705882, 0.8362222222222222, 0.8302105263157895, 0.8115]
2025-12-11 16:28:28,923 [trainer.py] => W-NCM: {'00-04': 85.0, '05-09': 93.8, '10-14': 73.0, '15-19': 90.60000000000001, '20-24': 88.8, '25-29': 88.0, '30-34': 79.4, '35-39': 85.39999999999999, '40-44': 92.0, '45-49': 76.2, '50-54': 81.6, '55-59': 86.6, '60-64': 86.0, '65-69': 92.2, '70-74': 88.0, '75-79': 95.19999999999999, '80-84': 92.80000000000001, '85-89': 96.39999999999999, '90-94': 96.39999999999999, '95-99': 96.2}
2025-12-11 16:28:28,923 [trainer.py] => Ave Acc (W-NCM): 88.18%
2025-12-11 16:28:28,924 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 85.00% (best 99.80%); T2: W-NCM 93.80% (best 99.60%); T3: W-NCM 73.00% (best 99.40%); T4: W-NCM 90.60% (best 98.20%); T5: W-NCM 88.80% (best 99.20%); T6: W-NCM 88.00% (best 96.80%); T7: W-NCM 79.40% (best 97.80%); T8: W-NCM 85.40% (best 98.20%); T9: W-NCM 92.00% (best 97.20%); T10: W-NCM 76.20% (best 98.40%); T11: W-NCM 81.60% (best 98.40%); T12: W-NCM 86.60% (best 96.00%); T13: W-NCM 86.00% (best 95.80%); T14: W-NCM 92.20% (best 98.40%); T15: W-NCM 88.00% (best 94.20%); T16: W-NCM 95.20% (best 99.40%); T17: W-NCM 92.80% (best 96.60%); T18: W-NCM 96.40% (best 97.60%); T19: W-NCM 96.40% (best 96.80%); T20: W-NCM 96.20% (best 96.20%)
2025-12-11 16:28:28,924 [trainer.py] => Average forgetting (W-NCM): 10.02% | Max forgetting (W-NCM): 26.40%
2025-12-11 16:28:29,466 [trainer.py] => 
===== Summary =====
2025-12-11 16:28:29,466 [trainer.py] => Final average accuracy: 81.09%
2025-12-11 16:28:29,466 [trainer.py] => Average accuracy over tasks: 89.23%
2025-12-11 16:28:29,466 [trainer.py] => Final average forgetting: 7.53%
2025-12-11 16:28:29,467 [trainer.py] => Final max forgetting: 21.60%
2025-12-11 16:28:29,467 [trainer.py] => W-NCM final average accuracy: 88.18%
2025-12-11 16:28:29,467 [trainer.py] => W-NCM average accuracy over tasks: 92.66%
2025-12-11 16:28:29,467 [trainer.py] => W-NCM final average forgetting: 10.02%
2025-12-11 16:28:29,467 [trainer.py] => W-NCM final max forgetting: 26.40%
