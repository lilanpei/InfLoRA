logs/ImageNet_R/20_20_sip/InfLoRA/adam/10/0.98_1.0-0.0005/42
2025-12-10 01:55:37,937 [trainer.py] => config: configs/mimg10_inflora_seed42.json
2025-12-10 01:55:37,938 [trainer.py] => device: [device(type='cuda', index=0)]
2025-12-10 01:55:37,938 [trainer.py] => prefix: reproduce
2025-12-10 01:55:37,938 [trainer.py] => dataset: ImageNet_R
2025-12-10 01:55:37,938 [trainer.py] => data_path: data/imagenet-r
2025-12-10 01:55:37,938 [trainer.py] => memory_size: 0
2025-12-10 01:55:37,939 [trainer.py] => memory_per_class: 0
2025-12-10 01:55:37,939 [trainer.py] => fixed_memory: True
2025-12-10 01:55:37,939 [trainer.py] => shuffle: False
2025-12-10 01:55:37,939 [trainer.py] => init_cls: 20
2025-12-10 01:55:37,939 [trainer.py] => increment: 20
2025-12-10 01:55:37,939 [trainer.py] => model_name: InfLoRA
2025-12-10 01:55:37,939 [trainer.py] => net_type: sip
2025-12-10 01:55:37,939 [trainer.py] => embd_dim: 768
2025-12-10 01:55:37,939 [trainer.py] => num_heads: 12
2025-12-10 01:55:37,939 [trainer.py] => total_sessions: 10
2025-12-10 01:55:37,939 [trainer.py] => seed: 42
2025-12-10 01:55:37,939 [trainer.py] => EPSILON: 1e-08
2025-12-10 01:55:37,939 [trainer.py] => init_epoch: 50
2025-12-10 01:55:37,939 [trainer.py] => optim: adam
2025-12-10 01:55:37,939 [trainer.py] => init_lr: 0.0005
2025-12-10 01:55:37,939 [trainer.py] => init_lr_decay: 0.1
2025-12-10 01:55:37,939 [trainer.py] => init_weight_decay: 0.0
2025-12-10 01:55:37,939 [trainer.py] => epochs: 50
2025-12-10 01:55:37,939 [trainer.py] => lrate: 0.0005
2025-12-10 01:55:37,939 [trainer.py] => lrate_decay: 0.1
2025-12-10 01:55:37,939 [trainer.py] => batch_size: 128
2025-12-10 01:55:37,939 [trainer.py] => weight_decay: 0.0
2025-12-10 01:55:37,939 [trainer.py] => rank: 10
2025-12-10 01:55:37,939 [trainer.py] => lamb: 0.98
2025-12-10 01:55:37,940 [trainer.py] => lame: 1.0
2025-12-10 01:55:37,940 [trainer.py] => num_workers: 8
2025-12-10 01:55:38,231 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
Loading ViT weights from local checkpoint: /leonardo/home/userexternal/lli00001/vit_b16_in21k.pth
Loaded 152 keys, missing 482, unexpected 0
2025-12-10 01:55:40,082 [trainer.py] => All params: 111348451
2025-12-10 01:55:40,084 [trainer.py] => Trainable params: 111348451
2025-12-10 01:55:40,084 [inflora.py] => Learning on 0-20
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight'}
2025-12-10 02:08:17,628 [inflora.py] => Task 0, Epoch 50/50 => Loss 0.125, Train_accy 96.40
Threshold:  0.98
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 14/768 type remove
Layer 4 : 18/768 type remove
Layer 5 : 27/768 type remove
Layer 6 : 26/768 type remove
Layer 7 : 29/768 type remove
Layer 8 : 33/768 type remove
Layer 9 : 60/768 type remove
Layer 10 : 71/768 type remove
Layer 11 : 29/768 type remove
Layer 12 : 72/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 02:08:35,783 [trainer.py] => Time:775.69904088974
650 650
650 650
2025-12-10 02:08:38,536 [trainer.py] => Time:2.7527694702148438
2025-12-10 02:08:38,537 [inflora.py] => Exemplar size: 0
2025-12-10 02:08:38,537 [trainer.py] => CNN: {'total': np.float64(88.77), '00-19': np.float64(88.77), 'old': 0, 'new': np.float64(88.77)}
2025-12-10 02:08:38,537 [trainer.py] => CNN top1 curve: [np.float64(88.77)]
2025-12-10 02:08:38,537 [trainer.py] => CNN top1 with task curve: [np.float64(88.77)]
2025-12-10 02:08:38,537 [trainer.py] => CNN top1 task curve: [1.0]
2025-12-10 02:08:39,105 [trainer.py] => All params: 111348451
2025-12-10 02:08:39,107 [trainer.py] => Trainable params: 199700
2025-12-10 02:08:39,107 [inflora.py] => Learning on 20-40
Parameters to be updated: {'image_encoder.blocks.7.attn.lora_B_v.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.1.weight', 'image_encoder.blocks.4.attn.lora_B_k.1.weight', 'image_encoder.blocks.11.attn.lora_B_v.1.weight', 'image_encoder.blocks.9.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_v.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.1.weight', 'image_encoder.blocks.3.attn.lora_B_v.1.weight', 'image_encoder.blocks.3.attn.lora_B_k.1.weight', 'classifier_pool.1.bias', 'image_encoder.blocks.0.attn.lora_B_v.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.1.weight', 'image_encoder.blocks.6.attn.lora_B_k.1.weight', 'image_encoder.blocks.9.attn.lora_B_k.1.weight', 'image_encoder.blocks.4.attn.lora_B_v.1.weight', 'image_encoder.blocks.5.attn.lora_B_k.1.weight', 'classifier_pool.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.1.weight', 'image_encoder.blocks.8.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_k.1.weight', 'image_encoder.blocks.1.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.1.weight', 'image_encoder.blocks.1.attn.lora_B_k.1.weight', 'image_encoder.blocks.10.attn.lora_B_k.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.1.weight'}
2025-12-10 02:22:32,453 [inflora.py] => Task 1, Epoch 50/50 => Loss 0.165, Train_accy 95.59
Threshold:  0.982
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 21/768 type remove
Layer 4 : 26/768 type remove
Layer 5 : 38/768 type remove
Layer 6 : 35/768 type remove
Layer 7 : 40/768 type remove
Layer 8 : 45/768 type remove
Layer 9 : 82/768 type remove
Layer 10 : 99/768 type remove
Layer 11 : 47/768 type remove
Layer 12 : 142/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 02:22:54,448 [trainer.py] => Time:855.3407282829285
1400 1400
1400 1400
2025-12-10 02:22:59,086 [trainer.py] => Time:4.637874126434326
2025-12-10 02:22:59,086 [inflora.py] => Exemplar size: 0
2025-12-10 02:22:59,087 [trainer.py] => CNN: {'total': np.float64(86.71), '00-19': np.float64(86.15), '20-39': np.float64(87.2), 'old': np.float64(86.15), 'new': np.float64(87.2)}
2025-12-10 02:22:59,087 [trainer.py] => CNN top1 curve: [np.float64(88.77), np.float64(86.71)]
2025-12-10 02:22:59,087 [trainer.py] => CNN top1 with task curve: [np.float64(88.77), np.float64(90.43)]
2025-12-10 02:22:59,087 [trainer.py] => CNN top1 task curve: [1.0, 0.9342857142857143]
2025-12-10 02:22:59,788 [trainer.py] => All params: 111348451
2025-12-10 02:22:59,790 [trainer.py] => Trainable params: 199700
2025-12-10 02:22:59,790 [inflora.py] => Learning on 40-60
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_k.2.weight', 'image_encoder.blocks.3.attn.lora_B_v.2.weight', 'image_encoder.blocks.6.attn.lora_B_k.2.weight', 'image_encoder.blocks.5.attn.lora_B_v.2.weight', 'image_encoder.blocks.6.attn.lora_B_v.2.weight', 'image_encoder.blocks.11.attn.lora_B_v.2.weight', 'image_encoder.blocks.7.attn.lora_B_v.2.weight', 'classifier_pool.2.weight', 'classifier_pool.2.bias', 'image_encoder.blocks.2.attn.lora_B_v.2.weight', 'image_encoder.blocks.5.attn.lora_B_k.2.weight', 'image_encoder.blocks.0.attn.lora_B_k.2.weight', 'image_encoder.blocks.3.attn.lora_B_k.2.weight', 'image_encoder.blocks.8.attn.lora_B_v.2.weight', 'image_encoder.blocks.0.attn.lora_B_v.2.weight', 'image_encoder.blocks.1.attn.lora_B_k.2.weight', 'image_encoder.blocks.2.attn.lora_B_k.2.weight', 'image_encoder.blocks.10.attn.lora_B_k.2.weight', 'image_encoder.blocks.4.attn.lora_B_v.2.weight', 'image_encoder.blocks.4.attn.lora_B_k.2.weight', 'image_encoder.blocks.7.attn.lora_B_k.2.weight', 'image_encoder.blocks.10.attn.lora_B_v.2.weight', 'image_encoder.blocks.8.attn.lora_B_k.2.weight', 'image_encoder.blocks.9.attn.lora_B_v.2.weight', 'image_encoder.blocks.11.attn.lora_B_k.2.weight', 'image_encoder.blocks.1.attn.lora_B_v.2.weight'}
2025-12-10 02:31:52,241 [inflora.py] => Task 2, Epoch 50/50 => Loss 0.205, Train_accy 93.71
Threshold:  0.984
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 24/768 type remove
Layer 4 : 33/768 type remove
Layer 5 : 45/768 type remove
Layer 6 : 43/768 type remove
Layer 7 : 53/768 type remove
Layer 8 : 60/768 type remove
Layer 9 : 103/768 type remove
Layer 10 : 118/768 type remove
Layer 11 : 69/768 type remove
Layer 12 : 156/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 02:32:07,514 [trainer.py] => Time:547.724221944809
1827 1827
1827 1827
2025-12-10 02:32:13,239 [trainer.py] => Time:5.724514722824097
2025-12-10 02:32:13,239 [inflora.py] => Exemplar size: 0
2025-12-10 02:32:13,239 [trainer.py] => CNN: {'total': np.float64(83.31), '00-19': np.float64(83.69), '20-39': np.float64(85.2), '40-59': np.float64(79.39), 'old': np.float64(84.5), 'new': np.float64(79.39)}
2025-12-10 02:32:13,239 [trainer.py] => CNN top1 curve: [np.float64(88.77), np.float64(86.71), np.float64(83.31)]
2025-12-10 02:32:13,239 [trainer.py] => CNN top1 with task curve: [np.float64(88.77), np.float64(90.43), np.float64(88.89)]
2025-12-10 02:32:13,240 [trainer.py] => CNN top1 task curve: [1.0, 0.9342857142857143, 0.8976464148877942]
2025-12-10 02:32:13,727 [trainer.py] => All params: 111348451
2025-12-10 02:32:13,729 [trainer.py] => Trainable params: 199700
2025-12-10 02:32:13,729 [inflora.py] => Learning on 60-80
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_v.3.weight', 'image_encoder.blocks.0.attn.lora_B_v.3.weight', 'image_encoder.blocks.5.attn.lora_B_k.3.weight', 'image_encoder.blocks.7.attn.lora_B_v.3.weight', 'image_encoder.blocks.8.attn.lora_B_v.3.weight', 'image_encoder.blocks.2.attn.lora_B_k.3.weight', 'classifier_pool.3.weight', 'image_encoder.blocks.4.attn.lora_B_v.3.weight', 'image_encoder.blocks.1.attn.lora_B_k.3.weight', 'image_encoder.blocks.8.attn.lora_B_k.3.weight', 'image_encoder.blocks.6.attn.lora_B_k.3.weight', 'image_encoder.blocks.3.attn.lora_B_v.3.weight', 'image_encoder.blocks.1.attn.lora_B_v.3.weight', 'image_encoder.blocks.0.attn.lora_B_k.3.weight', 'image_encoder.blocks.11.attn.lora_B_k.3.weight', 'image_encoder.blocks.6.attn.lora_B_v.3.weight', 'image_encoder.blocks.5.attn.lora_B_v.3.weight', 'classifier_pool.3.bias', 'image_encoder.blocks.7.attn.lora_B_k.3.weight', 'image_encoder.blocks.9.attn.lora_B_k.3.weight', 'image_encoder.blocks.3.attn.lora_B_k.3.weight', 'image_encoder.blocks.4.attn.lora_B_k.3.weight', 'image_encoder.blocks.10.attn.lora_B_k.3.weight', 'image_encoder.blocks.10.attn.lora_B_v.3.weight', 'image_encoder.blocks.9.attn.lora_B_v.3.weight', 'image_encoder.blocks.2.attn.lora_B_v.3.weight'}
2025-12-10 02:43:53,150 [inflora.py] => Task 3, Epoch 50/50 => Loss 0.156, Train_accy 95.67
Threshold:  0.986
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 29/768 type remove
Layer 4 : 41/768 type remove
Layer 5 : 55/768 type remove
Layer 6 : 53/768 type remove
Layer 7 : 65/768 type remove
Layer 8 : 76/768 type remove
Layer 9 : 132/768 type remove
Layer 10 : 149/768 type remove
Layer 11 : 91/768 type remove
Layer 12 : 181/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 02:44:11,911 [trainer.py] => Time:718.1826822757721
2403 2403
2403 2403
2025-12-10 02:44:19,116 [trainer.py] => Time:7.204476594924927
2025-12-10 02:44:19,117 [inflora.py] => Exemplar size: 0
2025-12-10 02:44:19,117 [trainer.py] => CNN: {'total': np.float64(80.48), '00-19': np.float64(84.0), '20-39': np.float64(80.4), '40-59': np.float64(75.88), '60-79': np.float64(80.03), 'old': np.float64(80.62), 'new': np.float64(80.03)}
2025-12-10 02:44:19,117 [trainer.py] => CNN top1 curve: [np.float64(88.77), np.float64(86.71), np.float64(83.31), np.float64(80.48)]
2025-12-10 02:44:19,117 [trainer.py] => CNN top1 with task curve: [np.float64(88.77), np.float64(90.43), np.float64(88.89), np.float64(88.56)]
2025-12-10 02:44:19,117 [trainer.py] => CNN top1 task curve: [1.0, 0.9342857142857143, 0.8976464148877942, 0.8680815647107782]
2025-12-10 02:44:19,609 [trainer.py] => All params: 111348451
2025-12-10 02:44:19,611 [trainer.py] => Trainable params: 199700
2025-12-10 02:44:19,611 [inflora.py] => Learning on 80-100
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_k.4.weight', 'image_encoder.blocks.5.attn.lora_B_k.4.weight', 'image_encoder.blocks.2.attn.lora_B_k.4.weight', 'image_encoder.blocks.8.attn.lora_B_k.4.weight', 'image_encoder.blocks.9.attn.lora_B_v.4.weight', 'image_encoder.blocks.7.attn.lora_B_k.4.weight', 'image_encoder.blocks.1.attn.lora_B_v.4.weight', 'image_encoder.blocks.11.attn.lora_B_v.4.weight', 'image_encoder.blocks.10.attn.lora_B_v.4.weight', 'image_encoder.blocks.4.attn.lora_B_k.4.weight', 'image_encoder.blocks.4.attn.lora_B_v.4.weight', 'image_encoder.blocks.9.attn.lora_B_k.4.weight', 'image_encoder.blocks.3.attn.lora_B_v.4.weight', 'image_encoder.blocks.8.attn.lora_B_v.4.weight', 'classifier_pool.4.weight', 'image_encoder.blocks.11.attn.lora_B_k.4.weight', 'image_encoder.blocks.0.attn.lora_B_v.4.weight', 'image_encoder.blocks.2.attn.lora_B_v.4.weight', 'image_encoder.blocks.5.attn.lora_B_v.4.weight', 'image_encoder.blocks.6.attn.lora_B_v.4.weight', 'image_encoder.blocks.10.attn.lora_B_k.4.weight', 'classifier_pool.4.bias', 'image_encoder.blocks.7.attn.lora_B_v.4.weight', 'image_encoder.blocks.6.attn.lora_B_k.4.weight', 'image_encoder.blocks.3.attn.lora_B_k.4.weight', 'image_encoder.blocks.0.attn.lora_B_k.4.weight'}
2025-12-10 02:58:00,601 [inflora.py] => Task 4, Epoch 50/50 => Loss 0.184, Train_accy 94.90
Threshold:  0.988
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 18/768 type remove
Layer 3 : 39/768 type remove
Layer 4 : 50/768 type remove
Layer 5 : 69/768 type remove
Layer 6 : 69/768 type remove
Layer 7 : 85/768 type remove
Layer 8 : 101/768 type remove
Layer 9 : 169/768 type remove
Layer 10 : 206/768 type remove
Layer 11 : 129/768 type remove
Layer 12 : 271/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 02:58:22,278 [trainer.py] => Time:842.6664988994598
3119 3119
3119 3119
2025-12-10 02:58:31,260 [trainer.py] => Time:8.981445789337158
2025-12-10 02:58:31,260 [inflora.py] => Exemplar size: 0
2025-12-10 02:58:31,260 [trainer.py] => CNN: {'total': np.float64(80.47), '00-19': np.float64(83.08), '20-39': np.float64(82.53), '40-59': np.float64(74.47), '60-79': np.float64(78.82), '80-99': np.float64(80.87), 'old': np.float64(80.36), 'new': np.float64(80.87)}
2025-12-10 02:58:31,260 [trainer.py] => CNN top1 curve: [np.float64(88.77), np.float64(86.71), np.float64(83.31), np.float64(80.48), np.float64(80.47)]
2025-12-10 02:58:31,260 [trainer.py] => CNN top1 with task curve: [np.float64(88.77), np.float64(90.43), np.float64(88.89), np.float64(88.56), np.float64(88.36)]
2025-12-10 02:58:31,260 [trainer.py] => CNN top1 task curve: [1.0, 0.9342857142857143, 0.8976464148877942, 0.8680815647107782, 0.8534786790638025]
2025-12-10 02:58:31,753 [trainer.py] => All params: 111348451
2025-12-10 02:58:31,755 [trainer.py] => Trainable params: 199700
2025-12-10 02:58:31,755 [inflora.py] => Learning on 100-120
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.5.weight', 'image_encoder.blocks.11.attn.lora_B_v.5.weight', 'image_encoder.blocks.2.attn.lora_B_v.5.weight', 'image_encoder.blocks.3.attn.lora_B_v.5.weight', 'image_encoder.blocks.5.attn.lora_B_k.5.weight', 'classifier_pool.5.bias', 'image_encoder.blocks.8.attn.lora_B_v.5.weight', 'image_encoder.blocks.9.attn.lora_B_k.5.weight', 'image_encoder.blocks.1.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_v.5.weight', 'classifier_pool.5.weight', 'image_encoder.blocks.3.attn.lora_B_k.5.weight', 'image_encoder.blocks.5.attn.lora_B_v.5.weight', 'image_encoder.blocks.9.attn.lora_B_v.5.weight', 'image_encoder.blocks.10.attn.lora_B_v.5.weight', 'image_encoder.blocks.6.attn.lora_B_k.5.weight', 'image_encoder.blocks.1.attn.lora_B_v.5.weight', 'image_encoder.blocks.4.attn.lora_B_v.5.weight', 'image_encoder.blocks.7.attn.lora_B_v.5.weight', 'image_encoder.blocks.2.attn.lora_B_k.5.weight', 'image_encoder.blocks.4.attn.lora_B_k.5.weight', 'image_encoder.blocks.7.attn.lora_B_k.5.weight', 'image_encoder.blocks.8.attn.lora_B_k.5.weight', 'image_encoder.blocks.11.attn.lora_B_k.5.weight', 'image_encoder.blocks.10.attn.lora_B_k.5.weight'}
2025-12-10 03:09:30,549 [inflora.py] => Task 5, Epoch 50/50 => Loss 0.167, Train_accy 95.16
Threshold:  0.99
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 20/768 type remove
Layer 3 : 43/768 type remove
Layer 4 : 57/768 type remove
Layer 5 : 80/768 type remove
Layer 6 : 84/768 type remove
Layer 7 : 103/768 type remove
Layer 8 : 126/768 type remove
Layer 9 : 209/768 type remove
Layer 10 : 265/768 type remove
Layer 11 : 180/768 type remove
Layer 12 : 371/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 03:09:48,124 [trainer.py] => Time:676.3690941333771
3677 3677
3677 3677
2025-12-10 03:09:58,615 [trainer.py] => Time:10.490443229675293
2025-12-10 03:09:58,615 [inflora.py] => Exemplar size: 0
2025-12-10 03:09:58,615 [trainer.py] => CNN: {'total': np.float64(78.95), '00-19': np.float64(80.62), '20-39': np.float64(81.2), '40-59': np.float64(71.66), '60-79': np.float64(76.56), '80-99': np.float64(79.47), '100-119': np.float64(81.36), 'old': np.float64(78.52), 'new': np.float64(81.36)}
2025-12-10 03:09:58,615 [trainer.py] => CNN top1 curve: [np.float64(88.77), np.float64(86.71), np.float64(83.31), np.float64(80.48), np.float64(80.47), np.float64(78.95)]
2025-12-10 03:09:58,615 [trainer.py] => CNN top1 with task curve: [np.float64(88.77), np.float64(90.43), np.float64(88.89), np.float64(88.56), np.float64(88.36), np.float64(88.47)]
2025-12-10 03:09:58,615 [trainer.py] => CNN top1 task curve: [1.0, 0.9342857142857143, 0.8976464148877942, 0.8680815647107782, 0.8534786790638025, 0.8379113407669295]
2025-12-10 03:09:59,108 [trainer.py] => All params: 111348451
2025-12-10 03:09:59,109 [trainer.py] => Trainable params: 199700
2025-12-10 03:09:59,109 [inflora.py] => Learning on 120-140
Parameters to be updated: {'image_encoder.blocks.8.attn.lora_B_v.6.weight', 'image_encoder.blocks.8.attn.lora_B_k.6.weight', 'image_encoder.blocks.11.attn.lora_B_k.6.weight', 'image_encoder.blocks.4.attn.lora_B_k.6.weight', 'image_encoder.blocks.10.attn.lora_B_k.6.weight', 'image_encoder.blocks.3.attn.lora_B_v.6.weight', 'image_encoder.blocks.0.attn.lora_B_v.6.weight', 'image_encoder.blocks.6.attn.lora_B_k.6.weight', 'image_encoder.blocks.1.attn.lora_B_v.6.weight', 'image_encoder.blocks.0.attn.lora_B_k.6.weight', 'image_encoder.blocks.10.attn.lora_B_v.6.weight', 'image_encoder.blocks.5.attn.lora_B_k.6.weight', 'image_encoder.blocks.6.attn.lora_B_v.6.weight', 'image_encoder.blocks.5.attn.lora_B_v.6.weight', 'image_encoder.blocks.3.attn.lora_B_k.6.weight', 'image_encoder.blocks.1.attn.lora_B_k.6.weight', 'image_encoder.blocks.11.attn.lora_B_v.6.weight', 'image_encoder.blocks.2.attn.lora_B_k.6.weight', 'image_encoder.blocks.4.attn.lora_B_v.6.weight', 'image_encoder.blocks.7.attn.lora_B_k.6.weight', 'image_encoder.blocks.9.attn.lora_B_v.6.weight', 'image_encoder.blocks.7.attn.lora_B_v.6.weight', 'classifier_pool.6.weight', 'classifier_pool.6.bias', 'image_encoder.blocks.2.attn.lora_B_v.6.weight', 'image_encoder.blocks.9.attn.lora_B_k.6.weight'}
2025-12-10 03:21:19,656 [inflora.py] => Task 6, Epoch 50/50 => Loss 0.251, Train_accy 92.78
Threshold:  0.992
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 24/768 type remove
Layer 3 : 55/768 type remove
Layer 4 : 73/768 type remove
Layer 5 : 102/768 type remove
Layer 6 : 108/768 type remove
Layer 7 : 135/768 type remove
Layer 8 : 162/768 type remove
Layer 9 : 266/768 type remove
Layer 10 : 346/768 type remove
Layer 11 : 261/768 type remove
Layer 12 : 286/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 03:21:38,235 [trainer.py] => Time:699.1258931159973
4234 4234
4234 4234
2025-12-10 03:21:50,171 [trainer.py] => Time:11.935490131378174
2025-12-10 03:21:50,172 [inflora.py] => Exemplar size: 0
2025-12-10 03:21:50,172 [trainer.py] => CNN: {'total': np.float64(76.88), '00-19': np.float64(79.38), '20-39': np.float64(79.6), '40-59': np.float64(71.19), '60-79': np.float64(75.35), '80-99': np.float64(76.26), '100-119': np.float64(78.67), '120-139': np.float64(75.22), 'old': np.float64(77.13), 'new': np.float64(75.22)}
2025-12-10 03:21:50,172 [trainer.py] => CNN top1 curve: [np.float64(88.77), np.float64(86.71), np.float64(83.31), np.float64(80.48), np.float64(80.47), np.float64(78.95), np.float64(76.88)]
2025-12-10 03:21:50,172 [trainer.py] => CNN top1 with task curve: [np.float64(88.77), np.float64(90.43), np.float64(88.89), np.float64(88.56), np.float64(88.36), np.float64(88.47), np.float64(87.29)]
2025-12-10 03:21:50,172 [trainer.py] => CNN top1 task curve: [1.0, 0.9342857142857143, 0.8976464148877942, 0.8680815647107782, 0.8534786790638025, 0.8379113407669295, 0.8162494095418045]
2025-12-10 03:21:50,991 [trainer.py] => All params: 111348451
2025-12-10 03:21:50,993 [trainer.py] => Trainable params: 199700
2025-12-10 03:21:50,993 [inflora.py] => Learning on 140-160
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_v.7.weight', 'image_encoder.blocks.7.attn.lora_B_k.7.weight', 'image_encoder.blocks.3.attn.lora_B_v.7.weight', 'image_encoder.blocks.1.attn.lora_B_k.7.weight', 'image_encoder.blocks.10.attn.lora_B_v.7.weight', 'image_encoder.blocks.8.attn.lora_B_k.7.weight', 'image_encoder.blocks.5.attn.lora_B_v.7.weight', 'image_encoder.blocks.2.attn.lora_B_v.7.weight', 'image_encoder.blocks.0.attn.lora_B_v.7.weight', 'classifier_pool.7.bias', 'image_encoder.blocks.6.attn.lora_B_v.7.weight', 'image_encoder.blocks.6.attn.lora_B_k.7.weight', 'image_encoder.blocks.9.attn.lora_B_k.7.weight', 'image_encoder.blocks.11.attn.lora_B_v.7.weight', 'image_encoder.blocks.5.attn.lora_B_k.7.weight', 'image_encoder.blocks.8.attn.lora_B_v.7.weight', 'classifier_pool.7.weight', 'image_encoder.blocks.9.attn.lora_B_v.7.weight', 'image_encoder.blocks.10.attn.lora_B_k.7.weight', 'image_encoder.blocks.2.attn.lora_B_k.7.weight', 'image_encoder.blocks.4.attn.lora_B_k.7.weight', 'image_encoder.blocks.7.attn.lora_B_v.7.weight', 'image_encoder.blocks.4.attn.lora_B_v.7.weight', 'image_encoder.blocks.11.attn.lora_B_k.7.weight', 'image_encoder.blocks.0.attn.lora_B_k.7.weight', 'image_encoder.blocks.3.attn.lora_B_k.7.weight'}
2025-12-10 03:31:05,931 [inflora.py] => Task 7, Epoch 50/50 => Loss 0.199, Train_accy 93.67
Threshold:  0.994
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 11/768 type remove
Layer 2 : 27/768 type remove
Layer 3 : 63/768 type remove
Layer 4 : 87/768 type remove
Layer 5 : 119/768 type remove
Layer 6 : 132/768 type remove
Layer 7 : 166/768 type remove
Layer 8 : 202/768 type remove
Layer 9 : 309/768 type remove
Layer 10 : 378/768 type retain
Layer 11 : 313/768 type remove
Layer 12 : 243/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 03:31:22,098 [trainer.py] => Time:571.1043648719788
4679 4679
4679 4679
2025-12-10 03:31:35,085 [trainer.py] => Time:12.98677659034729
2025-12-10 03:31:35,085 [inflora.py] => Exemplar size: 0
2025-12-10 03:31:35,085 [trainer.py] => CNN: {'total': np.float64(75.89), '00-19': np.float64(78.31), '20-39': np.float64(79.73), '40-59': np.float64(70.49), '60-79': np.float64(74.65), '80-99': np.float64(74.44), '100-119': np.float64(78.14), '120-139': np.float64(73.43), '140-159': np.float64(75.28), 'old': np.float64(75.96), 'new': np.float64(75.28)}
2025-12-10 03:31:35,085 [trainer.py] => CNN top1 curve: [np.float64(88.77), np.float64(86.71), np.float64(83.31), np.float64(80.48), np.float64(80.47), np.float64(78.95), np.float64(76.88), np.float64(75.89)]
2025-12-10 03:31:35,086 [trainer.py] => CNN top1 with task curve: [np.float64(88.77), np.float64(90.43), np.float64(88.89), np.float64(88.56), np.float64(88.36), np.float64(88.47), np.float64(87.29), np.float64(86.88)]
2025-12-10 03:31:35,086 [trainer.py] => CNN top1 task curve: [1.0, 0.9342857142857143, 0.8976464148877942, 0.8680815647107782, 0.8534786790638025, 0.8379113407669295, 0.8162494095418045, 0.8029493481513144]
2025-12-10 03:31:35,588 [trainer.py] => All params: 111348451
2025-12-10 03:31:35,589 [trainer.py] => Trainable params: 199700
2025-12-10 03:31:35,590 [inflora.py] => Learning on 160-180
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_k.8.weight', 'image_encoder.blocks.10.attn.lora_B_k.8.weight', 'image_encoder.blocks.3.attn.lora_B_v.8.weight', 'image_encoder.blocks.6.attn.lora_B_k.8.weight', 'image_encoder.blocks.1.attn.lora_B_v.8.weight', 'image_encoder.blocks.8.attn.lora_B_k.8.weight', 'classifier_pool.8.bias', 'image_encoder.blocks.2.attn.lora_B_v.8.weight', 'image_encoder.blocks.4.attn.lora_B_k.8.weight', 'image_encoder.blocks.9.attn.lora_B_k.8.weight', 'image_encoder.blocks.0.attn.lora_B_v.8.weight', 'image_encoder.blocks.5.attn.lora_B_k.8.weight', 'image_encoder.blocks.6.attn.lora_B_v.8.weight', 'image_encoder.blocks.8.attn.lora_B_v.8.weight', 'image_encoder.blocks.1.attn.lora_B_k.8.weight', 'image_encoder.blocks.11.attn.lora_B_k.8.weight', 'image_encoder.blocks.5.attn.lora_B_v.8.weight', 'image_encoder.blocks.3.attn.lora_B_k.8.weight', 'image_encoder.blocks.0.attn.lora_B_k.8.weight', 'image_encoder.blocks.10.attn.lora_B_v.8.weight', 'classifier_pool.8.weight', 'image_encoder.blocks.9.attn.lora_B_v.8.weight', 'image_encoder.blocks.11.attn.lora_B_v.8.weight', 'image_encoder.blocks.7.attn.lora_B_k.8.weight', 'image_encoder.blocks.4.attn.lora_B_v.8.weight', 'image_encoder.blocks.7.attn.lora_B_v.8.weight'}
2025-12-10 03:43:49,412 [inflora.py] => Task 8, Epoch 50/50 => Loss 0.185, Train_accy 94.68
Threshold:  0.996
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 13/768 type remove
Layer 2 : 34/768 type remove
Layer 3 : 87/768 type remove
Layer 4 : 123/768 type remove
Layer 5 : 165/768 type remove
Layer 6 : 181/768 type remove
Layer 7 : 222/768 type remove
Layer 8 : 264/768 type remove
Layer 9 : 379/768 type retain
Layer 10 : 291/768 type retain
Layer 11 : 358/768 type retain
Layer 12 : 189/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 03:44:09,079 [trainer.py] => Time:753.489333152771
5306 5306
5306 5306
2025-12-10 03:44:23,718 [trainer.py] => Time:14.638936519622803
2025-12-10 03:44:23,719 [inflora.py] => Exemplar size: 0
2025-12-10 03:44:23,719 [trainer.py] => CNN: {'total': np.float64(76.18), '00-19': np.float64(78.62), '20-39': np.float64(79.73), '40-59': np.float64(70.02), '60-79': np.float64(73.44), '80-99': np.float64(73.88), '100-119': np.float64(77.6), '120-139': np.float64(72.35), '140-159': np.float64(71.91), '160-179': np.float64(83.89), 'old': np.float64(75.14), 'new': np.float64(83.89)}
2025-12-10 03:44:23,719 [trainer.py] => CNN top1 curve: [np.float64(88.77), np.float64(86.71), np.float64(83.31), np.float64(80.48), np.float64(80.47), np.float64(78.95), np.float64(76.88), np.float64(75.89), np.float64(76.18)]
2025-12-10 03:44:23,719 [trainer.py] => CNN top1 with task curve: [np.float64(88.77), np.float64(90.43), np.float64(88.89), np.float64(88.56), np.float64(88.36), np.float64(88.47), np.float64(87.29), np.float64(86.88), np.float64(87.73)]
2025-12-10 03:44:23,719 [trainer.py] => CNN top1 task curve: [1.0, 0.9342857142857143, 0.8976464148877942, 0.8680815647107782, 0.8534786790638025, 0.8379113407669295, 0.8162494095418045, 0.8029493481513144, 0.8022992838296268]
2025-12-10 03:44:24,655 [trainer.py] => All params: 111348451
2025-12-10 03:44:24,657 [trainer.py] => Trainable params: 199700
2025-12-10 03:44:24,657 [inflora.py] => Learning on 180-200
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_v.9.weight', 'image_encoder.blocks.4.attn.lora_B_k.9.weight', 'image_encoder.blocks.3.attn.lora_B_v.9.weight', 'image_encoder.blocks.6.attn.lora_B_v.9.weight', 'image_encoder.blocks.1.attn.lora_B_v.9.weight', 'image_encoder.blocks.4.attn.lora_B_v.9.weight', 'image_encoder.blocks.0.attn.lora_B_k.9.weight', 'image_encoder.blocks.7.attn.lora_B_k.9.weight', 'classifier_pool.9.weight', 'image_encoder.blocks.5.attn.lora_B_v.9.weight', 'image_encoder.blocks.3.attn.lora_B_k.9.weight', 'image_encoder.blocks.10.attn.lora_B_k.9.weight', 'image_encoder.blocks.5.attn.lora_B_k.9.weight', 'image_encoder.blocks.10.attn.lora_B_v.9.weight', 'image_encoder.blocks.1.attn.lora_B_k.9.weight', 'image_encoder.blocks.2.attn.lora_B_k.9.weight', 'image_encoder.blocks.9.attn.lora_B_v.9.weight', 'image_encoder.blocks.2.attn.lora_B_v.9.weight', 'image_encoder.blocks.0.attn.lora_B_v.9.weight', 'image_encoder.blocks.8.attn.lora_B_v.9.weight', 'image_encoder.blocks.7.attn.lora_B_v.9.weight', 'image_encoder.blocks.6.attn.lora_B_k.9.weight', 'classifier_pool.9.bias', 'image_encoder.blocks.9.attn.lora_B_k.9.weight', 'image_encoder.blocks.11.attn.lora_B_k.9.weight', 'image_encoder.blocks.8.attn.lora_B_k.9.weight'}
2025-12-10 03:58:17,143 [inflora.py] => Task 9, Epoch 50/50 => Loss 0.166, Train_accy 95.08
Threshold:  0.998
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 17/768 type remove
Layer 2 : 52/768 type remove
Layer 3 : 123/768 type remove
Layer 4 : 176/768 type remove
Layer 5 : 232/768 type remove
Layer 6 : 259/768 type remove
Layer 7 : 314/768 type remove
Layer 8 : 367/768 type remove
Layer 9 : 279/768 type retain
Layer 10 : 201/768 type retain
Layer 11 : 236/768 type retain
Layer 12 : 116/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-10 03:58:39,124 [trainer.py] => Time:854.4670686721802
6000 6000
6000 6000
2025-12-10 03:58:55,576 [trainer.py] => Time:16.451346397399902
2025-12-10 03:58:55,577 [inflora.py] => Exemplar size: 0
2025-12-10 03:58:55,577 [trainer.py] => CNN: {'total': np.float64(76.03), '00-19': np.float64(76.92), '20-39': np.float64(79.2), '40-59': np.float64(70.49), '60-79': np.float64(73.09), '80-99': np.float64(74.44), '100-119': np.float64(76.7), '120-139': np.float64(71.1), '140-159': np.float64(72.36), '160-179': np.float64(81.66), '180-199': np.float64(79.97), 'old': np.float64(75.52), 'new': np.float64(79.97)}
2025-12-10 03:58:55,577 [trainer.py] => CNN top1 curve: [np.float64(88.77), np.float64(86.71), np.float64(83.31), np.float64(80.48), np.float64(80.47), np.float64(78.95), np.float64(76.88), np.float64(75.89), np.float64(76.18), np.float64(76.03)]
2025-12-10 03:58:55,577 [trainer.py] => CNN top1 with task curve: [np.float64(88.77), np.float64(90.43), np.float64(88.89), np.float64(88.56), np.float64(88.36), np.float64(88.47), np.float64(87.29), np.float64(86.88), np.float64(87.73), np.float64(87.57)]
2025-12-10 03:58:55,577 [trainer.py] => CNN top1 task curve: [1.0, 0.9342857142857143, 0.8976464148877942, 0.8680815647107782, 0.8534786790638025, 0.8379113407669295, 0.8162494095418045, 0.8029493481513144, 0.8022992838296268, 0.7998333333333333]
