logs/ImageNet_R/4_4_sip/InfLoRA/adam/10/0.98_1.0-0.0005/42
2025-12-11 17:06:13,466 [trainer.py] => config: configs/mimg50_inflora_seed42.json
2025-12-11 17:06:13,467 [trainer.py] => device: [device(type='cuda', index=0)]
2025-12-11 17:06:13,467 [trainer.py] => prefix: reproduce
2025-12-11 17:06:13,467 [trainer.py] => dataset: ImageNet_R
2025-12-11 17:06:13,467 [trainer.py] => data_path: data/imagenet-r
2025-12-11 17:06:13,467 [trainer.py] => memory_size: 0
2025-12-11 17:06:13,468 [trainer.py] => memory_per_class: 0
2025-12-11 17:06:13,468 [trainer.py] => fixed_memory: True
2025-12-11 17:06:13,468 [trainer.py] => shuffle: False
2025-12-11 17:06:13,468 [trainer.py] => init_cls: 4
2025-12-11 17:06:13,468 [trainer.py] => increment: 4
2025-12-11 17:06:13,468 [trainer.py] => model_name: InfLoRA
2025-12-11 17:06:13,468 [trainer.py] => net_type: sip
2025-12-11 17:06:13,468 [trainer.py] => embd_dim: 768
2025-12-11 17:06:13,468 [trainer.py] => num_heads: 12
2025-12-11 17:06:13,468 [trainer.py] => total_sessions: 50
2025-12-11 17:06:13,468 [trainer.py] => seed: 42
2025-12-11 17:06:13,468 [trainer.py] => EPSILON: 1e-08
2025-12-11 17:06:13,468 [trainer.py] => init_epoch: 50
2025-12-11 17:06:13,468 [trainer.py] => optim: adam
2025-12-11 17:06:13,468 [trainer.py] => init_lr: 0.0005
2025-12-11 17:06:13,468 [trainer.py] => init_lr_decay: 0.1
2025-12-11 17:06:13,468 [trainer.py] => init_weight_decay: 0.0
2025-12-11 17:06:13,468 [trainer.py] => epochs: 50
2025-12-11 17:06:13,468 [trainer.py] => lrate: 0.0005
2025-12-11 17:06:13,468 [trainer.py] => lrate_decay: 0.1
2025-12-11 17:06:13,468 [trainer.py] => batch_size: 128
2025-12-11 17:06:13,468 [trainer.py] => weight_decay: 0.0
2025-12-11 17:06:13,468 [trainer.py] => rank: 10
2025-12-11 17:06:13,469 [trainer.py] => lamb: 0.98
2025-12-11 17:06:13,469 [trainer.py] => lame: 1.0
2025-12-11 17:06:13,469 [trainer.py] => num_workers: 8
2025-12-11 17:06:13,469 [trainer.py] => use_wncm: True
2025-12-11 17:06:13,469 [trainer.py] => wncm_lambda: 0.07
2025-12-11 17:06:13,469 [trainer.py] => save_checkpoints: False
2025-12-11 17:06:13,740 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
Loading ViT weights from local checkpoint: /leonardo/home/userexternal/lli00001/vit_b16_in21k.pth
Loaded 152 keys, missing 2402, unexpected 0
2025-12-11 17:06:15,703 [whitened_ncm_head.py] => WhitenedNCM: Using CPU
2025-12-11 17:06:15,710 [trainer.py] => All params: 126094051
2025-12-11 17:06:15,717 [trainer.py] => Trainable params: 126094051
2025-12-11 17:06:15,717 [inflora.py] => Learning on 0-4
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight'}
2025-12-11 17:09:38,854 [inflora.py] => Task 0, Epoch 50/50 => Loss 0.092, Train_accy 96.00
Threshold:  0.98
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 15/768 type remove
Layer 4 : 18/768 type remove
Layer 5 : 30/768 type remove
Layer 6 : 27/768 type remove
Layer 7 : 27/768 type remove
Layer 8 : 34/768 type remove
Layer 9 : 62/768 type remove
Layer 10 : 66/768 type remove
Layer 11 : 30/768 type remove
Layer 12 : 52/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:09:45,452 [trainer.py] => Time:209.73477911949158
155 155
155 155
2025-12-11 17:09:46,927 [trainer.py] => Time:1.4743108749389648
2025-12-11 17:09:46,927 [inflora.py] => Exemplar size: 0
2025-12-11 17:09:46,927 [trainer.py] => CNN: {'total': np.float64(90.32), '00-03': np.float64(90.32), 'old': 0, 'new': np.float64(90.32)}
2025-12-11 17:09:46,927 [trainer.py] => CNN top1 curve: [np.float64(90.32)]
2025-12-11 17:09:46,927 [trainer.py] => CNN top1 with task curve: [np.float64(90.32)]
2025-12-11 17:09:46,927 [trainer.py] => CNN top1 task curve: [1.0]
2025-12-11 17:09:50,881 [trainer.py] => W-NCM: {'00-03': 83.22580645161291}
2025-12-11 17:09:50,881 [trainer.py] => Ave Acc (W-NCM): 83.23%
2025-12-11 17:09:50,881 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 83.23% (best 83.23%)
2025-12-11 17:09:50,881 [trainer.py] => Average forgetting (W-NCM): 0.00% | Max forgetting (W-NCM): 0.00%
2025-12-11 17:09:50,888 [trainer.py] => All params: 126094051
2025-12-11 17:09:50,894 [trainer.py] => Trainable params: 187396
2025-12-11 17:09:50,894 [inflora.py] => Learning on 4-8
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_k.12.weight', 'image_encoder.blocks.8.attn.lora_B_v.15.weight', 'image_encoder.blocks.2.attn.lora_B_k.19.weight', 'image_encoder.blocks.5.attn.lora_B_k.10.weight', 'image_encoder.blocks.9.attn.lora_B_v.14.weight', 'image_encoder.blocks.10.attn.lora_B_v.14.weight', 'image_encoder.blocks.9.attn.lora_B_k.14.weight', 'classifier_pool.18.bias', 'image_encoder.blocks.1.attn.lora_B_k.18.weight', 'image_encoder.blocks.0.attn.lora_B_v.19.weight', 'image_encoder.blocks.1.attn.lora_B_v.10.weight', 'image_encoder.blocks.7.attn.lora_B_v.11.weight', 'image_encoder.blocks.11.attn.lora_B_k.12.weight', 'image_encoder.blocks.1.attn.lora_B_k.10.weight', 'image_encoder.blocks.1.attn.lora_B_v.17.weight', 'image_encoder.blocks.5.attn.lora_B_k.18.weight', 'classifier_pool.14.weight', 'image_encoder.blocks.1.attn.lora_B_k.1.weight', 'image_encoder.blocks.1.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_k.16.weight', 'image_encoder.blocks.10.attn.lora_B_v.16.weight', 'image_encoder.blocks.4.attn.lora_B_v.13.weight', 'image_encoder.blocks.3.attn.lora_B_k.12.weight', 'image_encoder.blocks.3.attn.lora_B_k.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.13.weight', 'image_encoder.blocks.8.attn.lora_B_v.11.weight', 'image_encoder.blocks.0.attn.lora_B_v.17.weight', 'image_encoder.blocks.11.attn.lora_B_v.15.weight', 'image_encoder.blocks.11.attn.lora_B_v.10.weight', 'image_encoder.blocks.3.attn.lora_B_v.16.weight', 'image_encoder.blocks.2.attn.lora_B_k.16.weight', 'image_encoder.blocks.5.attn.lora_B_v.11.weight', 'classifier_pool.17.bias', 'image_encoder.blocks.1.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_k.18.weight', 'image_encoder.blocks.5.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_v.13.weight', 'image_encoder.blocks.8.attn.lora_B_v.16.weight', 'image_encoder.blocks.11.attn.lora_B_v.17.weight', 'image_encoder.blocks.1.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_k.17.weight', 'image_encoder.blocks.7.attn.lora_B_k.17.weight', 'image_encoder.blocks.7.attn.lora_B_k.11.weight', 'image_encoder.blocks.8.attn.lora_B_k.15.weight', 'image_encoder.blocks.9.attn.lora_B_k.19.weight', 'image_encoder.blocks.9.attn.lora_B_v.12.weight', 'image_encoder.blocks.4.attn.lora_B_k.12.weight', 'image_encoder.blocks.1.attn.lora_B_v.16.weight', 'image_encoder.blocks.9.attn.lora_B_v.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.16.weight', 'image_encoder.blocks.3.attn.lora_B_v.12.weight', 'image_encoder.blocks.11.attn.lora_B_k.1.weight', 'image_encoder.blocks.6.attn.lora_B_k.1.weight', 'image_encoder.blocks.9.attn.lora_B_k.12.weight', 'image_encoder.blocks.10.attn.lora_B_k.17.weight', 'image_encoder.blocks.8.attn.lora_B_v.12.weight', 'image_encoder.blocks.6.attn.lora_B_k.17.weight', 'image_encoder.blocks.3.attn.lora_B_k.19.weight', 'image_encoder.blocks.9.attn.lora_B_k.11.weight', 'image_encoder.blocks.11.attn.lora_B_v.12.weight', 'image_encoder.blocks.7.attn.lora_B_v.15.weight', 'image_encoder.blocks.1.attn.lora_B_v.1.weight', 'image_encoder.blocks.3.attn.lora_B_v.1.weight', 'image_encoder.blocks.3.attn.lora_B_k.18.weight', 'image_encoder.blocks.8.attn.lora_B_v.14.weight', 'image_encoder.blocks.0.attn.lora_B_v.16.weight', 'image_encoder.blocks.0.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_k.13.weight', 'image_encoder.blocks.4.attn.lora_B_k.10.weight', 'image_encoder.blocks.4.attn.lora_B_k.17.weight', 'image_encoder.blocks.5.attn.lora_B_k.17.weight', 'image_encoder.blocks.10.attn.lora_B_k.18.weight', 'image_encoder.blocks.8.attn.lora_B_v.19.weight', 'image_encoder.blocks.0.attn.lora_B_k.13.weight', 'image_encoder.blocks.10.attn.lora_B_v.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.19.weight', 'image_encoder.blocks.7.attn.lora_B_v.18.weight', 'image_encoder.blocks.8.attn.lora_B_k.13.weight', 'classifier_pool.18.weight', 'image_encoder.blocks.0.attn.lora_B_v.14.weight', 'image_encoder.blocks.11.attn.lora_B_k.15.weight', 'image_encoder.blocks.10.attn.lora_B_k.11.weight', 'image_encoder.blocks.1.attn.lora_B_k.11.weight', 'image_encoder.blocks.11.attn.lora_B_v.11.weight', 'image_encoder.blocks.0.attn.lora_B_v.18.weight', 'image_encoder.blocks.4.attn.lora_B_v.17.weight', 'image_encoder.blocks.2.attn.lora_B_k.11.weight', 'image_encoder.blocks.7.attn.lora_B_k.16.weight', 'image_encoder.blocks.4.attn.lora_B_v.10.weight', 'image_encoder.blocks.7.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_k.11.weight', 'image_encoder.blocks.11.attn.lora_B_v.18.weight', 'image_encoder.blocks.11.attn.lora_B_v.16.weight', 'image_encoder.blocks.3.attn.lora_B_k.13.weight', 'image_encoder.blocks.5.attn.lora_B_v.17.weight', 'image_encoder.blocks.11.attn.lora_B_v.19.weight', 'image_encoder.blocks.0.attn.lora_B_k.17.weight', 'image_encoder.blocks.9.attn.lora_B_k.16.weight', 'classifier_pool.16.bias', 'image_encoder.blocks.0.attn.lora_B_k.14.weight', 'image_encoder.blocks.10.attn.lora_B_k.10.weight', 'image_encoder.blocks.9.attn.lora_B_v.10.weight', 'image_encoder.blocks.11.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_k.11.weight', 'image_encoder.blocks.9.attn.lora_B_k.18.weight', 'image_encoder.blocks.2.attn.lora_B_v.13.weight', 'image_encoder.blocks.10.attn.lora_B_v.19.weight', 'image_encoder.blocks.9.attn.lora_B_k.15.weight', 'image_encoder.blocks.0.attn.lora_B_k.12.weight', 'image_encoder.blocks.1.attn.lora_B_v.15.weight', 'image_encoder.blocks.8.attn.lora_B_k.18.weight', 'image_encoder.blocks.10.attn.lora_B_k.19.weight', 'image_encoder.blocks.1.attn.lora_B_v.18.weight', 'image_encoder.blocks.5.attn.lora_B_k.15.weight', 'image_encoder.blocks.4.attn.lora_B_k.19.weight', 'image_encoder.blocks.2.attn.lora_B_k.12.weight', 'classifier_pool.16.weight', 'image_encoder.blocks.6.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_k.18.weight', 'image_encoder.blocks.1.attn.lora_B_v.19.weight', 'image_encoder.blocks.10.attn.lora_B_k.12.weight', 'image_encoder.blocks.1.attn.lora_B_k.15.weight', 'classifier_pool.15.weight', 'image_encoder.blocks.3.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_v.18.weight', 'classifier_pool.17.weight', 'image_encoder.blocks.10.attn.lora_B_v.17.weight', 'image_encoder.blocks.6.attn.lora_B_k.18.weight', 'image_encoder.blocks.3.attn.lora_B_v.10.weight', 'image_encoder.blocks.3.attn.lora_B_k.14.weight', 'image_encoder.blocks.9.attn.lora_B_v.17.weight', 'image_encoder.blocks.2.attn.lora_B_v.19.weight', 'image_encoder.blocks.5.attn.lora_B_v.14.weight', 'image_encoder.blocks.7.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.10.weight', 'classifier_pool.12.weight', 'image_encoder.blocks.6.attn.lora_B_v.12.weight', 'image_encoder.blocks.9.attn.lora_B_k.10.weight', 'image_encoder.blocks.4.attn.lora_B_v.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.12.weight', 'image_encoder.blocks.5.attn.lora_B_k.11.weight', 'image_encoder.blocks.10.attn.lora_B_v.12.weight', 'image_encoder.blocks.0.attn.lora_B_v.13.weight', 'image_encoder.blocks.8.attn.lora_B_k.11.weight', 'image_encoder.blocks.5.attn.lora_B_k.1.weight', 'image_encoder.blocks.11.attn.lora_B_k.18.weight', 'image_encoder.blocks.3.attn.lora_B_v.13.weight', 'image_encoder.blocks.0.attn.lora_B_v.10.weight', 'image_encoder.blocks.0.attn.lora_B_k.15.weight', 'image_encoder.blocks.2.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.1.weight', 'image_encoder.blocks.2.attn.lora_B_v.12.weight', 'image_encoder.blocks.2.attn.lora_B_v.18.weight', 'image_encoder.blocks.4.attn.lora_B_v.14.weight', 'image_encoder.blocks.5.attn.lora_B_v.10.weight', 'image_encoder.blocks.7.attn.lora_B_v.16.weight', 'image_encoder.blocks.7.attn.lora_B_v.19.weight', 'image_encoder.blocks.9.attn.lora_B_k.1.weight', 'image_encoder.blocks.1.attn.lora_B_k.13.weight', 'image_encoder.blocks.5.attn.lora_B_v.15.weight', 'image_encoder.blocks.9.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.16.weight', 'classifier_pool.10.weight', 'image_encoder.blocks.2.attn.lora_B_k.17.weight', 'image_encoder.blocks.2.attn.lora_B_k.10.weight', 'image_encoder.blocks.7.attn.lora_B_k.1.weight', 'classifier_pool.10.bias', 'image_encoder.blocks.8.attn.lora_B_v.18.weight', 'image_encoder.blocks.10.attn.lora_B_v.10.weight', 'image_encoder.blocks.9.attn.lora_B_v.15.weight', 'image_encoder.blocks.6.attn.lora_B_k.15.weight', 'image_encoder.blocks.6.attn.lora_B_k.13.weight', 'image_encoder.blocks.7.attn.lora_B_k.12.weight', 'classifier_pool.11.bias', 'image_encoder.blocks.8.attn.lora_B_k.16.weight', 'image_encoder.blocks.4.attn.lora_B_k.11.weight', 'image_encoder.blocks.4.attn.lora_B_v.18.weight', 'image_encoder.blocks.0.attn.lora_B_k.1.weight', 'classifier_pool.1.bias', 'image_encoder.blocks.1.attn.lora_B_v.12.weight', 'image_encoder.blocks.10.attn.lora_B_k.13.weight', 'image_encoder.blocks.6.attn.lora_B_k.10.weight', 'image_encoder.blocks.6.attn.lora_B_v.19.weight', 'image_encoder.blocks.1.attn.lora_B_v.13.weight', 'image_encoder.blocks.5.attn.lora_B_k.19.weight', 'image_encoder.blocks.7.attn.lora_B_k.15.weight', 'image_encoder.blocks.7.attn.lora_B_k.10.weight', 'image_encoder.blocks.9.attn.lora_B_k.13.weight', 'classifier_pool.19.weight', 'image_encoder.blocks.5.attn.lora_B_v.18.weight', 'image_encoder.blocks.11.attn.lora_B_k.19.weight', 'image_encoder.blocks.0.attn.lora_B_k.10.weight', 'image_encoder.blocks.4.attn.lora_B_k.16.weight', 'classifier_pool.13.bias', 'image_encoder.blocks.5.attn.lora_B_k.13.weight', 'image_encoder.blocks.4.attn.lora_B_k.1.weight', 'image_encoder.blocks.3.attn.lora_B_k.16.weight', 'image_encoder.blocks.2.attn.lora_B_v.10.weight', 'image_encoder.blocks.6.attn.lora_B_v.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.13.weight', 'image_encoder.blocks.8.attn.lora_B_k.14.weight', 'image_encoder.blocks.9.attn.lora_B_k.17.weight', 'image_encoder.blocks.7.attn.lora_B_v.13.weight', 'image_encoder.blocks.10.attn.lora_B_k.14.weight', 'image_encoder.blocks.11.attn.lora_B_k.14.weight', 'image_encoder.blocks.5.attn.lora_B_v.19.weight', 'image_encoder.blocks.9.attn.lora_B_v.19.weight', 'image_encoder.blocks.0.attn.lora_B_k.19.weight', 'image_encoder.blocks.0.attn.lora_B_v.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.14.weight', 'image_encoder.blocks.8.attn.lora_B_v.13.weight', 'image_encoder.blocks.4.attn.lora_B_v.19.weight', 'image_encoder.blocks.3.attn.lora_B_v.19.weight', 'classifier_pool.19.bias', 'image_encoder.blocks.0.attn.lora_B_k.18.weight', 'image_encoder.blocks.2.attn.lora_B_v.17.weight', 'image_encoder.blocks.3.attn.lora_B_v.14.weight', 'image_encoder.blocks.5.attn.lora_B_k.12.weight', 'image_encoder.blocks.6.attn.lora_B_k.12.weight', 'image_encoder.blocks.2.attn.lora_B_v.11.weight', 'image_encoder.blocks.3.attn.lora_B_v.15.weight', 'image_encoder.blocks.5.attn.lora_B_v.1.weight', 'image_encoder.blocks.4.attn.lora_B_v.16.weight', 'image_encoder.blocks.4.attn.lora_B_k.14.weight', 'image_encoder.blocks.10.attn.lora_B_v.15.weight', 'classifier_pool.12.bias', 'image_encoder.blocks.8.attn.lora_B_v.10.weight', 'image_encoder.blocks.7.attn.lora_B_v.17.weight', 'image_encoder.blocks.8.attn.lora_B_v.17.weight', 'image_encoder.blocks.2.attn.lora_B_k.15.weight', 'image_encoder.blocks.4.attn.lora_B_v.12.weight', 'image_encoder.blocks.10.attn.lora_B_k.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.11.weight', 'image_encoder.blocks.5.attn.lora_B_v.13.weight', 'classifier_pool.11.weight', 'image_encoder.blocks.1.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.15.weight', 'image_encoder.blocks.1.attn.lora_B_k.14.weight', 'image_encoder.blocks.8.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.18.weight', 'image_encoder.blocks.2.attn.lora_B_k.18.weight', 'image_encoder.blocks.0.attn.lora_B_v.15.weight', 'image_encoder.blocks.9.attn.lora_B_v.16.weight', 'image_encoder.blocks.10.attn.lora_B_k.15.weight', 'image_encoder.blocks.10.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_v.18.weight', 'image_encoder.blocks.6.attn.lora_B_k.19.weight', 'classifier_pool.13.weight', 'image_encoder.blocks.10.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.11.weight', 'image_encoder.blocks.5.attn.lora_B_k.14.weight', 'image_encoder.blocks.2.attn.lora_B_k.13.weight', 'image_encoder.blocks.2.attn.lora_B_v.15.weight', 'image_encoder.blocks.3.attn.lora_B_k.17.weight', 'image_encoder.blocks.6.attn.lora_B_v.14.weight', 'image_encoder.blocks.6.attn.lora_B_v.15.weight', 'image_encoder.blocks.8.attn.lora_B_k.10.weight', 'image_encoder.blocks.11.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_k.13.weight', 'image_encoder.blocks.6.attn.lora_B_v.11.weight', 'image_encoder.blocks.10.attn.lora_B_v.11.weight', 'image_encoder.blocks.3.attn.lora_B_v.17.weight', 'image_encoder.blocks.6.attn.lora_B_v.10.weight', 'image_encoder.blocks.8.attn.lora_B_k.12.weight', 'image_encoder.blocks.4.attn.lora_B_v.15.weight', 'image_encoder.blocks.5.attn.lora_B_v.16.weight', 'image_encoder.blocks.7.attn.lora_B_v.10.weight', 'classifier_pool.15.bias', 'classifier_pool.1.weight', 'image_encoder.blocks.7.attn.lora_B_v.12.weight', 'image_encoder.blocks.8.attn.lora_B_k.1.weight', 'image_encoder.blocks.4.attn.lora_B_k.15.weight', 'image_encoder.blocks.8.attn.lora_B_k.17.weight', 'image_encoder.blocks.9.attn.lora_B_v.18.weight', 'classifier_pool.14.bias', 'image_encoder.blocks.7.attn.lora_B_v.14.weight', 'image_encoder.blocks.3.attn.lora_B_k.11.weight', 'image_encoder.blocks.2.attn.lora_B_k.14.weight', 'image_encoder.blocks.0.attn.lora_B_v.12.weight', 'image_encoder.blocks.6.attn.lora_B_k.14.weight', 'image_encoder.blocks.2.attn.lora_B_v.16.weight', 'image_encoder.blocks.1.attn.lora_B_v.14.weight', 'image_encoder.blocks.9.attn.lora_B_v.11.weight'}
2025-12-11 17:12:57,711 [inflora.py] => Task 1, Epoch 50/50 => Loss 0.065, Train_accy 98.04
Threshold:  0.9803999999999999
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 18/768 type remove
Layer 4 : 22/768 type remove
Layer 5 : 34/768 type remove
Layer 6 : 30/768 type remove
Layer 7 : 32/768 type remove
Layer 8 : 38/768 type remove
Layer 9 : 70/768 type remove
Layer 10 : 80/768 type remove
Layer 11 : 37/768 type remove
Layer 12 : 60/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:13:05,726 [trainer.py] => Time:194.8319447040558
300 300
300 300
2025-12-11 17:13:07,467 [trainer.py] => Time:1.740046501159668
2025-12-11 17:13:07,467 [inflora.py] => Exemplar size: 0
2025-12-11 17:13:07,467 [trainer.py] => CNN: {'total': np.float64(82.67), '00-03': np.float64(81.29), '04-07': np.float64(84.14), 'old': np.float64(81.29), 'new': np.float64(84.14)}
2025-12-11 17:13:07,467 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67)]
2025-12-11 17:13:07,467 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33)]
2025-12-11 17:13:07,467 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666]
2025-12-11 17:13:11,631 [trainer.py] => W-NCM: {'00-03': 76.77419354838709, '04-07': 93.79310344827586}
2025-12-11 17:13:11,631 [trainer.py] => Ave Acc (W-NCM): 85.28%
2025-12-11 17:13:11,631 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 76.77% (best 83.23%); T2: W-NCM 93.79% (best 93.79%)
2025-12-11 17:13:11,631 [trainer.py] => Average forgetting (W-NCM): 6.45% | Max forgetting (W-NCM): 6.45%
2025-12-11 17:13:11,638 [trainer.py] => All params: 126094051
2025-12-11 17:13:11,644 [trainer.py] => Trainable params: 2061356
2025-12-11 17:13:11,644 [inflora.py] => Learning on 8-12
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.29.weight', 'image_encoder.blocks.5.attn.lora_B_k.29.weight', 'image_encoder.blocks.6.attn.lora_B_k.21.weight', 'image_encoder.blocks.3.attn.lora_B_v.21.weight', 'image_encoder.blocks.3.attn.lora_B_k.23.weight', 'image_encoder.blocks.5.attn.lora_B_k.2.weight', 'image_encoder.blocks.1.attn.lora_B_v.20.weight', 'image_encoder.blocks.11.attn.lora_B_k.21.weight', 'classifier_pool.23.weight', 'image_encoder.blocks.1.attn.lora_B_v.24.weight', 'image_encoder.blocks.9.attn.lora_B_k.29.weight', 'image_encoder.blocks.3.attn.lora_B_v.25.weight', 'image_encoder.blocks.9.attn.lora_B_v.27.weight', 'image_encoder.blocks.7.attn.lora_B_v.26.weight', 'image_encoder.blocks.0.attn.lora_B_v.29.weight', 'image_encoder.blocks.6.attn.lora_B_v.29.weight', 'image_encoder.blocks.10.attn.lora_B_v.26.weight', 'image_encoder.blocks.11.attn.lora_B_v.24.weight', 'image_encoder.blocks.2.attn.lora_B_v.23.weight', 'image_encoder.blocks.11.attn.lora_B_k.20.weight', 'image_encoder.blocks.3.attn.lora_B_v.24.weight', 'image_encoder.blocks.5.attn.lora_B_k.26.weight', 'image_encoder.blocks.6.attn.lora_B_k.26.weight', 'image_encoder.blocks.5.attn.lora_B_v.25.weight', 'image_encoder.blocks.4.attn.lora_B_v.25.weight', 'image_encoder.blocks.0.attn.lora_B_k.28.weight', 'image_encoder.blocks.1.attn.lora_B_v.2.weight', 'image_encoder.blocks.0.attn.lora_B_k.25.weight', 'image_encoder.blocks.4.attn.lora_B_v.22.weight', 'image_encoder.blocks.5.attn.lora_B_k.22.weight', 'image_encoder.blocks.5.attn.lora_B_v.22.weight', 'image_encoder.blocks.5.attn.lora_B_v.27.weight', 'image_encoder.blocks.0.attn.lora_B_k.24.weight', 'image_encoder.blocks.7.attn.lora_B_v.28.weight', 'image_encoder.blocks.8.attn.lora_B_v.26.weight', 'image_encoder.blocks.2.attn.lora_B_k.26.weight', 'image_encoder.blocks.3.attn.lora_B_k.24.weight', 'image_encoder.blocks.8.attn.lora_B_k.2.weight', 'image_encoder.blocks.10.attn.lora_B_v.24.weight', 'image_encoder.blocks.10.attn.lora_B_v.29.weight', 'classifier_pool.29.weight', 'image_encoder.blocks.3.attn.lora_B_v.29.weight', 'image_encoder.blocks.3.attn.lora_B_v.2.weight', 'image_encoder.blocks.5.attn.lora_B_v.21.weight', 'image_encoder.blocks.11.attn.lora_B_v.29.weight', 'image_encoder.blocks.9.attn.lora_B_v.29.weight', 'image_encoder.blocks.7.attn.lora_B_k.26.weight', 'image_encoder.blocks.1.attn.lora_B_k.21.weight', 'classifier_pool.26.weight', 'image_encoder.blocks.7.attn.lora_B_v.21.weight', 'image_encoder.blocks.5.attn.lora_B_k.27.weight', 'image_encoder.blocks.8.attn.lora_B_k.29.weight', 'image_encoder.blocks.2.attn.lora_B_k.20.weight', 'image_encoder.blocks.4.attn.lora_B_k.27.weight', 'classifier_pool.24.weight', 'image_encoder.blocks.7.attn.lora_B_k.20.weight', 'image_encoder.blocks.10.attn.lora_B_k.24.weight', 'image_encoder.blocks.10.attn.lora_B_k.28.weight', 'image_encoder.blocks.4.attn.lora_B_k.23.weight', 'image_encoder.blocks.5.attn.lora_B_k.21.weight', 'image_encoder.blocks.11.attn.lora_B_k.22.weight', 'image_encoder.blocks.7.attn.lora_B_k.21.weight', 'image_encoder.blocks.11.attn.lora_B_v.20.weight', 'image_encoder.blocks.0.attn.lora_B_k.23.weight', 'image_encoder.blocks.6.attn.lora_B_v.22.weight', 'image_encoder.blocks.11.attn.lora_B_v.23.weight', 'classifier_pool.22.weight', 'image_encoder.blocks.0.attn.lora_B_v.2.weight', 'image_encoder.blocks.10.attn.lora_B_k.22.weight', 'image_encoder.blocks.10.attn.lora_B_v.2.weight', 'image_encoder.blocks.7.attn.lora_B_v.20.weight', 'image_encoder.blocks.9.attn.lora_B_k.27.weight', 'image_encoder.blocks.7.attn.lora_B_k.2.weight', 'image_encoder.blocks.9.attn.lora_B_v.20.weight', 'image_encoder.blocks.9.attn.lora_B_k.26.weight', 'image_encoder.blocks.8.attn.lora_B_k.28.weight', 'image_encoder.blocks.1.attn.lora_B_k.27.weight', 'image_encoder.blocks.10.attn.lora_B_v.23.weight', 'image_encoder.blocks.11.attn.lora_B_v.2.weight', 'image_encoder.blocks.8.attn.lora_B_v.23.weight', 'image_encoder.blocks.5.attn.lora_B_k.24.weight', 'image_encoder.blocks.7.attn.lora_B_k.23.weight', 'image_encoder.blocks.9.attn.lora_B_v.25.weight', 'image_encoder.blocks.11.attn.lora_B_v.22.weight', 'image_encoder.blocks.5.attn.lora_B_v.20.weight', 'image_encoder.blocks.10.attn.lora_B_k.27.weight', 'image_encoder.blocks.3.attn.lora_B_k.29.weight', 'image_encoder.blocks.10.attn.lora_B_k.2.weight', 'classifier_pool.21.bias', 'image_encoder.blocks.1.attn.lora_B_v.22.weight', 'image_encoder.blocks.2.attn.lora_B_k.2.weight', 'image_encoder.blocks.4.attn.lora_B_v.26.weight', 'image_encoder.blocks.1.attn.lora_B_v.21.weight', 'image_encoder.blocks.9.attn.lora_B_v.23.weight', 'image_encoder.blocks.9.attn.lora_B_k.22.weight', 'image_encoder.blocks.6.attn.lora_B_k.25.weight', 'image_encoder.blocks.9.attn.lora_B_k.20.weight', 'image_encoder.blocks.7.attn.lora_B_k.27.weight', 'image_encoder.blocks.10.attn.lora_B_k.20.weight', 'image_encoder.blocks.1.attn.lora_B_k.26.weight', 'classifier_pool.28.weight', 'image_encoder.blocks.0.attn.lora_B_v.21.weight', 'image_encoder.blocks.9.attn.lora_B_v.24.weight', 'image_encoder.blocks.5.attn.lora_B_k.28.weight', 'image_encoder.blocks.1.attn.lora_B_k.2.weight', 'image_encoder.blocks.8.attn.lora_B_k.23.weight', 'image_encoder.blocks.1.attn.lora_B_k.24.weight', 'image_encoder.blocks.7.attn.lora_B_k.25.weight', 'image_encoder.blocks.6.attn.lora_B_k.20.weight', 'image_encoder.blocks.4.attn.lora_B_v.28.weight', 'image_encoder.blocks.10.attn.lora_B_v.22.weight', 'image_encoder.blocks.3.attn.lora_B_v.23.weight', 'classifier_pool.20.bias', 'image_encoder.blocks.6.attn.lora_B_k.2.weight', 'image_encoder.blocks.0.attn.lora_B_k.21.weight', 'image_encoder.blocks.2.attn.lora_B_v.21.weight', 'image_encoder.blocks.4.attn.lora_B_v.23.weight', 'image_encoder.blocks.4.attn.lora_B_v.24.weight', 'image_encoder.blocks.2.attn.lora_B_v.22.weight', 'image_encoder.blocks.9.attn.lora_B_k.2.weight', 'image_encoder.blocks.4.attn.lora_B_k.21.weight', 'image_encoder.blocks.11.attn.lora_B_k.26.weight', 'image_encoder.blocks.4.attn.lora_B_k.26.weight', 'image_encoder.blocks.11.attn.lora_B_k.29.weight', 'image_encoder.blocks.4.attn.lora_B_k.22.weight', 'image_encoder.blocks.8.attn.lora_B_k.21.weight', 'image_encoder.blocks.6.attn.lora_B_k.24.weight', 'image_encoder.blocks.0.attn.lora_B_k.22.weight', 'image_encoder.blocks.8.attn.lora_B_v.27.weight', 'image_encoder.blocks.5.attn.lora_B_v.23.weight', 'image_encoder.blocks.8.attn.lora_B_k.25.weight', 'image_encoder.blocks.9.attn.lora_B_v.26.weight', 'image_encoder.blocks.2.attn.lora_B_k.27.weight', 'image_encoder.blocks.7.attn.lora_B_k.24.weight', 'image_encoder.blocks.4.attn.lora_B_v.27.weight', 'image_encoder.blocks.11.attn.lora_B_k.2.weight', 'image_encoder.blocks.11.attn.lora_B_k.23.weight', 'image_encoder.blocks.8.attn.lora_B_v.25.weight', 'image_encoder.blocks.10.attn.lora_B_v.25.weight', 'image_encoder.blocks.9.attn.lora_B_v.22.weight', 'image_encoder.blocks.5.attn.lora_B_v.2.weight', 'image_encoder.blocks.4.attn.lora_B_k.25.weight', 'image_encoder.blocks.9.attn.lora_B_k.24.weight', 'image_encoder.blocks.0.attn.lora_B_k.26.weight', 'image_encoder.blocks.6.attn.lora_B_v.28.weight', 'image_encoder.blocks.10.attn.lora_B_k.26.weight', 'image_encoder.blocks.4.attn.lora_B_k.24.weight', 'image_encoder.blocks.1.attn.lora_B_k.20.weight', 'image_encoder.blocks.9.attn.lora_B_k.28.weight', 'image_encoder.blocks.11.attn.lora_B_k.24.weight', 'image_encoder.blocks.10.attn.lora_B_v.28.weight', 'classifier_pool.27.weight', 'image_encoder.blocks.11.attn.lora_B_v.27.weight', 'classifier_pool.2.weight', 'image_encoder.blocks.6.attn.lora_B_v.2.weight', 'image_encoder.blocks.3.attn.lora_B_k.22.weight', 'classifier_pool.23.bias', 'image_encoder.blocks.0.attn.lora_B_v.28.weight', 'image_encoder.blocks.0.attn.lora_B_k.29.weight', 'image_encoder.blocks.4.attn.lora_B_k.20.weight', 'image_encoder.blocks.10.attn.lora_B_v.27.weight', 'image_encoder.blocks.3.attn.lora_B_k.27.weight', 'image_encoder.blocks.5.attn.lora_B_v.24.weight', 'image_encoder.blocks.10.attn.lora_B_k.29.weight', 'image_encoder.blocks.2.attn.lora_B_v.26.weight', 'image_encoder.blocks.5.attn.lora_B_v.29.weight', 'classifier_pool.21.weight', 'image_encoder.blocks.3.attn.lora_B_k.26.weight', 'image_encoder.blocks.6.attn.lora_B_k.22.weight', 'image_encoder.blocks.6.attn.lora_B_v.27.weight', 'image_encoder.blocks.0.attn.lora_B_v.27.weight', 'image_encoder.blocks.3.attn.lora_B_k.28.weight', 'image_encoder.blocks.3.attn.lora_B_v.22.weight', 'image_encoder.blocks.2.attn.lora_B_v.20.weight', 'classifier_pool.26.bias', 'image_encoder.blocks.10.attn.lora_B_v.20.weight', 'image_encoder.blocks.8.attn.lora_B_v.21.weight', 'image_encoder.blocks.2.attn.lora_B_v.27.weight', 'image_encoder.blocks.8.attn.lora_B_k.24.weight', 'classifier_pool.2.bias', 'image_encoder.blocks.7.attn.lora_B_v.23.weight', 'image_encoder.blocks.3.attn.lora_B_v.20.weight', 'image_encoder.blocks.8.attn.lora_B_v.22.weight', 'image_encoder.blocks.0.attn.lora_B_k.27.weight', 'image_encoder.blocks.4.attn.lora_B_v.21.weight', 'image_encoder.blocks.2.attn.lora_B_k.29.weight', 'image_encoder.blocks.1.attn.lora_B_v.29.weight', 'image_encoder.blocks.7.attn.lora_B_v.2.weight', 'classifier_pool.28.bias', 'image_encoder.blocks.0.attn.lora_B_v.20.weight', 'image_encoder.blocks.8.attn.lora_B_v.28.weight', 'image_encoder.blocks.11.attn.lora_B_v.26.weight', 'image_encoder.blocks.8.attn.lora_B_v.29.weight', 'image_encoder.blocks.9.attn.lora_B_k.25.weight', 'image_encoder.blocks.11.attn.lora_B_v.25.weight', 'image_encoder.blocks.7.attn.lora_B_v.27.weight', 'image_encoder.blocks.6.attn.lora_B_k.29.weight', 'image_encoder.blocks.6.attn.lora_B_v.24.weight', 'image_encoder.blocks.7.attn.lora_B_k.22.weight', 'image_encoder.blocks.11.attn.lora_B_v.28.weight', 'image_encoder.blocks.1.attn.lora_B_k.23.weight', 'image_encoder.blocks.0.attn.lora_B_k.20.weight', 'image_encoder.blocks.2.attn.lora_B_k.23.weight', 'image_encoder.blocks.9.attn.lora_B_k.21.weight', 'image_encoder.blocks.1.attn.lora_B_v.26.weight', 'image_encoder.blocks.9.attn.lora_B_v.2.weight', 'classifier_pool.24.bias', 'image_encoder.blocks.0.attn.lora_B_v.23.weight', 'image_encoder.blocks.0.attn.lora_B_v.26.weight', 'image_encoder.blocks.2.attn.lora_B_k.25.weight', 'image_encoder.blocks.10.attn.lora_B_k.21.weight', 'image_encoder.blocks.2.attn.lora_B_k.28.weight', 'image_encoder.blocks.2.attn.lora_B_k.24.weight', 'image_encoder.blocks.4.attn.lora_B_v.20.weight', 'image_encoder.blocks.5.attn.lora_B_k.25.weight', 'image_encoder.blocks.1.attn.lora_B_v.28.weight', 'image_encoder.blocks.6.attn.lora_B_v.25.weight', 'image_encoder.blocks.2.attn.lora_B_v.25.weight', 'image_encoder.blocks.7.attn.lora_B_v.22.weight', 'image_encoder.blocks.1.attn.lora_B_k.28.weight', 'image_encoder.blocks.5.attn.lora_B_v.28.weight', 'image_encoder.blocks.10.attn.lora_B_v.21.weight', 'classifier_pool.20.weight', 'image_encoder.blocks.0.attn.lora_B_k.2.weight', 'image_encoder.blocks.11.attn.lora_B_k.28.weight', 'image_encoder.blocks.4.attn.lora_B_v.29.weight', 'image_encoder.blocks.1.attn.lora_B_k.22.weight', 'image_encoder.blocks.2.attn.lora_B_v.24.weight', 'image_encoder.blocks.6.attn.lora_B_k.27.weight', 'image_encoder.blocks.3.attn.lora_B_v.26.weight', 'image_encoder.blocks.9.attn.lora_B_v.21.weight', 'image_encoder.blocks.11.attn.lora_B_k.27.weight', 'image_encoder.blocks.5.attn.lora_B_v.26.weight', 'image_encoder.blocks.0.attn.lora_B_v.22.weight', 'image_encoder.blocks.3.attn.lora_B_k.21.weight', 'image_encoder.blocks.8.attn.lora_B_k.22.weight', 'image_encoder.blocks.8.attn.lora_B_v.24.weight', 'image_encoder.blocks.10.attn.lora_B_k.23.weight', 'image_encoder.blocks.6.attn.lora_B_v.20.weight', 'image_encoder.blocks.2.attn.lora_B_v.29.weight', 'image_encoder.blocks.3.attn.lora_B_k.25.weight', 'classifier_pool.22.bias', 'image_encoder.blocks.2.attn.lora_B_k.22.weight', 'image_encoder.blocks.3.attn.lora_B_k.20.weight', 'image_encoder.blocks.7.attn.lora_B_k.28.weight', 'image_encoder.blocks.2.attn.lora_B_v.28.weight', 'image_encoder.blocks.6.attn.lora_B_k.28.weight', 'image_encoder.blocks.0.attn.lora_B_v.24.weight', 'image_encoder.blocks.1.attn.lora_B_k.29.weight', 'image_encoder.blocks.8.attn.lora_B_k.26.weight', 'image_encoder.blocks.4.attn.lora_B_k.28.weight', 'image_encoder.blocks.5.attn.lora_B_k.23.weight', 'image_encoder.blocks.5.attn.lora_B_k.20.weight', 'image_encoder.blocks.6.attn.lora_B_v.21.weight', 'image_encoder.blocks.1.attn.lora_B_k.25.weight', 'image_encoder.blocks.6.attn.lora_B_v.23.weight', 'image_encoder.blocks.7.attn.lora_B_k.29.weight', 'image_encoder.blocks.8.attn.lora_B_v.2.weight', 'classifier_pool.25.weight', 'image_encoder.blocks.11.attn.lora_B_v.21.weight', 'image_encoder.blocks.8.attn.lora_B_k.27.weight', 'image_encoder.blocks.2.attn.lora_B_v.2.weight', 'image_encoder.blocks.6.attn.lora_B_v.26.weight', 'classifier_pool.27.bias', 'image_encoder.blocks.3.attn.lora_B_v.28.weight', 'image_encoder.blocks.1.attn.lora_B_v.27.weight', 'image_encoder.blocks.7.attn.lora_B_v.24.weight', 'image_encoder.blocks.9.attn.lora_B_v.28.weight', 'image_encoder.blocks.2.attn.lora_B_k.21.weight', 'image_encoder.blocks.1.attn.lora_B_v.25.weight', 'image_encoder.blocks.1.attn.lora_B_v.23.weight', 'image_encoder.blocks.8.attn.lora_B_v.20.weight', 'image_encoder.blocks.7.attn.lora_B_v.25.weight', 'image_encoder.blocks.8.attn.lora_B_k.20.weight', 'image_encoder.blocks.0.attn.lora_B_v.25.weight', 'image_encoder.blocks.4.attn.lora_B_k.2.weight', 'image_encoder.blocks.7.attn.lora_B_v.29.weight', 'image_encoder.blocks.10.attn.lora_B_k.25.weight', 'image_encoder.blocks.11.attn.lora_B_k.25.weight', 'classifier_pool.25.bias', 'image_encoder.blocks.3.attn.lora_B_v.27.weight', 'image_encoder.blocks.3.attn.lora_B_k.2.weight', 'classifier_pool.29.bias', 'image_encoder.blocks.4.attn.lora_B_v.2.weight', 'image_encoder.blocks.9.attn.lora_B_k.23.weight', 'image_encoder.blocks.6.attn.lora_B_k.23.weight'}
2025-12-11 17:16:32,267 [inflora.py] => Task 2, Epoch 50/50 => Loss 0.074, Train_accy 97.80
Threshold:  0.9808
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 22/768 type remove
Layer 4 : 26/768 type remove
Layer 5 : 39/768 type remove
Layer 6 : 33/768 type remove
Layer 7 : 35/768 type remove
Layer 8 : 42/768 type remove
Layer 9 : 76/768 type remove
Layer 10 : 89/768 type remove
Layer 11 : 45/768 type remove
Layer 12 : 68/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:16:40,726 [trainer.py] => Time:209.08207082748413
414 414
414 414
2025-12-11 17:16:42,770 [trainer.py] => Time:2.0435941219329834
2025-12-11 17:16:42,770 [inflora.py] => Exemplar size: 0
2025-12-11 17:16:42,770 [trainer.py] => CNN: {'total': np.float64(80.43), '00-03': np.float64(79.35), '04-07': np.float64(82.07), '08-11': np.float64(79.82), 'old': np.float64(80.67), 'new': np.float64(79.82)}
2025-12-11 17:16:42,770 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43)]
2025-12-11 17:16:42,770 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1)]
2025-12-11 17:16:42,770 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102]
2025-12-11 17:16:47,418 [trainer.py] => W-NCM: {'00-03': 78.06451612903226, '04-07': 83.44827586206897, '08-11': 84.21052631578947}
2025-12-11 17:16:47,418 [trainer.py] => Ave Acc (W-NCM): 81.91%
2025-12-11 17:16:47,418 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 78.06% (best 83.23%); T2: W-NCM 83.45% (best 93.79%); T3: W-NCM 84.21% (best 84.21%)
2025-12-11 17:16:47,418 [trainer.py] => Average forgetting (W-NCM): 7.75% | Max forgetting (W-NCM): 10.34%
2025-12-11 17:16:47,425 [trainer.py] => All params: 126094051
2025-12-11 17:16:47,432 [trainer.py] => Trainable params: 2061356
2025-12-11 17:16:47,432 [inflora.py] => Learning on 12-16
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.35.weight', 'classifier_pool.36.bias', 'image_encoder.blocks.6.attn.lora_B_v.34.weight', 'image_encoder.blocks.11.attn.lora_B_k.3.weight', 'image_encoder.blocks.9.attn.lora_B_k.30.weight', 'image_encoder.blocks.9.attn.lora_B_k.32.weight', 'image_encoder.blocks.11.attn.lora_B_v.3.weight', 'image_encoder.blocks.8.attn.lora_B_k.3.weight', 'image_encoder.blocks.5.attn.lora_B_v.39.weight', 'image_encoder.blocks.11.attn.lora_B_v.39.weight', 'image_encoder.blocks.11.attn.lora_B_v.38.weight', 'image_encoder.blocks.9.attn.lora_B_k.37.weight', 'classifier_pool.31.bias', 'image_encoder.blocks.0.attn.lora_B_v.3.weight', 'image_encoder.blocks.2.attn.lora_B_k.32.weight', 'image_encoder.blocks.2.attn.lora_B_k.39.weight', 'image_encoder.blocks.4.attn.lora_B_k.32.weight', 'image_encoder.blocks.10.attn.lora_B_k.3.weight', 'image_encoder.blocks.9.attn.lora_B_k.34.weight', 'classifier_pool.34.bias', 'classifier_pool.36.weight', 'image_encoder.blocks.4.attn.lora_B_v.33.weight', 'image_encoder.blocks.6.attn.lora_B_v.30.weight', 'image_encoder.blocks.6.attn.lora_B_v.38.weight', 'image_encoder.blocks.10.attn.lora_B_v.34.weight', 'classifier_pool.38.bias', 'image_encoder.blocks.10.attn.lora_B_k.36.weight', 'image_encoder.blocks.8.attn.lora_B_k.31.weight', 'image_encoder.blocks.2.attn.lora_B_k.38.weight', 'image_encoder.blocks.6.attn.lora_B_v.3.weight', 'image_encoder.blocks.11.attn.lora_B_v.35.weight', 'image_encoder.blocks.4.attn.lora_B_v.39.weight', 'image_encoder.blocks.10.attn.lora_B_k.35.weight', 'image_encoder.blocks.6.attn.lora_B_k.35.weight', 'classifier_pool.3.weight', 'image_encoder.blocks.4.attn.lora_B_k.37.weight', 'image_encoder.blocks.6.attn.lora_B_k.37.weight', 'image_encoder.blocks.1.attn.lora_B_v.35.weight', 'image_encoder.blocks.5.attn.lora_B_v.3.weight', 'image_encoder.blocks.8.attn.lora_B_k.38.weight', 'image_encoder.blocks.11.attn.lora_B_k.35.weight', 'image_encoder.blocks.3.attn.lora_B_k.33.weight', 'image_encoder.blocks.8.attn.lora_B_v.33.weight', 'image_encoder.blocks.9.attn.lora_B_k.38.weight', 'image_encoder.blocks.1.attn.lora_B_k.32.weight', 'image_encoder.blocks.7.attn.lora_B_v.39.weight', 'image_encoder.blocks.3.attn.lora_B_v.36.weight', 'image_encoder.blocks.10.attn.lora_B_k.33.weight', 'image_encoder.blocks.1.attn.lora_B_k.36.weight', 'image_encoder.blocks.5.attn.lora_B_k.35.weight', 'image_encoder.blocks.5.attn.lora_B_k.3.weight', 'image_encoder.blocks.5.attn.lora_B_k.38.weight', 'image_encoder.blocks.4.attn.lora_B_v.32.weight', 'image_encoder.blocks.9.attn.lora_B_v.38.weight', 'image_encoder.blocks.0.attn.lora_B_v.36.weight', 'image_encoder.blocks.8.attn.lora_B_v.35.weight', 'image_encoder.blocks.10.attn.lora_B_v.31.weight', 'image_encoder.blocks.11.attn.lora_B_k.34.weight', 'image_encoder.blocks.1.attn.lora_B_k.37.weight', 'image_encoder.blocks.4.attn.lora_B_k.38.weight', 'image_encoder.blocks.7.attn.lora_B_k.34.weight', 'image_encoder.blocks.10.attn.lora_B_k.37.weight', 'image_encoder.blocks.9.attn.lora_B_v.3.weight', 'classifier_pool.38.weight', 'image_encoder.blocks.7.attn.lora_B_k.3.weight', 'image_encoder.blocks.7.attn.lora_B_k.31.weight', 'image_encoder.blocks.10.attn.lora_B_k.38.weight', 'image_encoder.blocks.8.attn.lora_B_k.37.weight', 'image_encoder.blocks.5.attn.lora_B_k.31.weight', 'image_encoder.blocks.1.attn.lora_B_k.38.weight', 'image_encoder.blocks.5.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_v.34.weight', 'image_encoder.blocks.8.attn.lora_B_k.35.weight', 'image_encoder.blocks.3.attn.lora_B_v.38.weight', 'classifier_pool.30.weight', 'image_encoder.blocks.5.attn.lora_B_k.30.weight', 'image_encoder.blocks.2.attn.lora_B_v.36.weight', 'image_encoder.blocks.1.attn.lora_B_k.30.weight', 'classifier_pool.3.bias', 'image_encoder.blocks.9.attn.lora_B_v.36.weight', 'image_encoder.blocks.1.attn.lora_B_k.39.weight', 'image_encoder.blocks.8.attn.lora_B_k.36.weight', 'image_encoder.blocks.9.attn.lora_B_v.35.weight', 'image_encoder.blocks.1.attn.lora_B_v.31.weight', 'image_encoder.blocks.9.attn.lora_B_k.39.weight', 'image_encoder.blocks.0.attn.lora_B_v.34.weight', 'image_encoder.blocks.0.attn.lora_B_v.38.weight', 'image_encoder.blocks.2.attn.lora_B_k.31.weight', 'image_encoder.blocks.9.attn.lora_B_k.35.weight', 'image_encoder.blocks.0.attn.lora_B_k.34.weight', 'image_encoder.blocks.11.attn.lora_B_k.30.weight', 'classifier_pool.34.weight', 'image_encoder.blocks.4.attn.lora_B_v.36.weight', 'image_encoder.blocks.7.attn.lora_B_k.33.weight', 'image_encoder.blocks.7.attn.lora_B_v.38.weight', 'image_encoder.blocks.4.attn.lora_B_v.37.weight', 'image_encoder.blocks.4.attn.lora_B_v.38.weight', 'classifier_pool.32.weight', 'classifier_pool.32.bias', 'image_encoder.blocks.6.attn.lora_B_v.32.weight', 'image_encoder.blocks.7.attn.lora_B_v.33.weight', 'classifier_pool.37.bias', 'image_encoder.blocks.4.attn.lora_B_v.35.weight', 'image_encoder.blocks.0.attn.lora_B_k.32.weight', 'image_encoder.blocks.10.attn.lora_B_v.33.weight', 'classifier_pool.35.bias', 'image_encoder.blocks.7.attn.lora_B_k.32.weight', 'image_encoder.blocks.7.attn.lora_B_k.39.weight', 'image_encoder.blocks.5.attn.lora_B_k.36.weight', 'image_encoder.blocks.4.attn.lora_B_v.3.weight', 'image_encoder.blocks.4.attn.lora_B_k.3.weight', 'image_encoder.blocks.8.attn.lora_B_v.37.weight', 'image_encoder.blocks.11.attn.lora_B_k.31.weight', 'image_encoder.blocks.11.attn.lora_B_v.33.weight', 'image_encoder.blocks.0.attn.lora_B_k.35.weight', 'classifier_pool.37.weight', 'image_encoder.blocks.1.attn.lora_B_k.35.weight', 'image_encoder.blocks.9.attn.lora_B_v.39.weight', 'image_encoder.blocks.0.attn.lora_B_k.37.weight', 'image_encoder.blocks.7.attn.lora_B_v.3.weight', 'image_encoder.blocks.10.attn.lora_B_v.38.weight', 'image_encoder.blocks.9.attn.lora_B_k.3.weight', 'image_encoder.blocks.3.attn.lora_B_k.31.weight', 'image_encoder.blocks.0.attn.lora_B_v.37.weight', 'image_encoder.blocks.5.attn.lora_B_k.39.weight', 'image_encoder.blocks.5.attn.lora_B_v.31.weight', 'image_encoder.blocks.5.attn.lora_B_v.37.weight', 'image_encoder.blocks.1.attn.lora_B_v.34.weight', 'image_encoder.blocks.3.attn.lora_B_v.33.weight', 'image_encoder.blocks.1.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_k.30.weight', 'image_encoder.blocks.8.attn.lora_B_k.39.weight', 'image_encoder.blocks.9.attn.lora_B_k.33.weight', 'image_encoder.blocks.4.attn.lora_B_v.31.weight', 'image_encoder.blocks.9.attn.lora_B_v.34.weight', 'image_encoder.blocks.10.attn.lora_B_k.30.weight', 'image_encoder.blocks.10.attn.lora_B_v.3.weight', 'image_encoder.blocks.11.attn.lora_B_k.38.weight', 'image_encoder.blocks.5.attn.lora_B_v.36.weight', 'image_encoder.blocks.7.attn.lora_B_v.34.weight', 'image_encoder.blocks.3.attn.lora_B_v.31.weight', 'image_encoder.blocks.8.attn.lora_B_v.30.weight', 'image_encoder.blocks.9.attn.lora_B_k.36.weight', 'image_encoder.blocks.2.attn.lora_B_k.34.weight', 'image_encoder.blocks.10.attn.lora_B_k.34.weight', 'image_encoder.blocks.1.attn.lora_B_v.37.weight', 'image_encoder.blocks.10.attn.lora_B_k.32.weight', 'image_encoder.blocks.3.attn.lora_B_k.35.weight', 'image_encoder.blocks.0.attn.lora_B_v.30.weight', 'image_encoder.blocks.7.attn.lora_B_k.38.weight', 'image_encoder.blocks.2.attn.lora_B_k.35.weight', 'image_encoder.blocks.0.attn.lora_B_k.36.weight', 'image_encoder.blocks.1.attn.lora_B_k.31.weight', 'image_encoder.blocks.1.attn.lora_B_v.38.weight', 'image_encoder.blocks.2.attn.lora_B_v.31.weight', 'image_encoder.blocks.4.attn.lora_B_v.30.weight', 'image_encoder.blocks.6.attn.lora_B_k.39.weight', 'image_encoder.blocks.11.attn.lora_B_v.30.weight', 'image_encoder.blocks.8.attn.lora_B_v.34.weight', 'image_encoder.blocks.2.attn.lora_B_v.35.weight', 'image_encoder.blocks.6.attn.lora_B_k.38.weight', 'image_encoder.blocks.11.attn.lora_B_k.36.weight', 'image_encoder.blocks.11.attn.lora_B_v.34.weight', 'image_encoder.blocks.2.attn.lora_B_v.38.weight', 'image_encoder.blocks.11.attn.lora_B_v.32.weight', 'image_encoder.blocks.6.attn.lora_B_v.35.weight', 'image_encoder.blocks.8.attn.lora_B_v.3.weight', 'classifier_pool.33.weight', 'image_encoder.blocks.5.attn.lora_B_v.33.weight', 'image_encoder.blocks.10.attn.lora_B_v.39.weight', 'image_encoder.blocks.3.attn.lora_B_k.37.weight', 'image_encoder.blocks.4.attn.lora_B_k.31.weight', 'classifier_pool.33.bias', 'image_encoder.blocks.2.attn.lora_B_v.37.weight', 'image_encoder.blocks.3.attn.lora_B_v.32.weight', 'image_encoder.blocks.7.attn.lora_B_k.35.weight', 'image_encoder.blocks.1.attn.lora_B_v.39.weight', 'image_encoder.blocks.8.attn.lora_B_k.30.weight', 'image_encoder.blocks.0.attn.lora_B_v.31.weight', 'image_encoder.blocks.1.attn.lora_B_k.34.weight', 'image_encoder.blocks.8.attn.lora_B_k.34.weight', 'image_encoder.blocks.6.attn.lora_B_k.32.weight', 'image_encoder.blocks.1.attn.lora_B_v.36.weight', 'image_encoder.blocks.9.attn.lora_B_v.31.weight', 'image_encoder.blocks.9.attn.lora_B_v.37.weight', 'image_encoder.blocks.1.attn.lora_B_k.3.weight', 'image_encoder.blocks.3.attn.lora_B_k.3.weight', 'image_encoder.blocks.11.attn.lora_B_k.33.weight', 'image_encoder.blocks.8.attn.lora_B_k.32.weight', 'image_encoder.blocks.9.attn.lora_B_k.31.weight', 'image_encoder.blocks.2.attn.lora_B_v.3.weight', 'image_encoder.blocks.6.attn.lora_B_k.3.weight', 'image_encoder.blocks.0.attn.lora_B_k.30.weight', 'image_encoder.blocks.3.attn.lora_B_k.39.weight', 'image_encoder.blocks.5.attn.lora_B_v.35.weight', 'image_encoder.blocks.9.attn.lora_B_v.32.weight', 'image_encoder.blocks.6.attn.lora_B_k.33.weight', 'classifier_pool.39.bias', 'image_encoder.blocks.11.attn.lora_B_k.32.weight', 'image_encoder.blocks.2.attn.lora_B_v.32.weight', 'classifier_pool.35.weight', 'image_encoder.blocks.4.attn.lora_B_k.34.weight', 'image_encoder.blocks.6.attn.lora_B_k.34.weight', 'image_encoder.blocks.1.attn.lora_B_v.3.weight', 'image_encoder.blocks.1.attn.lora_B_v.32.weight', 'image_encoder.blocks.0.attn.lora_B_v.32.weight', 'image_encoder.blocks.3.attn.lora_B_v.3.weight', 'image_encoder.blocks.7.attn.lora_B_v.35.weight', 'image_encoder.blocks.7.attn.lora_B_v.30.weight', 'image_encoder.blocks.7.attn.lora_B_v.37.weight', 'image_encoder.blocks.10.attn.lora_B_k.39.weight', 'image_encoder.blocks.11.attn.lora_B_k.37.weight', 'image_encoder.blocks.0.attn.lora_B_v.35.weight', 'image_encoder.blocks.2.attn.lora_B_k.36.weight', 'image_encoder.blocks.11.attn.lora_B_k.39.weight', 'image_encoder.blocks.0.attn.lora_B_k.3.weight', 'image_encoder.blocks.10.attn.lora_B_v.35.weight', 'image_encoder.blocks.3.attn.lora_B_k.38.weight', 'image_encoder.blocks.5.attn.lora_B_k.32.weight', 'image_encoder.blocks.5.attn.lora_B_k.33.weight', 'image_encoder.blocks.9.attn.lora_B_v.30.weight', 'image_encoder.blocks.11.attn.lora_B_v.37.weight', 'image_encoder.blocks.5.attn.lora_B_k.34.weight', 'image_encoder.blocks.5.attn.lora_B_v.38.weight', 'image_encoder.blocks.2.attn.lora_B_k.3.weight', 'image_encoder.blocks.8.attn.lora_B_k.33.weight', 'image_encoder.blocks.0.attn.lora_B_k.31.weight', 'image_encoder.blocks.0.attn.lora_B_v.39.weight', 'image_encoder.blocks.10.attn.lora_B_v.30.weight', 'image_encoder.blocks.10.attn.lora_B_v.36.weight', 'image_encoder.blocks.2.attn.lora_B_k.30.weight', 'image_encoder.blocks.1.attn.lora_B_v.33.weight', 'image_encoder.blocks.3.attn.lora_B_v.30.weight', 'image_encoder.blocks.4.attn.lora_B_k.30.weight', 'image_encoder.blocks.3.attn.lora_B_v.35.weight', 'image_encoder.blocks.4.attn.lora_B_k.39.weight', 'image_encoder.blocks.7.attn.lora_B_v.32.weight', 'image_encoder.blocks.7.attn.lora_B_k.30.weight', 'image_encoder.blocks.6.attn.lora_B_k.31.weight', 'image_encoder.blocks.8.attn.lora_B_v.31.weight', 'image_encoder.blocks.1.attn.lora_B_k.33.weight', 'image_encoder.blocks.9.attn.lora_B_v.33.weight', 'image_encoder.blocks.8.attn.lora_B_v.32.weight', 'image_encoder.blocks.7.attn.lora_B_k.37.weight', 'image_encoder.blocks.10.attn.lora_B_v.37.weight', 'image_encoder.blocks.6.attn.lora_B_v.37.weight', 'classifier_pool.39.weight', 'image_encoder.blocks.4.attn.lora_B_k.36.weight', 'image_encoder.blocks.0.attn.lora_B_v.33.weight', 'image_encoder.blocks.11.attn.lora_B_v.31.weight', 'image_encoder.blocks.7.attn.lora_B_k.36.weight', 'image_encoder.blocks.7.attn.lora_B_v.36.weight', 'image_encoder.blocks.2.attn.lora_B_v.34.weight', 'image_encoder.blocks.8.attn.lora_B_v.38.weight', 'image_encoder.blocks.8.attn.lora_B_v.36.weight', 'image_encoder.blocks.2.attn.lora_B_k.37.weight', 'image_encoder.blocks.10.attn.lora_B_k.31.weight', 'image_encoder.blocks.6.attn.lora_B_k.36.weight', 'image_encoder.blocks.6.attn.lora_B_v.31.weight', 'image_encoder.blocks.3.attn.lora_B_v.39.weight', 'image_encoder.blocks.6.attn.lora_B_v.39.weight', 'image_encoder.blocks.10.attn.lora_B_v.32.weight', 'image_encoder.blocks.11.attn.lora_B_v.36.weight', 'image_encoder.blocks.2.attn.lora_B_k.33.weight', 'image_encoder.blocks.3.attn.lora_B_k.34.weight', 'image_encoder.blocks.4.attn.lora_B_v.34.weight', 'image_encoder.blocks.6.attn.lora_B_v.33.weight', 'image_encoder.blocks.6.attn.lora_B_k.30.weight', 'image_encoder.blocks.2.attn.lora_B_v.39.weight', 'image_encoder.blocks.3.attn.lora_B_v.37.weight', 'classifier_pool.31.weight', 'image_encoder.blocks.0.attn.lora_B_k.39.weight', 'image_encoder.blocks.0.attn.lora_B_k.38.weight', 'image_encoder.blocks.2.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_k.36.weight', 'image_encoder.blocks.2.attn.lora_B_v.33.weight', 'image_encoder.blocks.5.attn.lora_B_v.34.weight', 'image_encoder.blocks.0.attn.lora_B_k.33.weight', 'image_encoder.blocks.7.attn.lora_B_v.31.weight', 'image_encoder.blocks.8.attn.lora_B_v.39.weight', 'classifier_pool.30.bias', 'image_encoder.blocks.6.attn.lora_B_v.36.weight', 'image_encoder.blocks.3.attn.lora_B_k.32.weight', 'image_encoder.blocks.4.attn.lora_B_k.33.weight', 'image_encoder.blocks.5.attn.lora_B_v.32.weight', 'image_encoder.blocks.5.attn.lora_B_k.37.weight'}
2025-12-11 17:19:39,411 [inflora.py] => Task 3, Epoch 50/50 => Loss 0.091, Train_accy 97.76
Threshold:  0.9812
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 26/768 type remove
Layer 4 : 31/768 type remove
Layer 5 : 46/768 type remove
Layer 6 : 39/768 type remove
Layer 7 : 40/768 type remove
Layer 8 : 47/768 type remove
Layer 9 : 82/768 type remove
Layer 10 : 101/768 type remove
Layer 11 : 51/768 type remove
Layer 12 : 73/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:19:47,270 [trainer.py] => Time:179.83866333961487
524 524
524 524
2025-12-11 17:19:49,615 [trainer.py] => Time:2.3442840576171875
2025-12-11 17:19:49,615 [inflora.py] => Exemplar size: 0
2025-12-11 17:19:49,615 [trainer.py] => CNN: {'total': np.float64(80.53), '00-03': np.float64(78.06), '04-07': np.float64(82.07), '08-11': np.float64(79.82), '12-15': np.float64(82.73), 'old': np.float64(79.95), 'new': np.float64(82.73)}
2025-12-11 17:19:49,615 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53)]
2025-12-11 17:19:49,615 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6)]
2025-12-11 17:19:49,615 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939]
2025-12-11 17:19:54,368 [trainer.py] => W-NCM: {'00-03': 74.83870967741936, '04-07': 82.06896551724138, '08-11': 77.19298245614034, '12-15': 92.72727272727272}
2025-12-11 17:19:54,369 [trainer.py] => Ave Acc (W-NCM): 81.71%
2025-12-11 17:19:54,369 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 74.84% (best 83.23%); T2: W-NCM 82.07% (best 93.79%); T3: W-NCM 77.19% (best 84.21%); T4: W-NCM 92.73% (best 92.73%)
2025-12-11 17:19:54,369 [trainer.py] => Average forgetting (W-NCM): 9.04% | Max forgetting (W-NCM): 11.72%
2025-12-11 17:19:54,375 [trainer.py] => All params: 126094051
2025-12-11 17:19:54,382 [trainer.py] => Trainable params: 2061356
2025-12-11 17:19:54,382 [inflora.py] => Learning on 16-20
Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_k.43.weight', 'image_encoder.blocks.10.attn.lora_B_k.48.weight', 'image_encoder.blocks.3.attn.lora_B_k.47.weight', 'image_encoder.blocks.6.attn.lora_B_k.46.weight', 'image_encoder.blocks.0.attn.lora_B_k.45.weight', 'image_encoder.blocks.7.attn.lora_B_k.40.weight', 'image_encoder.blocks.7.attn.lora_B_k.48.weight', 'image_encoder.blocks.10.attn.lora_B_v.4.weight', 'classifier_pool.45.bias', 'image_encoder.blocks.3.attn.lora_B_v.49.weight', 'image_encoder.blocks.4.attn.lora_B_k.45.weight', 'image_encoder.blocks.6.attn.lora_B_v.42.weight', 'image_encoder.blocks.3.attn.lora_B_v.45.weight', 'image_encoder.blocks.4.attn.lora_B_k.49.weight', 'image_encoder.blocks.5.attn.lora_B_k.45.weight', 'image_encoder.blocks.6.attn.lora_B_k.47.weight', 'image_encoder.blocks.0.attn.lora_B_k.47.weight', 'image_encoder.blocks.2.attn.lora_B_v.41.weight', 'image_encoder.blocks.7.attn.lora_B_v.4.weight', 'image_encoder.blocks.9.attn.lora_B_k.46.weight', 'image_encoder.blocks.5.attn.lora_B_v.4.weight', 'image_encoder.blocks.9.attn.lora_B_v.47.weight', 'classifier_pool.46.weight', 'image_encoder.blocks.4.attn.lora_B_v.4.weight', 'image_encoder.blocks.2.attn.lora_B_v.43.weight', 'image_encoder.blocks.4.attn.lora_B_v.45.weight', 'image_encoder.blocks.2.attn.lora_B_k.44.weight', 'image_encoder.blocks.2.attn.lora_B_v.45.weight', 'image_encoder.blocks.6.attn.lora_B_k.40.weight', 'image_encoder.blocks.10.attn.lora_B_v.40.weight', 'image_encoder.blocks.5.attn.lora_B_v.49.weight', 'image_encoder.blocks.4.attn.lora_B_v.42.weight', 'image_encoder.blocks.3.attn.lora_B_v.41.weight', 'image_encoder.blocks.10.attn.lora_B_k.42.weight', 'image_encoder.blocks.7.attn.lora_B_v.44.weight', 'image_encoder.blocks.4.attn.lora_B_v.40.weight', 'image_encoder.blocks.6.attn.lora_B_k.49.weight', 'image_encoder.blocks.1.attn.lora_B_k.43.weight', 'image_encoder.blocks.11.attn.lora_B_k.4.weight', 'image_encoder.blocks.1.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_v.40.weight', 'image_encoder.blocks.11.attn.lora_B_v.41.weight', 'image_encoder.blocks.4.attn.lora_B_v.47.weight', 'image_encoder.blocks.11.attn.lora_B_v.46.weight', 'image_encoder.blocks.9.attn.lora_B_v.44.weight', 'image_encoder.blocks.11.attn.lora_B_v.4.weight', 'image_encoder.blocks.3.attn.lora_B_k.49.weight', 'image_encoder.blocks.1.attn.lora_B_k.40.weight', 'image_encoder.blocks.2.attn.lora_B_v.47.weight', 'image_encoder.blocks.3.attn.lora_B_k.42.weight', 'image_encoder.blocks.6.attn.lora_B_k.4.weight', 'image_encoder.blocks.10.attn.lora_B_k.49.weight', 'image_encoder.blocks.2.attn.lora_B_v.46.weight', 'image_encoder.blocks.3.attn.lora_B_v.43.weight', 'image_encoder.blocks.11.attn.lora_B_v.49.weight', 'image_encoder.blocks.8.attn.lora_B_v.40.weight', 'image_encoder.blocks.2.attn.lora_B_k.45.weight', 'image_encoder.blocks.1.attn.lora_B_v.4.weight', 'image_encoder.blocks.0.attn.lora_B_k.44.weight', 'image_encoder.blocks.2.attn.lora_B_k.47.weight', 'image_encoder.blocks.4.attn.lora_B_k.47.weight', 'image_encoder.blocks.5.attn.lora_B_v.43.weight', 'image_encoder.blocks.11.attn.lora_B_v.44.weight', 'image_encoder.blocks.6.attn.lora_B_v.48.weight', 'image_encoder.blocks.7.attn.lora_B_v.46.weight', 'image_encoder.blocks.9.attn.lora_B_v.40.weight', 'image_encoder.blocks.6.attn.lora_B_v.43.weight', 'image_encoder.blocks.9.attn.lora_B_k.47.weight', 'image_encoder.blocks.0.attn.lora_B_v.44.weight', 'image_encoder.blocks.4.attn.lora_B_v.49.weight', 'image_encoder.blocks.6.attn.lora_B_v.40.weight', 'image_encoder.blocks.10.attn.lora_B_k.41.weight', 'image_encoder.blocks.3.attn.lora_B_v.42.weight', 'image_encoder.blocks.6.attn.lora_B_v.44.weight', 'image_encoder.blocks.7.attn.lora_B_k.46.weight', 'image_encoder.blocks.10.attn.lora_B_k.46.weight', 'image_encoder.blocks.11.attn.lora_B_k.41.weight', 'image_encoder.blocks.3.attn.lora_B_v.47.weight', 'classifier_pool.41.weight', 'image_encoder.blocks.8.attn.lora_B_k.43.weight', 'image_encoder.blocks.3.attn.lora_B_v.40.weight', 'image_encoder.blocks.6.attn.lora_B_k.43.weight', 'image_encoder.blocks.8.attn.lora_B_k.41.weight', 'image_encoder.blocks.10.attn.lora_B_k.43.weight', 'image_encoder.blocks.4.attn.lora_B_k.40.weight', 'image_encoder.blocks.5.attn.lora_B_k.43.weight', 'image_encoder.blocks.11.attn.lora_B_k.46.weight', 'image_encoder.blocks.8.attn.lora_B_v.41.weight', 'image_encoder.blocks.9.attn.lora_B_k.48.weight', 'image_encoder.blocks.9.attn.lora_B_v.45.weight', 'image_encoder.blocks.0.attn.lora_B_v.40.weight', 'image_encoder.blocks.3.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_v.42.weight', 'image_encoder.blocks.7.attn.lora_B_v.41.weight', 'image_encoder.blocks.11.attn.lora_B_k.47.weight', 'image_encoder.blocks.11.attn.lora_B_v.45.weight', 'image_encoder.blocks.3.attn.lora_B_v.46.weight', 'image_encoder.blocks.0.attn.lora_B_k.46.weight', 'classifier_pool.4.weight', 'image_encoder.blocks.5.attn.lora_B_k.40.weight', 'classifier_pool.49.weight', 'image_encoder.blocks.1.attn.lora_B_k.46.weight', 'image_encoder.blocks.8.attn.lora_B_k.47.weight', 'image_encoder.blocks.9.attn.lora_B_v.41.weight', 'image_encoder.blocks.10.attn.lora_B_v.48.weight', 'image_encoder.blocks.11.attn.lora_B_k.42.weight', 'image_encoder.blocks.0.attn.lora_B_v.43.weight', 'image_encoder.blocks.0.attn.lora_B_v.41.weight', 'image_encoder.blocks.5.attn.lora_B_v.41.weight', 'image_encoder.blocks.1.attn.lora_B_v.48.weight', 'classifier_pool.4.bias', 'image_encoder.blocks.1.attn.lora_B_k.4.weight', 'image_encoder.blocks.0.attn.lora_B_k.42.weight', 'image_encoder.blocks.4.attn.lora_B_k.43.weight', 'image_encoder.blocks.7.attn.lora_B_k.42.weight', 'classifier_pool.42.bias', 'image_encoder.blocks.0.attn.lora_B_k.40.weight', 'image_encoder.blocks.1.attn.lora_B_k.47.weight', 'image_encoder.blocks.7.attn.lora_B_k.44.weight', 'image_encoder.blocks.11.attn.lora_B_k.48.weight', 'image_encoder.blocks.3.attn.lora_B_k.4.weight', 'image_encoder.blocks.2.attn.lora_B_k.42.weight', 'image_encoder.blocks.3.attn.lora_B_k.45.weight', 'image_encoder.blocks.10.attn.lora_B_k.45.weight', 'image_encoder.blocks.5.attn.lora_B_k.4.weight', 'image_encoder.blocks.1.attn.lora_B_k.48.weight', 'image_encoder.blocks.9.attn.lora_B_v.4.weight', 'image_encoder.blocks.0.attn.lora_B_k.49.weight', 'image_encoder.blocks.10.attn.lora_B_k.47.weight', 'image_encoder.blocks.4.attn.lora_B_k.42.weight', 'image_encoder.blocks.4.attn.lora_B_v.43.weight', 'image_encoder.blocks.1.attn.lora_B_k.49.weight', 'image_encoder.blocks.8.attn.lora_B_k.49.weight', 'image_encoder.blocks.11.attn.lora_B_v.42.weight', 'image_encoder.blocks.7.attn.lora_B_k.47.weight', 'image_encoder.blocks.1.attn.lora_B_v.41.weight', 'classifier_pool.47.bias', 'image_encoder.blocks.0.attn.lora_B_v.47.weight', 'image_encoder.blocks.7.attn.lora_B_v.42.weight', 'image_encoder.blocks.0.attn.lora_B_v.42.weight', 'image_encoder.blocks.11.attn.lora_B_v.40.weight', 'classifier_pool.43.bias', 'image_encoder.blocks.1.attn.lora_B_v.42.weight', 'image_encoder.blocks.2.attn.lora_B_k.49.weight', 'classifier_pool.43.weight', 'image_encoder.blocks.5.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_k.48.weight', 'image_encoder.blocks.9.attn.lora_B_v.49.weight', 'image_encoder.blocks.7.attn.lora_B_v.48.weight', 'image_encoder.blocks.11.attn.lora_B_k.40.weight', 'image_encoder.blocks.9.attn.lora_B_k.44.weight', 'image_encoder.blocks.7.attn.lora_B_k.4.weight', 'image_encoder.blocks.7.attn.lora_B_v.43.weight', 'image_encoder.blocks.8.attn.lora_B_k.45.weight', 'image_encoder.blocks.10.attn.lora_B_v.44.weight', 'image_encoder.blocks.3.attn.lora_B_k.44.weight', 'image_encoder.blocks.10.attn.lora_B_v.47.weight', 'classifier_pool.44.bias', 'image_encoder.blocks.5.attn.lora_B_k.47.weight', 'image_encoder.blocks.5.attn.lora_B_k.44.weight', 'image_encoder.blocks.1.attn.lora_B_v.43.weight', 'image_encoder.blocks.6.attn.lora_B_k.44.weight', 'image_encoder.blocks.2.attn.lora_B_k.40.weight', 'classifier_pool.48.weight', 'image_encoder.blocks.8.attn.lora_B_v.45.weight', 'image_encoder.blocks.7.attn.lora_B_k.45.weight', 'image_encoder.blocks.10.attn.lora_B_v.41.weight', 'classifier_pool.44.weight', 'image_encoder.blocks.9.attn.lora_B_v.43.weight', 'image_encoder.blocks.9.attn.lora_B_k.43.weight', 'image_encoder.blocks.7.attn.lora_B_k.43.weight', 'image_encoder.blocks.8.attn.lora_B_k.46.weight', 'image_encoder.blocks.3.attn.lora_B_k.48.weight', 'image_encoder.blocks.2.attn.lora_B_k.48.weight', 'image_encoder.blocks.8.attn.lora_B_v.46.weight', 'image_encoder.blocks.8.attn.lora_B_v.43.weight', 'image_encoder.blocks.0.attn.lora_B_v.4.weight', 'image_encoder.blocks.2.attn.lora_B_v.42.weight', 'image_encoder.blocks.2.attn.lora_B_v.48.weight', 'image_encoder.blocks.0.attn.lora_B_v.46.weight', 'classifier_pool.49.bias', 'classifier_pool.48.bias', 'image_encoder.blocks.6.attn.lora_B_k.45.weight', 'image_encoder.blocks.8.attn.lora_B_v.48.weight', 'image_encoder.blocks.0.attn.lora_B_k.48.weight', 'image_encoder.blocks.4.attn.lora_B_k.41.weight', 'image_encoder.blocks.2.attn.lora_B_v.40.weight', 'image_encoder.blocks.6.attn.lora_B_v.47.weight', 'image_encoder.blocks.6.attn.lora_B_v.49.weight', 'image_encoder.blocks.10.attn.lora_B_v.49.weight', 'image_encoder.blocks.5.attn.lora_B_k.46.weight', 'image_encoder.blocks.8.attn.lora_B_k.4.weight', 'image_encoder.blocks.5.attn.lora_B_k.42.weight', 'image_encoder.blocks.9.attn.lora_B_k.4.weight', 'image_encoder.blocks.5.attn.lora_B_v.45.weight', 'image_encoder.blocks.3.attn.lora_B_k.46.weight', 'image_encoder.blocks.6.attn.lora_B_v.46.weight', 'image_encoder.blocks.8.attn.lora_B_v.49.weight', 'image_encoder.blocks.8.attn.lora_B_k.48.weight', 'image_encoder.blocks.4.attn.lora_B_v.41.weight', 'image_encoder.blocks.9.attn.lora_B_k.40.weight', 'image_encoder.blocks.9.attn.lora_B_k.41.weight', 'image_encoder.blocks.9.attn.lora_B_k.42.weight', 'image_encoder.blocks.11.attn.lora_B_v.48.weight', 'image_encoder.blocks.9.attn.lora_B_k.49.weight', 'image_encoder.blocks.1.attn.lora_B_v.44.weight', 'image_encoder.blocks.1.attn.lora_B_v.47.weight', 'classifier_pool.41.bias', 'image_encoder.blocks.6.attn.lora_B_v.45.weight', 'image_encoder.blocks.4.attn.lora_B_k.48.weight', 'classifier_pool.47.weight', 'image_encoder.blocks.8.attn.lora_B_k.40.weight', 'image_encoder.blocks.2.attn.lora_B_v.44.weight', 'image_encoder.blocks.8.attn.lora_B_v.44.weight', 'image_encoder.blocks.8.attn.lora_B_k.44.weight', 'image_encoder.blocks.1.attn.lora_B_v.40.weight', 'image_encoder.blocks.1.attn.lora_B_v.49.weight', 'image_encoder.blocks.4.attn.lora_B_v.48.weight', 'image_encoder.blocks.4.attn.lora_B_k.44.weight', 'image_encoder.blocks.11.attn.lora_B_k.43.weight', 'image_encoder.blocks.10.attn.lora_B_k.40.weight', 'image_encoder.blocks.7.attn.lora_B_v.45.weight', 'classifier_pool.40.weight', 'image_encoder.blocks.0.attn.lora_B_v.45.weight', 'image_encoder.blocks.3.attn.lora_B_v.4.weight', 'image_encoder.blocks.5.attn.lora_B_v.46.weight', 'image_encoder.blocks.5.attn.lora_B_v.48.weight', 'image_encoder.blocks.5.attn.lora_B_v.44.weight', 'image_encoder.blocks.6.attn.lora_B_v.41.weight', 'image_encoder.blocks.10.attn.lora_B_v.46.weight', 'image_encoder.blocks.4.attn.lora_B_v.46.weight', 'image_encoder.blocks.10.attn.lora_B_k.4.weight', 'image_encoder.blocks.2.attn.lora_B_v.4.weight', 'image_encoder.blocks.7.attn.lora_B_v.47.weight', 'image_encoder.blocks.1.attn.lora_B_k.44.weight', 'image_encoder.blocks.9.attn.lora_B_v.42.weight', 'image_encoder.blocks.9.attn.lora_B_v.48.weight', 'image_encoder.blocks.0.attn.lora_B_k.4.weight', 'image_encoder.blocks.3.attn.lora_B_v.44.weight', 'image_encoder.blocks.10.attn.lora_B_k.44.weight', 'image_encoder.blocks.9.attn.lora_B_v.46.weight', 'image_encoder.blocks.11.attn.lora_B_v.47.weight', 'image_encoder.blocks.6.attn.lora_B_v.4.weight', 'image_encoder.blocks.8.attn.lora_B_v.42.weight', 'classifier_pool.40.bias', 'image_encoder.blocks.1.attn.lora_B_k.42.weight', 'image_encoder.blocks.8.attn.lora_B_k.42.weight', 'image_encoder.blocks.0.attn.lora_B_k.41.weight', 'image_encoder.blocks.7.attn.lora_B_v.49.weight', 'image_encoder.blocks.0.attn.lora_B_k.43.weight', 'image_encoder.blocks.2.attn.lora_B_k.43.weight', 'image_encoder.blocks.3.attn.lora_B_k.40.weight', 'image_encoder.blocks.4.attn.lora_B_k.4.weight', 'image_encoder.blocks.1.attn.lora_B_k.45.weight', 'image_encoder.blocks.2.attn.lora_B_v.49.weight', 'classifier_pool.46.bias', 'image_encoder.blocks.6.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_v.47.weight', 'image_encoder.blocks.6.attn.lora_B_k.42.weight', 'classifier_pool.42.weight', 'image_encoder.blocks.11.attn.lora_B_v.43.weight', 'image_encoder.blocks.1.attn.lora_B_v.46.weight', 'image_encoder.blocks.7.attn.lora_B_k.41.weight', 'image_encoder.blocks.1.attn.lora_B_v.45.weight', 'image_encoder.blocks.10.attn.lora_B_v.42.weight', 'image_encoder.blocks.10.attn.lora_B_v.45.weight', 'image_encoder.blocks.8.attn.lora_B_v.47.weight', 'image_encoder.blocks.5.attn.lora_B_k.49.weight', 'image_encoder.blocks.10.attn.lora_B_v.43.weight', 'image_encoder.blocks.2.attn.lora_B_k.4.weight', 'classifier_pool.45.weight', 'image_encoder.blocks.4.attn.lora_B_v.44.weight', 'image_encoder.blocks.9.attn.lora_B_k.45.weight', 'image_encoder.blocks.0.attn.lora_B_v.49.weight', 'image_encoder.blocks.4.attn.lora_B_k.46.weight', 'image_encoder.blocks.11.attn.lora_B_k.44.weight', 'image_encoder.blocks.11.attn.lora_B_k.49.weight', 'image_encoder.blocks.6.attn.lora_B_k.48.weight', 'image_encoder.blocks.2.attn.lora_B_k.41.weight', 'image_encoder.blocks.7.attn.lora_B_k.49.weight', 'image_encoder.blocks.7.attn.lora_B_v.40.weight', 'image_encoder.blocks.3.attn.lora_B_v.48.weight', 'image_encoder.blocks.8.attn.lora_B_v.4.weight', 'image_encoder.blocks.11.attn.lora_B_k.45.weight', 'image_encoder.blocks.0.attn.lora_B_v.48.weight', 'image_encoder.blocks.2.attn.lora_B_k.46.weight'}
2025-12-11 17:23:03,575 [inflora.py] => Task 4, Epoch 50/50 => Loss 0.052, Train_accy 98.41
Threshold:  0.9816
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 28/768 type remove
Layer 4 : 34/768 type remove
Layer 5 : 50/768 type remove
Layer 6 : 45/768 type remove
Layer 7 : 47/768 type remove
Layer 8 : 58/768 type remove
Layer 9 : 95/768 type remove
Layer 10 : 119/768 type remove
Layer 11 : 62/768 type remove
Layer 12 : 83/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:23:12,059 [trainer.py] => Time:197.67703127861023
650 650
650 650
2025-12-11 17:23:14,688 [trainer.py] => Time:2.6295857429504395
2025-12-11 17:23:14,689 [inflora.py] => Exemplar size: 0
2025-12-11 17:23:14,689 [trainer.py] => CNN: {'total': np.float64(78.46), '00-03': np.float64(78.71), '04-07': np.float64(78.62), '08-11': np.float64(78.07), '12-15': np.float64(79.09), '16-19': np.float64(77.78), 'old': np.float64(78.63), 'new': np.float64(77.78)}
2025-12-11 17:23:14,689 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46)]
2025-12-11 17:23:14,689 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0)]
2025-12-11 17:23:14,689 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923]
2025-12-11 17:23:19,969 [trainer.py] => W-NCM: {'00-03': 72.25806451612902, '04-07': 73.79310344827587, '08-11': 77.19298245614034, '12-15': 90.0, '16-19': 95.23809523809523}
2025-12-11 17:23:19,969 [trainer.py] => Ave Acc (W-NCM): 81.70%
2025-12-11 17:23:19,969 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 72.26% (best 83.23%); T2: W-NCM 73.79% (best 93.79%); T3: W-NCM 77.19% (best 84.21%); T4: W-NCM 90.00% (best 92.73%); T5: W-NCM 95.24% (best 95.24%)
2025-12-11 17:23:19,969 [trainer.py] => Average forgetting (W-NCM): 10.18% | Max forgetting (W-NCM): 20.00%
2025-12-11 17:23:19,976 [trainer.py] => All params: 126094051
2025-12-11 17:23:19,982 [trainer.py] => Trainable params: 2061356
2025-12-11 17:23:19,982 [inflora.py] => Learning on 20-24
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_k.5.weight', 'image_encoder.blocks.6.attn.lora_B_v.5.weight', 'image_encoder.blocks.11.attn.lora_B_v.5.weight', 'image_encoder.blocks.4.attn.lora_B_k.5.weight', 'image_encoder.blocks.9.attn.lora_B_v.5.weight', 'image_encoder.blocks.10.attn.lora_B_v.5.weight', 'image_encoder.blocks.5.attn.lora_B_v.5.weight', 'image_encoder.blocks.2.attn.lora_B_v.5.weight', 'image_encoder.blocks.7.attn.lora_B_k.5.weight', 'image_encoder.blocks.8.attn.lora_B_k.5.weight', 'image_encoder.blocks.7.attn.lora_B_v.5.weight', 'image_encoder.blocks.9.attn.lora_B_k.5.weight', 'image_encoder.blocks.1.attn.lora_B_v.5.weight', 'image_encoder.blocks.3.attn.lora_B_k.5.weight', 'image_encoder.blocks.3.attn.lora_B_v.5.weight', 'image_encoder.blocks.4.attn.lora_B_v.5.weight', 'image_encoder.blocks.2.attn.lora_B_k.5.weight', 'image_encoder.blocks.5.attn.lora_B_k.5.weight', 'image_encoder.blocks.6.attn.lora_B_k.5.weight', 'image_encoder.blocks.11.attn.lora_B_k.5.weight', 'classifier_pool.5.bias', 'image_encoder.blocks.0.attn.lora_B_k.5.weight', 'image_encoder.blocks.10.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_v.5.weight', 'classifier_pool.5.weight', 'image_encoder.blocks.8.attn.lora_B_v.5.weight'}
2025-12-11 17:27:46,199 [inflora.py] => Task 5, Epoch 50/50 => Loss 0.115, Train_accy 96.33
Threshold:  0.982
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 29/768 type remove
Layer 4 : 36/768 type remove
Layer 5 : 52/768 type remove
Layer 6 : 47/768 type remove
Layer 7 : 50/768 type remove
Layer 8 : 60/768 type remove
Layer 9 : 97/768 type remove
Layer 10 : 121/768 type remove
Layer 11 : 64/768 type remove
Layer 12 : 87/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:27:56,116 [trainer.py] => Time:276.1333260536194
869 869
869 869
2025-12-11 17:27:59,315 [trainer.py] => Time:3.199251651763916
2025-12-11 17:27:59,315 [inflora.py] => Exemplar size: 0
2025-12-11 17:27:59,315 [trainer.py] => CNN: {'total': np.float64(77.22), '00-03': np.float64(73.55), '04-07': np.float64(79.31), '08-11': np.float64(74.56), '12-15': np.float64(80.91), '16-19': np.float64(77.78), '20-23': np.float64(77.63), 'old': np.float64(77.08), 'new': np.float64(77.63)}
2025-12-11 17:27:59,315 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22)]
2025-12-11 17:27:59,315 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17)]
2025-12-11 17:27:59,315 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348]
2025-12-11 17:28:05,716 [trainer.py] => W-NCM: {'00-03': 67.74193548387096, '04-07': 69.6551724137931, '08-11': 72.80701754385966, '12-15': 88.18181818181819, '16-19': 89.68253968253968, '20-23': 92.23744292237443}
2025-12-11 17:28:05,716 [trainer.py] => Ave Acc (W-NCM): 80.05%
2025-12-11 17:28:05,716 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 67.74% (best 83.23%); T2: W-NCM 69.66% (best 93.79%); T3: W-NCM 72.81% (best 84.21%); T4: W-NCM 88.18% (best 92.73%); T5: W-NCM 89.68% (best 95.24%); T6: W-NCM 92.24% (best 92.24%)
2025-12-11 17:28:05,716 [trainer.py] => Average forgetting (W-NCM): 12.23% | Max forgetting (W-NCM): 24.14%
2025-12-11 17:28:05,723 [trainer.py] => All params: 126094051
2025-12-11 17:28:05,729 [trainer.py] => Trainable params: 187396
2025-12-11 17:28:05,729 [inflora.py] => Learning on 24-28
Parameters to be updated: {'classifier_pool.6.weight', 'image_encoder.blocks.1.attn.lora_B_k.6.weight', 'classifier_pool.6.bias', 'image_encoder.blocks.9.attn.lora_B_k.6.weight', 'image_encoder.blocks.4.attn.lora_B_k.6.weight', 'image_encoder.blocks.8.attn.lora_B_v.6.weight', 'image_encoder.blocks.2.attn.lora_B_k.6.weight', 'image_encoder.blocks.9.attn.lora_B_v.6.weight', 'image_encoder.blocks.10.attn.lora_B_v.6.weight', 'image_encoder.blocks.1.attn.lora_B_v.6.weight', 'image_encoder.blocks.7.attn.lora_B_v.6.weight', 'image_encoder.blocks.11.attn.lora_B_v.6.weight', 'image_encoder.blocks.6.attn.lora_B_v.6.weight', 'image_encoder.blocks.5.attn.lora_B_k.6.weight', 'image_encoder.blocks.0.attn.lora_B_k.6.weight', 'image_encoder.blocks.5.attn.lora_B_v.6.weight', 'image_encoder.blocks.7.attn.lora_B_k.6.weight', 'image_encoder.blocks.3.attn.lora_B_k.6.weight', 'image_encoder.blocks.6.attn.lora_B_k.6.weight', 'image_encoder.blocks.8.attn.lora_B_k.6.weight', 'image_encoder.blocks.4.attn.lora_B_v.6.weight', 'image_encoder.blocks.10.attn.lora_B_k.6.weight', 'image_encoder.blocks.0.attn.lora_B_v.6.weight', 'image_encoder.blocks.3.attn.lora_B_v.6.weight', 'image_encoder.blocks.11.attn.lora_B_k.6.weight', 'image_encoder.blocks.2.attn.lora_B_v.6.weight'}
2025-12-11 17:31:57,246 [inflora.py] => Task 6, Epoch 50/50 => Loss 0.073, Train_accy 97.30
Threshold:  0.9823999999999999
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 30/768 type remove
Layer 4 : 38/768 type remove
Layer 5 : 54/768 type remove
Layer 6 : 49/768 type remove
Layer 7 : 54/768 type remove
Layer 8 : 64/768 type remove
Layer 9 : 105/768 type remove
Layer 10 : 132/768 type remove
Layer 11 : 70/768 type remove
Layer 12 : 104/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:32:06,057 [trainer.py] => Time:240.32826232910156
1033 1033
1033 1033
2025-12-11 17:32:09,760 [trainer.py] => Time:3.7026679515838623
2025-12-11 17:32:09,761 [inflora.py] => Exemplar size: 0
2025-12-11 17:32:09,761 [trainer.py] => CNN: {'total': np.float64(78.32), '00-03': np.float64(73.55), '04-07': np.float64(82.07), '08-11': np.float64(73.68), '12-15': np.float64(82.73), '16-19': np.float64(78.57), '20-23': np.float64(75.8), '24-27': np.float64(82.93), 'old': np.float64(77.45), 'new': np.float64(82.93)}
2025-12-11 17:32:09,761 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32)]
2025-12-11 17:32:09,761 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55)]
2025-12-11 17:32:09,761 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289]
2025-12-11 17:32:16,296 [trainer.py] => W-NCM: {'00-03': 72.90322580645162, '04-07': 72.41379310344827, '08-11': 77.19298245614034, '12-15': 90.0, '16-19': 90.47619047619048, '20-23': 80.82191780821918, '24-27': 89.02439024390245}
2025-12-11 17:32:16,296 [trainer.py] => Ave Acc (W-NCM): 81.83%
2025-12-11 17:32:16,296 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 72.90% (best 83.23%); T2: W-NCM 72.41% (best 93.79%); T3: W-NCM 77.19% (best 84.21%); T4: W-NCM 90.00% (best 92.73%); T5: W-NCM 90.48% (best 95.24%); T6: W-NCM 80.82% (best 92.24%); T7: W-NCM 89.02% (best 89.02%)
2025-12-11 17:32:16,296 [trainer.py] => Average forgetting (W-NCM): 9.60% | Max forgetting (W-NCM): 21.38%
2025-12-11 17:32:16,303 [trainer.py] => All params: 126094051
2025-12-11 17:32:16,309 [trainer.py] => Trainable params: 187396
2025-12-11 17:32:16,309 [inflora.py] => Learning on 28-32
Parameters to be updated: {'image_encoder.blocks.5.attn.lora_B_k.7.weight', 'image_encoder.blocks.1.attn.lora_B_k.7.weight', 'image_encoder.blocks.8.attn.lora_B_k.7.weight', 'image_encoder.blocks.10.attn.lora_B_k.7.weight', 'image_encoder.blocks.9.attn.lora_B_v.7.weight', 'image_encoder.blocks.8.attn.lora_B_v.7.weight', 'image_encoder.blocks.11.attn.lora_B_k.7.weight', 'image_encoder.blocks.4.attn.lora_B_k.7.weight', 'image_encoder.blocks.0.attn.lora_B_k.7.weight', 'image_encoder.blocks.6.attn.lora_B_v.7.weight', 'image_encoder.blocks.2.attn.lora_B_v.7.weight', 'image_encoder.blocks.11.attn.lora_B_v.7.weight', 'classifier_pool.7.bias', 'image_encoder.blocks.3.attn.lora_B_v.7.weight', 'image_encoder.blocks.4.attn.lora_B_v.7.weight', 'image_encoder.blocks.0.attn.lora_B_v.7.weight', 'image_encoder.blocks.6.attn.lora_B_k.7.weight', 'image_encoder.blocks.9.attn.lora_B_k.7.weight', 'image_encoder.blocks.2.attn.lora_B_k.7.weight', 'image_encoder.blocks.3.attn.lora_B_k.7.weight', 'image_encoder.blocks.5.attn.lora_B_v.7.weight', 'image_encoder.blocks.7.attn.lora_B_v.7.weight', 'image_encoder.blocks.10.attn.lora_B_v.7.weight', 'classifier_pool.7.weight', 'image_encoder.blocks.1.attn.lora_B_v.7.weight', 'image_encoder.blocks.7.attn.lora_B_k.7.weight'}
2025-12-11 17:36:14,010 [inflora.py] => Task 7, Epoch 50/50 => Loss 0.087, Train_accy 97.34
Threshold:  0.9828
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 31/768 type remove
Layer 4 : 39/768 type remove
Layer 5 : 58/768 type remove
Layer 6 : 52/768 type remove
Layer 7 : 59/768 type remove
Layer 8 : 69/768 type remove
Layer 9 : 110/768 type remove
Layer 10 : 137/768 type remove
Layer 11 : 74/768 type remove
Layer 12 : 117/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:36:23,050 [trainer.py] => Time:246.74093866348267
1224 1224
1224 1224
2025-12-11 17:36:27,214 [trainer.py] => Time:4.1637046337127686
2025-12-11 17:36:27,214 [inflora.py] => Exemplar size: 0
2025-12-11 17:36:27,214 [trainer.py] => CNN: {'total': np.float64(75.25), '00-03': np.float64(76.13), '04-07': np.float64(79.31), '08-11': np.float64(75.44), '12-15': np.float64(83.64), '16-19': np.float64(73.81), '20-23': np.float64(76.26), '24-27': np.float64(80.49), '28-31': np.float64(61.78), 'old': np.float64(77.73), 'new': np.float64(61.78)}
2025-12-11 17:36:27,214 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25)]
2025-12-11 17:36:27,214 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14)]
2025-12-11 17:36:27,215 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641]
2025-12-11 17:36:34,188 [trainer.py] => W-NCM: {'00-03': 70.3225806451613, '04-07': 68.96551724137932, '08-11': 73.68421052631578, '12-15': 88.18181818181819, '16-19': 80.95238095238095, '20-23': 80.36529680365297, '24-27': 84.7560975609756, '28-31': 91.62303664921467}
2025-12-11 17:36:34,188 [trainer.py] => Ave Acc (W-NCM): 79.86%
2025-12-11 17:36:34,188 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 70.32% (best 83.23%); T2: W-NCM 68.97% (best 93.79%); T3: W-NCM 73.68% (best 84.21%); T4: W-NCM 88.18% (best 92.73%); T5: W-NCM 80.95% (best 95.24%); T6: W-NCM 80.37% (best 92.24%); T7: W-NCM 84.76% (best 89.02%); T8: W-NCM 91.62% (best 91.62%)
2025-12-11 17:36:34,188 [trainer.py] => Average forgetting (W-NCM): 11.89% | Max forgetting (W-NCM): 24.83%
2025-12-11 17:36:34,194 [trainer.py] => All params: 126094051
2025-12-11 17:36:34,200 [trainer.py] => Trainable params: 187396
2025-12-11 17:36:34,200 [inflora.py] => Learning on 32-36
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_k.8.weight', 'image_encoder.blocks.10.attn.lora_B_v.8.weight', 'image_encoder.blocks.9.attn.lora_B_v.8.weight', 'image_encoder.blocks.7.attn.lora_B_k.8.weight', 'image_encoder.blocks.4.attn.lora_B_k.8.weight', 'image_encoder.blocks.7.attn.lora_B_v.8.weight', 'image_encoder.blocks.0.attn.lora_B_v.8.weight', 'image_encoder.blocks.0.attn.lora_B_k.8.weight', 'image_encoder.blocks.5.attn.lora_B_k.8.weight', 'image_encoder.blocks.11.attn.lora_B_k.8.weight', 'image_encoder.blocks.9.attn.lora_B_k.8.weight', 'image_encoder.blocks.6.attn.lora_B_v.8.weight', 'classifier_pool.8.bias', 'image_encoder.blocks.1.attn.lora_B_k.8.weight', 'image_encoder.blocks.1.attn.lora_B_v.8.weight', 'image_encoder.blocks.2.attn.lora_B_v.8.weight', 'image_encoder.blocks.2.attn.lora_B_k.8.weight', 'image_encoder.blocks.3.attn.lora_B_v.8.weight', 'image_encoder.blocks.8.attn.lora_B_v.8.weight', 'image_encoder.blocks.3.attn.lora_B_k.8.weight', 'image_encoder.blocks.11.attn.lora_B_v.8.weight', 'classifier_pool.8.weight', 'image_encoder.blocks.10.attn.lora_B_k.8.weight', 'image_encoder.blocks.5.attn.lora_B_v.8.weight', 'image_encoder.blocks.8.attn.lora_B_k.8.weight', 'image_encoder.blocks.4.attn.lora_B_v.8.weight'}
2025-12-11 17:38:52,217 [inflora.py] => Task 8, Epoch 50/50 => Loss 0.103, Train_accy 97.41
Threshold:  0.9832
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 32/768 type remove
Layer 4 : 40/768 type remove
Layer 5 : 60/768 type remove
Layer 6 : 54/768 type remove
Layer 7 : 61/768 type remove
Layer 8 : 70/768 type remove
Layer 9 : 112/768 type remove
Layer 10 : 139/768 type remove
Layer 11 : 76/768 type remove
Layer 12 : 121/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:38:59,698 [trainer.py] => Time:145.49715447425842
1299 1299
1299 1299
2025-12-11 17:39:04,053 [trainer.py] => Time:4.354851245880127
2025-12-11 17:39:04,053 [inflora.py] => Exemplar size: 0
2025-12-11 17:39:04,053 [trainer.py] => CNN: {'total': np.float64(73.52), '00-03': np.float64(73.55), '04-07': np.float64(77.93), '08-11': np.float64(75.44), '12-15': np.float64(84.55), '16-19': np.float64(72.22), '20-23': np.float64(76.71), '24-27': np.float64(82.93), '28-31': np.float64(53.4), '32-35': np.float64(69.33), 'old': np.float64(73.77), 'new': np.float64(69.33)}
2025-12-11 17:39:04,053 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52)]
2025-12-11 17:39:04,053 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84)]
2025-12-11 17:39:04,053 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791]
2025-12-11 17:39:10,328 [trainer.py] => W-NCM: {'00-03': 60.64516129032258, '04-07': 68.27586206896552, '08-11': 71.9298245614035, '12-15': 88.18181818181819, '16-19': 77.77777777777779, '20-23': 77.6255707762557, '24-27': 79.8780487804878, '28-31': 82.19895287958116, '32-35': 96.0}
2025-12-11 17:39:10,328 [trainer.py] => Ave Acc (W-NCM): 78.06%
2025-12-11 17:39:10,328 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 60.65% (best 83.23%); T2: W-NCM 68.28% (best 93.79%); T3: W-NCM 71.93% (best 84.21%); T4: W-NCM 88.18% (best 92.73%); T5: W-NCM 77.78% (best 95.24%); T6: W-NCM 77.63% (best 92.24%); T7: W-NCM 79.88% (best 89.02%); T8: W-NCM 82.20% (best 91.62%); T9: W-NCM 96.00% (best 96.00%)
2025-12-11 17:39:10,328 [trainer.py] => Average forgetting (W-NCM): 14.45% | Max forgetting (W-NCM): 25.52%
2025-12-11 17:39:10,335 [trainer.py] => All params: 126094051
2025-12-11 17:39:10,341 [trainer.py] => Trainable params: 187396
2025-12-11 17:39:10,341 [inflora.py] => Learning on 36-40
Parameters to be updated: {'image_encoder.blocks.5.attn.lora_B_k.9.weight', 'image_encoder.blocks.11.attn.lora_B_k.9.weight', 'classifier_pool.9.weight', 'image_encoder.blocks.8.attn.lora_B_v.9.weight', 'image_encoder.blocks.7.attn.lora_B_k.9.weight', 'image_encoder.blocks.9.attn.lora_B_v.9.weight', 'image_encoder.blocks.10.attn.lora_B_v.9.weight', 'image_encoder.blocks.10.attn.lora_B_k.9.weight', 'image_encoder.blocks.8.attn.lora_B_k.9.weight', 'image_encoder.blocks.1.attn.lora_B_v.9.weight', 'image_encoder.blocks.0.attn.lora_B_v.9.weight', 'image_encoder.blocks.4.attn.lora_B_v.9.weight', 'image_encoder.blocks.2.attn.lora_B_k.9.weight', 'image_encoder.blocks.7.attn.lora_B_v.9.weight', 'image_encoder.blocks.1.attn.lora_B_k.9.weight', 'image_encoder.blocks.9.attn.lora_B_k.9.weight', 'image_encoder.blocks.3.attn.lora_B_k.9.weight', 'image_encoder.blocks.6.attn.lora_B_v.9.weight', 'image_encoder.blocks.6.attn.lora_B_k.9.weight', 'classifier_pool.9.bias', 'image_encoder.blocks.4.attn.lora_B_k.9.weight', 'image_encoder.blocks.0.attn.lora_B_k.9.weight', 'image_encoder.blocks.3.attn.lora_B_v.9.weight', 'image_encoder.blocks.11.attn.lora_B_v.9.weight', 'image_encoder.blocks.5.attn.lora_B_v.9.weight', 'image_encoder.blocks.2.attn.lora_B_v.9.weight'}
2025-12-11 17:41:55,304 [inflora.py] => Task 9, Epoch 50/50 => Loss 0.122, Train_accy 96.37
Threshold:  0.9836
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 33/768 type remove
Layer 4 : 43/768 type remove
Layer 5 : 65/768 type remove
Layer 6 : 58/768 type remove
Layer 7 : 65/768 type remove
Layer 8 : 73/768 type remove
Layer 9 : 117/768 type remove
Layer 10 : 145/768 type remove
Layer 11 : 83/768 type remove
Layer 12 : 127/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:42:03,049 [trainer.py] => Time:172.70817804336548
1400 1400
1400 1400
2025-12-11 17:42:07,636 [trainer.py] => Time:4.5866429805755615
2025-12-11 17:42:07,636 [inflora.py] => Exemplar size: 0
2025-12-11 17:42:07,637 [trainer.py] => CNN: {'total': np.float64(73.57), '00-03': np.float64(69.68), '04-07': np.float64(75.86), '08-11': np.float64(72.81), '12-15': np.float64(83.64), '16-19': np.float64(73.81), '20-23': np.float64(74.89), '24-27': np.float64(82.32), '28-31': np.float64(55.5), '32-35': np.float64(73.33), '36-39': np.float64(83.17), 'old': np.float64(72.83), 'new': np.float64(83.17)}
2025-12-11 17:42:07,637 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57)]
2025-12-11 17:42:07,637 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07)]
2025-12-11 17:42:07,637 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286]
2025-12-11 17:42:14,438 [trainer.py] => W-NCM: {'00-03': 64.51612903225806, '04-07': 71.03448275862068, '08-11': 71.9298245614035, '12-15': 88.18181818181819, '16-19': 80.95238095238095, '20-23': 77.6255707762557, '24-27': 80.48780487804879, '28-31': 78.01047120418848, '32-35': 93.33333333333333, '36-39': 92.07920792079209}
2025-12-11 17:42:14,439 [trainer.py] => Ave Acc (W-NCM): 79.82%
2025-12-11 17:42:14,439 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 64.52% (best 83.23%); T2: W-NCM 71.03% (best 93.79%); T3: W-NCM 71.93% (best 84.21%); T4: W-NCM 88.18% (best 92.73%); T5: W-NCM 80.95% (best 95.24%); T6: W-NCM 77.63% (best 92.24%); T7: W-NCM 80.49% (best 89.02%); T8: W-NCM 78.01% (best 91.62%); T9: W-NCM 93.33% (best 96.00%); T10: W-NCM 92.08% (best 92.08%)
2025-12-11 17:42:14,439 [trainer.py] => Average forgetting (W-NCM): 12.45% | Max forgetting (W-NCM): 22.76%
2025-12-11 17:42:14,445 [trainer.py] => All params: 126094051
2025-12-11 17:42:14,451 [trainer.py] => Trainable params: 187396
2025-12-11 17:42:14,452 [inflora.py] => Learning on 40-44
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.10.weight', 'image_encoder.blocks.3.attn.lora_B_v.10.weight', 'image_encoder.blocks.5.attn.lora_B_k.10.weight', 'image_encoder.blocks.3.attn.lora_B_k.10.weight', 'image_encoder.blocks.9.attn.lora_B_k.10.weight', 'image_encoder.blocks.1.attn.lora_B_v.10.weight', 'image_encoder.blocks.8.attn.lora_B_v.10.weight', 'image_encoder.blocks.1.attn.lora_B_k.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.10.weight', 'image_encoder.blocks.9.attn.lora_B_v.10.weight', 'image_encoder.blocks.5.attn.lora_B_v.10.weight', 'classifier_pool.10.weight', 'image_encoder.blocks.2.attn.lora_B_k.10.weight', 'image_encoder.blocks.11.attn.lora_B_v.10.weight', 'image_encoder.blocks.4.attn.lora_B_v.10.weight', 'classifier_pool.10.bias', 'image_encoder.blocks.10.attn.lora_B_v.10.weight', 'image_encoder.blocks.11.attn.lora_B_k.10.weight', 'image_encoder.blocks.8.attn.lora_B_k.10.weight', 'image_encoder.blocks.10.attn.lora_B_k.10.weight', 'image_encoder.blocks.6.attn.lora_B_k.10.weight', 'image_encoder.blocks.7.attn.lora_B_k.10.weight', 'image_encoder.blocks.6.attn.lora_B_v.10.weight', 'image_encoder.blocks.0.attn.lora_B_k.10.weight', 'image_encoder.blocks.7.attn.lora_B_v.10.weight', 'image_encoder.blocks.2.attn.lora_B_v.10.weight'}
2025-12-11 17:44:28,758 [inflora.py] => Task 10, Epoch 50/50 => Loss 0.118, Train_accy 95.78
Threshold:  0.984
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 17/768 type remove
Layer 3 : 35/768 type remove
Layer 4 : 48/768 type remove
Layer 5 : 70/768 type remove
Layer 6 : 63/768 type remove
Layer 7 : 70/768 type remove
Layer 8 : 79/768 type remove
Layer 9 : 125/768 type remove
Layer 10 : 152/768 type remove
Layer 11 : 90/768 type remove
Layer 12 : 132/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:44:35,793 [trainer.py] => Time:141.34133887290955
1486 1486
1486 1486
2025-12-11 17:44:40,594 [trainer.py] => Time:4.800356864929199
2025-12-11 17:44:40,594 [inflora.py] => Exemplar size: 0
2025-12-11 17:44:40,594 [trainer.py] => CNN: {'total': np.float64(70.79), '00-03': np.float64(67.1), '04-07': np.float64(74.48), '08-11': np.float64(71.05), '12-15': np.float64(84.55), '16-19': np.float64(70.63), '20-23': np.float64(73.97), '24-27': np.float64(81.71), '28-31': np.float64(52.36), '32-35': np.float64(70.67), '36-39': np.float64(81.19), '40-43': np.float64(53.49), 'old': np.float64(71.86), 'new': np.float64(53.49)}
2025-12-11 17:44:40,594 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79)]
2025-12-11 17:44:40,594 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66)]
2025-12-11 17:44:40,594 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323]
2025-12-11 17:44:47,403 [trainer.py] => W-NCM: {'00-03': 64.51612903225806, '04-07': 71.72413793103448, '08-11': 71.9298245614035, '12-15': 89.0909090909091, '16-19': 83.33333333333334, '20-23': 77.1689497716895, '24-27': 81.09756097560977, '28-31': 75.91623036649214, '32-35': 93.33333333333333, '36-39': 92.07920792079209, '40-43': 76.74418604651163}
2025-12-11 17:44:47,403 [trainer.py] => Ave Acc (W-NCM): 79.72%
2025-12-11 17:44:47,403 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 64.52% (best 83.23%); T2: W-NCM 71.72% (best 93.79%); T3: W-NCM 71.93% (best 84.21%); T4: W-NCM 89.09% (best 92.73%); T5: W-NCM 83.33% (best 95.24%); T6: W-NCM 77.17% (best 92.24%); T7: W-NCM 81.10% (best 89.02%); T8: W-NCM 75.92% (best 91.62%); T9: W-NCM 93.33% (best 96.00%); T10: W-NCM 92.08% (best 92.08%); T11: W-NCM 76.74% (best 76.74%)
2025-12-11 17:44:47,403 [trainer.py] => Average forgetting (W-NCM): 11.00% | Max forgetting (W-NCM): 22.07%
2025-12-11 17:44:47,410 [trainer.py] => All params: 126094051
2025-12-11 17:44:47,416 [trainer.py] => Trainable params: 187396
2025-12-11 17:44:47,416 [inflora.py] => Learning on 44-48
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_v.11.weight', 'image_encoder.blocks.5.attn.lora_B_k.11.weight', 'image_encoder.blocks.7.attn.lora_B_v.11.weight', 'image_encoder.blocks.8.attn.lora_B_k.11.weight', 'classifier_pool.11.weight', 'image_encoder.blocks.0.attn.lora_B_k.11.weight', 'image_encoder.blocks.1.attn.lora_B_v.11.weight', 'image_encoder.blocks.10.attn.lora_B_k.11.weight', 'image_encoder.blocks.1.attn.lora_B_k.11.weight', 'image_encoder.blocks.11.attn.lora_B_v.11.weight', 'image_encoder.blocks.8.attn.lora_B_v.11.weight', 'image_encoder.blocks.2.attn.lora_B_k.11.weight', 'image_encoder.blocks.11.attn.lora_B_k.11.weight', 'image_encoder.blocks.5.attn.lora_B_v.11.weight', 'image_encoder.blocks.0.attn.lora_B_v.11.weight', 'classifier_pool.11.bias', 'image_encoder.blocks.4.attn.lora_B_k.11.weight', 'image_encoder.blocks.7.attn.lora_B_k.11.weight', 'image_encoder.blocks.4.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_k.11.weight', 'image_encoder.blocks.6.attn.lora_B_v.11.weight', 'image_encoder.blocks.10.attn.lora_B_v.11.weight', 'image_encoder.blocks.9.attn.lora_B_k.11.weight', 'image_encoder.blocks.3.attn.lora_B_k.11.weight', 'image_encoder.blocks.3.attn.lora_B_v.11.weight', 'image_encoder.blocks.9.attn.lora_B_v.11.weight'}
2025-12-11 17:46:55,130 [inflora.py] => Task 11, Epoch 50/50 => Loss 0.144, Train_accy 93.99
Threshold:  0.9843999999999999
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 17/768 type remove
Layer 3 : 36/768 type remove
Layer 4 : 51/768 type remove
Layer 5 : 74/768 type remove
Layer 6 : 67/768 type remove
Layer 7 : 75/768 type remove
Layer 8 : 84/768 type remove
Layer 9 : 131/768 type remove
Layer 10 : 155/768 type remove
Layer 11 : 94/768 type remove
Layer 12 : 136/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:47:02,028 [trainer.py] => Time:134.61229753494263
1540 1540
1540 1540
2025-12-11 17:47:07,041 [trainer.py] => Time:5.012733697891235
2025-12-11 17:47:07,041 [inflora.py] => Exemplar size: 0
2025-12-11 17:47:07,042 [trainer.py] => CNN: {'total': np.float64(69.22), '00-03': np.float64(69.03), '04-07': np.float64(74.48), '08-11': np.float64(69.3), '12-15': np.float64(84.55), '16-19': np.float64(69.84), '20-23': np.float64(74.89), '24-27': np.float64(79.27), '28-31': np.float64(53.93), '32-35': np.float64(69.33), '36-39': np.float64(78.22), '40-43': np.float64(53.49), '44-47': np.float64(31.48), 'old': np.float64(70.59), 'new': np.float64(31.48)}
2025-12-11 17:47:07,042 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22)]
2025-12-11 17:47:07,042 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56)]
2025-12-11 17:47:07,042 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103]
2025-12-11 17:47:13,882 [trainer.py] => W-NCM: {'00-03': 61.935483870967744, '04-07': 68.96551724137932, '08-11': 71.9298245614035, '12-15': 86.36363636363636, '16-19': 80.15873015873017, '20-23': 75.79908675799086, '24-27': 79.26829268292683, '28-31': 74.86910994764398, '32-35': 92.0, '36-39': 85.14851485148515, '40-43': 72.09302325581395, '44-47': 75.92592592592592}
2025-12-11 17:47:13,882 [trainer.py] => Ave Acc (W-NCM): 77.04%
2025-12-11 17:47:13,882 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 61.94% (best 83.23%); T2: W-NCM 68.97% (best 93.79%); T3: W-NCM 71.93% (best 84.21%); T4: W-NCM 86.36% (best 92.73%); T5: W-NCM 80.16% (best 95.24%); T6: W-NCM 75.80% (best 92.24%); T7: W-NCM 79.27% (best 89.02%); T8: W-NCM 74.87% (best 91.62%); T9: W-NCM 92.00% (best 96.00%); T10: W-NCM 85.15% (best 92.08%); T11: W-NCM 72.09% (best 76.74%); T12: W-NCM 75.93% (best 75.93%)
2025-12-11 17:47:13,882 [trainer.py] => Average forgetting (W-NCM): 12.58% | Max forgetting (W-NCM): 24.83%
2025-12-11 17:47:13,889 [trainer.py] => All params: 126094051
2025-12-11 17:47:13,895 [trainer.py] => Trainable params: 187396
2025-12-11 17:47:13,895 [inflora.py] => Learning on 48-52
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_k.12.weight', 'image_encoder.blocks.5.attn.lora_B_k.12.weight', 'image_encoder.blocks.6.attn.lora_B_k.12.weight', 'classifier_pool.12.weight', 'image_encoder.blocks.6.attn.lora_B_v.12.weight', 'image_encoder.blocks.10.attn.lora_B_v.12.weight', 'image_encoder.blocks.5.attn.lora_B_v.12.weight', 'classifier_pool.12.bias', 'image_encoder.blocks.4.attn.lora_B_v.12.weight', 'image_encoder.blocks.2.attn.lora_B_v.12.weight', 'image_encoder.blocks.3.attn.lora_B_k.12.weight', 'image_encoder.blocks.7.attn.lora_B_k.12.weight', 'image_encoder.blocks.9.attn.lora_B_v.12.weight', 'image_encoder.blocks.1.attn.lora_B_v.12.weight', 'image_encoder.blocks.4.attn.lora_B_k.12.weight', 'image_encoder.blocks.8.attn.lora_B_k.12.weight', 'image_encoder.blocks.0.attn.lora_B_k.12.weight', 'image_encoder.blocks.3.attn.lora_B_v.12.weight', 'image_encoder.blocks.9.attn.lora_B_k.12.weight', 'image_encoder.blocks.7.attn.lora_B_v.12.weight', 'image_encoder.blocks.2.attn.lora_B_k.12.weight', 'image_encoder.blocks.8.attn.lora_B_v.12.weight', 'image_encoder.blocks.11.attn.lora_B_v.12.weight', 'image_encoder.blocks.10.attn.lora_B_k.12.weight', 'image_encoder.blocks.0.attn.lora_B_v.12.weight', 'image_encoder.blocks.11.attn.lora_B_k.12.weight'}
2025-12-11 17:50:07,399 [inflora.py] => Task 12, Epoch 50/50 => Loss 0.060, Train_accy 97.12
Threshold:  0.9848
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 18/768 type remove
Layer 3 : 37/768 type remove
Layer 4 : 53/768 type remove
Layer 5 : 77/768 type remove
Layer 6 : 69/768 type remove
Layer 7 : 78/768 type remove
Layer 8 : 87/768 type remove
Layer 9 : 136/768 type remove
Layer 10 : 159/768 type remove
Layer 11 : 98/768 type remove
Layer 12 : 140/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:50:15,155 [trainer.py] => Time:181.26060843467712
1671 1671
1671 1671
2025-12-11 17:50:20,483 [trainer.py] => Time:5.327395677566528
2025-12-11 17:50:20,483 [inflora.py] => Exemplar size: 0
2025-12-11 17:50:20,484 [trainer.py] => CNN: {'total': np.float64(69.96), '00-03': np.float64(67.1), '04-07': np.float64(80.0), '08-11': np.float64(67.54), '12-15': np.float64(84.55), '16-19': np.float64(73.81), '20-23': np.float64(74.43), '24-27': np.float64(81.1), '28-31': np.float64(49.74), '32-35': np.float64(70.67), '36-39': np.float64(80.2), '40-43': np.float64(52.33), '44-47': np.float64(35.19), '48-51': np.float64(74.05), 'old': np.float64(69.61), 'new': np.float64(74.05)}
2025-12-11 17:50:20,484 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96)]
2025-12-11 17:50:20,484 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86)]
2025-12-11 17:50:20,484 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065]
2025-12-11 17:50:28,060 [trainer.py] => W-NCM: {'00-03': 64.51612903225806, '04-07': 71.03448275862068, '08-11': 72.80701754385966, '12-15': 86.36363636363636, '16-19': 82.53968253968253, '20-23': 74.88584474885845, '24-27': 78.65853658536585, '28-31': 73.82198952879581, '32-35': 92.0, '36-39': 81.1881188118812, '40-43': 74.4186046511628, '44-47': 70.37037037037037, '48-51': 95.41984732824427}
2025-12-11 17:50:28,060 [trainer.py] => Ave Acc (W-NCM): 78.31%
2025-12-11 17:50:28,060 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 64.52% (best 83.23%); T2: W-NCM 71.03% (best 93.79%); T3: W-NCM 72.81% (best 84.21%); T4: W-NCM 86.36% (best 92.73%); T5: W-NCM 82.54% (best 95.24%); T6: W-NCM 74.89% (best 92.24%); T7: W-NCM 78.66% (best 89.02%); T8: W-NCM 73.82% (best 91.62%); T9: W-NCM 92.00% (best 96.00%); T10: W-NCM 81.19% (best 92.08%); T11: W-NCM 74.42% (best 76.74%); T12: W-NCM 70.37% (best 75.93%); T13: W-NCM 95.42% (best 95.42%)
2025-12-11 17:50:28,060 [trainer.py] => Average forgetting (W-NCM): 11.69% | Max forgetting (W-NCM): 22.76%
2025-12-11 17:50:28,067 [trainer.py] => All params: 126094051
2025-12-11 17:50:28,073 [trainer.py] => Trainable params: 187396
2025-12-11 17:50:28,073 [inflora.py] => Learning on 52-56
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.13.weight', 'image_encoder.blocks.0.attn.lora_B_v.13.weight', 'image_encoder.blocks.8.attn.lora_B_k.13.weight', 'image_encoder.blocks.3.attn.lora_B_v.13.weight', 'image_encoder.blocks.5.attn.lora_B_v.13.weight', 'image_encoder.blocks.9.attn.lora_B_v.13.weight', 'image_encoder.blocks.4.attn.lora_B_v.13.weight', 'image_encoder.blocks.1.attn.lora_B_k.13.weight', 'image_encoder.blocks.6.attn.lora_B_v.13.weight', 'image_encoder.blocks.3.attn.lora_B_k.13.weight', 'classifier_pool.13.weight', 'image_encoder.blocks.10.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_v.13.weight', 'image_encoder.blocks.6.attn.lora_B_k.13.weight', 'image_encoder.blocks.2.attn.lora_B_k.13.weight', 'image_encoder.blocks.10.attn.lora_B_k.13.weight', 'image_encoder.blocks.1.attn.lora_B_v.13.weight', 'image_encoder.blocks.9.attn.lora_B_k.13.weight', 'image_encoder.blocks.2.attn.lora_B_v.13.weight', 'image_encoder.blocks.4.attn.lora_B_k.13.weight', 'classifier_pool.13.bias', 'image_encoder.blocks.5.attn.lora_B_k.13.weight', 'image_encoder.blocks.7.attn.lora_B_k.13.weight', 'image_encoder.blocks.7.attn.lora_B_v.13.weight', 'image_encoder.blocks.8.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.13.weight'}
2025-12-11 17:52:43,905 [inflora.py] => Task 13, Epoch 50/50 => Loss 0.132, Train_accy 94.81
Threshold:  0.9852
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 18/768 type remove
Layer 3 : 39/768 type remove
Layer 4 : 56/768 type remove
Layer 5 : 82/768 type remove
Layer 6 : 74/768 type remove
Layer 7 : 83/768 type remove
Layer 8 : 92/768 type remove
Layer 9 : 142/768 type remove
Layer 10 : 163/768 type remove
Layer 11 : 103/768 type remove
Layer 12 : 144/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:52:51,138 [trainer.py] => Time:143.0644772052765
1732 1732
1732 1732
2025-12-11 17:52:56,659 [trainer.py] => Time:5.520776033401489
2025-12-11 17:52:56,659 [inflora.py] => Exemplar size: 0
2025-12-11 17:52:56,659 [trainer.py] => CNN: {'total': np.float64(68.13), '00-03': np.float64(63.87), '04-07': np.float64(75.17), '08-11': np.float64(65.79), '12-15': np.float64(78.18), '16-19': np.float64(76.19), '20-23': np.float64(75.34), '24-27': np.float64(78.66), '28-31': np.float64(50.79), '32-35': np.float64(72.0), '36-39': np.float64(74.26), '40-43': np.float64(51.16), '44-47': np.float64(37.04), '48-51': np.float64(74.81), '52-55': np.float64(54.1), 'old': np.float64(68.64), 'new': np.float64(54.1)}
2025-12-11 17:52:56,659 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13)]
2025-12-11 17:52:56,659 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92)]
2025-12-11 17:52:56,659 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693]
2025-12-11 17:53:04,020 [trainer.py] => W-NCM: {'00-03': 67.74193548387096, '04-07': 73.79310344827587, '08-11': 72.80701754385966, '12-15': 85.45454545454545, '16-19': 84.12698412698413, '20-23': 74.42922374429224, '24-27': 77.4390243902439, '28-31': 76.96335078534031, '32-35': 92.0, '36-39': 81.1881188118812, '40-43': 68.6046511627907, '44-47': 64.81481481481481, '48-51': 89.31297709923665, '52-55': 85.24590163934425}
2025-12-11 17:53:04,020 [trainer.py] => Ave Acc (W-NCM): 78.14%
2025-12-11 17:53:04,020 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 67.74% (best 83.23%); T2: W-NCM 73.79% (best 93.79%); T3: W-NCM 72.81% (best 84.21%); T4: W-NCM 85.45% (best 92.73%); T5: W-NCM 84.13% (best 95.24%); T6: W-NCM 74.43% (best 92.24%); T7: W-NCM 77.44% (best 89.02%); T8: W-NCM 76.96% (best 91.62%); T9: W-NCM 92.00% (best 96.00%); T10: W-NCM 81.19% (best 92.08%); T11: W-NCM 68.60% (best 76.74%); T12: W-NCM 64.81% (best 75.93%); T13: W-NCM 89.31% (best 95.42%); T14: W-NCM 85.25% (best 85.25%)
2025-12-11 17:53:04,020 [trainer.py] => Average forgetting (W-NCM): 11.51% | Max forgetting (W-NCM): 20.00%
2025-12-11 17:53:04,027 [trainer.py] => All params: 126094051
2025-12-11 17:53:04,033 [trainer.py] => Trainable params: 187396
2025-12-11 17:53:04,033 [inflora.py] => Learning on 56-60
Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_k.14.weight', 'image_encoder.blocks.10.attn.lora_B_v.14.weight', 'image_encoder.blocks.9.attn.lora_B_v.14.weight', 'image_encoder.blocks.3.attn.lora_B_v.14.weight', 'image_encoder.blocks.9.attn.lora_B_k.14.weight', 'image_encoder.blocks.5.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_k.14.weight', 'image_encoder.blocks.4.attn.lora_B_v.14.weight', 'classifier_pool.14.weight', 'image_encoder.blocks.0.attn.lora_B_v.14.weight', 'image_encoder.blocks.1.attn.lora_B_k.14.weight', 'image_encoder.blocks.5.attn.lora_B_k.14.weight', 'image_encoder.blocks.0.attn.lora_B_k.14.weight', 'image_encoder.blocks.6.attn.lora_B_v.14.weight', 'image_encoder.blocks.2.attn.lora_B_v.14.weight', 'image_encoder.blocks.11.attn.lora_B_v.14.weight', 'image_encoder.blocks.11.attn.lora_B_k.14.weight', 'classifier_pool.14.bias', 'image_encoder.blocks.8.attn.lora_B_k.14.weight', 'image_encoder.blocks.10.attn.lora_B_k.14.weight', 'image_encoder.blocks.7.attn.lora_B_v.14.weight', 'image_encoder.blocks.2.attn.lora_B_k.14.weight', 'image_encoder.blocks.6.attn.lora_B_k.14.weight', 'image_encoder.blocks.7.attn.lora_B_k.14.weight', 'image_encoder.blocks.1.attn.lora_B_v.14.weight', 'image_encoder.blocks.8.attn.lora_B_v.14.weight'}
2025-12-11 17:55:48,381 [inflora.py] => Task 14, Epoch 50/50 => Loss 0.145, Train_accy 92.71
Threshold:  0.9856
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 18/768 type remove
Layer 3 : 40/768 type remove
Layer 4 : 58/768 type remove
Layer 5 : 84/768 type remove
Layer 6 : 76/768 type remove
Layer 7 : 87/768 type remove
Layer 8 : 97/768 type remove
Layer 9 : 148/768 type remove
Layer 10 : 169/768 type remove
Layer 11 : 109/768 type remove
Layer 12 : 148/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:55:56,207 [trainer.py] => Time:172.1739637851715
1827 1827
1827 1827
2025-12-11 17:56:01,896 [trainer.py] => Time:5.688744068145752
2025-12-11 17:56:01,896 [inflora.py] => Exemplar size: 0
2025-12-11 17:56:01,896 [trainer.py] => CNN: {'total': np.float64(69.68), '00-03': np.float64(65.81), '04-07': np.float64(73.79), '08-11': np.float64(73.68), '12-15': np.float64(83.64), '16-19': np.float64(79.37), '20-23': np.float64(74.43), '24-27': np.float64(81.71), '28-31': np.float64(53.4), '32-35': np.float64(70.67), '36-39': np.float64(79.21), '40-43': np.float64(59.3), '44-47': np.float64(40.74), '48-51': np.float64(73.28), '52-55': np.float64(55.74), '56-59': np.float64(55.79), 'old': np.float64(70.44), 'new': np.float64(55.79)}
2025-12-11 17:56:01,896 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68)]
2025-12-11 17:56:01,896 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56)]
2025-12-11 17:56:01,896 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143]
2025-12-11 17:56:10,063 [trainer.py] => W-NCM: {'00-03': 70.3225806451613, '04-07': 73.10344827586206, '08-11': 73.68421052631578, '12-15': 85.45454545454545, '16-19': 81.74603174603175, '20-23': 78.99543378995433, '24-27': 79.8780487804878, '28-31': 76.43979057591623, '32-35': 92.0, '36-39': 78.21782178217822, '40-43': 68.6046511627907, '44-47': 64.81481481481481, '48-51': 68.70229007633588, '52-55': 75.40983606557377, '56-59': 90.52631578947368}
2025-12-11 17:56:10,063 [trainer.py] => Ave Acc (W-NCM): 77.19%
2025-12-11 17:56:10,063 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 70.32% (best 83.23%); T2: W-NCM 73.10% (best 93.79%); T3: W-NCM 73.68% (best 84.21%); T4: W-NCM 85.45% (best 92.73%); T5: W-NCM 81.75% (best 95.24%); T6: W-NCM 79.00% (best 92.24%); T7: W-NCM 79.88% (best 89.02%); T8: W-NCM 76.44% (best 91.62%); T9: W-NCM 92.00% (best 96.00%); T10: W-NCM 78.22% (best 92.08%); T11: W-NCM 68.60% (best 76.74%); T12: W-NCM 64.81% (best 75.93%); T13: W-NCM 68.70% (best 95.42%); T14: W-NCM 75.41% (best 85.25%); T15: W-NCM 90.53% (best 90.53%)
2025-12-11 17:56:10,063 [trainer.py] => Average forgetting (W-NCM): 12.58% | Max forgetting (W-NCM): 26.72%
2025-12-11 17:56:10,070 [trainer.py] => All params: 126094051
2025-12-11 17:56:10,076 [trainer.py] => Trainable params: 187396
2025-12-11 17:56:10,076 [inflora.py] => Learning on 60-64
Parameters to be updated: {'image_encoder.blocks.8.attn.lora_B_v.15.weight', 'image_encoder.blocks.3.attn.lora_B_v.15.weight', 'image_encoder.blocks.10.attn.lora_B_v.15.weight', 'image_encoder.blocks.2.attn.lora_B_k.15.weight', 'image_encoder.blocks.0.attn.lora_B_k.15.weight', 'image_encoder.blocks.11.attn.lora_B_k.15.weight', 'image_encoder.blocks.3.attn.lora_B_k.15.weight', 'image_encoder.blocks.5.attn.lora_B_v.15.weight', 'image_encoder.blocks.11.attn.lora_B_v.15.weight', 'image_encoder.blocks.0.attn.lora_B_v.15.weight', 'image_encoder.blocks.10.attn.lora_B_k.15.weight', 'image_encoder.blocks.9.attn.lora_B_v.15.weight', 'image_encoder.blocks.6.attn.lora_B_k.15.weight', 'image_encoder.blocks.2.attn.lora_B_v.15.weight', 'image_encoder.blocks.6.attn.lora_B_v.15.weight', 'image_encoder.blocks.8.attn.lora_B_k.15.weight', 'image_encoder.blocks.7.attn.lora_B_k.15.weight', 'image_encoder.blocks.9.attn.lora_B_k.15.weight', 'image_encoder.blocks.1.attn.lora_B_v.15.weight', 'image_encoder.blocks.4.attn.lora_B_v.15.weight', 'image_encoder.blocks.5.attn.lora_B_k.15.weight', 'classifier_pool.15.bias', 'image_encoder.blocks.4.attn.lora_B_k.15.weight', 'image_encoder.blocks.7.attn.lora_B_v.15.weight', 'image_encoder.blocks.1.attn.lora_B_k.15.weight', 'classifier_pool.15.weight'}
2025-12-11 17:59:39,893 [inflora.py] => Task 15, Epoch 50/50 => Loss 0.048, Train_accy 97.94
Threshold:  0.986
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 19/768 type remove
Layer 3 : 42/768 type remove
Layer 4 : 60/768 type remove
Layer 5 : 87/768 type remove
Layer 6 : 80/768 type remove
Layer 7 : 91/768 type remove
Layer 8 : 102/768 type remove
Layer 9 : 153/768 type remove
Layer 10 : 174/768 type remove
Layer 11 : 113/768 type remove
Layer 12 : 151/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 17:59:48,368 [trainer.py] => Time:218.2923083305359
1974 1974
1974 1974
2025-12-11 17:59:54,556 [trainer.py] => Time:6.187123775482178
2025-12-11 17:59:54,556 [inflora.py] => Exemplar size: 0
2025-12-11 17:59:54,556 [trainer.py] => CNN: {'total': np.float64(68.69), '00-03': np.float64(72.26), '04-07': np.float64(73.1), '08-11': np.float64(68.42), '12-15': np.float64(82.73), '16-19': np.float64(76.98), '20-23': np.float64(74.89), '24-27': np.float64(78.66), '28-31': np.float64(47.12), '32-35': np.float64(68.0), '36-39': np.float64(76.24), '40-43': np.float64(54.65), '44-47': np.float64(40.74), '48-51': np.float64(72.52), '52-55': np.float64(40.98), '56-59': np.float64(47.37), '60-63': np.float64(86.39), 'old': np.float64(67.27), 'new': np.float64(86.39)}
2025-12-11 17:59:54,556 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69)]
2025-12-11 17:59:54,556 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3)]
2025-12-11 17:59:54,556 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251]
2025-12-11 18:00:03,424 [trainer.py] => W-NCM: {'00-03': 67.0967741935484, '04-07': 73.10344827586206, '08-11': 70.17543859649122, '12-15': 84.54545454545455, '16-19': 81.74603174603175, '20-23': 74.88584474885845, '24-27': 67.07317073170732, '28-31': 74.3455497382199, '32-35': 89.33333333333333, '36-39': 79.20792079207921, '40-43': 63.95348837209303, '44-47': 62.96296296296296, '48-51': 80.1526717557252, '52-55': 75.40983606557377, '56-59': 83.15789473684211, '60-63': 91.83673469387756}
2025-12-11 18:00:03,425 [trainer.py] => Ave Acc (W-NCM): 76.19%
2025-12-11 18:00:03,425 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 67.10% (best 83.23%); T2: W-NCM 73.10% (best 93.79%); T3: W-NCM 70.18% (best 84.21%); T4: W-NCM 84.55% (best 92.73%); T5: W-NCM 81.75% (best 95.24%); T6: W-NCM 74.89% (best 92.24%); T7: W-NCM 67.07% (best 89.02%); T8: W-NCM 74.35% (best 91.62%); T9: W-NCM 89.33% (best 96.00%); T10: W-NCM 79.21% (best 92.08%); T11: W-NCM 63.95% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 80.15% (best 95.42%); T14: W-NCM 75.41% (best 85.25%); T15: W-NCM 83.16% (best 90.53%); T16: W-NCM 91.84% (best 91.84%)
2025-12-11 18:00:03,425 [trainer.py] => Average forgetting (W-NCM): 13.79% | Max forgetting (W-NCM): 21.95%
2025-12-11 18:00:03,431 [trainer.py] => All params: 126094051
2025-12-11 18:00:03,438 [trainer.py] => Trainable params: 187396
2025-12-11 18:00:03,438 [inflora.py] => Learning on 64-68
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.16.weight', 'image_encoder.blocks.7.attn.lora_B_v.16.weight', 'image_encoder.blocks.10.attn.lora_B_v.16.weight', 'image_encoder.blocks.6.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_k.16.weight', 'image_encoder.blocks.9.attn.lora_B_v.16.weight', 'image_encoder.blocks.10.attn.lora_B_k.16.weight', 'image_encoder.blocks.7.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_v.16.weight', 'image_encoder.blocks.2.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_v.16.weight', 'image_encoder.blocks.5.attn.lora_B_k.16.weight', 'image_encoder.blocks.9.attn.lora_B_k.16.weight', 'image_encoder.blocks.8.attn.lora_B_v.16.weight', 'image_encoder.blocks.8.attn.lora_B_k.16.weight', 'image_encoder.blocks.1.attn.lora_B_k.16.weight', 'image_encoder.blocks.1.attn.lora_B_v.16.weight', 'image_encoder.blocks.6.attn.lora_B_v.16.weight', 'image_encoder.blocks.5.attn.lora_B_v.16.weight', 'image_encoder.blocks.4.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_k.16.weight', 'classifier_pool.16.weight', 'image_encoder.blocks.2.attn.lora_B_v.16.weight', 'classifier_pool.16.bias', 'image_encoder.blocks.0.attn.lora_B_v.16.weight', 'image_encoder.blocks.0.attn.lora_B_k.16.weight'}
2025-12-11 18:01:58,786 [inflora.py] => Task 16, Epoch 50/50 => Loss 0.134, Train_accy 95.93
Threshold:  0.9863999999999999
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 19/768 type remove
Layer 3 : 44/768 type remove
Layer 4 : 64/768 type remove
Layer 5 : 92/768 type remove
Layer 6 : 85/768 type remove
Layer 7 : 97/768 type remove
Layer 8 : 109/768 type remove
Layer 9 : 161/768 type remove
Layer 10 : 180/768 type remove
Layer 11 : 120/768 type remove
Layer 12 : 155/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:02:05,524 [trainer.py] => Time:122.0856466293335
2023 2023
2023 2023
2025-12-11 18:02:11,774 [trainer.py] => Time:6.2497148513793945
2025-12-11 18:02:11,774 [inflora.py] => Exemplar size: 0
2025-12-11 18:02:11,774 [trainer.py] => CNN: {'total': np.float64(66.34), '00-03': np.float64(65.16), '04-07': np.float64(70.34), '08-11': np.float64(70.18), '12-15': np.float64(81.82), '16-19': np.float64(73.02), '20-23': np.float64(73.97), '24-27': np.float64(78.66), '28-31': np.float64(44.5), '32-35': np.float64(65.33), '36-39': np.float64(74.26), '40-43': np.float64(50.0), '44-47': np.float64(38.89), '48-51': np.float64(69.47), '52-55': np.float64(37.7), '56-59': np.float64(49.47), '60-63': np.float64(86.39), '64-67': np.float64(51.02), 'old': np.float64(66.72), 'new': np.float64(51.02)}
2025-12-11 18:02:11,774 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34)]
2025-12-11 18:02:11,774 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19)]
2025-12-11 18:02:11,774 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062]
2025-12-11 18:02:19,903 [trainer.py] => W-NCM: {'00-03': 65.16129032258064, '04-07': 69.6551724137931, '08-11': 74.56140350877193, '12-15': 84.54545454545455, '16-19': 79.36507936507937, '20-23': 74.88584474885845, '24-27': 71.34146341463415, '28-31': 71.20418848167539, '32-35': 88.0, '36-39': 74.25742574257426, '40-43': 65.11627906976744, '44-47': 61.111111111111114, '48-51': 80.1526717557252, '52-55': 72.1311475409836, '56-59': 83.15789473684211, '60-63': 91.15646258503402, '64-67': 91.83673469387756}
2025-12-11 18:02:19,903 [trainer.py] => Ave Acc (W-NCM): 76.33%
2025-12-11 18:02:19,903 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 65.16% (best 83.23%); T2: W-NCM 69.66% (best 93.79%); T3: W-NCM 74.56% (best 84.21%); T4: W-NCM 84.55% (best 92.73%); T5: W-NCM 79.37% (best 95.24%); T6: W-NCM 74.89% (best 92.24%); T7: W-NCM 71.34% (best 89.02%); T8: W-NCM 71.20% (best 91.62%); T9: W-NCM 88.00% (best 96.00%); T10: W-NCM 74.26% (best 92.08%); T11: W-NCM 65.12% (best 76.74%); T12: W-NCM 61.11% (best 75.93%); T13: W-NCM 80.15% (best 95.42%); T14: W-NCM 72.13% (best 85.25%); T15: W-NCM 83.16% (best 90.53%); T16: W-NCM 91.16% (best 91.84%); T17: W-NCM 91.84% (best 91.84%)
2025-12-11 18:02:19,903 [trainer.py] => Average forgetting (W-NCM): 13.75% | Max forgetting (W-NCM): 24.14%
2025-12-11 18:02:19,910 [trainer.py] => All params: 126094051
2025-12-11 18:02:19,916 [trainer.py] => Trainable params: 187396
2025-12-11 18:02:19,916 [inflora.py] => Learning on 68-72
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.17.weight', 'image_encoder.blocks.9.attn.lora_B_v.17.weight', 'image_encoder.blocks.2.attn.lora_B_v.17.weight', 'image_encoder.blocks.5.attn.lora_B_k.17.weight', 'image_encoder.blocks.8.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_v.17.weight', 'image_encoder.blocks.1.attn.lora_B_v.17.weight', 'image_encoder.blocks.0.attn.lora_B_v.17.weight', 'image_encoder.blocks.2.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_v.17.weight', 'classifier_pool.17.bias', 'image_encoder.blocks.1.attn.lora_B_k.17.weight', 'image_encoder.blocks.5.attn.lora_B_v.17.weight', 'image_encoder.blocks.0.attn.lora_B_k.17.weight', 'image_encoder.blocks.3.attn.lora_B_k.17.weight', 'image_encoder.blocks.11.attn.lora_B_v.17.weight', 'image_encoder.blocks.11.attn.lora_B_k.17.weight', 'image_encoder.blocks.7.attn.lora_B_k.17.weight', 'image_encoder.blocks.3.attn.lora_B_v.17.weight', 'image_encoder.blocks.10.attn.lora_B_k.17.weight', 'image_encoder.blocks.6.attn.lora_B_k.17.weight', 'image_encoder.blocks.9.attn.lora_B_k.17.weight', 'image_encoder.blocks.6.attn.lora_B_v.17.weight', 'image_encoder.blocks.8.attn.lora_B_k.17.weight', 'classifier_pool.17.weight', 'image_encoder.blocks.10.attn.lora_B_v.17.weight'}
2025-12-11 18:04:51,599 [inflora.py] => Task 17, Epoch 50/50 => Loss 0.112, Train_accy 96.49
Threshold:  0.9868
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 20/768 type remove
Layer 3 : 46/768 type remove
Layer 4 : 67/768 type remove
Layer 5 : 96/768 type remove
Layer 6 : 89/768 type remove
Layer 7 : 100/768 type remove
Layer 8 : 114/768 type remove
Layer 9 : 170/768 type remove
Layer 10 : 191/768 type remove
Layer 11 : 125/768 type remove
Layer 12 : 162/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:04:59,055 [trainer.py] => Time:159.13892889022827
2120 2120
2120 2120
2025-12-11 18:05:05,536 [trainer.py] => Time:6.480886697769165
2025-12-11 18:05:05,536 [inflora.py] => Exemplar size: 0
2025-12-11 18:05:05,536 [trainer.py] => CNN: {'total': np.float64(65.94), '00-03': np.float64(63.87), '04-07': np.float64(70.34), '08-11': np.float64(69.3), '12-15': np.float64(80.0), '16-19': np.float64(74.6), '20-23': np.float64(74.89), '24-27': np.float64(79.27), '28-31': np.float64(44.5), '32-35': np.float64(70.67), '36-39': np.float64(75.25), '40-43': np.float64(53.49), '44-47': np.float64(40.74), '48-51': np.float64(70.23), '52-55': np.float64(42.62), '56-59': np.float64(54.74), '60-63': np.float64(81.63), '64-67': np.float64(55.1), '68-71': np.float64(44.33), 'old': np.float64(66.98), 'new': np.float64(44.33)}
2025-12-11 18:05:05,536 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94)]
2025-12-11 18:05:05,537 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79)]
2025-12-11 18:05:05,537 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623]
2025-12-11 18:05:14,148 [trainer.py] => W-NCM: {'00-03': 61.935483870967744, '04-07': 66.20689655172414, '08-11': 70.17543859649122, '12-15': 83.63636363636363, '16-19': 75.39682539682539, '20-23': 71.68949771689498, '24-27': 68.90243902439023, '28-31': 65.44502617801047, '32-35': 86.66666666666667, '36-39': 73.26732673267327, '40-43': 63.95348837209303, '44-47': 62.96296296296296, '48-51': 77.09923664122137, '52-55': 75.40983606557377, '56-59': 82.10526315789474, '60-63': 80.95238095238095, '64-67': 81.63265306122449, '68-71': 87.62886597938144}
2025-12-11 18:05:14,149 [trainer.py] => Ave Acc (W-NCM): 74.17%
2025-12-11 18:05:14,149 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 61.94% (best 83.23%); T2: W-NCM 66.21% (best 93.79%); T3: W-NCM 70.18% (best 84.21%); T4: W-NCM 83.64% (best 92.73%); T5: W-NCM 75.40% (best 95.24%); T6: W-NCM 71.69% (best 92.24%); T7: W-NCM 68.90% (best 89.02%); T8: W-NCM 65.45% (best 91.62%); T9: W-NCM 86.67% (best 96.00%); T10: W-NCM 73.27% (best 92.08%); T11: W-NCM 63.95% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 77.10% (best 95.42%); T14: W-NCM 75.41% (best 85.25%); T15: W-NCM 82.11% (best 90.53%); T16: W-NCM 80.95% (best 91.84%); T17: W-NCM 81.63% (best 91.84%); T18: W-NCM 87.63% (best 87.63%)
2025-12-11 18:05:14,149 [trainer.py] => Average forgetting (W-NCM): 15.90% | Max forgetting (W-NCM): 27.59%
2025-12-11 18:05:14,155 [trainer.py] => All params: 126094051
2025-12-11 18:05:14,161 [trainer.py] => Trainable params: 187396
2025-12-11 18:05:14,161 [inflora.py] => Learning on 72-76
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_k.18.weight', 'classifier_pool.18.bias', 'image_encoder.blocks.0.attn.lora_B_k.18.weight', 'image_encoder.blocks.1.attn.lora_B_k.18.weight', 'image_encoder.blocks.10.attn.lora_B_k.18.weight', 'image_encoder.blocks.11.attn.lora_B_k.18.weight', 'image_encoder.blocks.7.attn.lora_B_v.18.weight', 'image_encoder.blocks.5.attn.lora_B_k.18.weight', 'classifier_pool.18.weight', 'image_encoder.blocks.2.attn.lora_B_v.18.weight', 'image_encoder.blocks.0.attn.lora_B_v.18.weight', 'image_encoder.blocks.10.attn.lora_B_v.18.weight', 'image_encoder.blocks.2.attn.lora_B_k.18.weight', 'image_encoder.blocks.3.attn.lora_B_v.18.weight', 'image_encoder.blocks.11.attn.lora_B_v.18.weight', 'image_encoder.blocks.8.attn.lora_B_v.18.weight', 'image_encoder.blocks.4.attn.lora_B_k.18.weight', 'image_encoder.blocks.4.attn.lora_B_v.18.weight', 'image_encoder.blocks.9.attn.lora_B_k.18.weight', 'image_encoder.blocks.5.attn.lora_B_v.18.weight', 'image_encoder.blocks.8.attn.lora_B_k.18.weight', 'image_encoder.blocks.1.attn.lora_B_v.18.weight', 'image_encoder.blocks.9.attn.lora_B_v.18.weight', 'image_encoder.blocks.7.attn.lora_B_k.18.weight', 'image_encoder.blocks.6.attn.lora_B_v.18.weight', 'image_encoder.blocks.3.attn.lora_B_k.18.weight'}
2025-12-11 18:08:37,967 [inflora.py] => Task 18, Epoch 50/50 => Loss 0.071, Train_accy 97.11
Threshold:  0.9872
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 21/768 type remove
Layer 3 : 51/768 type remove
Layer 4 : 75/768 type remove
Layer 5 : 106/768 type remove
Layer 6 : 97/768 type remove
Layer 7 : 112/768 type remove
Layer 8 : 128/768 type remove
Layer 9 : 198/768 type remove
Layer 10 : 214/768 type remove
Layer 11 : 140/768 type remove
Layer 12 : 185/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:08:46,286 [trainer.py] => Time:212.124418258667
2238 2238
2238 2238
2025-12-11 18:08:53,085 [trainer.py] => Time:6.799071311950684
2025-12-11 18:08:53,086 [inflora.py] => Exemplar size: 0
2025-12-11 18:08:53,086 [trainer.py] => CNN: {'total': np.float64(64.25), '00-03': np.float64(60.65), '04-07': np.float64(68.28), '08-11': np.float64(64.04), '12-15': np.float64(80.0), '16-19': np.float64(72.22), '20-23': np.float64(74.89), '24-27': np.float64(77.44), '28-31': np.float64(44.5), '32-35': np.float64(69.33), '36-39': np.float64(73.27), '40-43': np.float64(48.84), '44-47': np.float64(42.59), '48-51': np.float64(61.83), '52-55': np.float64(44.26), '56-59': np.float64(50.53), '60-63': np.float64(80.27), '64-67': np.float64(51.02), '68-71': np.float64(48.45), '72-75': np.float64(67.8), 'old': np.float64(64.06), 'new': np.float64(67.8)}
2025-12-11 18:08:53,086 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25)]
2025-12-11 18:08:53,086 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0)]
2025-12-11 18:08:53,086 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033]
2025-12-11 18:09:02,471 [trainer.py] => W-NCM: {'00-03': 60.0, '04-07': 65.51724137931035, '08-11': 63.1578947368421, '12-15': 79.0909090909091, '16-19': 75.39682539682539, '20-23': 70.77625570776256, '24-27': 67.6829268292683, '28-31': 63.87434554973822, '32-35': 78.66666666666666, '36-39': 67.32673267326733, '40-43': 60.46511627906976, '44-47': 66.66666666666666, '48-51': 76.33587786259542, '52-55': 70.49180327868852, '56-59': 76.84210526315789, '60-63': 72.78911564625851, '64-67': 81.63265306122449, '68-71': 80.41237113402062, '72-75': 92.37288135593221}
2025-12-11 18:09:02,471 [trainer.py] => Ave Acc (W-NCM): 72.08%
2025-12-11 18:09:02,471 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 60.00% (best 83.23%); T2: W-NCM 65.52% (best 93.79%); T3: W-NCM 63.16% (best 84.21%); T4: W-NCM 79.09% (best 92.73%); T5: W-NCM 75.40% (best 95.24%); T6: W-NCM 70.78% (best 92.24%); T7: W-NCM 67.68% (best 89.02%); T8: W-NCM 63.87% (best 91.62%); T9: W-NCM 78.67% (best 96.00%); T10: W-NCM 67.33% (best 92.08%); T11: W-NCM 60.47% (best 76.74%); T12: W-NCM 66.67% (best 75.93%); T13: W-NCM 76.34% (best 95.42%); T14: W-NCM 70.49% (best 85.25%); T15: W-NCM 76.84% (best 90.53%); T16: W-NCM 72.79% (best 91.84%); T17: W-NCM 81.63% (best 91.84%); T18: W-NCM 80.41% (best 87.63%); T19: W-NCM 92.37% (best 92.37%)
2025-12-11 18:09:02,471 [trainer.py] => Average forgetting (W-NCM): 18.23% | Max forgetting (W-NCM): 28.28%
2025-12-11 18:09:02,478 [trainer.py] => All params: 126094051
2025-12-11 18:09:02,484 [trainer.py] => Trainable params: 187396
2025-12-11 18:09:02,484 [inflora.py] => Learning on 76-80
Parameters to be updated: {'classifier_pool.19.bias', 'image_encoder.blocks.2.attn.lora_B_k.19.weight', 'image_encoder.blocks.2.attn.lora_B_v.19.weight', 'image_encoder.blocks.7.attn.lora_B_k.19.weight', 'image_encoder.blocks.0.attn.lora_B_v.19.weight', 'image_encoder.blocks.8.attn.lora_B_v.19.weight', 'image_encoder.blocks.8.attn.lora_B_k.19.weight', 'image_encoder.blocks.7.attn.lora_B_v.19.weight', 'image_encoder.blocks.1.attn.lora_B_k.19.weight', 'image_encoder.blocks.6.attn.lora_B_k.19.weight', 'image_encoder.blocks.11.attn.lora_B_v.19.weight', 'image_encoder.blocks.9.attn.lora_B_k.19.weight', 'classifier_pool.19.weight', 'image_encoder.blocks.6.attn.lora_B_v.19.weight', 'image_encoder.blocks.5.attn.lora_B_k.19.weight', 'image_encoder.blocks.10.attn.lora_B_v.19.weight', 'image_encoder.blocks.10.attn.lora_B_k.19.weight', 'image_encoder.blocks.11.attn.lora_B_k.19.weight', 'image_encoder.blocks.4.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.19.weight', 'image_encoder.blocks.1.attn.lora_B_v.19.weight', 'image_encoder.blocks.5.attn.lora_B_v.19.weight', 'image_encoder.blocks.9.attn.lora_B_v.19.weight', 'image_encoder.blocks.0.attn.lora_B_k.19.weight', 'image_encoder.blocks.4.attn.lora_B_v.19.weight', 'image_encoder.blocks.3.attn.lora_B_v.19.weight'}
2025-12-11 18:12:48,881 [inflora.py] => Task 19, Epoch 50/50 => Loss 0.062, Train_accy 98.10
Threshold:  0.9876
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 22/768 type remove
Layer 3 : 53/768 type remove
Layer 4 : 77/768 type remove
Layer 5 : 108/768 type remove
Layer 6 : 99/768 type remove
Layer 7 : 114/768 type remove
Layer 8 : 132/768 type remove
Layer 9 : 205/768 type remove
Layer 10 : 224/768 type remove
Layer 11 : 144/768 type remove
Layer 12 : 190/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:12:57,989 [trainer.py] => Time:235.50509428977966
2403 2403
2403 2403
2025-12-11 18:13:05,282 [trainer.py] => Time:7.292302846908569
2025-12-11 18:13:05,282 [inflora.py] => Exemplar size: 0
2025-12-11 18:13:05,282 [trainer.py] => CNN: {'total': np.float64(62.67), '00-03': np.float64(58.06), '04-07': np.float64(66.9), '08-11': np.float64(59.65), '12-15': np.float64(77.27), '16-19': np.float64(72.22), '20-23': np.float64(69.86), '24-27': np.float64(78.66), '28-31': np.float64(43.46), '32-35': np.float64(66.67), '36-39': np.float64(74.26), '40-43': np.float64(46.51), '44-47': np.float64(40.74), '48-51': np.float64(54.96), '52-55': np.float64(44.26), '56-59': np.float64(52.63), '60-63': np.float64(75.51), '64-67': np.float64(55.1), '68-71': np.float64(49.48), '72-75': np.float64(62.71), '76-79': np.float64(69.09), 'old': np.float64(62.2), 'new': np.float64(69.09)}
2025-12-11 18:13:05,282 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67)]
2025-12-11 18:13:05,282 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01)]
2025-12-11 18:13:05,283 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685]
2025-12-11 18:13:15,181 [trainer.py] => W-NCM: {'00-03': 63.2258064516129, '04-07': 68.96551724137932, '08-11': 65.78947368421053, '12-15': 85.45454545454545, '16-19': 78.57142857142857, '20-23': 71.68949771689498, '24-27': 68.90243902439023, '28-31': 64.3979057591623, '32-35': 82.66666666666667, '36-39': 67.32673267326733, '40-43': 62.7906976744186, '44-47': 68.51851851851852, '48-51': 79.38931297709924, '52-55': 73.77049180327869, '56-59': 83.15789473684211, '60-63': 72.78911564625851, '64-67': 83.6734693877551, '68-71': 82.4742268041237, '72-75': 76.27118644067797, '76-79': 84.84848484848484}
2025-12-11 18:13:15,182 [trainer.py] => Ave Acc (W-NCM): 74.23%
2025-12-11 18:13:15,182 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 63.23% (best 83.23%); T2: W-NCM 68.97% (best 93.79%); T3: W-NCM 65.79% (best 84.21%); T4: W-NCM 85.45% (best 92.73%); T5: W-NCM 78.57% (best 95.24%); T6: W-NCM 71.69% (best 92.24%); T7: W-NCM 68.90% (best 89.02%); T8: W-NCM 64.40% (best 91.62%); T9: W-NCM 82.67% (best 96.00%); T10: W-NCM 67.33% (best 92.08%); T11: W-NCM 62.79% (best 76.74%); T12: W-NCM 68.52% (best 75.93%); T13: W-NCM 79.39% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 83.16% (best 90.53%); T16: W-NCM 72.79% (best 91.84%); T17: W-NCM 83.67% (best 91.84%); T18: W-NCM 82.47% (best 87.63%); T19: W-NCM 76.27% (best 92.37%); T20: W-NCM 84.85% (best 84.85%)
2025-12-11 18:13:15,182 [trainer.py] => Average forgetting (W-NCM): 15.68% | Max forgetting (W-NCM): 27.23%
2025-12-11 18:13:15,189 [trainer.py] => All params: 126094051
2025-12-11 18:13:15,195 [trainer.py] => Trainable params: 187396
2025-12-11 18:13:15,195 [inflora.py] => Learning on 80-84
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_v.20.weight', 'image_encoder.blocks.1.attn.lora_B_k.20.weight', 'image_encoder.blocks.4.attn.lora_B_v.20.weight', 'image_encoder.blocks.1.attn.lora_B_v.20.weight', 'classifier_pool.20.weight', 'image_encoder.blocks.4.attn.lora_B_k.20.weight', 'image_encoder.blocks.5.attn.lora_B_v.20.weight', 'image_encoder.blocks.6.attn.lora_B_v.20.weight', 'image_encoder.blocks.9.attn.lora_B_k.20.weight', 'image_encoder.blocks.2.attn.lora_B_v.20.weight', 'image_encoder.blocks.3.attn.lora_B_k.20.weight', 'image_encoder.blocks.10.attn.lora_B_k.20.weight', 'image_encoder.blocks.10.attn.lora_B_v.20.weight', 'image_encoder.blocks.5.attn.lora_B_k.20.weight', 'classifier_pool.20.bias', 'image_encoder.blocks.6.attn.lora_B_k.20.weight', 'image_encoder.blocks.3.attn.lora_B_v.20.weight', 'image_encoder.blocks.2.attn.lora_B_k.20.weight', 'image_encoder.blocks.0.attn.lora_B_v.20.weight', 'image_encoder.blocks.7.attn.lora_B_k.20.weight', 'image_encoder.blocks.8.attn.lora_B_v.20.weight', 'image_encoder.blocks.8.attn.lora_B_k.20.weight', 'image_encoder.blocks.11.attn.lora_B_v.20.weight', 'image_encoder.blocks.0.attn.lora_B_k.20.weight', 'image_encoder.blocks.7.attn.lora_B_v.20.weight', 'image_encoder.blocks.11.attn.lora_B_k.20.weight'}
2025-12-11 18:17:21,569 [inflora.py] => Task 20, Epoch 50/50 => Loss 0.112, Train_accy 95.90
Threshold:  0.988
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 23/768 type remove
Layer 3 : 55/768 type remove
Layer 4 : 81/768 type remove
Layer 5 : 110/768 type remove
Layer 6 : 101/768 type remove
Layer 7 : 117/768 type remove
Layer 8 : 138/768 type remove
Layer 9 : 214/768 type remove
Layer 10 : 237/768 type remove
Layer 11 : 152/768 type remove
Layer 12 : 218/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:17:30,864 [trainer.py] => Time:255.66890668869019
2593 2593
2593 2593
2025-12-11 18:17:38,604 [trainer.py] => Time:7.739933729171753
2025-12-11 18:17:38,605 [inflora.py] => Exemplar size: 0
2025-12-11 18:17:38,605 [trainer.py] => CNN: {'total': np.float64(63.32), '00-03': np.float64(60.0), '04-07': np.float64(65.52), '08-11': np.float64(64.91), '12-15': np.float64(80.0), '16-19': np.float64(75.4), '20-23': np.float64(73.52), '24-27': np.float64(79.88), '28-31': np.float64(46.07), '32-35': np.float64(65.33), '36-39': np.float64(73.27), '40-43': np.float64(46.51), '44-47': np.float64(37.04), '48-51': np.float64(56.49), '52-55': np.float64(49.18), '56-59': np.float64(53.68), '60-63': np.float64(74.15), '64-67': np.float64(51.02), '68-71': np.float64(49.48), '72-75': np.float64(58.47), '76-79': np.float64(66.67), '80-83': np.float64(62.11), 'old': np.float64(63.42), 'new': np.float64(62.11)}
2025-12-11 18:17:38,605 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32)]
2025-12-11 18:17:38,605 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02)]
2025-12-11 18:17:38,605 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632]
2025-12-11 18:17:49,323 [trainer.py] => W-NCM: {'00-03': 67.74193548387096, '04-07': 71.72413793103448, '08-11': 68.42105263157895, '12-15': 86.36363636363636, '16-19': 80.95238095238095, '20-23': 75.79908675799086, '24-27': 73.78048780487805, '28-31': 71.72774869109948, '32-35': 84.0, '36-39': 71.28712871287128, '40-43': 68.6046511627907, '44-47': 68.51851851851852, '48-51': 77.86259541984732, '52-55': 73.77049180327869, '56-59': 83.15789473684211, '60-63': 76.87074829931973, '64-67': 83.6734693877551, '68-71': 78.35051546391753, '72-75': 69.49152542372882, '76-79': 81.21212121212122, '80-83': 88.42105263157895}
2025-12-11 18:17:49,324 [trainer.py] => Ave Acc (W-NCM): 76.27%
2025-12-11 18:17:49,324 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 67.74% (best 83.23%); T2: W-NCM 71.72% (best 93.79%); T3: W-NCM 68.42% (best 84.21%); T4: W-NCM 86.36% (best 92.73%); T5: W-NCM 80.95% (best 95.24%); T6: W-NCM 75.80% (best 92.24%); T7: W-NCM 73.78% (best 89.02%); T8: W-NCM 71.73% (best 91.62%); T9: W-NCM 84.00% (best 96.00%); T10: W-NCM 71.29% (best 92.08%); T11: W-NCM 68.60% (best 76.74%); T12: W-NCM 68.52% (best 75.93%); T13: W-NCM 77.86% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 83.16% (best 90.53%); T16: W-NCM 76.87% (best 91.84%); T17: W-NCM 83.67% (best 91.84%); T18: W-NCM 78.35% (best 87.63%); T19: W-NCM 69.49% (best 92.37%); T20: W-NCM 81.21% (best 84.85%); T21: W-NCM 88.42% (best 88.42%)
2025-12-11 18:17:49,324 [trainer.py] => Average forgetting (W-NCM): 13.46% | Max forgetting (W-NCM): 22.88%
2025-12-11 18:17:49,331 [trainer.py] => All params: 126094051
2025-12-11 18:17:49,337 [trainer.py] => Trainable params: 187396
2025-12-11 18:17:49,337 [inflora.py] => Learning on 84-88
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_k.21.weight', 'image_encoder.blocks.3.attn.lora_B_v.21.weight', 'image_encoder.blocks.11.attn.lora_B_k.21.weight', 'image_encoder.blocks.10.attn.lora_B_v.21.weight', 'image_encoder.blocks.9.attn.lora_B_v.21.weight', 'classifier_pool.21.bias', 'classifier_pool.21.weight', 'image_encoder.blocks.1.attn.lora_B_v.21.weight', 'image_encoder.blocks.3.attn.lora_B_k.21.weight', 'image_encoder.blocks.8.attn.lora_B_v.21.weight', 'image_encoder.blocks.0.attn.lora_B_v.21.weight', 'image_encoder.blocks.5.attn.lora_B_v.21.weight', 'image_encoder.blocks.6.attn.lora_B_v.21.weight', 'image_encoder.blocks.1.attn.lora_B_k.21.weight', 'image_encoder.blocks.7.attn.lora_B_v.21.weight', 'image_encoder.blocks.0.attn.lora_B_k.21.weight', 'image_encoder.blocks.2.attn.lora_B_v.21.weight', 'image_encoder.blocks.4.attn.lora_B_v.21.weight', 'image_encoder.blocks.11.attn.lora_B_v.21.weight', 'image_encoder.blocks.4.attn.lora_B_k.21.weight', 'image_encoder.blocks.2.attn.lora_B_k.21.weight', 'image_encoder.blocks.5.attn.lora_B_k.21.weight', 'image_encoder.blocks.8.attn.lora_B_k.21.weight', 'image_encoder.blocks.7.attn.lora_B_k.21.weight', 'image_encoder.blocks.9.attn.lora_B_k.21.weight', 'image_encoder.blocks.10.attn.lora_B_k.21.weight'}
2025-12-11 18:21:26,798 [inflora.py] => Task 21, Epoch 50/50 => Loss 0.114, Train_accy 95.70
Threshold:  0.9884
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 24/768 type remove
Layer 3 : 56/768 type remove
Layer 4 : 84/768 type remove
Layer 5 : 114/768 type remove
Layer 6 : 105/768 type remove
Layer 7 : 122/768 type remove
Layer 8 : 144/768 type remove
Layer 9 : 223/768 type remove
Layer 10 : 247/768 type remove
Layer 11 : 156/768 type remove
Layer 12 : 222/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:21:35,530 [trainer.py] => Time:226.19295930862427
2726 2726
2726 2726
2025-12-11 18:21:43,640 [trainer.py] => Time:8.109896898269653
2025-12-11 18:21:43,640 [inflora.py] => Exemplar size: 0
2025-12-11 18:21:43,640 [trainer.py] => CNN: {'total': np.float64(63.28), '00-03': np.float64(60.0), '04-07': np.float64(65.52), '08-11': np.float64(61.4), '12-15': np.float64(81.82), '16-19': np.float64(76.98), '20-23': np.float64(78.08), '24-27': np.float64(79.88), '28-31': np.float64(48.17), '32-35': np.float64(65.33), '36-39': np.float64(77.23), '40-43': np.float64(52.33), '44-47': np.float64(40.74), '48-51': np.float64(54.96), '52-55': np.float64(42.62), '56-59': np.float64(47.37), '60-63': np.float64(72.11), '64-67': np.float64(42.86), '68-71': np.float64(52.58), '72-75': np.float64(52.54), '76-79': np.float64(63.03), '80-83': np.float64(64.21), '84-87': np.float64(62.41), 'old': np.float64(63.32), 'new': np.float64(62.41)}
2025-12-11 18:21:43,641 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28)]
2025-12-11 18:21:43,641 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59)]
2025-12-11 18:21:43,641 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291]
2025-12-11 18:21:54,464 [trainer.py] => W-NCM: {'00-03': 68.38709677419355, '04-07': 66.20689655172414, '08-11': 69.2982456140351, '12-15': 86.36363636363636, '16-19': 78.57142857142857, '20-23': 73.0593607305936, '24-27': 73.17073170731707, '28-31': 68.06282722513089, '32-35': 80.0, '36-39': 71.28712871287128, '40-43': 70.93023255813954, '44-47': 66.66666666666666, '48-51': 82.44274809160305, '52-55': 73.77049180327869, '56-59': 80.0, '60-63': 73.46938775510205, '64-67': 81.63265306122449, '68-71': 76.28865979381443, '72-75': 68.64406779661016, '76-79': 80.60606060606061, '80-83': 83.15789473684211, '84-87': 88.7218045112782}
2025-12-11 18:21:54,465 [trainer.py] => Ave Acc (W-NCM): 75.49%
2025-12-11 18:21:54,465 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 68.39% (best 83.23%); T2: W-NCM 66.21% (best 93.79%); T3: W-NCM 69.30% (best 84.21%); T4: W-NCM 86.36% (best 92.73%); T5: W-NCM 78.57% (best 95.24%); T6: W-NCM 73.06% (best 92.24%); T7: W-NCM 73.17% (best 89.02%); T8: W-NCM 68.06% (best 91.62%); T9: W-NCM 80.00% (best 96.00%); T10: W-NCM 71.29% (best 92.08%); T11: W-NCM 70.93% (best 76.74%); T12: W-NCM 66.67% (best 75.93%); T13: W-NCM 82.44% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 80.00% (best 90.53%); T16: W-NCM 73.47% (best 91.84%); T17: W-NCM 81.63% (best 91.84%); T18: W-NCM 76.29% (best 87.63%); T19: W-NCM 68.64% (best 92.37%); T20: W-NCM 80.61% (best 84.85%); T21: W-NCM 83.16% (best 88.42%); T22: W-NCM 88.72% (best 88.72%)
2025-12-11 18:21:54,465 [trainer.py] => Average forgetting (W-NCM): 14.24% | Max forgetting (W-NCM): 27.59%
2025-12-11 18:21:54,471 [trainer.py] => All params: 126094051
2025-12-11 18:21:54,478 [trainer.py] => Trainable params: 187396
2025-12-11 18:21:54,478 [inflora.py] => Learning on 88-92
Parameters to be updated: {'image_encoder.blocks.7.attn.lora_B_v.22.weight', 'image_encoder.blocks.3.attn.lora_B_k.22.weight', 'image_encoder.blocks.11.attn.lora_B_v.22.weight', 'image_encoder.blocks.1.attn.lora_B_k.22.weight', 'image_encoder.blocks.1.attn.lora_B_v.22.weight', 'image_encoder.blocks.4.attn.lora_B_v.22.weight', 'image_encoder.blocks.0.attn.lora_B_v.22.weight', 'image_encoder.blocks.5.attn.lora_B_k.22.weight', 'image_encoder.blocks.5.attn.lora_B_v.22.weight', 'image_encoder.blocks.8.attn.lora_B_k.22.weight', 'image_encoder.blocks.9.attn.lora_B_k.22.weight', 'image_encoder.blocks.6.attn.lora_B_k.22.weight', 'classifier_pool.22.bias', 'image_encoder.blocks.2.attn.lora_B_k.22.weight', 'image_encoder.blocks.3.attn.lora_B_v.22.weight', 'image_encoder.blocks.10.attn.lora_B_v.22.weight', 'image_encoder.blocks.8.attn.lora_B_v.22.weight', 'image_encoder.blocks.2.attn.lora_B_v.22.weight', 'image_encoder.blocks.4.attn.lora_B_k.22.weight', 'image_encoder.blocks.11.attn.lora_B_k.22.weight', 'image_encoder.blocks.0.attn.lora_B_k.22.weight', 'image_encoder.blocks.7.attn.lora_B_k.22.weight', 'image_encoder.blocks.6.attn.lora_B_v.22.weight', 'image_encoder.blocks.9.attn.lora_B_v.22.weight', 'classifier_pool.22.weight', 'image_encoder.blocks.10.attn.lora_B_k.22.weight'}
2025-12-11 18:24:37,135 [inflora.py] => Task 22, Epoch 50/50 => Loss 0.048, Train_accy 98.23
Threshold:  0.9888
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 25/768 type remove
Layer 3 : 58/768 type remove
Layer 4 : 88/768 type remove
Layer 5 : 119/768 type remove
Layer 6 : 111/768 type remove
Layer 7 : 132/768 type remove
Layer 8 : 154/768 type remove
Layer 9 : 236/768 type remove
Layer 10 : 256/768 type remove
Layer 11 : 164/768 type remove
Layer 12 : 230/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:24:44,862 [trainer.py] => Time:170.38384461402893
2826 2826
2826 2826
2025-12-11 18:24:53,217 [trainer.py] => Time:8.35487174987793
2025-12-11 18:24:53,217 [inflora.py] => Exemplar size: 0
2025-12-11 18:24:53,217 [trainer.py] => CNN: {'total': np.float64(63.48), '00-03': np.float64(60.0), '04-07': np.float64(66.21), '08-11': np.float64(63.16), '12-15': np.float64(80.91), '16-19': np.float64(74.6), '20-23': np.float64(76.26), '24-27': np.float64(77.44), '28-31': np.float64(48.69), '32-35': np.float64(64.0), '36-39': np.float64(75.25), '40-43': np.float64(53.49), '44-47': np.float64(42.59), '48-51': np.float64(56.49), '52-55': np.float64(34.43), '56-59': np.float64(49.47), '60-63': np.float64(73.47), '64-67': np.float64(42.86), '68-71': np.float64(53.61), '72-75': np.float64(51.69), '76-79': np.float64(61.21), '80-83': np.float64(62.11), '84-87': np.float64(64.66), '88-91': np.float64(81.0), 'old': np.float64(62.84), 'new': np.float64(81.0)}
2025-12-11 18:24:53,218 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48)]
2025-12-11 18:24:53,218 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75)]
2025-12-11 18:24:53,218 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934]
2025-12-11 18:25:03,773 [trainer.py] => W-NCM: {'00-03': 67.74193548387096, '04-07': 62.758620689655174, '08-11': 63.1578947368421, '12-15': 82.72727272727273, '16-19': 75.39682539682539, '20-23': 73.0593607305936, '24-27': 72.5609756097561, '28-31': 68.06282722513089, '32-35': 80.0, '36-39': 71.28712871287128, '40-43': 65.11627906976744, '44-47': 62.96296296296296, '48-51': 80.91603053435115, '52-55': 73.77049180327869, '56-59': 81.05263157894737, '60-63': 74.14965986394559, '64-67': 73.46938775510205, '68-71': 75.25773195876289, '72-75': 57.6271186440678, '76-79': 76.36363636363637, '80-83': 77.89473684210526, '84-87': 86.46616541353383, '88-91': 94.0}
2025-12-11 18:25:03,774 [trainer.py] => Ave Acc (W-NCM): 73.73%
2025-12-11 18:25:03,774 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 67.74% (best 83.23%); T2: W-NCM 62.76% (best 93.79%); T3: W-NCM 63.16% (best 84.21%); T4: W-NCM 82.73% (best 92.73%); T5: W-NCM 75.40% (best 95.24%); T6: W-NCM 73.06% (best 92.24%); T7: W-NCM 72.56% (best 89.02%); T8: W-NCM 68.06% (best 91.62%); T9: W-NCM 80.00% (best 96.00%); T10: W-NCM 71.29% (best 92.08%); T11: W-NCM 65.12% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 80.92% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 81.05% (best 90.53%); T16: W-NCM 74.15% (best 91.84%); T17: W-NCM 73.47% (best 91.84%); T18: W-NCM 75.26% (best 87.63%); T19: W-NCM 57.63% (best 92.37%); T20: W-NCM 76.36% (best 84.85%); T21: W-NCM 77.89% (best 88.42%); T22: W-NCM 86.47% (best 88.72%); T23: W-NCM 94.00% (best 94.00%)
2025-12-11 18:25:03,774 [trainer.py] => Average forgetting (W-NCM): 16.27% | Max forgetting (W-NCM): 34.75%
2025-12-11 18:25:03,781 [trainer.py] => All params: 126094051
2025-12-11 18:25:03,787 [trainer.py] => Trainable params: 187396
2025-12-11 18:25:03,787 [inflora.py] => Learning on 92-96
Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_k.23.weight', 'image_encoder.blocks.10.attn.lora_B_v.23.weight', 'classifier_pool.23.weight', 'image_encoder.blocks.8.attn.lora_B_v.23.weight', 'classifier_pool.23.bias', 'image_encoder.blocks.7.attn.lora_B_k.23.weight', 'image_encoder.blocks.2.attn.lora_B_v.23.weight', 'image_encoder.blocks.9.attn.lora_B_v.23.weight', 'image_encoder.blocks.10.attn.lora_B_k.23.weight', 'image_encoder.blocks.5.attn.lora_B_k.23.weight', 'image_encoder.blocks.8.attn.lora_B_k.23.weight', 'image_encoder.blocks.7.attn.lora_B_v.23.weight', 'image_encoder.blocks.3.attn.lora_B_v.23.weight', 'image_encoder.blocks.6.attn.lora_B_v.23.weight', 'image_encoder.blocks.4.attn.lora_B_v.23.weight', 'image_encoder.blocks.4.attn.lora_B_k.23.weight', 'image_encoder.blocks.1.attn.lora_B_v.23.weight', 'image_encoder.blocks.5.attn.lora_B_v.23.weight', 'image_encoder.blocks.11.attn.lora_B_k.23.weight', 'image_encoder.blocks.0.attn.lora_B_k.23.weight', 'image_encoder.blocks.1.attn.lora_B_k.23.weight', 'image_encoder.blocks.2.attn.lora_B_k.23.weight', 'image_encoder.blocks.11.attn.lora_B_v.23.weight', 'image_encoder.blocks.0.attn.lora_B_v.23.weight', 'image_encoder.blocks.9.attn.lora_B_k.23.weight', 'image_encoder.blocks.6.attn.lora_B_k.23.weight'}
2025-12-11 18:27:59,493 [inflora.py] => Task 23, Epoch 50/50 => Loss 0.120, Train_accy 95.73
Threshold:  0.9892
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 26/768 type remove
Layer 3 : 59/768 type remove
Layer 4 : 90/768 type remove
Layer 5 : 122/768 type remove
Layer 6 : 114/768 type remove
Layer 7 : 137/768 type remove
Layer 8 : 160/768 type remove
Layer 9 : 246/768 type remove
Layer 10 : 267/768 type remove
Layer 11 : 172/768 type remove
Layer 12 : 241/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:28:07,681 [trainer.py] => Time:183.8943476676941
2946 2946
2946 2946
2025-12-11 18:28:16,383 [trainer.py] => Time:8.701290130615234
2025-12-11 18:28:16,383 [inflora.py] => Exemplar size: 0
2025-12-11 18:28:16,383 [trainer.py] => CNN: {'total': np.float64(62.36), '00-03': np.float64(60.65), '04-07': np.float64(64.83), '08-11': np.float64(57.89), '12-15': np.float64(79.09), '16-19': np.float64(73.02), '20-23': np.float64(73.06), '24-27': np.float64(78.05), '28-31': np.float64(49.21), '32-35': np.float64(62.67), '36-39': np.float64(76.24), '40-43': np.float64(50.0), '44-47': np.float64(44.44), '48-51': np.float64(57.25), '52-55': np.float64(44.26), '56-59': np.float64(47.37), '60-63': np.float64(72.79), '64-67': np.float64(42.86), '68-71': np.float64(51.55), '72-75': np.float64(56.78), '76-79': np.float64(61.21), '80-83': np.float64(60.0), '84-87': np.float64(64.66), '88-91': np.float64(80.0), '92-95': np.float64(48.33), 'old': np.float64(62.95), 'new': np.float64(48.33)}
2025-12-11 18:28:16,383 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36)]
2025-12-11 18:28:16,384 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99)]
2025-12-11 18:28:16,384 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932]
2025-12-11 18:28:27,319 [trainer.py] => W-NCM: {'00-03': 61.29032258064516, '04-07': 62.758620689655174, '08-11': 59.64912280701754, '12-15': 82.72727272727273, '16-19': 77.77777777777779, '20-23': 70.31963470319634, '24-27': 68.90243902439023, '28-31': 64.92146596858639, '32-35': 77.33333333333333, '36-39': 67.32673267326733, '40-43': 66.27906976744185, '44-47': 61.111111111111114, '48-51': 80.91603053435115, '52-55': 75.40983606557377, '56-59': 73.68421052631578, '60-63': 72.78911564625851, '64-67': 73.46938775510205, '68-71': 72.16494845360825, '72-75': 55.08474576271186, '76-79': 72.72727272727273, '80-83': 72.63157894736842, '84-87': 81.95488721804512, '88-91': 88.0, '92-95': 90.0}
2025-12-11 18:28:27,320 [trainer.py] => Ave Acc (W-NCM): 72.05%
2025-12-11 18:28:27,320 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 61.29% (best 83.23%); T2: W-NCM 62.76% (best 93.79%); T3: W-NCM 59.65% (best 84.21%); T4: W-NCM 82.73% (best 92.73%); T5: W-NCM 77.78% (best 95.24%); T6: W-NCM 70.32% (best 92.24%); T7: W-NCM 68.90% (best 89.02%); T8: W-NCM 64.92% (best 91.62%); T9: W-NCM 77.33% (best 96.00%); T10: W-NCM 67.33% (best 92.08%); T11: W-NCM 66.28% (best 76.74%); T12: W-NCM 61.11% (best 75.93%); T13: W-NCM 80.92% (best 95.42%); T14: W-NCM 75.41% (best 85.25%); T15: W-NCM 73.68% (best 90.53%); T16: W-NCM 72.79% (best 91.84%); T17: W-NCM 73.47% (best 91.84%); T18: W-NCM 72.16% (best 87.63%); T19: W-NCM 55.08% (best 92.37%); T20: W-NCM 72.73% (best 84.85%); T21: W-NCM 72.63% (best 88.42%); T22: W-NCM 81.95% (best 88.72%); T23: W-NCM 88.00% (best 94.00%); T24: W-NCM 90.00% (best 90.00%)
2025-12-11 18:28:27,320 [trainer.py] => Average forgetting (W-NCM): 18.02% | Max forgetting (W-NCM): 37.29%
2025-12-11 18:28:27,327 [trainer.py] => All params: 126094051
2025-12-11 18:28:27,333 [trainer.py] => Trainable params: 187396
2025-12-11 18:28:27,333 [inflora.py] => Learning on 96-100
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.24.weight', 'image_encoder.blocks.2.attn.lora_B_k.24.weight', 'image_encoder.blocks.11.attn.lora_B_k.24.weight', 'image_encoder.blocks.1.attn.lora_B_v.24.weight', 'image_encoder.blocks.5.attn.lora_B_k.24.weight', 'image_encoder.blocks.5.attn.lora_B_v.24.weight', 'image_encoder.blocks.11.attn.lora_B_v.24.weight', 'image_encoder.blocks.2.attn.lora_B_v.24.weight', 'image_encoder.blocks.3.attn.lora_B_v.24.weight', 'image_encoder.blocks.8.attn.lora_B_v.24.weight', 'image_encoder.blocks.10.attn.lora_B_v.24.weight', 'image_encoder.blocks.0.attn.lora_B_k.24.weight', 'image_encoder.blocks.3.attn.lora_B_k.24.weight', 'image_encoder.blocks.0.attn.lora_B_v.24.weight', 'image_encoder.blocks.9.attn.lora_B_v.24.weight', 'image_encoder.blocks.8.attn.lora_B_k.24.weight', 'image_encoder.blocks.1.attn.lora_B_k.24.weight', 'image_encoder.blocks.4.attn.lora_B_v.24.weight', 'classifier_pool.24.weight', 'image_encoder.blocks.10.attn.lora_B_k.24.weight', 'image_encoder.blocks.7.attn.lora_B_v.24.weight', 'image_encoder.blocks.6.attn.lora_B_k.24.weight', 'image_encoder.blocks.7.attn.lora_B_k.24.weight', 'image_encoder.blocks.6.attn.lora_B_v.24.weight', 'classifier_pool.24.bias', 'image_encoder.blocks.9.attn.lora_B_k.24.weight'}
2025-12-11 18:32:19,807 [inflora.py] => Task 24, Epoch 50/50 => Loss 0.160, Train_accy 94.46
Threshold:  0.9896
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 27/768 type remove
Layer 3 : 61/768 type remove
Layer 4 : 92/768 type remove
Layer 5 : 126/768 type remove
Layer 6 : 119/768 type remove
Layer 7 : 143/768 type remove
Layer 8 : 170/768 type remove
Layer 9 : 262/768 type remove
Layer 10 : 288/768 type remove
Layer 11 : 191/768 type remove
Layer 12 : 265/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:32:28,981 [trainer.py] => Time:241.64730381965637
3119 3119
3119 3119
2025-12-11 18:32:38,150 [trainer.py] => Time:9.16885757446289
2025-12-11 18:32:38,150 [inflora.py] => Exemplar size: 0
2025-12-11 18:32:38,150 [trainer.py] => CNN: {'total': np.float64(61.91), '00-03': np.float64(60.0), '04-07': np.float64(68.97), '08-11': np.float64(57.02), '12-15': np.float64(80.0), '16-19': np.float64(74.6), '20-23': np.float64(71.69), '24-27': np.float64(79.88), '28-31': np.float64(44.5), '32-35': np.float64(66.67), '36-39': np.float64(78.22), '40-43': np.float64(51.16), '44-47': np.float64(40.74), '48-51': np.float64(52.67), '52-55': np.float64(42.62), '56-59': np.float64(46.32), '60-63': np.float64(74.15), '64-67': np.float64(46.94), '68-71': np.float64(51.55), '72-75': np.float64(60.17), '76-79': np.float64(64.24), '80-83': np.float64(60.53), '84-87': np.float64(57.89), '88-91': np.float64(79.0), '92-95': np.float64(48.33), '96-99': np.float64(55.49), 'old': np.float64(62.29), 'new': np.float64(55.49)}
2025-12-11 18:32:38,150 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91)]
2025-12-11 18:32:38,150 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34)]
2025-12-11 18:32:38,151 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193]
2025-12-11 18:32:50,114 [trainer.py] => W-NCM: {'00-03': 65.16129032258064, '04-07': 67.58620689655173, '08-11': 64.91228070175438, '12-15': 84.54545454545455, '16-19': 81.74603174603175, '20-23': 73.97260273972603, '24-27': 71.95121951219512, '28-31': 63.35078534031413, '32-35': 85.33333333333334, '36-39': 71.28712871287128, '40-43': 68.6046511627907, '44-47': 66.66666666666666, '48-51': 78.62595419847328, '52-55': 75.40983606557377, '56-59': 80.0, '60-63': 76.87074829931973, '64-67': 79.59183673469387, '68-71': 74.22680412371135, '72-75': 60.16949152542372, '76-79': 73.33333333333333, '80-83': 72.10526315789474, '84-87': 82.70676691729322, '88-91': 87.0, '92-95': 78.33333333333333, '96-99': 87.28323699421965}
2025-12-11 18:32:50,115 [trainer.py] => Ave Acc (W-NCM): 74.83%
2025-12-11 18:32:50,115 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 65.16% (best 83.23%); T2: W-NCM 67.59% (best 93.79%); T3: W-NCM 64.91% (best 84.21%); T4: W-NCM 84.55% (best 92.73%); T5: W-NCM 81.75% (best 95.24%); T6: W-NCM 73.97% (best 92.24%); T7: W-NCM 71.95% (best 89.02%); T8: W-NCM 63.35% (best 91.62%); T9: W-NCM 85.33% (best 96.00%); T10: W-NCM 71.29% (best 92.08%); T11: W-NCM 68.60% (best 76.74%); T12: W-NCM 66.67% (best 75.93%); T13: W-NCM 78.63% (best 95.42%); T14: W-NCM 75.41% (best 85.25%); T15: W-NCM 80.00% (best 90.53%); T16: W-NCM 76.87% (best 91.84%); T17: W-NCM 79.59% (best 91.84%); T18: W-NCM 74.23% (best 87.63%); T19: W-NCM 60.17% (best 92.37%); T20: W-NCM 73.33% (best 84.85%); T21: W-NCM 72.11% (best 88.42%); T22: W-NCM 82.71% (best 88.72%); T23: W-NCM 87.00% (best 94.00%); T24: W-NCM 78.33% (best 90.00%); T25: W-NCM 87.28% (best 87.28%)
2025-12-11 18:32:50,115 [trainer.py] => Average forgetting (W-NCM): 15.01% | Max forgetting (W-NCM): 32.20%
2025-12-11 18:32:50,122 [trainer.py] => All params: 126094051
2025-12-11 18:32:50,128 [trainer.py] => Trainable params: 187396
2025-12-11 18:32:50,129 [inflora.py] => Learning on 100-104
Parameters to be updated: {'image_encoder.blocks.5.attn.lora_B_k.25.weight', 'image_encoder.blocks.6.attn.lora_B_v.25.weight', 'image_encoder.blocks.2.attn.lora_B_v.25.weight', 'image_encoder.blocks.3.attn.lora_B_v.25.weight', 'image_encoder.blocks.9.attn.lora_B_v.25.weight', 'image_encoder.blocks.5.attn.lora_B_v.25.weight', 'image_encoder.blocks.4.attn.lora_B_v.25.weight', 'image_encoder.blocks.0.attn.lora_B_k.25.weight', 'image_encoder.blocks.6.attn.lora_B_k.25.weight', 'image_encoder.blocks.3.attn.lora_B_k.25.weight', 'image_encoder.blocks.7.attn.lora_B_k.25.weight', 'image_encoder.blocks.1.attn.lora_B_k.25.weight', 'classifier_pool.25.weight', 'image_encoder.blocks.9.attn.lora_B_k.25.weight', 'image_encoder.blocks.1.attn.lora_B_v.25.weight', 'image_encoder.blocks.11.attn.lora_B_v.25.weight', 'image_encoder.blocks.7.attn.lora_B_v.25.weight', 'image_encoder.blocks.0.attn.lora_B_v.25.weight', 'image_encoder.blocks.8.attn.lora_B_k.25.weight', 'image_encoder.blocks.10.attn.lora_B_k.25.weight', 'classifier_pool.25.bias', 'image_encoder.blocks.11.attn.lora_B_k.25.weight', 'image_encoder.blocks.8.attn.lora_B_v.25.weight', 'image_encoder.blocks.10.attn.lora_B_v.25.weight', 'image_encoder.blocks.4.attn.lora_B_k.25.weight', 'image_encoder.blocks.2.attn.lora_B_k.25.weight'}
2025-12-11 18:35:48,095 [inflora.py] => Task 25, Epoch 50/50 => Loss 0.143, Train_accy 94.79
Threshold:  0.99
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 28/768 type remove
Layer 3 : 62/768 type remove
Layer 4 : 94/768 type remove
Layer 5 : 128/768 type remove
Layer 6 : 123/768 type remove
Layer 7 : 147/768 type remove
Layer 8 : 176/768 type remove
Layer 9 : 270/768 type remove
Layer 10 : 298/768 type remove
Layer 11 : 200/768 type remove
Layer 12 : 272/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:35:55,951 [trainer.py] => Time:185.82219457626343
3237 3237
3237 3237
2025-12-11 18:36:05,436 [trainer.py] => Time:9.4853994846344
2025-12-11 18:36:05,437 [inflora.py] => Exemplar size: 0
2025-12-11 18:36:05,437 [trainer.py] => CNN: {'total': np.float64(63.05), '00-03': np.float64(62.58), '04-07': np.float64(71.03), '08-11': np.float64(63.16), '12-15': np.float64(81.82), '16-19': np.float64(73.02), '20-23': np.float64(71.69), '24-27': np.float64(79.88), '28-31': np.float64(45.55), '32-35': np.float64(64.0), '36-39': np.float64(78.22), '40-43': np.float64(51.16), '44-47': np.float64(42.59), '48-51': np.float64(56.49), '52-55': np.float64(42.62), '56-59': np.float64(53.68), '60-63': np.float64(76.87), '64-67': np.float64(53.06), '68-71': np.float64(52.58), '72-75': np.float64(57.63), '76-79': np.float64(62.42), '80-83': np.float64(60.0), '84-87': np.float64(59.4), '88-91': np.float64(75.0), '92-95': np.float64(52.5), '96-99': np.float64(53.76), '100-103': np.float64(69.49), 'old': np.float64(62.81), 'new': np.float64(69.49)}
2025-12-11 18:36:05,437 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05)]
2025-12-11 18:36:05,437 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37)]
2025-12-11 18:36:05,437 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927]
2025-12-11 18:36:17,185 [trainer.py] => W-NCM: {'00-03': 67.0967741935484, '04-07': 65.51724137931035, '08-11': 67.54385964912281, '12-15': 84.54545454545455, '16-19': 81.74603174603175, '20-23': 74.42922374429224, '24-27': 70.73170731707317, '28-31': 65.44502617801047, '32-35': 89.33333333333333, '36-39': 70.29702970297029, '40-43': 70.93023255813954, '44-47': 62.96296296296296, '48-51': 79.38931297709924, '52-55': 73.77049180327869, '56-59': 83.15789473684211, '60-63': 77.55102040816327, '64-67': 81.63265306122449, '68-71': 77.31958762886599, '72-75': 61.016949152542374, '76-79': 73.33333333333333, '80-83': 76.84210526315789, '84-87': 81.203007518797, '88-91': 87.0, '92-95': 70.0, '96-99': 78.61271676300578, '100-103': 88.13559322033898}
2025-12-11 18:36:17,186 [trainer.py] => Ave Acc (W-NCM): 75.37%
2025-12-11 18:36:17,186 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 67.10% (best 83.23%); T2: W-NCM 65.52% (best 93.79%); T3: W-NCM 67.54% (best 84.21%); T4: W-NCM 84.55% (best 92.73%); T5: W-NCM 81.75% (best 95.24%); T6: W-NCM 74.43% (best 92.24%); T7: W-NCM 70.73% (best 89.02%); T8: W-NCM 65.45% (best 91.62%); T9: W-NCM 89.33% (best 96.00%); T10: W-NCM 70.30% (best 92.08%); T11: W-NCM 70.93% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 79.39% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 83.16% (best 90.53%); T16: W-NCM 77.55% (best 91.84%); T17: W-NCM 81.63% (best 91.84%); T18: W-NCM 77.32% (best 87.63%); T19: W-NCM 61.02% (best 92.37%); T20: W-NCM 73.33% (best 84.85%); T21: W-NCM 76.84% (best 88.42%); T22: W-NCM 81.20% (best 88.72%); T23: W-NCM 87.00% (best 94.00%); T24: W-NCM 70.00% (best 90.00%); T25: W-NCM 78.61% (best 87.28%); T26: W-NCM 88.14% (best 88.14%)
2025-12-11 18:36:17,186 [trainer.py] => Average forgetting (W-NCM): 14.38% | Max forgetting (W-NCM): 31.36%
2025-12-11 18:36:17,193 [trainer.py] => All params: 126094051
2025-12-11 18:36:17,200 [trainer.py] => Trainable params: 187396
2025-12-11 18:36:17,200 [inflora.py] => Learning on 104-108
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_k.26.weight', 'image_encoder.blocks.7.attn.lora_B_v.26.weight', 'image_encoder.blocks.10.attn.lora_B_v.26.weight', 'image_encoder.blocks.5.attn.lora_B_k.26.weight', 'image_encoder.blocks.2.attn.lora_B_v.26.weight', 'image_encoder.blocks.3.attn.lora_B_v.26.weight', 'image_encoder.blocks.6.attn.lora_B_k.26.weight', 'image_encoder.blocks.10.attn.lora_B_k.26.weight', 'image_encoder.blocks.5.attn.lora_B_v.26.weight', 'image_encoder.blocks.4.attn.lora_B_v.26.weight', 'image_encoder.blocks.3.attn.lora_B_k.26.weight', 'image_encoder.blocks.8.attn.lora_B_v.26.weight', 'image_encoder.blocks.11.attn.lora_B_v.26.weight', 'image_encoder.blocks.2.attn.lora_B_k.26.weight', 'classifier_pool.26.bias', 'image_encoder.blocks.1.attn.lora_B_k.26.weight', 'image_encoder.blocks.8.attn.lora_B_k.26.weight', 'image_encoder.blocks.7.attn.lora_B_k.26.weight', 'classifier_pool.26.weight', 'image_encoder.blocks.6.attn.lora_B_v.26.weight', 'image_encoder.blocks.11.attn.lora_B_k.26.weight', 'image_encoder.blocks.4.attn.lora_B_k.26.weight', 'image_encoder.blocks.9.attn.lora_B_v.26.weight', 'image_encoder.blocks.1.attn.lora_B_v.26.weight', 'image_encoder.blocks.0.attn.lora_B_v.26.weight', 'image_encoder.blocks.0.attn.lora_B_k.26.weight'}
2025-12-11 18:39:31,296 [inflora.py] => Task 26, Epoch 50/50 => Loss 0.224, Train_accy 89.11
Threshold:  0.9904
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 33/768 type remove
Layer 3 : 65/768 type remove
Layer 4 : 99/768 type remove
Layer 5 : 135/768 type remove
Layer 6 : 131/768 type remove
Layer 7 : 154/768 type remove
Layer 8 : 185/768 type remove
Layer 9 : 282/768 type remove
Layer 10 : 313/768 type remove
Layer 11 : 213/768 type remove
Layer 12 : 276/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:39:39,714 [trainer.py] => Time:202.5146608352661
3370 3370
3370 3370
2025-12-11 18:39:49,542 [trainer.py] => Time:9.827324867248535
2025-12-11 18:39:49,542 [inflora.py] => Exemplar size: 0
2025-12-11 18:39:49,542 [trainer.py] => CNN: {'total': np.float64(61.6), '00-03': np.float64(64.52), '04-07': np.float64(70.34), '08-11': np.float64(65.79), '12-15': np.float64(80.91), '16-19': np.float64(69.84), '20-23': np.float64(72.15), '24-27': np.float64(79.27), '28-31': np.float64(45.55), '32-35': np.float64(64.0), '36-39': np.float64(79.21), '40-43': np.float64(50.0), '44-47': np.float64(44.44), '48-51': np.float64(54.2), '52-55': np.float64(49.18), '56-59': np.float64(54.74), '60-63': np.float64(78.23), '64-67': np.float64(51.02), '68-71': np.float64(53.61), '72-75': np.float64(58.47), '76-79': np.float64(60.61), '80-83': np.float64(59.47), '84-87': np.float64(58.65), '88-91': np.float64(73.0), '92-95': np.float64(51.67), '96-99': np.float64(53.76), '100-103': np.float64(72.03), '104-107': np.float64(25.56), 'old': np.float64(63.08), 'new': np.float64(25.56)}
2025-12-11 18:39:49,543 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6)]
2025-12-11 18:39:49,543 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99)]
2025-12-11 18:39:49,543 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834]
2025-12-11 18:40:01,704 [trainer.py] => W-NCM: {'00-03': 67.0967741935484, '04-07': 66.20689655172414, '08-11': 67.54385964912281, '12-15': 86.36363636363636, '16-19': 81.74603174603175, '20-23': 73.97260273972603, '24-27': 69.51219512195121, '28-31': 66.49214659685863, '32-35': 88.0, '36-39': 72.27722772277228, '40-43': 73.25581395348837, '44-47': 62.96296296296296, '48-51': 77.09923664122137, '52-55': 70.49180327868852, '56-59': 82.10526315789474, '60-63': 80.27210884353741, '64-67': 79.59183673469387, '68-71': 78.35051546391753, '72-75': 53.38983050847458, '76-79': 74.54545454545455, '80-83': 75.26315789473685, '84-87': 78.94736842105263, '88-91': 86.0, '92-95': 69.16666666666667, '96-99': 68.78612716763006, '100-103': 83.05084745762711, '104-107': 78.94736842105263}
2025-12-11 18:40:01,705 [trainer.py] => Ave Acc (W-NCM): 74.50%
2025-12-11 18:40:01,705 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 67.10% (best 83.23%); T2: W-NCM 66.21% (best 93.79%); T3: W-NCM 67.54% (best 84.21%); T4: W-NCM 86.36% (best 92.73%); T5: W-NCM 81.75% (best 95.24%); T6: W-NCM 73.97% (best 92.24%); T7: W-NCM 69.51% (best 89.02%); T8: W-NCM 66.49% (best 91.62%); T9: W-NCM 88.00% (best 96.00%); T10: W-NCM 72.28% (best 92.08%); T11: W-NCM 73.26% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 77.10% (best 95.42%); T14: W-NCM 70.49% (best 85.25%); T15: W-NCM 82.11% (best 90.53%); T16: W-NCM 80.27% (best 91.84%); T17: W-NCM 79.59% (best 91.84%); T18: W-NCM 78.35% (best 87.63%); T19: W-NCM 53.39% (best 92.37%); T20: W-NCM 74.55% (best 84.85%); T21: W-NCM 75.26% (best 88.42%); T22: W-NCM 78.95% (best 88.72%); T23: W-NCM 86.00% (best 94.00%); T24: W-NCM 69.17% (best 90.00%); T25: W-NCM 68.79% (best 87.28%); T26: W-NCM 83.05% (best 88.14%); T27: W-NCM 78.95% (best 78.95%)
2025-12-11 18:40:01,705 [trainer.py] => Average forgetting (W-NCM): 14.87% | Max forgetting (W-NCM): 38.98%
2025-12-11 18:40:01,712 [trainer.py] => All params: 126094051
2025-12-11 18:40:01,718 [trainer.py] => Trainable params: 187396
2025-12-11 18:40:01,718 [inflora.py] => Learning on 108-112
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_k.27.weight', 'classifier_pool.27.weight', 'image_encoder.blocks.11.attn.lora_B_v.27.weight', 'image_encoder.blocks.9.attn.lora_B_v.27.weight', 'image_encoder.blocks.10.attn.lora_B_v.27.weight', 'image_encoder.blocks.3.attn.lora_B_k.27.weight', 'image_encoder.blocks.6.attn.lora_B_k.27.weight', 'image_encoder.blocks.10.attn.lora_B_k.27.weight', 'image_encoder.blocks.5.attn.lora_B_v.27.weight', 'image_encoder.blocks.11.attn.lora_B_k.27.weight', 'image_encoder.blocks.6.attn.lora_B_v.27.weight', 'image_encoder.blocks.7.attn.lora_B_k.27.weight', 'image_encoder.blocks.0.attn.lora_B_v.27.weight', 'image_encoder.blocks.2.attn.lora_B_v.27.weight', 'image_encoder.blocks.5.attn.lora_B_k.27.weight', 'image_encoder.blocks.0.attn.lora_B_k.27.weight', 'image_encoder.blocks.4.attn.lora_B_k.27.weight', 'image_encoder.blocks.8.attn.lora_B_k.27.weight', 'image_encoder.blocks.1.attn.lora_B_v.27.weight', 'image_encoder.blocks.8.attn.lora_B_v.27.weight', 'image_encoder.blocks.7.attn.lora_B_v.27.weight', 'image_encoder.blocks.2.attn.lora_B_k.27.weight', 'image_encoder.blocks.4.attn.lora_B_v.27.weight', 'image_encoder.blocks.3.attn.lora_B_v.27.weight', 'classifier_pool.27.bias', 'image_encoder.blocks.9.attn.lora_B_k.27.weight'}
2025-12-11 18:43:22,874 [inflora.py] => Task 27, Epoch 50/50 => Loss 0.109, Train_accy 96.83
Threshold:  0.9908
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 34/768 type remove
Layer 3 : 67/768 type remove
Layer 4 : 102/768 type remove
Layer 5 : 140/768 type remove
Layer 6 : 136/768 type remove
Layer 7 : 161/768 type remove
Layer 8 : 198/768 type remove
Layer 9 : 302/768 type remove
Layer 10 : 331/768 type remove
Layer 11 : 227/768 type remove
Layer 12 : 297/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:43:31,436 [trainer.py] => Time:209.71759819984436
3497 3497
3497 3497
2025-12-11 18:43:41,623 [trainer.py] => Time:10.186651468276978
2025-12-11 18:43:41,623 [inflora.py] => Exemplar size: 0
2025-12-11 18:43:41,623 [trainer.py] => CNN: {'total': np.float64(60.48), '00-03': np.float64(65.81), '04-07': np.float64(65.52), '08-11': np.float64(64.04), '12-15': np.float64(80.91), '16-19': np.float64(71.43), '20-23': np.float64(71.23), '24-27': np.float64(78.05), '28-31': np.float64(45.55), '32-35': np.float64(66.67), '36-39': np.float64(77.23), '40-43': np.float64(50.0), '44-47': np.float64(42.59), '48-51': np.float64(53.44), '52-55': np.float64(49.18), '56-59': np.float64(51.58), '60-63': np.float64(76.19), '64-67': np.float64(53.06), '68-71': np.float64(48.45), '72-75': np.float64(47.46), '76-79': np.float64(59.39), '80-83': np.float64(53.68), '84-87': np.float64(57.14), '88-91': np.float64(76.0), '92-95': np.float64(49.17), '96-99': np.float64(54.34), '100-103': np.float64(70.34), '104-107': np.float64(27.07), '108-111': np.float64(68.5), 'old': np.float64(60.18), 'new': np.float64(68.5)}
2025-12-11 18:43:41,623 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48)]
2025-12-11 18:43:41,623 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19)]
2025-12-11 18:43:41,623 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902]
2025-12-11 18:43:54,227 [trainer.py] => W-NCM: {'00-03': 60.0, '04-07': 66.20689655172414, '08-11': 64.03508771929825, '12-15': 82.72727272727273, '16-19': 76.19047619047619, '20-23': 73.97260273972603, '24-27': 67.6829268292683, '28-31': 59.16230366492147, '32-35': 76.0, '36-39': 68.31683168316832, '40-43': 73.25581395348837, '44-47': 57.407407407407405, '48-51': 78.62595419847328, '52-55': 73.77049180327869, '56-59': 78.94736842105263, '60-63': 74.14965986394559, '64-67': 77.55102040816327, '68-71': 75.25773195876289, '72-75': 51.69491525423729, '76-79': 70.3030303030303, '80-83': 70.52631578947368, '84-87': 76.69172932330827, '88-91': 87.0, '92-95': 70.0, '96-99': 64.16184971098265, '100-103': 79.66101694915254, '104-107': 72.93233082706767, '108-111': 93.7007874015748}
2025-12-11 18:43:54,228 [trainer.py] => Ave Acc (W-NCM): 72.14%
2025-12-11 18:43:54,228 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 60.00% (best 83.23%); T2: W-NCM 66.21% (best 93.79%); T3: W-NCM 64.04% (best 84.21%); T4: W-NCM 82.73% (best 92.73%); T5: W-NCM 76.19% (best 95.24%); T6: W-NCM 73.97% (best 92.24%); T7: W-NCM 67.68% (best 89.02%); T8: W-NCM 59.16% (best 91.62%); T9: W-NCM 76.00% (best 96.00%); T10: W-NCM 68.32% (best 92.08%); T11: W-NCM 73.26% (best 76.74%); T12: W-NCM 57.41% (best 75.93%); T13: W-NCM 78.63% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 78.95% (best 90.53%); T16: W-NCM 74.15% (best 91.84%); T17: W-NCM 77.55% (best 91.84%); T18: W-NCM 75.26% (best 87.63%); T19: W-NCM 51.69% (best 92.37%); T20: W-NCM 70.30% (best 84.85%); T21: W-NCM 70.53% (best 88.42%); T22: W-NCM 76.69% (best 88.72%); T23: W-NCM 87.00% (best 94.00%); T24: W-NCM 70.00% (best 90.00%); T25: W-NCM 64.16% (best 87.28%); T26: W-NCM 79.66% (best 88.14%); T27: W-NCM 72.93% (best 78.95%); T28: W-NCM 93.70% (best 93.70%)
2025-12-11 18:43:54,228 [trainer.py] => Average forgetting (W-NCM): 17.47% | Max forgetting (W-NCM): 40.68%
2025-12-11 18:43:54,234 [trainer.py] => All params: 126094051
2025-12-11 18:43:54,241 [trainer.py] => Trainable params: 187396
2025-12-11 18:43:54,241 [inflora.py] => Learning on 112-116
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_k.28.weight', 'image_encoder.blocks.9.attn.lora_B_k.28.weight', 'image_encoder.blocks.8.attn.lora_B_k.28.weight', 'image_encoder.blocks.10.attn.lora_B_v.28.weight', 'image_encoder.blocks.1.attn.lora_B_v.28.weight', 'image_encoder.blocks.1.attn.lora_B_k.28.weight', 'image_encoder.blocks.5.attn.lora_B_v.28.weight', 'image_encoder.blocks.0.attn.lora_B_v.28.weight', 'image_encoder.blocks.11.attn.lora_B_k.28.weight', 'image_encoder.blocks.7.attn.lora_B_v.28.weight', 'image_encoder.blocks.0.attn.lora_B_k.28.weight', 'image_encoder.blocks.3.attn.lora_B_k.28.weight', 'image_encoder.blocks.7.attn.lora_B_k.28.weight', 'classifier_pool.28.weight', 'image_encoder.blocks.2.attn.lora_B_v.28.weight', 'image_encoder.blocks.6.attn.lora_B_k.28.weight', 'image_encoder.blocks.5.attn.lora_B_k.28.weight', 'image_encoder.blocks.4.attn.lora_B_k.28.weight', 'image_encoder.blocks.4.attn.lora_B_v.28.weight', 'classifier_pool.28.bias', 'image_encoder.blocks.8.attn.lora_B_v.28.weight', 'image_encoder.blocks.3.attn.lora_B_v.28.weight', 'image_encoder.blocks.9.attn.lora_B_v.28.weight', 'image_encoder.blocks.10.attn.lora_B_k.28.weight', 'image_encoder.blocks.11.attn.lora_B_v.28.weight', 'image_encoder.blocks.6.attn.lora_B_v.28.weight'}
2025-12-11 18:46:16,484 [inflora.py] => Task 28, Epoch 50/50 => Loss 0.075, Train_accy 96.95
Threshold:  0.9912
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 35/768 type remove
Layer 3 : 69/768 type remove
Layer 4 : 104/768 type remove
Layer 5 : 144/768 type remove
Layer 6 : 142/768 type remove
Layer 7 : 171/768 type remove
Layer 8 : 208/768 type remove
Layer 9 : 319/768 type remove
Layer 10 : 354/768 type remove
Layer 11 : 250/768 type remove
Layer 12 : 326/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:46:23,852 [trainer.py] => Time:149.6109275817871
3589 3589
3589 3589
2025-12-11 18:46:34,260 [trainer.py] => Time:10.408122062683105
2025-12-11 18:46:34,260 [inflora.py] => Exemplar size: 0
2025-12-11 18:46:34,261 [trainer.py] => CNN: {'total': np.float64(59.63), '00-03': np.float64(65.16), '04-07': np.float64(67.59), '08-11': np.float64(63.16), '12-15': np.float64(80.0), '16-19': np.float64(70.63), '20-23': np.float64(69.86), '24-27': np.float64(77.44), '28-31': np.float64(46.07), '32-35': np.float64(61.33), '36-39': np.float64(77.23), '40-43': np.float64(50.0), '44-47': np.float64(38.89), '48-51': np.float64(51.91), '52-55': np.float64(44.26), '56-59': np.float64(52.63), '60-63': np.float64(73.47), '64-67': np.float64(48.98), '68-71': np.float64(45.36), '72-75': np.float64(44.92), '76-79': np.float64(57.58), '80-83': np.float64(51.05), '84-87': np.float64(48.87), '88-91': np.float64(78.0), '92-95': np.float64(50.0), '96-99': np.float64(53.76), '100-103': np.float64(70.34), '104-107': np.float64(21.05), '108-111': np.float64(68.5), '112-115': np.float64(82.61), 'old': np.float64(59.02), 'new': np.float64(82.61)}
2025-12-11 18:46:34,261 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63)]
2025-12-11 18:46:34,261 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39)]
2025-12-11 18:46:34,261 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248]
2025-12-11 18:46:46,584 [trainer.py] => W-NCM: {'00-03': 63.87096774193548, '04-07': 67.58620689655173, '08-11': 64.03508771929825, '12-15': 83.63636363636363, '16-19': 78.57142857142857, '20-23': 74.42922374429224, '24-27': 70.1219512195122, '28-31': 65.44502617801047, '32-35': 76.0, '36-39': 72.27722772277228, '40-43': 72.09302325581395, '44-47': 59.25925925925925, '48-51': 78.62595419847328, '52-55': 73.77049180327869, '56-59': 75.78947368421053, '60-63': 74.82993197278913, '64-67': 73.46938775510205, '68-71': 74.22680412371135, '72-75': 52.54237288135594, '76-79': 69.0909090909091, '80-83': 69.47368421052632, '84-87': 78.94736842105263, '88-91': 87.0, '92-95': 66.66666666666666, '96-99': 65.3179190751445, '100-103': 79.66101694915254, '104-107': 71.42857142857143, '108-111': 92.1259842519685, '112-115': 93.47826086956522}
2025-12-11 18:46:46,584 [trainer.py] => Ave Acc (W-NCM): 73.23%
2025-12-11 18:46:46,585 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 63.87% (best 83.23%); T2: W-NCM 67.59% (best 93.79%); T3: W-NCM 64.04% (best 84.21%); T4: W-NCM 83.64% (best 92.73%); T5: W-NCM 78.57% (best 95.24%); T6: W-NCM 74.43% (best 92.24%); T7: W-NCM 70.12% (best 89.02%); T8: W-NCM 65.45% (best 91.62%); T9: W-NCM 76.00% (best 96.00%); T10: W-NCM 72.28% (best 92.08%); T11: W-NCM 72.09% (best 76.74%); T12: W-NCM 59.26% (best 75.93%); T13: W-NCM 78.63% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 75.79% (best 90.53%); T16: W-NCM 74.83% (best 91.84%); T17: W-NCM 73.47% (best 91.84%); T18: W-NCM 74.23% (best 87.63%); T19: W-NCM 52.54% (best 92.37%); T20: W-NCM 69.09% (best 84.85%); T21: W-NCM 69.47% (best 88.42%); T22: W-NCM 78.95% (best 88.72%); T23: W-NCM 87.00% (best 94.00%); T24: W-NCM 66.67% (best 90.00%); T25: W-NCM 65.32% (best 87.28%); T26: W-NCM 79.66% (best 88.14%); T27: W-NCM 71.43% (best 78.95%); T28: W-NCM 92.13% (best 93.70%); T29: W-NCM 93.48% (best 93.48%)
2025-12-11 18:46:46,585 [trainer.py] => Average forgetting (W-NCM): 16.48% | Max forgetting (W-NCM): 39.83%
2025-12-11 18:46:46,591 [trainer.py] => All params: 126094051
2025-12-11 18:46:46,598 [trainer.py] => Trainable params: 187396
2025-12-11 18:46:46,598 [inflora.py] => Learning on 116-120
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.29.weight', 'image_encoder.blocks.5.attn.lora_B_k.29.weight', 'image_encoder.blocks.9.attn.lora_B_k.29.weight', 'image_encoder.blocks.0.attn.lora_B_k.29.weight', 'image_encoder.blocks.0.attn.lora_B_v.29.weight', 'image_encoder.blocks.6.attn.lora_B_v.29.weight', 'image_encoder.blocks.4.attn.lora_B_v.29.weight', 'image_encoder.blocks.10.attn.lora_B_k.29.weight', 'image_encoder.blocks.3.attn.lora_B_k.29.weight', 'image_encoder.blocks.5.attn.lora_B_v.29.weight', 'image_encoder.blocks.9.attn.lora_B_v.29.weight', 'image_encoder.blocks.2.attn.lora_B_v.29.weight', 'image_encoder.blocks.10.attn.lora_B_v.29.weight', 'classifier_pool.29.weight', 'image_encoder.blocks.3.attn.lora_B_v.29.weight', 'image_encoder.blocks.1.attn.lora_B_k.29.weight', 'image_encoder.blocks.11.attn.lora_B_v.29.weight', 'image_encoder.blocks.8.attn.lora_B_k.29.weight', 'image_encoder.blocks.7.attn.lora_B_k.29.weight', 'image_encoder.blocks.2.attn.lora_B_k.29.weight', 'image_encoder.blocks.1.attn.lora_B_v.29.weight', 'image_encoder.blocks.8.attn.lora_B_v.29.weight', 'image_encoder.blocks.11.attn.lora_B_k.29.weight', 'image_encoder.blocks.7.attn.lora_B_v.29.weight', 'image_encoder.blocks.6.attn.lora_B_k.29.weight', 'classifier_pool.29.bias'}
2025-12-11 18:49:20,160 [inflora.py] => Task 29, Epoch 50/50 => Loss 0.140, Train_accy 95.16
Threshold:  0.9916
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 35/768 type remove
Layer 3 : 71/768 type remove
Layer 4 : 109/768 type remove
Layer 5 : 149/768 type remove
Layer 6 : 149/768 type remove
Layer 7 : 179/768 type remove
Layer 8 : 215/768 type remove
Layer 9 : 334/768 type remove
Layer 10 : 379/768 type remove
Layer 11 : 276/768 type remove
Layer 12 : 378/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:49:27,693 [trainer.py] => Time:161.09477877616882
3677 3677
3677 3677
2025-12-11 18:49:38,302 [trainer.py] => Time:10.609375
2025-12-11 18:49:38,303 [inflora.py] => Exemplar size: 0
2025-12-11 18:49:38,303 [trainer.py] => CNN: {'total': np.float64(59.7), '00-03': np.float64(65.16), '04-07': np.float64(68.97), '08-11': np.float64(63.16), '12-15': np.float64(80.0), '16-19': np.float64(72.22), '20-23': np.float64(68.04), '24-27': np.float64(79.27), '28-31': np.float64(43.46), '32-35': np.float64(64.0), '36-39': np.float64(73.27), '40-43': np.float64(51.16), '44-47': np.float64(37.04), '48-51': np.float64(56.49), '52-55': np.float64(45.9), '56-59': np.float64(49.47), '60-63': np.float64(71.43), '64-67': np.float64(46.94), '68-71': np.float64(46.39), '72-75': np.float64(47.46), '76-79': np.float64(56.97), '80-83': np.float64(45.79), '84-87': np.float64(48.87), '88-91': np.float64(74.0), '92-95': np.float64(51.67), '96-99': np.float64(57.23), '100-103': np.float64(69.49), '104-107': np.float64(18.8), '108-111': np.float64(66.14), '112-115': np.float64(83.7), '116-119': np.float64(77.27), 'old': np.float64(59.26), 'new': np.float64(77.27)}
2025-12-11 18:49:38,303 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7)]
2025-12-11 18:49:38,303 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47)]
2025-12-11 18:49:38,303 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629]
2025-12-11 18:49:51,069 [trainer.py] => W-NCM: {'00-03': 68.38709677419355, '04-07': 71.03448275862068, '08-11': 69.2982456140351, '12-15': 85.45454545454545, '16-19': 80.95238095238095, '20-23': 74.42922374429224, '24-27': 74.39024390243902, '28-31': 68.06282722513089, '32-35': 81.33333333333333, '36-39': 76.23762376237624, '40-43': 73.25581395348837, '44-47': 64.81481481481481, '48-51': 79.38931297709924, '52-55': 77.04918032786885, '56-59': 80.0, '60-63': 74.14965986394559, '64-67': 75.51020408163265, '68-71': 75.25773195876289, '72-75': 59.32203389830508, '76-79': 67.87878787878789, '80-83': 69.47368421052632, '84-87': 79.69924812030075, '88-91': 86.0, '92-95': 71.66666666666667, '96-99': 66.47398843930635, '100-103': 78.8135593220339, '104-107': 71.42857142857143, '108-111': 89.76377952755905, '112-115': 93.47826086956522, '116-119': 96.5909090909091}
2025-12-11 18:49:51,069 [trainer.py] => Ave Acc (W-NCM): 75.99%
2025-12-11 18:49:51,070 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 68.39% (best 83.23%); T2: W-NCM 71.03% (best 93.79%); T3: W-NCM 69.30% (best 84.21%); T4: W-NCM 85.45% (best 92.73%); T5: W-NCM 80.95% (best 95.24%); T6: W-NCM 74.43% (best 92.24%); T7: W-NCM 74.39% (best 89.02%); T8: W-NCM 68.06% (best 91.62%); T9: W-NCM 81.33% (best 96.00%); T10: W-NCM 76.24% (best 92.08%); T11: W-NCM 73.26% (best 76.74%); T12: W-NCM 64.81% (best 75.93%); T13: W-NCM 79.39% (best 95.42%); T14: W-NCM 77.05% (best 85.25%); T15: W-NCM 80.00% (best 90.53%); T16: W-NCM 74.15% (best 91.84%); T17: W-NCM 75.51% (best 91.84%); T18: W-NCM 75.26% (best 87.63%); T19: W-NCM 59.32% (best 92.37%); T20: W-NCM 67.88% (best 84.85%); T21: W-NCM 69.47% (best 88.42%); T22: W-NCM 79.70% (best 88.72%); T23: W-NCM 86.00% (best 94.00%); T24: W-NCM 71.67% (best 90.00%); T25: W-NCM 66.47% (best 87.28%); T26: W-NCM 78.81% (best 88.14%); T27: W-NCM 71.43% (best 78.95%); T28: W-NCM 89.76% (best 93.70%); T29: W-NCM 93.48% (best 93.48%); T30: W-NCM 96.59% (best 96.59%)
2025-12-11 18:49:51,070 [trainer.py] => Average forgetting (W-NCM): 13.87% | Max forgetting (W-NCM): 33.05%
2025-12-11 18:49:51,076 [trainer.py] => All params: 126094051
2025-12-11 18:49:51,083 [trainer.py] => Trainable params: 187396
2025-12-11 18:49:51,083 [inflora.py] => Learning on 120-124
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_v.30.weight', 'image_encoder.blocks.8.attn.lora_B_v.30.weight', 'image_encoder.blocks.9.attn.lora_B_k.30.weight', 'image_encoder.blocks.10.attn.lora_B_v.30.weight', 'image_encoder.blocks.5.attn.lora_B_v.30.weight', 'image_encoder.blocks.2.attn.lora_B_k.30.weight', 'image_encoder.blocks.0.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_v.30.weight', 'classifier_pool.30.weight', 'image_encoder.blocks.4.attn.lora_B_v.30.weight', 'image_encoder.blocks.4.attn.lora_B_k.30.weight', 'image_encoder.blocks.5.attn.lora_B_k.30.weight', 'image_encoder.blocks.11.attn.lora_B_v.30.weight', 'image_encoder.blocks.1.attn.lora_B_k.30.weight', 'image_encoder.blocks.6.attn.lora_B_v.30.weight', 'image_encoder.blocks.7.attn.lora_B_k.30.weight', 'image_encoder.blocks.11.attn.lora_B_k.30.weight', 'image_encoder.blocks.8.attn.lora_B_k.30.weight', 'image_encoder.blocks.6.attn.lora_B_k.30.weight', 'image_encoder.blocks.0.attn.lora_B_k.30.weight', 'image_encoder.blocks.2.attn.lora_B_v.30.weight', 'classifier_pool.30.bias', 'image_encoder.blocks.7.attn.lora_B_v.30.weight', 'image_encoder.blocks.10.attn.lora_B_k.30.weight', 'image_encoder.blocks.1.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_k.30.weight'}
2025-12-11 18:52:48,313 [inflora.py] => Task 30, Epoch 50/50 => Loss 0.083, Train_accy 97.73
Threshold:  0.992
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 36/768 type remove
Layer 3 : 75/768 type remove
Layer 4 : 114/768 type remove
Layer 5 : 156/768 type remove
Layer 6 : 158/768 type remove
Layer 7 : 190/768 type remove
Layer 8 : 228/768 type remove
Layer 9 : 349/768 type remove
Layer 10 : 374/768 type retain
Layer 11 : 286/768 type remove
Layer 12 : 365/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:52:56,438 [trainer.py] => Time:185.35503911972046
3794 3794
3794 3794
2025-12-11 18:53:07,374 [trainer.py] => Time:10.93600869178772
2025-12-11 18:53:07,375 [inflora.py] => Exemplar size: 0
2025-12-11 18:53:07,375 [trainer.py] => CNN: {'total': np.float64(58.54), '00-03': np.float64(64.52), '04-07': np.float64(67.59), '08-11': np.float64(65.79), '12-15': np.float64(80.0), '16-19': np.float64(69.05), '20-23': np.float64(68.49), '24-27': np.float64(77.44), '28-31': np.float64(39.79), '32-35': np.float64(60.0), '36-39': np.float64(73.27), '40-43': np.float64(48.84), '44-47': np.float64(33.33), '48-51': np.float64(55.73), '52-55': np.float64(45.9), '56-59': np.float64(48.42), '60-63': np.float64(74.15), '64-67': np.float64(46.94), '68-71': np.float64(41.24), '72-75': np.float64(49.15), '76-79': np.float64(56.97), '80-83': np.float64(40.0), '84-87': np.float64(48.12), '88-91': np.float64(75.0), '92-95': np.float64(49.17), '96-99': np.float64(54.34), '100-103': np.float64(66.95), '104-107': np.float64(21.8), '108-111': np.float64(63.78), '112-115': np.float64(79.35), '116-119': np.float64(71.59), '120-123': np.float64(65.81), 'old': np.float64(58.31), 'new': np.float64(65.81)}
2025-12-11 18:53:07,375 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54)]
2025-12-11 18:53:07,375 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28)]
2025-12-11 18:53:07,375 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768]
2025-12-11 18:53:20,488 [trainer.py] => W-NCM: {'00-03': 70.96774193548387, '04-07': 69.6551724137931, '08-11': 67.54385964912281, '12-15': 85.45454545454545, '16-19': 78.57142857142857, '20-23': 74.42922374429224, '24-27': 75.60975609756098, '28-31': 66.49214659685863, '32-35': 80.0, '36-39': 76.23762376237624, '40-43': 73.25581395348837, '44-47': 62.96296296296296, '48-51': 78.62595419847328, '52-55': 77.04918032786885, '56-59': 80.0, '60-63': 74.14965986394559, '64-67': 77.55102040816327, '68-71': 75.25773195876289, '72-75': 58.47457627118644, '76-79': 69.0909090909091, '80-83': 70.52631578947368, '84-87': 76.69172932330827, '88-91': 84.0, '92-95': 70.0, '96-99': 66.47398843930635, '100-103': 77.11864406779661, '104-107': 69.92481203007519, '108-111': 89.76377952755905, '112-115': 90.21739130434783, '116-119': 94.31818181818183, '120-123': 90.5982905982906}
2025-12-11 18:53:20,489 [trainer.py] => Ave Acc (W-NCM): 75.84%
2025-12-11 18:53:20,489 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 70.97% (best 83.23%); T2: W-NCM 69.66% (best 93.79%); T3: W-NCM 67.54% (best 84.21%); T4: W-NCM 85.45% (best 92.73%); T5: W-NCM 78.57% (best 95.24%); T6: W-NCM 74.43% (best 92.24%); T7: W-NCM 75.61% (best 89.02%); T8: W-NCM 66.49% (best 91.62%); T9: W-NCM 80.00% (best 96.00%); T10: W-NCM 76.24% (best 92.08%); T11: W-NCM 73.26% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 78.63% (best 95.42%); T14: W-NCM 77.05% (best 85.25%); T15: W-NCM 80.00% (best 90.53%); T16: W-NCM 74.15% (best 91.84%); T17: W-NCM 77.55% (best 91.84%); T18: W-NCM 75.26% (best 87.63%); T19: W-NCM 58.47% (best 92.37%); T20: W-NCM 69.09% (best 84.85%); T21: W-NCM 70.53% (best 88.42%); T22: W-NCM 76.69% (best 88.72%); T23: W-NCM 84.00% (best 94.00%); T24: W-NCM 70.00% (best 90.00%); T25: W-NCM 66.47% (best 87.28%); T26: W-NCM 77.12% (best 88.14%); T27: W-NCM 69.92% (best 78.95%); T28: W-NCM 89.76% (best 93.70%); T29: W-NCM 90.22% (best 93.48%); T30: W-NCM 94.32% (best 96.59%); T31: W-NCM 90.60% (best 90.60%)
2025-12-11 18:53:20,489 [trainer.py] => Average forgetting (W-NCM): 14.05% | Max forgetting (W-NCM): 33.90%
2025-12-11 18:53:20,496 [trainer.py] => All params: 126094051
2025-12-11 18:53:20,502 [trainer.py] => Trainable params: 187396
2025-12-11 18:53:20,502 [inflora.py] => Learning on 124-128
Parameters to be updated: {'image_encoder.blocks.7.attn.lora_B_k.31.weight', 'image_encoder.blocks.3.attn.lora_B_v.31.weight', 'image_encoder.blocks.5.attn.lora_B_k.31.weight', 'image_encoder.blocks.0.attn.lora_B_k.31.weight', 'classifier_pool.31.bias', 'image_encoder.blocks.2.attn.lora_B_v.31.weight', 'image_encoder.blocks.1.attn.lora_B_k.31.weight', 'image_encoder.blocks.6.attn.lora_B_k.31.weight', 'image_encoder.blocks.8.attn.lora_B_v.31.weight', 'image_encoder.blocks.1.attn.lora_B_v.31.weight', 'image_encoder.blocks.8.attn.lora_B_k.31.weight', 'image_encoder.blocks.2.attn.lora_B_k.31.weight', 'image_encoder.blocks.4.attn.lora_B_k.31.weight', 'image_encoder.blocks.11.attn.lora_B_v.31.weight', 'image_encoder.blocks.10.attn.lora_B_k.31.weight', 'image_encoder.blocks.6.attn.lora_B_v.31.weight', 'image_encoder.blocks.0.attn.lora_B_v.31.weight', 'image_encoder.blocks.9.attn.lora_B_v.31.weight', 'image_encoder.blocks.9.attn.lora_B_k.31.weight', 'image_encoder.blocks.11.attn.lora_B_k.31.weight', 'classifier_pool.31.weight', 'image_encoder.blocks.3.attn.lora_B_k.31.weight', 'image_encoder.blocks.5.attn.lora_B_v.31.weight', 'image_encoder.blocks.7.attn.lora_B_v.31.weight', 'image_encoder.blocks.10.attn.lora_B_v.31.weight', 'image_encoder.blocks.4.attn.lora_B_v.31.weight'}
2025-12-11 18:56:24,281 [inflora.py] => Task 31, Epoch 50/50 => Loss 0.199, Train_accy 93.78
Threshold:  0.9924
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 36/768 type remove
Layer 3 : 76/768 type remove
Layer 4 : 115/768 type remove
Layer 5 : 158/768 type remove
Layer 6 : 161/768 type remove
Layer 7 : 194/768 type remove
Layer 8 : 231/768 type remove
Layer 9 : 352/768 type remove
Layer 10 : 370/768 type retain
Layer 11 : 295/768 type remove
Layer 12 : 324/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:56:32,922 [trainer.py] => Time:192.41937971115112
3896 3896
3896 3896
2025-12-11 18:56:44,153 [trainer.py] => Time:11.230514526367188
2025-12-11 18:56:44,153 [inflora.py] => Exemplar size: 0
2025-12-11 18:56:44,153 [trainer.py] => CNN: {'total': np.float64(57.29), '00-03': np.float64(62.58), '04-07': np.float64(65.52), '08-11': np.float64(62.28), '12-15': np.float64(79.09), '16-19': np.float64(70.63), '20-23': np.float64(68.04), '24-27': np.float64(78.05), '28-31': np.float64(39.27), '32-35': np.float64(62.67), '36-39': np.float64(74.26), '40-43': np.float64(47.67), '44-47': np.float64(33.33), '48-51': np.float64(54.96), '52-55': np.float64(44.26), '56-59': np.float64(48.42), '60-63': np.float64(71.43), '64-67': np.float64(44.9), '68-71': np.float64(35.05), '72-75': np.float64(46.61), '76-79': np.float64(52.12), '80-83': np.float64(42.63), '84-87': np.float64(50.38), '88-91': np.float64(75.0), '92-95': np.float64(46.67), '96-99': np.float64(53.18), '100-103': np.float64(63.56), '104-107': np.float64(21.05), '108-111': np.float64(66.93), '112-115': np.float64(80.43), '116-119': np.float64(73.86), '120-123': np.float64(68.38), '124-127': np.float64(34.31), 'old': np.float64(57.91), 'new': np.float64(34.31)}
2025-12-11 18:56:44,154 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29)]
2025-12-11 18:56:44,154 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81)]
2025-12-11 18:56:44,154 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733]
2025-12-11 18:56:57,751 [trainer.py] => W-NCM: {'00-03': 69.6774193548387, '04-07': 66.89655172413794, '08-11': 66.66666666666666, '12-15': 83.63636363636363, '16-19': 74.60317460317461, '20-23': 74.88584474885845, '24-27': 70.73170731707317, '28-31': 66.49214659685863, '32-35': 78.66666666666666, '36-39': 74.25742574257426, '40-43': 74.4186046511628, '44-47': 68.51851851851852, '48-51': 74.80916030534351, '52-55': 77.04918032786885, '56-59': 80.0, '60-63': 75.51020408163265, '64-67': 77.55102040816327, '68-71': 69.0721649484536, '72-75': 54.23728813559322, '76-79': 67.27272727272727, '80-83': 65.78947368421053, '84-87': 76.69172932330827, '88-91': 83.0, '92-95': 65.83333333333333, '96-99': 63.005780346820806, '100-103': 74.57627118644068, '104-107': 69.17293233082707, '108-111': 84.25196850393701, '112-115': 89.13043478260869, '116-119': 87.5, '120-123': 86.32478632478633, '124-127': 79.41176470588235}
2025-12-11 18:56:57,751 [trainer.py] => Ave Acc (W-NCM): 74.05%
2025-12-11 18:56:57,752 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 69.68% (best 83.23%); T2: W-NCM 66.90% (best 93.79%); T3: W-NCM 66.67% (best 84.21%); T4: W-NCM 83.64% (best 92.73%); T5: W-NCM 74.60% (best 95.24%); T6: W-NCM 74.89% (best 92.24%); T7: W-NCM 70.73% (best 89.02%); T8: W-NCM 66.49% (best 91.62%); T9: W-NCM 78.67% (best 96.00%); T10: W-NCM 74.26% (best 92.08%); T11: W-NCM 74.42% (best 76.74%); T12: W-NCM 68.52% (best 75.93%); T13: W-NCM 74.81% (best 95.42%); T14: W-NCM 77.05% (best 85.25%); T15: W-NCM 80.00% (best 90.53%); T16: W-NCM 75.51% (best 91.84%); T17: W-NCM 77.55% (best 91.84%); T18: W-NCM 69.07% (best 87.63%); T19: W-NCM 54.24% (best 92.37%); T20: W-NCM 67.27% (best 84.85%); T21: W-NCM 65.79% (best 88.42%); T22: W-NCM 76.69% (best 88.72%); T23: W-NCM 83.00% (best 94.00%); T24: W-NCM 65.83% (best 90.00%); T25: W-NCM 63.01% (best 87.28%); T26: W-NCM 74.58% (best 88.14%); T27: W-NCM 69.17% (best 78.95%); T28: W-NCM 84.25% (best 93.70%); T29: W-NCM 89.13% (best 93.48%); T30: W-NCM 87.50% (best 96.59%); T31: W-NCM 86.32% (best 90.60%); T32: W-NCM 79.41% (best 79.41%)
2025-12-11 18:56:57,752 [trainer.py] => Average forgetting (W-NCM): 15.55% | Max forgetting (W-NCM): 38.14%
2025-12-11 18:56:57,758 [trainer.py] => All params: 126094051
2025-12-11 18:56:57,764 [trainer.py] => Trainable params: 187396
2025-12-11 18:56:57,765 [inflora.py] => Learning on 128-132
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_k.32.weight', 'image_encoder.blocks.10.attn.lora_B_k.32.weight', 'image_encoder.blocks.2.attn.lora_B_k.32.weight', 'image_encoder.blocks.4.attn.lora_B_k.32.weight', 'image_encoder.blocks.7.attn.lora_B_v.32.weight', 'image_encoder.blocks.8.attn.lora_B_v.32.weight', 'image_encoder.blocks.11.attn.lora_B_v.32.weight', 'image_encoder.blocks.3.attn.lora_B_v.32.weight', 'classifier_pool.32.weight', 'image_encoder.blocks.10.attn.lora_B_v.32.weight', 'image_encoder.blocks.6.attn.lora_B_v.32.weight', 'classifier_pool.32.bias', 'image_encoder.blocks.6.attn.lora_B_k.32.weight', 'image_encoder.blocks.0.attn.lora_B_k.32.weight', 'image_encoder.blocks.8.attn.lora_B_k.32.weight', 'image_encoder.blocks.7.attn.lora_B_k.32.weight', 'image_encoder.blocks.9.attn.lora_B_v.32.weight', 'image_encoder.blocks.1.attn.lora_B_k.32.weight', 'image_encoder.blocks.2.attn.lora_B_v.32.weight', 'image_encoder.blocks.11.attn.lora_B_k.32.weight', 'image_encoder.blocks.1.attn.lora_B_v.32.weight', 'image_encoder.blocks.0.attn.lora_B_v.32.weight', 'image_encoder.blocks.4.attn.lora_B_v.32.weight', 'image_encoder.blocks.3.attn.lora_B_k.32.weight', 'image_encoder.blocks.5.attn.lora_B_v.32.weight', 'image_encoder.blocks.5.attn.lora_B_k.32.weight'}
2025-12-11 18:59:44,517 [inflora.py] => Task 32, Epoch 50/50 => Loss 0.148, Train_accy 94.42
Threshold:  0.9928
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 36/768 type remove
Layer 3 : 78/768 type remove
Layer 4 : 119/768 type remove
Layer 5 : 163/768 type remove
Layer 6 : 170/768 type remove
Layer 7 : 201/768 type remove
Layer 8 : 238/768 type remove
Layer 9 : 362/768 type remove
Layer 10 : 355/768 type retain
Layer 11 : 315/768 type remove
Layer 12 : 298/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 18:59:52,710 [trainer.py] => Time:174.94534587860107
4020 4020
4020 4020
2025-12-11 19:00:04,298 [trainer.py] => Time:11.587820053100586
2025-12-11 19:00:04,298 [inflora.py] => Exemplar size: 0
2025-12-11 19:00:04,299 [trainer.py] => CNN: {'total': np.float64(57.11), '00-03': np.float64(60.65), '04-07': np.float64(64.14), '08-11': np.float64(60.53), '12-15': np.float64(78.18), '16-19': np.float64(68.25), '20-23': np.float64(68.95), '24-27': np.float64(78.05), '28-31': np.float64(46.07), '32-35': np.float64(62.67), '36-39': np.float64(76.24), '40-43': np.float64(46.51), '44-47': np.float64(37.04), '48-51': np.float64(50.38), '52-55': np.float64(42.62), '56-59': np.float64(47.37), '60-63': np.float64(74.15), '64-67': np.float64(46.94), '68-71': np.float64(36.08), '72-75': np.float64(43.22), '76-79': np.float64(52.12), '80-83': np.float64(44.74), '84-87': np.float64(45.86), '88-91': np.float64(75.0), '92-95': np.float64(49.17), '96-99': np.float64(50.87), '100-103': np.float64(62.71), '104-107': np.float64(21.8), '108-111': np.float64(64.57), '112-115': np.float64(81.52), '116-119': np.float64(70.45), '120-123': np.float64(69.23), '124-127': np.float64(33.33), '128-131': np.float64(57.26), 'old': np.float64(57.11), 'new': np.float64(57.26)}
2025-12-11 19:00:04,299 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11)]
2025-12-11 19:00:04,299 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92)]
2025-12-11 19:00:04,299 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129]
2025-12-11 19:00:17,960 [trainer.py] => W-NCM: {'00-03': 65.16129032258064, '04-07': 65.51724137931035, '08-11': 67.54385964912281, '12-15': 81.81818181818183, '16-19': 69.84126984126983, '20-23': 74.88584474885845, '24-27': 68.90243902439023, '28-31': 63.35078534031413, '32-35': 80.0, '36-39': 80.19801980198021, '40-43': 70.93023255813954, '44-47': 66.66666666666666, '48-51': 77.86259541984732, '52-55': 77.04918032786885, '56-59': 76.84210526315789, '60-63': 74.82993197278913, '64-67': 75.51020408163265, '68-71': 72.16494845360825, '72-75': 51.69491525423729, '76-79': 67.87878787878789, '80-83': 62.63157894736842, '84-87': 73.68421052631578, '88-91': 82.0, '92-95': 63.33333333333333, '96-99': 61.27167630057804, '100-103': 72.88135593220339, '104-107': 71.42857142857143, '108-111': 80.31496062992126, '112-115': 88.04347826086956, '116-119': 82.95454545454545, '120-123': 81.19658119658119, '124-127': 73.52941176470588, '128-131': 87.90322580645162}
2025-12-11 19:00:17,961 [trainer.py] => Ave Acc (W-NCM): 73.02%
2025-12-11 19:00:17,961 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 65.16% (best 83.23%); T2: W-NCM 65.52% (best 93.79%); T3: W-NCM 67.54% (best 84.21%); T4: W-NCM 81.82% (best 92.73%); T5: W-NCM 69.84% (best 95.24%); T6: W-NCM 74.89% (best 92.24%); T7: W-NCM 68.90% (best 89.02%); T8: W-NCM 63.35% (best 91.62%); T9: W-NCM 80.00% (best 96.00%); T10: W-NCM 80.20% (best 92.08%); T11: W-NCM 70.93% (best 76.74%); T12: W-NCM 66.67% (best 75.93%); T13: W-NCM 77.86% (best 95.42%); T14: W-NCM 77.05% (best 85.25%); T15: W-NCM 76.84% (best 90.53%); T16: W-NCM 74.83% (best 91.84%); T17: W-NCM 75.51% (best 91.84%); T18: W-NCM 72.16% (best 87.63%); T19: W-NCM 51.69% (best 92.37%); T20: W-NCM 67.88% (best 84.85%); T21: W-NCM 62.63% (best 88.42%); T22: W-NCM 73.68% (best 88.72%); T23: W-NCM 82.00% (best 94.00%); T24: W-NCM 63.33% (best 90.00%); T25: W-NCM 61.27% (best 87.28%); T26: W-NCM 72.88% (best 88.14%); T27: W-NCM 71.43% (best 78.95%); T28: W-NCM 80.31% (best 93.70%); T29: W-NCM 88.04% (best 93.48%); T30: W-NCM 82.95% (best 96.59%); T31: W-NCM 81.20% (best 90.60%); T32: W-NCM 73.53% (best 79.41%); T33: W-NCM 87.90% (best 87.90%)
2025-12-11 19:00:17,961 [trainer.py] => Average forgetting (W-NCM): 16.56% | Max forgetting (W-NCM): 40.68%
2025-12-11 19:00:17,967 [trainer.py] => All params: 126094051
2025-12-11 19:00:17,974 [trainer.py] => Trainable params: 187396
2025-12-11 19:00:17,974 [inflora.py] => Learning on 132-136
Parameters to be updated: {'image_encoder.blocks.8.attn.lora_B_k.33.weight', 'image_encoder.blocks.1.attn.lora_B_v.33.weight', 'image_encoder.blocks.4.attn.lora_B_v.33.weight', 'image_encoder.blocks.9.attn.lora_B_v.33.weight', 'image_encoder.blocks.1.attn.lora_B_k.33.weight', 'classifier_pool.33.weight', 'image_encoder.blocks.5.attn.lora_B_v.33.weight', 'image_encoder.blocks.0.attn.lora_B_v.33.weight', 'classifier_pool.33.bias', 'image_encoder.blocks.7.attn.lora_B_k.33.weight', 'image_encoder.blocks.7.attn.lora_B_v.33.weight', 'image_encoder.blocks.11.attn.lora_B_k.33.weight', 'image_encoder.blocks.2.attn.lora_B_k.33.weight', 'image_encoder.blocks.10.attn.lora_B_v.33.weight', 'image_encoder.blocks.6.attn.lora_B_v.33.weight', 'image_encoder.blocks.3.attn.lora_B_k.33.weight', 'image_encoder.blocks.8.attn.lora_B_v.33.weight', 'image_encoder.blocks.6.attn.lora_B_k.33.weight', 'image_encoder.blocks.11.attn.lora_B_v.33.weight', 'image_encoder.blocks.10.attn.lora_B_k.33.weight', 'image_encoder.blocks.2.attn.lora_B_v.33.weight', 'image_encoder.blocks.0.attn.lora_B_k.33.weight', 'image_encoder.blocks.9.attn.lora_B_k.33.weight', 'image_encoder.blocks.3.attn.lora_B_v.33.weight', 'image_encoder.blocks.4.attn.lora_B_k.33.weight', 'image_encoder.blocks.5.attn.lora_B_k.33.weight'}
2025-12-11 19:03:37,659 [inflora.py] => Task 33, Epoch 50/50 => Loss 0.101, Train_accy 96.25
Threshold:  0.9932
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 37/768 type remove
Layer 3 : 82/768 type remove
Layer 4 : 126/768 type remove
Layer 5 : 170/768 type remove
Layer 6 : 178/768 type remove
Layer 7 : 209/768 type remove
Layer 8 : 248/768 type remove
Layer 9 : 376/768 type remove
Layer 10 : 336/768 type retain
Layer 11 : 341/768 type remove
Layer 12 : 280/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:03:46,068 [trainer.py] => Time:208.09439945220947
4132 4132
4132 4132
2025-12-11 19:03:57,964 [trainer.py] => Time:11.895717859268188
2025-12-11 19:03:57,965 [inflora.py] => Exemplar size: 0
2025-12-11 19:03:57,965 [trainer.py] => CNN: {'total': np.float64(55.95), '00-03': np.float64(64.52), '04-07': np.float64(60.0), '08-11': np.float64(57.89), '12-15': np.float64(77.27), '16-19': np.float64(68.25), '20-23': np.float64(68.04), '24-27': np.float64(75.0), '28-31': np.float64(41.36), '32-35': np.float64(54.67), '36-39': np.float64(73.27), '40-43': np.float64(41.86), '44-47': np.float64(35.19), '48-51': np.float64(48.09), '52-55': np.float64(42.62), '56-59': np.float64(44.21), '60-63': np.float64(68.03), '64-67': np.float64(44.9), '68-71': np.float64(34.02), '72-75': np.float64(45.76), '76-79': np.float64(50.91), '80-83': np.float64(39.47), '84-87': np.float64(48.12), '88-91': np.float64(78.0), '92-95': np.float64(47.5), '96-99': np.float64(52.6), '100-103': np.float64(61.02), '104-107': np.float64(19.55), '108-111': np.float64(64.57), '112-115': np.float64(81.52), '116-119': np.float64(73.86), '120-123': np.float64(66.67), '124-127': np.float64(36.27), '128-131': np.float64(54.84), '132-135': np.float64(66.96), 'old': np.float64(55.65), 'new': np.float64(66.96)}
2025-12-11 19:03:57,965 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95)]
2025-12-11 19:03:57,965 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67)]
2025-12-11 19:03:57,965 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894]
2025-12-11 19:04:12,264 [trainer.py] => W-NCM: {'00-03': 63.2258064516129, '04-07': 64.82758620689654, '08-11': 65.78947368421053, '12-15': 81.81818181818183, '16-19': 74.60317460317461, '20-23': 74.42922374429224, '24-27': 68.90243902439023, '28-31': 61.25654450261781, '32-35': 78.66666666666666, '36-39': 75.24752475247524, '40-43': 70.93023255813954, '44-47': 62.96296296296296, '48-51': 77.09923664122137, '52-55': 77.04918032786885, '56-59': 74.73684210526315, '60-63': 73.46938775510205, '64-67': 77.55102040816327, '68-71': 70.10309278350515, '72-75': 50.847457627118644, '76-79': 68.48484848484848, '80-83': 63.68421052631579, '84-87': 73.68421052631578, '88-91': 82.0, '92-95': 65.0, '96-99': 60.69364161849711, '100-103': 68.64406779661016, '104-107': 69.92481203007519, '108-111': 78.74015748031496, '112-115': 90.21739130434783, '116-119': 85.22727272727273, '120-123': 81.19658119658119, '124-127': 70.58823529411765, '128-131': 76.61290322580645, '132-135': 88.39285714285714}
2025-12-11 19:04:12,264 [trainer.py] => Ave Acc (W-NCM): 72.55%
2025-12-11 19:04:12,265 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 63.23% (best 83.23%); T2: W-NCM 64.83% (best 93.79%); T3: W-NCM 65.79% (best 84.21%); T4: W-NCM 81.82% (best 92.73%); T5: W-NCM 74.60% (best 95.24%); T6: W-NCM 74.43% (best 92.24%); T7: W-NCM 68.90% (best 89.02%); T8: W-NCM 61.26% (best 91.62%); T9: W-NCM 78.67% (best 96.00%); T10: W-NCM 75.25% (best 92.08%); T11: W-NCM 70.93% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 77.10% (best 95.42%); T14: W-NCM 77.05% (best 85.25%); T15: W-NCM 74.74% (best 90.53%); T16: W-NCM 73.47% (best 91.84%); T17: W-NCM 77.55% (best 91.84%); T18: W-NCM 70.10% (best 87.63%); T19: W-NCM 50.85% (best 92.37%); T20: W-NCM 68.48% (best 84.85%); T21: W-NCM 63.68% (best 88.42%); T22: W-NCM 73.68% (best 88.72%); T23: W-NCM 82.00% (best 94.00%); T24: W-NCM 65.00% (best 90.00%); T25: W-NCM 60.69% (best 87.28%); T26: W-NCM 68.64% (best 88.14%); T27: W-NCM 69.92% (best 78.95%); T28: W-NCM 78.74% (best 93.70%); T29: W-NCM 90.22% (best 93.48%); T30: W-NCM 85.23% (best 96.59%); T31: W-NCM 81.20% (best 90.60%); T32: W-NCM 70.59% (best 79.41%); T33: W-NCM 76.61% (best 87.90%); T34: W-NCM 88.39% (best 88.39%)
2025-12-11 19:04:12,265 [trainer.py] => Average forgetting (W-NCM): 17.02% | Max forgetting (W-NCM): 41.53%
2025-12-11 19:04:12,271 [trainer.py] => All params: 126094051
2025-12-11 19:04:12,278 [trainer.py] => Trainable params: 187396
2025-12-11 19:04:12,278 [inflora.py] => Learning on 136-140
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.34.weight', 'image_encoder.blocks.5.attn.lora_B_k.34.weight', 'image_encoder.blocks.7.attn.lora_B_v.34.weight', 'image_encoder.blocks.10.attn.lora_B_k.34.weight', 'image_encoder.blocks.2.attn.lora_B_k.34.weight', 'image_encoder.blocks.3.attn.lora_B_v.34.weight', 'image_encoder.blocks.9.attn.lora_B_v.34.weight', 'image_encoder.blocks.9.attn.lora_B_k.34.weight', 'classifier_pool.34.bias', 'image_encoder.blocks.8.attn.lora_B_v.34.weight', 'image_encoder.blocks.10.attn.lora_B_v.34.weight', 'image_encoder.blocks.11.attn.lora_B_v.34.weight', 'image_encoder.blocks.0.attn.lora_B_v.34.weight', 'image_encoder.blocks.0.attn.lora_B_k.34.weight', 'classifier_pool.34.weight', 'image_encoder.blocks.2.attn.lora_B_v.34.weight', 'image_encoder.blocks.8.attn.lora_B_k.34.weight', 'image_encoder.blocks.1.attn.lora_B_k.34.weight', 'image_encoder.blocks.3.attn.lora_B_k.34.weight', 'image_encoder.blocks.4.attn.lora_B_v.34.weight', 'image_encoder.blocks.4.attn.lora_B_k.34.weight', 'image_encoder.blocks.6.attn.lora_B_k.34.weight', 'image_encoder.blocks.5.attn.lora_B_v.34.weight', 'image_encoder.blocks.11.attn.lora_B_k.34.weight', 'image_encoder.blocks.1.attn.lora_B_v.34.weight', 'image_encoder.blocks.7.attn.lora_B_k.34.weight'}
2025-12-11 19:06:58,815 [inflora.py] => Task 34, Epoch 50/50 => Loss 0.056, Train_accy 98.56
Threshold:  0.9936
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 39/768 type remove
Layer 3 : 88/768 type remove
Layer 4 : 135/768 type remove
Layer 5 : 183/768 type remove
Layer 6 : 191/768 type remove
Layer 7 : 222/768 type remove
Layer 8 : 264/768 type remove
Layer 9 : 369/768 type retain
Layer 10 : 305/768 type retain
Layer 11 : 383/768 type retain
Layer 12 : 269/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:07:06,945 [trainer.py] => Time:174.66710090637207
4234 4234
4234 4234
2025-12-11 19:07:19,185 [trainer.py] => Time:12.23975396156311
2025-12-11 19:07:19,185 [inflora.py] => Exemplar size: 0
2025-12-11 19:07:19,185 [trainer.py] => CNN: {'total': np.float64(55.9), '00-03': np.float64(63.23), '04-07': np.float64(57.93), '08-11': np.float64(57.89), '12-15': np.float64(78.18), '16-19': np.float64(68.25), '20-23': np.float64(64.84), '24-27': np.float64(72.56), '28-31': np.float64(43.46), '32-35': np.float64(52.0), '36-39': np.float64(73.27), '40-43': np.float64(43.02), '44-47': np.float64(35.19), '48-51': np.float64(47.33), '52-55': np.float64(42.62), '56-59': np.float64(47.37), '60-63': np.float64(69.39), '64-67': np.float64(44.9), '68-71': np.float64(37.11), '72-75': np.float64(42.37), '76-79': np.float64(49.7), '80-83': np.float64(39.47), '84-87': np.float64(45.86), '88-91': np.float64(75.0), '92-95': np.float64(47.5), '96-99': np.float64(46.24), '100-103': np.float64(63.56), '104-107': np.float64(24.06), '108-111': np.float64(61.42), '112-115': np.float64(78.26), '116-119': np.float64(73.86), '120-123': np.float64(65.81), '124-127': np.float64(36.27), '128-131': np.float64(53.23), '132-135': np.float64(68.75), '136-139': np.float64(80.39), 'old': np.float64(55.3), 'new': np.float64(80.39)}
2025-12-11 19:07:19,186 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9)]
2025-12-11 19:07:19,186 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76)]
2025-12-11 19:07:19,186 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164]
2025-12-11 19:07:33,313 [trainer.py] => W-NCM: {'00-03': 66.45161290322581, '04-07': 66.20689655172414, '08-11': 65.78947368421053, '12-15': 81.81818181818183, '16-19': 73.80952380952381, '20-23': 76.25570776255708, '24-27': 65.2439024390244, '28-31': 63.35078534031413, '32-35': 77.33333333333333, '36-39': 74.25742574257426, '40-43': 73.25581395348837, '44-47': 64.81481481481481, '48-51': 79.38931297709924, '52-55': 73.77049180327869, '56-59': 74.73684210526315, '60-63': 72.78911564625851, '64-67': 77.55102040816327, '68-71': 72.16494845360825, '72-75': 48.30508474576271, '76-79': 67.27272727272727, '80-83': 65.26315789473685, '84-87': 74.43609022556392, '88-91': 84.0, '92-95': 66.66666666666666, '96-99': 63.005780346820806, '100-103': 72.88135593220339, '104-107': 67.66917293233082, '108-111': 79.52755905511812, '112-115': 82.6086956521739, '116-119': 85.22727272727273, '120-123': 81.19658119658119, '124-127': 64.70588235294117, '128-131': 77.41935483870968, '132-135': 81.25, '136-139': 92.15686274509804}
2025-12-11 19:07:33,314 [trainer.py] => Ave Acc (W-NCM): 72.93%
2025-12-11 19:07:33,314 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 66.45% (best 83.23%); T2: W-NCM 66.21% (best 93.79%); T3: W-NCM 65.79% (best 84.21%); T4: W-NCM 81.82% (best 92.73%); T5: W-NCM 73.81% (best 95.24%); T6: W-NCM 76.26% (best 92.24%); T7: W-NCM 65.24% (best 89.02%); T8: W-NCM 63.35% (best 91.62%); T9: W-NCM 77.33% (best 96.00%); T10: W-NCM 74.26% (best 92.08%); T11: W-NCM 73.26% (best 76.74%); T12: W-NCM 64.81% (best 75.93%); T13: W-NCM 79.39% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 74.74% (best 90.53%); T16: W-NCM 72.79% (best 91.84%); T17: W-NCM 77.55% (best 91.84%); T18: W-NCM 72.16% (best 87.63%); T19: W-NCM 48.31% (best 92.37%); T20: W-NCM 67.27% (best 84.85%); T21: W-NCM 65.26% (best 88.42%); T22: W-NCM 74.44% (best 88.72%); T23: W-NCM 84.00% (best 94.00%); T24: W-NCM 66.67% (best 90.00%); T25: W-NCM 63.01% (best 87.28%); T26: W-NCM 72.88% (best 88.14%); T27: W-NCM 67.67% (best 78.95%); T28: W-NCM 79.53% (best 93.70%); T29: W-NCM 82.61% (best 93.48%); T30: W-NCM 85.23% (best 96.59%); T31: W-NCM 81.20% (best 90.60%); T32: W-NCM 64.71% (best 79.41%); T33: W-NCM 77.42% (best 87.90%); T34: W-NCM 81.25% (best 88.39%); T35: W-NCM 92.16% (best 92.16%)
2025-12-11 19:07:33,314 [trainer.py] => Average forgetting (W-NCM): 16.70% | Max forgetting (W-NCM): 44.07%
2025-12-11 19:07:33,320 [trainer.py] => All params: 126094051
2025-12-11 19:07:33,327 [trainer.py] => Trainable params: 187396
2025-12-11 19:07:33,327 [inflora.py] => Learning on 140-144
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.35.weight', 'image_encoder.blocks.3.attn.lora_B_k.35.weight', 'image_encoder.blocks.8.attn.lora_B_k.35.weight', 'image_encoder.blocks.2.attn.lora_B_k.35.weight', 'image_encoder.blocks.3.attn.lora_B_v.35.weight', 'image_encoder.blocks.2.attn.lora_B_v.35.weight', 'image_encoder.blocks.9.attn.lora_B_v.35.weight', 'image_encoder.blocks.6.attn.lora_B_v.35.weight', 'image_encoder.blocks.9.attn.lora_B_k.35.weight', 'image_encoder.blocks.11.attn.lora_B_v.35.weight', 'image_encoder.blocks.10.attn.lora_B_k.35.weight', 'image_encoder.blocks.6.attn.lora_B_k.35.weight', 'image_encoder.blocks.7.attn.lora_B_k.35.weight', 'image_encoder.blocks.1.attn.lora_B_v.35.weight', 'image_encoder.blocks.4.attn.lora_B_v.35.weight', 'classifier_pool.35.bias', 'image_encoder.blocks.11.attn.lora_B_k.35.weight', 'image_encoder.blocks.5.attn.lora_B_v.35.weight', 'classifier_pool.35.weight', 'image_encoder.blocks.0.attn.lora_B_k.35.weight', 'image_encoder.blocks.1.attn.lora_B_k.35.weight', 'image_encoder.blocks.5.attn.lora_B_k.35.weight', 'image_encoder.blocks.7.attn.lora_B_v.35.weight', 'image_encoder.blocks.8.attn.lora_B_v.35.weight', 'image_encoder.blocks.0.attn.lora_B_v.35.weight', 'image_encoder.blocks.10.attn.lora_B_v.35.weight'}
2025-12-11 19:10:02,563 [inflora.py] => Task 35, Epoch 50/50 => Loss 0.127, Train_accy 95.74
Threshold:  0.994
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 39/768 type remove
Layer 3 : 89/768 type remove
Layer 4 : 136/768 type remove
Layer 5 : 185/768 type remove
Layer 6 : 194/768 type remove
Layer 7 : 228/768 type remove
Layer 8 : 273/768 type remove
Layer 9 : 362/768 type retain
Layer 10 : 301/768 type retain
Layer 11 : 379/768 type retain
Layer 12 : 264/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:10:10,649 [trainer.py] => Time:157.32155776023865
4329 4329
4329 4329
2025-12-11 19:10:23,072 [trainer.py] => Time:12.422847032546997
2025-12-11 19:10:23,072 [inflora.py] => Exemplar size: 0
2025-12-11 19:10:23,072 [trainer.py] => CNN: {'total': np.float64(56.06), '00-03': np.float64(62.58), '04-07': np.float64(58.62), '08-11': np.float64(59.65), '12-15': np.float64(80.0), '16-19': np.float64(68.25), '20-23': np.float64(64.38), '24-27': np.float64(75.0), '28-31': np.float64(42.93), '32-35': np.float64(50.67), '36-39': np.float64(70.3), '40-43': np.float64(46.51), '44-47': np.float64(37.04), '48-51': np.float64(51.15), '52-55': np.float64(44.26), '56-59': np.float64(44.21), '60-63': np.float64(73.47), '64-67': np.float64(44.9), '68-71': np.float64(35.05), '72-75': np.float64(41.53), '76-79': np.float64(49.7), '80-83': np.float64(37.37), '84-87': np.float64(42.86), '88-91': np.float64(73.0), '92-95': np.float64(46.67), '96-99': np.float64(46.24), '100-103': np.float64(63.56), '104-107': np.float64(23.31), '108-111': np.float64(63.78), '112-115': np.float64(78.26), '116-119': np.float64(75.0), '120-123': np.float64(64.96), '124-127': np.float64(37.25), '128-131': np.float64(53.23), '132-135': np.float64(68.75), '136-139': np.float64(83.33), '140-143': np.float64(55.79), 'old': np.float64(56.07), 'new': np.float64(55.79)}
2025-12-11 19:10:23,072 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06)]
2025-12-11 19:10:23,073 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96)]
2025-12-11 19:10:23,073 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568]
2025-12-11 19:10:37,401 [trainer.py] => W-NCM: {'00-03': 62.58064516129033, '04-07': 64.82758620689654, '08-11': 67.54385964912281, '12-15': 82.72727272727273, '16-19': 74.60317460317461, '20-23': 73.97260273972603, '24-27': 67.6829268292683, '28-31': 63.35078534031413, '32-35': 77.33333333333333, '36-39': 75.24752475247524, '40-43': 74.4186046511628, '44-47': 64.81481481481481, '48-51': 77.86259541984732, '52-55': 73.77049180327869, '56-59': 77.89473684210526, '60-63': 74.82993197278913, '64-67': 79.59183673469387, '68-71': 71.1340206185567, '72-75': 50.0, '76-79': 68.48484848484848, '80-83': 63.1578947368421, '84-87': 72.18045112781954, '88-91': 84.0, '92-95': 65.83333333333333, '96-99': 63.58381502890174, '100-103': 71.1864406779661, '104-107': 67.66917293233082, '108-111': 77.95275590551181, '112-115': 80.43478260869566, '116-119': 86.36363636363636, '120-123': 80.34188034188034, '124-127': 59.80392156862745, '128-131': 72.58064516129032, '132-135': 77.67857142857143, '136-139': 87.25490196078431, '140-143': 91.57894736842105}
2025-12-11 19:10:37,402 [trainer.py] => Ave Acc (W-NCM): 72.90%
2025-12-11 19:10:37,402 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 62.58% (best 83.23%); T2: W-NCM 64.83% (best 93.79%); T3: W-NCM 67.54% (best 84.21%); T4: W-NCM 82.73% (best 92.73%); T5: W-NCM 74.60% (best 95.24%); T6: W-NCM 73.97% (best 92.24%); T7: W-NCM 67.68% (best 89.02%); T8: W-NCM 63.35% (best 91.62%); T9: W-NCM 77.33% (best 96.00%); T10: W-NCM 75.25% (best 92.08%); T11: W-NCM 74.42% (best 76.74%); T12: W-NCM 64.81% (best 75.93%); T13: W-NCM 77.86% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 77.89% (best 90.53%); T16: W-NCM 74.83% (best 91.84%); T17: W-NCM 79.59% (best 91.84%); T18: W-NCM 71.13% (best 87.63%); T19: W-NCM 50.00% (best 92.37%); T20: W-NCM 68.48% (best 84.85%); T21: W-NCM 63.16% (best 88.42%); T22: W-NCM 72.18% (best 88.72%); T23: W-NCM 84.00% (best 94.00%); T24: W-NCM 65.83% (best 90.00%); T25: W-NCM 63.58% (best 87.28%); T26: W-NCM 71.19% (best 88.14%); T27: W-NCM 67.67% (best 78.95%); T28: W-NCM 77.95% (best 93.70%); T29: W-NCM 80.43% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 80.34% (best 90.60%); T32: W-NCM 59.80% (best 79.41%); T33: W-NCM 72.58% (best 87.90%); T34: W-NCM 77.68% (best 88.39%); T35: W-NCM 87.25% (best 92.16%); T36: W-NCM 91.58% (best 91.58%)
2025-12-11 19:10:37,402 [trainer.py] => Average forgetting (W-NCM): 16.79% | Max forgetting (W-NCM): 42.37%
2025-12-11 19:10:37,408 [trainer.py] => All params: 126094051
2025-12-11 19:10:37,415 [trainer.py] => Trainable params: 187396
2025-12-11 19:10:37,415 [inflora.py] => Learning on 144-148
Parameters to be updated: {'classifier_pool.36.bias', 'image_encoder.blocks.5.attn.lora_B_v.36.weight', 'image_encoder.blocks.9.attn.lora_B_k.36.weight', 'image_encoder.blocks.10.attn.lora_B_v.36.weight', 'image_encoder.blocks.0.attn.lora_B_k.36.weight', 'classifier_pool.36.weight', 'image_encoder.blocks.2.attn.lora_B_v.36.weight', 'image_encoder.blocks.9.attn.lora_B_v.36.weight', 'image_encoder.blocks.10.attn.lora_B_k.36.weight', 'image_encoder.blocks.8.attn.lora_B_k.36.weight', 'image_encoder.blocks.11.attn.lora_B_k.36.weight', 'image_encoder.blocks.4.attn.lora_B_k.36.weight', 'image_encoder.blocks.7.attn.lora_B_k.36.weight', 'image_encoder.blocks.7.attn.lora_B_v.36.weight', 'image_encoder.blocks.4.attn.lora_B_v.36.weight', 'image_encoder.blocks.8.attn.lora_B_v.36.weight', 'image_encoder.blocks.6.attn.lora_B_k.36.weight', 'image_encoder.blocks.11.attn.lora_B_v.36.weight', 'image_encoder.blocks.1.attn.lora_B_v.36.weight', 'image_encoder.blocks.5.attn.lora_B_k.36.weight', 'image_encoder.blocks.3.attn.lora_B_v.36.weight', 'image_encoder.blocks.1.attn.lora_B_k.36.weight', 'image_encoder.blocks.3.attn.lora_B_k.36.weight', 'image_encoder.blocks.0.attn.lora_B_v.36.weight', 'image_encoder.blocks.2.attn.lora_B_k.36.weight', 'image_encoder.blocks.6.attn.lora_B_v.36.weight'}
2025-12-11 19:12:59,171 [inflora.py] => Task 36, Epoch 50/50 => Loss 0.080, Train_accy 96.63
Threshold:  0.9944
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 40/768 type remove
Layer 3 : 90/768 type remove
Layer 4 : 137/768 type remove
Layer 5 : 187/768 type remove
Layer 6 : 196/768 type remove
Layer 7 : 232/768 type remove
Layer 8 : 276/768 type remove
Layer 9 : 359/768 type retain
Layer 10 : 299/768 type retain
Layer 11 : 376/768 type retain
Layer 12 : 258/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:13:06,378 [trainer.py] => Time:148.96286177635193
4402 4402
4402 4402
2025-12-11 19:13:19,004 [trainer.py] => Time:12.626346826553345
2025-12-11 19:13:19,005 [inflora.py] => Exemplar size: 0
2025-12-11 19:13:19,005 [trainer.py] => CNN: {'total': np.float64(55.66), '00-03': np.float64(62.58), '04-07': np.float64(58.62), '08-11': np.float64(57.89), '12-15': np.float64(80.91), '16-19': np.float64(69.05), '20-23': np.float64(64.38), '24-27': np.float64(73.78), '28-31': np.float64(40.31), '32-35': np.float64(50.67), '36-39': np.float64(67.33), '40-43': np.float64(43.02), '44-47': np.float64(40.74), '48-51': np.float64(54.2), '52-55': np.float64(39.34), '56-59': np.float64(43.16), '60-63': np.float64(72.11), '64-67': np.float64(40.82), '68-71': np.float64(34.02), '72-75': np.float64(42.37), '76-79': np.float64(45.45), '80-83': np.float64(38.95), '84-87': np.float64(42.86), '88-91': np.float64(74.0), '92-95': np.float64(47.5), '96-99': np.float64(47.4), '100-103': np.float64(62.71), '104-107': np.float64(20.3), '108-111': np.float64(62.99), '112-115': np.float64(76.09), '116-119': np.float64(72.73), '120-123': np.float64(65.81), '124-127': np.float64(40.2), '128-131': np.float64(54.03), '132-135': np.float64(69.64), '136-139': np.float64(78.43), '140-143': np.float64(53.68), '144-147': np.float64(67.12), 'old': np.float64(55.46), 'new': np.float64(67.12)}
2025-12-11 19:13:19,005 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66)]
2025-12-11 19:13:19,005 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69)]
2025-12-11 19:13:19,005 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409]
2025-12-11 19:13:33,392 [trainer.py] => W-NCM: {'00-03': 61.935483870967744, '04-07': 64.13793103448275, '08-11': 64.91228070175438, '12-15': 84.54545454545455, '16-19': 72.22222222222221, '20-23': 73.51598173515981, '24-27': 64.63414634146342, '28-31': 60.20942408376963, '32-35': 76.0, '36-39': 73.26732673267327, '40-43': 69.76744186046511, '44-47': 62.96296296296296, '48-51': 78.62595419847328, '52-55': 72.1311475409836, '56-59': 73.68421052631578, '60-63': 74.82993197278913, '64-67': 77.55102040816327, '68-71': 69.0721649484536, '72-75': 51.69491525423729, '76-79': 65.45454545454545, '80-83': 61.05263157894737, '84-87': 74.43609022556392, '88-91': 85.0, '92-95': 67.5, '96-99': 64.16184971098265, '100-103': 68.64406779661016, '104-107': 66.9172932330827, '108-111': 80.31496062992126, '112-115': 80.43478260869566, '116-119': 86.36363636363636, '120-123': 80.34188034188034, '124-127': 59.80392156862745, '128-131': 66.12903225806451, '132-135': 79.46428571428571, '136-139': 84.31372549019608, '140-143': 86.31578947368422, '144-147': 90.41095890410958}
2025-12-11 19:13:33,392 [trainer.py] => Ave Acc (W-NCM): 72.24%
2025-12-11 19:13:33,392 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 61.94% (best 83.23%); T2: W-NCM 64.14% (best 93.79%); T3: W-NCM 64.91% (best 84.21%); T4: W-NCM 84.55% (best 92.73%); T5: W-NCM 72.22% (best 95.24%); T6: W-NCM 73.52% (best 92.24%); T7: W-NCM 64.63% (best 89.02%); T8: W-NCM 60.21% (best 91.62%); T9: W-NCM 76.00% (best 96.00%); T10: W-NCM 73.27% (best 92.08%); T11: W-NCM 69.77% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 78.63% (best 95.42%); T14: W-NCM 72.13% (best 85.25%); T15: W-NCM 73.68% (best 90.53%); T16: W-NCM 74.83% (best 91.84%); T17: W-NCM 77.55% (best 91.84%); T18: W-NCM 69.07% (best 87.63%); T19: W-NCM 51.69% (best 92.37%); T20: W-NCM 65.45% (best 84.85%); T21: W-NCM 61.05% (best 88.42%); T22: W-NCM 74.44% (best 88.72%); T23: W-NCM 85.00% (best 94.00%); T24: W-NCM 67.50% (best 90.00%); T25: W-NCM 64.16% (best 87.28%); T26: W-NCM 68.64% (best 88.14%); T27: W-NCM 66.92% (best 78.95%); T28: W-NCM 80.31% (best 93.70%); T29: W-NCM 80.43% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 80.34% (best 90.60%); T32: W-NCM 59.80% (best 79.41%); T33: W-NCM 66.13% (best 87.90%); T34: W-NCM 79.46% (best 88.39%); T35: W-NCM 84.31% (best 92.16%); T36: W-NCM 86.32% (best 91.58%); T37: W-NCM 90.41% (best 90.41%)
2025-12-11 19:13:33,392 [trainer.py] => Average forgetting (W-NCM): 17.49% | Max forgetting (W-NCM): 40.68%
2025-12-11 19:13:33,399 [trainer.py] => All params: 126094051
2025-12-11 19:13:33,405 [trainer.py] => Trainable params: 187396
2025-12-11 19:13:33,405 [inflora.py] => Learning on 148-152
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_v.37.weight', 'image_encoder.blocks.10.attn.lora_B_k.37.weight', 'image_encoder.blocks.8.attn.lora_B_k.37.weight', 'image_encoder.blocks.1.attn.lora_B_v.37.weight', 'image_encoder.blocks.9.attn.lora_B_k.37.weight', 'image_encoder.blocks.10.attn.lora_B_v.37.weight', 'image_encoder.blocks.7.attn.lora_B_k.37.weight', 'image_encoder.blocks.6.attn.lora_B_v.37.weight', 'image_encoder.blocks.3.attn.lora_B_k.37.weight', 'image_encoder.blocks.2.attn.lora_B_v.37.weight', 'image_encoder.blocks.2.attn.lora_B_k.37.weight', 'image_encoder.blocks.4.attn.lora_B_v.37.weight', 'image_encoder.blocks.4.attn.lora_B_k.37.weight', 'image_encoder.blocks.6.attn.lora_B_k.37.weight', 'image_encoder.blocks.9.attn.lora_B_v.37.weight', 'classifier_pool.37.bias', 'image_encoder.blocks.8.attn.lora_B_v.37.weight', 'image_encoder.blocks.3.attn.lora_B_v.37.weight', 'classifier_pool.37.weight', 'image_encoder.blocks.0.attn.lora_B_k.37.weight', 'image_encoder.blocks.7.attn.lora_B_v.37.weight', 'image_encoder.blocks.5.attn.lora_B_v.37.weight', 'image_encoder.blocks.0.attn.lora_B_v.37.weight', 'image_encoder.blocks.11.attn.lora_B_k.37.weight', 'image_encoder.blocks.1.attn.lora_B_k.37.weight', 'image_encoder.blocks.5.attn.lora_B_k.37.weight'}
2025-12-11 19:15:37,536 [inflora.py] => Task 37, Epoch 50/50 => Loss 0.147, Train_accy 90.11
Threshold:  0.9948
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 40/768 type remove
Layer 3 : 91/768 type remove
Layer 4 : 138/768 type remove
Layer 5 : 188/768 type remove
Layer 6 : 198/768 type remove
Layer 7 : 235/768 type remove
Layer 8 : 280/768 type remove
Layer 9 : 357/768 type retain
Layer 10 : 298/768 type retain
Layer 11 : 375/768 type retain
Layer 12 : 254/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:15:44,625 [trainer.py] => Time:131.21963000297546
4473 4473
4473 4473
2025-12-11 19:15:57,407 [trainer.py] => Time:12.781479835510254
2025-12-11 19:15:57,407 [inflora.py] => Exemplar size: 0
2025-12-11 19:15:57,407 [trainer.py] => CNN: {'total': np.float64(55.87), '00-03': np.float64(61.94), '04-07': np.float64(57.93), '08-11': np.float64(57.89), '12-15': np.float64(80.0), '16-19': np.float64(69.84), '20-23': np.float64(67.12), '24-27': np.float64(74.39), '28-31': np.float64(42.93), '32-35': np.float64(54.67), '36-39': np.float64(69.31), '40-43': np.float64(44.19), '44-47': np.float64(42.59), '48-51': np.float64(50.38), '52-55': np.float64(39.34), '56-59': np.float64(43.16), '60-63': np.float64(70.75), '64-67': np.float64(44.9), '68-71': np.float64(32.99), '72-75': np.float64(44.92), '76-79': np.float64(46.67), '80-83': np.float64(40.53), '84-87': np.float64(43.61), '88-91': np.float64(75.0), '92-95': np.float64(49.17), '96-99': np.float64(46.82), '100-103': np.float64(61.02), '104-107': np.float64(20.3), '108-111': np.float64(64.57), '112-115': np.float64(80.43), '116-119': np.float64(72.73), '120-123': np.float64(66.67), '124-127': np.float64(40.2), '128-131': np.float64(51.61), '132-135': np.float64(70.54), '136-139': np.float64(78.43), '140-143': np.float64(55.79), '144-147': np.float64(68.49), '148-151': np.float64(29.58), 'old': np.float64(56.29), 'new': np.float64(29.58)}
2025-12-11 19:15:57,408 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87)]
2025-12-11 19:15:57,408 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46)]
2025-12-11 19:15:57,408 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391]
2025-12-11 19:16:11,924 [trainer.py] => W-NCM: {'00-03': 60.0, '04-07': 61.37931034482759, '08-11': 64.91228070175438, '12-15': 80.9090909090909, '16-19': 71.42857142857143, '20-23': 71.23287671232876, '24-27': 62.19512195121951, '28-31': 56.54450261780105, '32-35': 73.33333333333333, '36-39': 71.28712871287128, '40-43': 68.6046511627907, '44-47': 68.51851851851852, '48-51': 79.38931297709924, '52-55': 72.1311475409836, '56-59': 73.68421052631578, '60-63': 72.78911564625851, '64-67': 75.51020408163265, '68-71': 71.1340206185567, '72-75': 52.54237288135594, '76-79': 63.63636363636363, '80-83': 58.94736842105262, '84-87': 73.68421052631578, '88-91': 81.0, '92-95': 64.16666666666667, '96-99': 60.69364161849711, '100-103': 66.10169491525424, '104-107': 66.16541353383458, '108-111': 77.95275590551181, '112-115': 81.52173913043478, '116-119': 87.5, '120-123': 80.34188034188034, '124-127': 61.76470588235294, '128-131': 65.32258064516128, '132-135': 73.21428571428571, '136-139': 81.37254901960785, '140-143': 82.10526315789474, '144-147': 87.67123287671232, '148-151': 85.91549295774648}
2025-12-11 19:16:11,925 [trainer.py] => Ave Acc (W-NCM): 71.23%
2025-12-11 19:16:11,925 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 60.00% (best 83.23%); T2: W-NCM 61.38% (best 93.79%); T3: W-NCM 64.91% (best 84.21%); T4: W-NCM 80.91% (best 92.73%); T5: W-NCM 71.43% (best 95.24%); T6: W-NCM 71.23% (best 92.24%); T7: W-NCM 62.20% (best 89.02%); T8: W-NCM 56.54% (best 91.62%); T9: W-NCM 73.33% (best 96.00%); T10: W-NCM 71.29% (best 92.08%); T11: W-NCM 68.60% (best 76.74%); T12: W-NCM 68.52% (best 75.93%); T13: W-NCM 79.39% (best 95.42%); T14: W-NCM 72.13% (best 85.25%); T15: W-NCM 73.68% (best 90.53%); T16: W-NCM 72.79% (best 91.84%); T17: W-NCM 75.51% (best 91.84%); T18: W-NCM 71.13% (best 87.63%); T19: W-NCM 52.54% (best 92.37%); T20: W-NCM 63.64% (best 84.85%); T21: W-NCM 58.95% (best 88.42%); T22: W-NCM 73.68% (best 88.72%); T23: W-NCM 81.00% (best 94.00%); T24: W-NCM 64.17% (best 90.00%); T25: W-NCM 60.69% (best 87.28%); T26: W-NCM 66.10% (best 88.14%); T27: W-NCM 66.17% (best 78.95%); T28: W-NCM 77.95% (best 93.70%); T29: W-NCM 81.52% (best 93.48%); T30: W-NCM 87.50% (best 96.59%); T31: W-NCM 80.34% (best 90.60%); T32: W-NCM 61.76% (best 79.41%); T33: W-NCM 65.32% (best 87.90%); T34: W-NCM 73.21% (best 88.39%); T35: W-NCM 81.37% (best 92.16%); T36: W-NCM 82.11% (best 91.58%); T37: W-NCM 87.67% (best 90.41%); T38: W-NCM 85.92% (best 85.92%)
2025-12-11 19:16:11,925 [trainer.py] => Average forgetting (W-NCM): 18.42% | Max forgetting (W-NCM): 39.83%
2025-12-11 19:16:11,931 [trainer.py] => All params: 126094051
2025-12-11 19:16:11,938 [trainer.py] => Trainable params: 187396
2025-12-11 19:16:11,938 [inflora.py] => Learning on 152-156
Parameters to be updated: {'classifier_pool.38.weight', 'image_encoder.blocks.10.attn.lora_B_k.38.weight', 'image_encoder.blocks.5.attn.lora_B_v.38.weight', 'image_encoder.blocks.1.attn.lora_B_k.38.weight', 'image_encoder.blocks.11.attn.lora_B_v.38.weight', 'image_encoder.blocks.7.attn.lora_B_k.38.weight', 'image_encoder.blocks.3.attn.lora_B_v.38.weight', 'image_encoder.blocks.1.attn.lora_B_v.38.weight', 'classifier_pool.38.bias', 'image_encoder.blocks.6.attn.lora_B_v.38.weight', 'image_encoder.blocks.6.attn.lora_B_k.38.weight', 'image_encoder.blocks.2.attn.lora_B_v.38.weight', 'image_encoder.blocks.2.attn.lora_B_k.38.weight', 'image_encoder.blocks.0.attn.lora_B_v.38.weight', 'image_encoder.blocks.8.attn.lora_B_v.38.weight', 'image_encoder.blocks.7.attn.lora_B_v.38.weight', 'image_encoder.blocks.4.attn.lora_B_v.38.weight', 'image_encoder.blocks.8.attn.lora_B_k.38.weight', 'image_encoder.blocks.9.attn.lora_B_k.38.weight', 'image_encoder.blocks.0.attn.lora_B_k.38.weight', 'image_encoder.blocks.5.attn.lora_B_k.38.weight', 'image_encoder.blocks.10.attn.lora_B_v.38.weight', 'image_encoder.blocks.9.attn.lora_B_v.38.weight', 'image_encoder.blocks.4.attn.lora_B_k.38.weight', 'image_encoder.blocks.3.attn.lora_B_k.38.weight', 'image_encoder.blocks.11.attn.lora_B_k.38.weight'}
2025-12-11 19:18:47,675 [inflora.py] => Task 38, Epoch 50/50 => Loss 0.097, Train_accy 96.54
Threshold:  0.9952
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 43/768 type remove
Layer 3 : 93/768 type remove
Layer 4 : 141/768 type remove
Layer 5 : 193/768 type remove
Layer 6 : 204/768 type remove
Layer 7 : 245/768 type remove
Layer 8 : 288/768 type remove
Layer 9 : 351/768 type retain
Layer 10 : 294/768 type retain
Layer 11 : 371/768 type retain
Layer 12 : 250/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:18:55,256 [trainer.py] => Time:163.3185760974884
4560 4560
4560 4560
2025-12-11 19:19:08,287 [trainer.py] => Time:13.030861854553223
2025-12-11 19:19:08,288 [inflora.py] => Exemplar size: 0
2025-12-11 19:19:08,288 [trainer.py] => CNN: {'total': np.float64(54.39), '00-03': np.float64(59.35), '04-07': np.float64(54.48), '08-11': np.float64(56.14), '12-15': np.float64(80.91), '16-19': np.float64(73.02), '20-23': np.float64(64.84), '24-27': np.float64(71.95), '28-31': np.float64(39.79), '32-35': np.float64(52.0), '36-39': np.float64(62.38), '40-43': np.float64(39.53), '44-47': np.float64(42.59), '48-51': np.float64(50.38), '52-55': np.float64(36.07), '56-59': np.float64(38.95), '60-63': np.float64(70.75), '64-67': np.float64(42.86), '68-71': np.float64(30.93), '72-75': np.float64(44.92), '76-79': np.float64(41.21), '80-83': np.float64(37.89), '84-87': np.float64(43.61), '88-91': np.float64(73.0), '92-95': np.float64(46.67), '96-99': np.float64(46.82), '100-103': np.float64(62.71), '104-107': np.float64(19.55), '108-111': np.float64(67.72), '112-115': np.float64(81.52), '116-119': np.float64(69.32), '120-123': np.float64(67.52), '124-127': np.float64(37.25), '128-131': np.float64(49.19), '132-135': np.float64(69.64), '136-139': np.float64(77.45), '140-143': np.float64(50.53), '144-147': np.float64(65.75), '148-151': np.float64(28.17), '152-155': np.float64(63.22), 'old': np.float64(54.21), 'new': np.float64(63.22)}
2025-12-11 19:19:08,288 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39)]
2025-12-11 19:19:08,288 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92)]
2025-12-11 19:19:08,288 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281]
2025-12-11 19:19:23,504 [trainer.py] => W-NCM: {'00-03': 59.354838709677416, '04-07': 60.0, '08-11': 59.64912280701754, '12-15': 79.0909090909091, '16-19': 71.42857142857143, '20-23': 69.40639269406392, '24-27': 59.14634146341463, '28-31': 53.403141361256544, '32-35': 73.33333333333333, '36-39': 69.3069306930693, '40-43': 69.76744186046511, '44-47': 62.96296296296296, '48-51': 75.57251908396947, '52-55': 70.49180327868852, '56-59': 69.47368421052632, '60-63': 68.02721088435374, '64-67': 75.51020408163265, '68-71': 64.94845360824742, '72-75': 45.76271186440678, '76-79': 62.42424242424243, '80-83': 53.1578947368421, '84-87': 72.93233082706767, '88-91': 77.0, '92-95': 59.166666666666664, '96-99': 58.95953757225434, '100-103': 63.559322033898304, '104-107': 65.41353383458647, '108-111': 77.16535433070865, '112-115': 82.6086956521739, '116-119': 86.36363636363636, '120-123': 77.77777777777779, '124-127': 60.78431372549019, '128-131': 58.06451612903226, '132-135': 69.64285714285714, '136-139': 79.41176470588235, '140-143': 74.73684210526315, '144-147': 84.93150684931507, '148-151': 74.64788732394366, '152-155': 87.35632183908046}
2025-12-11 19:19:23,505 [trainer.py] => Ave Acc (W-NCM): 68.79%
2025-12-11 19:19:23,505 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 59.35% (best 83.23%); T2: W-NCM 60.00% (best 93.79%); T3: W-NCM 59.65% (best 84.21%); T4: W-NCM 79.09% (best 92.73%); T5: W-NCM 71.43% (best 95.24%); T6: W-NCM 69.41% (best 92.24%); T7: W-NCM 59.15% (best 89.02%); T8: W-NCM 53.40% (best 91.62%); T9: W-NCM 73.33% (best 96.00%); T10: W-NCM 69.31% (best 92.08%); T11: W-NCM 69.77% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 75.57% (best 95.42%); T14: W-NCM 70.49% (best 85.25%); T15: W-NCM 69.47% (best 90.53%); T16: W-NCM 68.03% (best 91.84%); T17: W-NCM 75.51% (best 91.84%); T18: W-NCM 64.95% (best 87.63%); T19: W-NCM 45.76% (best 92.37%); T20: W-NCM 62.42% (best 84.85%); T21: W-NCM 53.16% (best 88.42%); T22: W-NCM 72.93% (best 88.72%); T23: W-NCM 77.00% (best 94.00%); T24: W-NCM 59.17% (best 90.00%); T25: W-NCM 58.96% (best 87.28%); T26: W-NCM 63.56% (best 88.14%); T27: W-NCM 65.41% (best 78.95%); T28: W-NCM 77.17% (best 93.70%); T29: W-NCM 82.61% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 77.78% (best 90.60%); T32: W-NCM 60.78% (best 79.41%); T33: W-NCM 58.06% (best 87.90%); T34: W-NCM 69.64% (best 88.39%); T35: W-NCM 79.41% (best 92.16%); T36: W-NCM 74.74% (best 91.58%); T37: W-NCM 84.93% (best 90.41%); T38: W-NCM 74.65% (best 85.92%); T39: W-NCM 87.36% (best 87.36%)
2025-12-11 19:19:23,505 [trainer.py] => Average forgetting (W-NCM): 20.86% | Max forgetting (W-NCM): 46.61%
2025-12-11 19:19:23,512 [trainer.py] => All params: 126094051
2025-12-11 19:19:23,518 [trainer.py] => Trainable params: 187396
2025-12-11 19:19:23,518 [inflora.py] => Learning on 156-160
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_v.39.weight', 'image_encoder.blocks.0.attn.lora_B_v.39.weight', 'image_encoder.blocks.5.attn.lora_B_v.39.weight', 'image_encoder.blocks.6.attn.lora_B_k.39.weight', 'image_encoder.blocks.2.attn.lora_B_k.39.weight', 'image_encoder.blocks.4.attn.lora_B_k.39.weight', 'classifier_pool.39.weight', 'image_encoder.blocks.1.attn.lora_B_k.39.weight', 'image_encoder.blocks.9.attn.lora_B_k.39.weight', 'image_encoder.blocks.10.attn.lora_B_v.39.weight', 'image_encoder.blocks.4.attn.lora_B_v.39.weight', 'image_encoder.blocks.1.attn.lora_B_v.39.weight', 'image_encoder.blocks.6.attn.lora_B_v.39.weight', 'image_encoder.blocks.3.attn.lora_B_v.39.weight', 'image_encoder.blocks.7.attn.lora_B_k.39.weight', 'image_encoder.blocks.3.attn.lora_B_k.39.weight', 'classifier_pool.39.bias', 'image_encoder.blocks.2.attn.lora_B_v.39.weight', 'image_encoder.blocks.7.attn.lora_B_v.39.weight', 'image_encoder.blocks.0.attn.lora_B_k.39.weight', 'image_encoder.blocks.9.attn.lora_B_v.39.weight', 'image_encoder.blocks.8.attn.lora_B_v.39.weight', 'image_encoder.blocks.10.attn.lora_B_k.39.weight', 'image_encoder.blocks.5.attn.lora_B_k.39.weight', 'image_encoder.blocks.11.attn.lora_B_k.39.weight', 'image_encoder.blocks.8.attn.lora_B_k.39.weight'}
2025-12-11 19:22:38,164 [inflora.py] => Task 39, Epoch 50/50 => Loss 0.429, Train_accy 93.98
Threshold:  0.9956
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 13/768 type remove
Layer 2 : 45/768 type remove
Layer 3 : 95/768 type remove
Layer 4 : 144/768 type remove
Layer 5 : 197/768 type remove
Layer 6 : 208/768 type remove
Layer 7 : 250/768 type remove
Layer 8 : 295/768 type remove
Layer 9 : 348/768 type retain
Layer 10 : 292/768 type retain
Layer 11 : 369/768 type retain
Layer 12 : 246/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:22:46,340 [trainer.py] => Time:202.8217749595642
4679 4679
4679 4679
2025-12-11 19:22:59,727 [trainer.py] => Time:13.387092590332031
2025-12-11 19:22:59,728 [inflora.py] => Exemplar size: 0
2025-12-11 19:22:59,728 [trainer.py] => CNN: {'total': np.float64(54.71), '00-03': np.float64(58.71), '04-07': np.float64(54.48), '08-11': np.float64(54.39), '12-15': np.float64(80.0), '16-19': np.float64(71.43), '20-23': np.float64(65.75), '24-27': np.float64(71.95), '28-31': np.float64(37.7), '32-35': np.float64(49.33), '36-39': np.float64(67.33), '40-43': np.float64(39.53), '44-47': np.float64(42.59), '48-51': np.float64(48.09), '52-55': np.float64(39.34), '56-59': np.float64(38.95), '60-63': np.float64(67.35), '64-67': np.float64(44.9), '68-71': np.float64(29.9), '72-75': np.float64(50.0), '76-79': np.float64(41.82), '80-83': np.float64(41.58), '84-87': np.float64(44.36), '88-91': np.float64(71.0), '92-95': np.float64(44.17), '96-99': np.float64(44.51), '100-103': np.float64(61.02), '104-107': np.float64(20.3), '108-111': np.float64(63.78), '112-115': np.float64(82.61), '116-119': np.float64(73.86), '120-123': np.float64(68.38), '124-127': np.float64(41.18), '128-131': np.float64(46.77), '132-135': np.float64(70.54), '136-139': np.float64(74.51), '140-143': np.float64(52.63), '144-147': np.float64(68.49), '148-151': np.float64(30.99), '152-155': np.float64(68.97), '156-159': np.float64(63.03), 'old': np.float64(54.5), 'new': np.float64(63.03)}
2025-12-11 19:22:59,728 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71)]
2025-12-11 19:22:59,728 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19)]
2025-12-11 19:22:59,728 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221]
2025-12-11 19:23:15,529 [trainer.py] => W-NCM: {'00-03': 67.0967741935484, '04-07': 62.06896551724138, '08-11': 61.40350877192983, '12-15': 80.9090909090909, '16-19': 73.01587301587301, '20-23': 73.97260273972603, '24-27': 65.2439024390244, '28-31': 59.16230366492147, '32-35': 72.0, '36-39': 71.28712871287128, '40-43': 68.6046511627907, '44-47': 66.66666666666666, '48-51': 77.09923664122137, '52-55': 70.49180327868852, '56-59': 75.78947368421053, '60-63': 68.70748299319727, '64-67': 71.42857142857143, '68-71': 62.88659793814433, '72-75': 45.76271186440678, '76-79': 63.63636363636363, '80-83': 58.94736842105262, '84-87': 75.93984962406014, '88-91': 85.0, '92-95': 65.0, '96-99': 62.42774566473989, '100-103': 65.2542372881356, '104-107': 62.40601503759399, '108-111': 79.52755905511812, '112-115': 79.34782608695652, '116-119': 87.5, '120-123': 79.48717948717949, '124-127': 63.725490196078425, '128-131': 58.87096774193549, '132-135': 68.75, '136-139': 78.43137254901961, '140-143': 77.89473684210526, '144-147': 84.93150684931507, '148-151': 74.64788732394366, '152-155': 86.20689655172413, '156-159': 88.23529411764706}
2025-12-11 19:23:15,530 [trainer.py] => Ave Acc (W-NCM): 70.99%
2025-12-11 19:23:15,530 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 67.10% (best 83.23%); T2: W-NCM 62.07% (best 93.79%); T3: W-NCM 61.40% (best 84.21%); T4: W-NCM 80.91% (best 92.73%); T5: W-NCM 73.02% (best 95.24%); T6: W-NCM 73.97% (best 92.24%); T7: W-NCM 65.24% (best 89.02%); T8: W-NCM 59.16% (best 91.62%); T9: W-NCM 72.00% (best 96.00%); T10: W-NCM 71.29% (best 92.08%); T11: W-NCM 68.60% (best 76.74%); T12: W-NCM 66.67% (best 75.93%); T13: W-NCM 77.10% (best 95.42%); T14: W-NCM 70.49% (best 85.25%); T15: W-NCM 75.79% (best 90.53%); T16: W-NCM 68.71% (best 91.84%); T17: W-NCM 71.43% (best 91.84%); T18: W-NCM 62.89% (best 87.63%); T19: W-NCM 45.76% (best 92.37%); T20: W-NCM 63.64% (best 84.85%); T21: W-NCM 58.95% (best 88.42%); T22: W-NCM 75.94% (best 88.72%); T23: W-NCM 85.00% (best 94.00%); T24: W-NCM 65.00% (best 90.00%); T25: W-NCM 62.43% (best 87.28%); T26: W-NCM 65.25% (best 88.14%); T27: W-NCM 62.41% (best 78.95%); T28: W-NCM 79.53% (best 93.70%); T29: W-NCM 79.35% (best 93.48%); T30: W-NCM 87.50% (best 96.59%); T31: W-NCM 79.49% (best 90.60%); T32: W-NCM 63.73% (best 79.41%); T33: W-NCM 58.87% (best 87.90%); T34: W-NCM 68.75% (best 88.39%); T35: W-NCM 78.43% (best 92.16%); T36: W-NCM 77.89% (best 91.58%); T37: W-NCM 84.93% (best 90.41%); T38: W-NCM 74.65% (best 85.92%); T39: W-NCM 86.21% (best 87.36%); T40: W-NCM 88.24% (best 88.24%)
2025-12-11 19:23:15,530 [trainer.py] => Average forgetting (W-NCM): 18.56% | Max forgetting (W-NCM): 46.61%
2025-12-11 19:23:15,536 [trainer.py] => All params: 126094051
2025-12-11 19:23:15,543 [trainer.py] => Trainable params: 187396
2025-12-11 19:23:15,543 [inflora.py] => Learning on 160-164
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_v.40.weight', 'image_encoder.blocks.8.attn.lora_B_k.40.weight', 'image_encoder.blocks.7.attn.lora_B_k.40.weight', 'image_encoder.blocks.9.attn.lora_B_v.40.weight', 'image_encoder.blocks.1.attn.lora_B_v.40.weight', 'image_encoder.blocks.6.attn.lora_B_v.40.weight', 'image_encoder.blocks.10.attn.lora_B_k.40.weight', 'image_encoder.blocks.11.attn.lora_B_k.40.weight', 'classifier_pool.40.weight', 'image_encoder.blocks.3.attn.lora_B_v.40.weight', 'image_encoder.blocks.4.attn.lora_B_k.40.weight', 'image_encoder.blocks.2.attn.lora_B_k.40.weight', 'image_encoder.blocks.0.attn.lora_B_v.40.weight', 'classifier_pool.40.bias', 'image_encoder.blocks.5.attn.lora_B_k.40.weight', 'image_encoder.blocks.3.attn.lora_B_k.40.weight', 'image_encoder.blocks.6.attn.lora_B_k.40.weight', 'image_encoder.blocks.10.attn.lora_B_v.40.weight', 'image_encoder.blocks.2.attn.lora_B_v.40.weight', 'image_encoder.blocks.4.attn.lora_B_v.40.weight', 'image_encoder.blocks.0.attn.lora_B_k.40.weight', 'image_encoder.blocks.5.attn.lora_B_v.40.weight', 'image_encoder.blocks.1.attn.lora_B_k.40.weight', 'image_encoder.blocks.9.attn.lora_B_k.40.weight', 'image_encoder.blocks.7.attn.lora_B_v.40.weight', 'image_encoder.blocks.8.attn.lora_B_v.40.weight'}
2025-12-11 19:26:12,076 [inflora.py] => Task 40, Epoch 50/50 => Loss 0.060, Train_accy 97.77
Threshold:  0.996
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 14/768 type remove
Layer 2 : 48/768 type remove
Layer 3 : 103/768 type remove
Layer 4 : 158/768 type remove
Layer 5 : 211/768 type remove
Layer 6 : 223/768 type remove
Layer 7 : 267/768 type remove
Layer 8 : 315/768 type remove
Layer 9 : 331/768 type retain
Layer 10 : 282/768 type retain
Layer 11 : 362/768 type retain
Layer 12 : 240/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:26:20,350 [trainer.py] => Time:184.80726838111877
4786 4786
4786 4786
2025-12-11 19:26:34,055 [trainer.py] => Time:13.704708337783813
2025-12-11 19:26:34,055 [inflora.py] => Exemplar size: 0
2025-12-11 19:26:34,056 [trainer.py] => CNN: {'total': np.float64(55.41), '00-03': np.float64(57.42), '04-07': np.float64(55.86), '08-11': np.float64(56.14), '12-15': np.float64(79.09), '16-19': np.float64(71.43), '20-23': np.float64(66.21), '24-27': np.float64(71.34), '28-31': np.float64(36.65), '32-35': np.float64(52.0), '36-39': np.float64(68.32), '40-43': np.float64(39.53), '44-47': np.float64(38.89), '48-51': np.float64(49.62), '52-55': np.float64(42.62), '56-59': np.float64(37.89), '60-63': np.float64(68.71), '64-67': np.float64(46.94), '68-71': np.float64(29.9), '72-75': np.float64(47.46), '76-79': np.float64(43.64), '80-83': np.float64(45.26), '84-87': np.float64(45.86), '88-91': np.float64(71.0), '92-95': np.float64(45.83), '96-99': np.float64(46.82), '100-103': np.float64(58.47), '104-107': np.float64(18.8), '108-111': np.float64(63.78), '112-115': np.float64(79.35), '116-119': np.float64(75.0), '120-123': np.float64(64.1), '124-127': np.float64(44.12), '128-131': np.float64(44.35), '132-135': np.float64(69.64), '136-139': np.float64(74.51), '140-143': np.float64(53.68), '144-147': np.float64(63.01), '148-151': np.float64(30.99), '152-155': np.float64(68.97), '156-159': np.float64(59.66), '160-163': np.float64(85.05), 'old': np.float64(54.73), 'new': np.float64(85.05)}
2025-12-11 19:26:34,056 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41)]
2025-12-11 19:26:34,056 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22)]
2025-12-11 19:26:34,056 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696]
2025-12-11 19:26:49,876 [trainer.py] => W-NCM: {'00-03': 60.64516129032258, '04-07': 61.37931034482759, '08-11': 61.40350877192983, '12-15': 80.9090909090909, '16-19': 69.84126984126983, '20-23': 71.68949771689498, '24-27': 65.85365853658537, '28-31': 58.1151832460733, '32-35': 76.0, '36-39': 69.3069306930693, '40-43': 68.6046511627907, '44-47': 59.25925925925925, '48-51': 77.86259541984732, '52-55': 72.1311475409836, '56-59': 74.73684210526315, '60-63': 72.78911564625851, '64-67': 75.51020408163265, '68-71': 63.91752577319587, '72-75': 41.52542372881356, '76-79': 65.45454545454545, '80-83': 58.94736842105262, '84-87': 75.18796992481202, '88-91': 81.0, '92-95': 64.16666666666667, '96-99': 58.95953757225434, '100-103': 64.40677966101694, '104-107': 62.40601503759399, '108-111': 76.37795275590551, '112-115': 82.6086956521739, '116-119': 89.77272727272727, '120-123': 76.92307692307693, '124-127': 57.84313725490197, '128-131': 54.83870967741935, '132-135': 70.53571428571429, '136-139': 74.50980392156863, '140-143': 77.89473684210526, '144-147': 82.1917808219178, '148-151': 73.23943661971832, '152-155': 78.16091954022988, '156-159': 84.03361344537815, '160-163': 94.39252336448598}
2025-12-11 19:26:49,877 [trainer.py] => Ave Acc (W-NCM): 70.37%
2025-12-11 19:26:49,877 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 60.65% (best 83.23%); T2: W-NCM 61.38% (best 93.79%); T3: W-NCM 61.40% (best 84.21%); T4: W-NCM 80.91% (best 92.73%); T5: W-NCM 69.84% (best 95.24%); T6: W-NCM 71.69% (best 92.24%); T7: W-NCM 65.85% (best 89.02%); T8: W-NCM 58.12% (best 91.62%); T9: W-NCM 76.00% (best 96.00%); T10: W-NCM 69.31% (best 92.08%); T11: W-NCM 68.60% (best 76.74%); T12: W-NCM 59.26% (best 75.93%); T13: W-NCM 77.86% (best 95.42%); T14: W-NCM 72.13% (best 85.25%); T15: W-NCM 74.74% (best 90.53%); T16: W-NCM 72.79% (best 91.84%); T17: W-NCM 75.51% (best 91.84%); T18: W-NCM 63.92% (best 87.63%); T19: W-NCM 41.53% (best 92.37%); T20: W-NCM 65.45% (best 84.85%); T21: W-NCM 58.95% (best 88.42%); T22: W-NCM 75.19% (best 88.72%); T23: W-NCM 81.00% (best 94.00%); T24: W-NCM 64.17% (best 90.00%); T25: W-NCM 58.96% (best 87.28%); T26: W-NCM 64.41% (best 88.14%); T27: W-NCM 62.41% (best 78.95%); T28: W-NCM 76.38% (best 93.70%); T29: W-NCM 82.61% (best 93.48%); T30: W-NCM 89.77% (best 96.59%); T31: W-NCM 76.92% (best 90.60%); T32: W-NCM 57.84% (best 79.41%); T33: W-NCM 54.84% (best 87.90%); T34: W-NCM 70.54% (best 88.39%); T35: W-NCM 74.51% (best 92.16%); T36: W-NCM 77.89% (best 91.58%); T37: W-NCM 82.19% (best 90.41%); T38: W-NCM 73.24% (best 85.92%); T39: W-NCM 78.16% (best 87.36%); T40: W-NCM 84.03% (best 88.24%); T41: W-NCM 94.39% (best 94.39%)
2025-12-11 19:26:49,877 [trainer.py] => Average forgetting (W-NCM): 19.32% | Max forgetting (W-NCM): 50.85%
2025-12-11 19:26:49,884 [trainer.py] => All params: 126094051
2025-12-11 19:26:49,890 [trainer.py] => Trainable params: 187396
2025-12-11 19:26:49,890 [inflora.py] => Learning on 164-168
Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_k.41.weight', 'classifier_pool.41.weight', 'image_encoder.blocks.11.attn.lora_B_k.41.weight', 'image_encoder.blocks.8.attn.lora_B_k.41.weight', 'image_encoder.blocks.2.attn.lora_B_v.41.weight', 'image_encoder.blocks.6.attn.lora_B_v.41.weight', 'image_encoder.blocks.8.attn.lora_B_v.41.weight', 'image_encoder.blocks.7.attn.lora_B_v.41.weight', 'image_encoder.blocks.3.attn.lora_B_k.41.weight', 'image_encoder.blocks.10.attn.lora_B_v.41.weight', 'image_encoder.blocks.0.attn.lora_B_k.41.weight', 'image_encoder.blocks.9.attn.lora_B_v.41.weight', 'image_encoder.blocks.0.attn.lora_B_v.41.weight', 'image_encoder.blocks.6.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_v.41.weight', 'image_encoder.blocks.3.attn.lora_B_v.41.weight', 'image_encoder.blocks.4.attn.lora_B_k.41.weight', 'image_encoder.blocks.7.attn.lora_B_k.41.weight', 'image_encoder.blocks.11.attn.lora_B_v.41.weight', 'image_encoder.blocks.1.attn.lora_B_k.41.weight', 'image_encoder.blocks.4.attn.lora_B_v.41.weight', 'image_encoder.blocks.9.attn.lora_B_k.41.weight', 'image_encoder.blocks.2.attn.lora_B_k.41.weight', 'image_encoder.blocks.1.attn.lora_B_v.41.weight', 'classifier_pool.41.bias'}
2025-12-11 19:30:11,806 [inflora.py] => Task 41, Epoch 50/50 => Loss 0.050, Train_accy 98.35
Threshold:  0.9964
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 16/768 type remove
Layer 2 : 53/768 type remove
Layer 3 : 111/768 type remove
Layer 4 : 166/768 type remove
Layer 5 : 226/768 type remove
Layer 6 : 238/768 type remove
Layer 7 : 282/768 type remove
Layer 8 : 333/768 type remove
Layer 9 : 307/768 type retain
Layer 10 : 259/768 type retain
Layer 11 : 340/768 type retain
Layer 12 : 235/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:30:20,712 [trainer.py] => Time:210.8221800327301
4933 4933
4933 4933
2025-12-11 19:30:34,783 [trainer.py] => Time:14.070109605789185
2025-12-11 19:30:34,783 [inflora.py] => Exemplar size: 0
2025-12-11 19:30:34,783 [trainer.py] => CNN: {'total': np.float64(55.85), '00-03': np.float64(61.94), '04-07': np.float64(54.48), '08-11': np.float64(57.02), '12-15': np.float64(76.36), '16-19': np.float64(69.84), '20-23': np.float64(66.21), '24-27': np.float64(71.95), '28-31': np.float64(37.17), '32-35': np.float64(49.33), '36-39': np.float64(63.37), '40-43': np.float64(45.35), '44-47': np.float64(42.59), '48-51': np.float64(52.67), '52-55': np.float64(36.07), '56-59': np.float64(36.84), '60-63': np.float64(68.03), '64-67': np.float64(44.9), '68-71': np.float64(34.02), '72-75': np.float64(45.76), '76-79': np.float64(40.61), '80-83': np.float64(46.32), '84-87': np.float64(42.11), '88-91': np.float64(73.0), '92-95': np.float64(45.83), '96-99': np.float64(41.04), '100-103': np.float64(59.32), '104-107': np.float64(18.8), '108-111': np.float64(66.14), '112-115': np.float64(76.09), '116-119': np.float64(79.55), '120-123': np.float64(66.67), '124-127': np.float64(39.22), '128-131': np.float64(44.35), '132-135': np.float64(73.21), '136-139': np.float64(73.53), '140-143': np.float64(55.79), '144-147': np.float64(63.01), '148-151': np.float64(25.35), '152-155': np.float64(70.11), '156-159': np.float64(61.34), '160-163': np.float64(81.31), '164-167': np.float64(77.55), 'old': np.float64(55.18), 'new': np.float64(77.55)}
2025-12-11 19:30:34,783 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41), np.float64(55.85)]
2025-12-11 19:30:34,783 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22), np.float64(91.49)]
2025-12-11 19:30:34,784 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696, 0.565984188120819]
2025-12-11 19:30:51,259 [trainer.py] => W-NCM: {'00-03': 57.41935483870968, '04-07': 56.55172413793104, '08-11': 55.26315789473685, '12-15': 76.36363636363637, '16-19': 67.46031746031747, '20-23': 66.66666666666666, '24-27': 58.536585365853654, '28-31': 53.403141361256544, '32-35': 72.0, '36-39': 68.31683168316832, '40-43': 65.11627906976744, '44-47': 59.25925925925925, '48-51': 77.09923664122137, '52-55': 67.21311475409836, '56-59': 67.36842105263158, '60-63': 63.26530612244898, '64-67': 73.46938775510205, '68-71': 60.824742268041234, '72-75': 42.3728813559322, '76-79': 60.0, '80-83': 52.10526315789473, '84-87': 69.92481203007519, '88-91': 77.0, '92-95': 59.166666666666664, '96-99': 52.601156069364166, '100-103': 59.32203389830508, '104-107': 54.88721804511278, '108-111': 74.01574803149606, '112-115': 81.52173913043478, '116-119': 86.36363636363636, '120-123': 77.77777777777779, '124-127': 53.92156862745098, '128-131': 53.2258064516129, '132-135': 70.53571428571429, '136-139': 75.49019607843137, '140-143': 72.63157894736842, '144-147': 80.82191780821918, '148-151': 73.23943661971832, '152-155': 75.86206896551724, '156-159': 78.15126050420169, '160-163': 88.78504672897196, '164-167': 91.15646258503402}
2025-12-11 19:30:51,260 [trainer.py] => Ave Acc (W-NCM): 67.30%
2025-12-11 19:30:51,261 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 57.42% (best 83.23%); T2: W-NCM 56.55% (best 93.79%); T3: W-NCM 55.26% (best 84.21%); T4: W-NCM 76.36% (best 92.73%); T5: W-NCM 67.46% (best 95.24%); T6: W-NCM 66.67% (best 92.24%); T7: W-NCM 58.54% (best 89.02%); T8: W-NCM 53.40% (best 91.62%); T9: W-NCM 72.00% (best 96.00%); T10: W-NCM 68.32% (best 92.08%); T11: W-NCM 65.12% (best 76.74%); T12: W-NCM 59.26% (best 75.93%); T13: W-NCM 77.10% (best 95.42%); T14: W-NCM 67.21% (best 85.25%); T15: W-NCM 67.37% (best 90.53%); T16: W-NCM 63.27% (best 91.84%); T17: W-NCM 73.47% (best 91.84%); T18: W-NCM 60.82% (best 87.63%); T19: W-NCM 42.37% (best 92.37%); T20: W-NCM 60.00% (best 84.85%); T21: W-NCM 52.11% (best 88.42%); T22: W-NCM 69.92% (best 88.72%); T23: W-NCM 77.00% (best 94.00%); T24: W-NCM 59.17% (best 90.00%); T25: W-NCM 52.60% (best 87.28%); T26: W-NCM 59.32% (best 88.14%); T27: W-NCM 54.89% (best 78.95%); T28: W-NCM 74.02% (best 93.70%); T29: W-NCM 81.52% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 77.78% (best 90.60%); T32: W-NCM 53.92% (best 79.41%); T33: W-NCM 53.23% (best 87.90%); T34: W-NCM 70.54% (best 88.39%); T35: W-NCM 75.49% (best 92.16%); T36: W-NCM 72.63% (best 91.58%); T37: W-NCM 80.82% (best 90.41%); T38: W-NCM 73.24% (best 85.92%); T39: W-NCM 75.86% (best 87.36%); T40: W-NCM 78.15% (best 88.24%); T41: W-NCM 88.79% (best 94.39%); T42: W-NCM 91.16% (best 91.16%)
2025-12-11 19:30:51,261 [trainer.py] => Average forgetting (W-NCM): 22.51% | Max forgetting (W-NCM): 50.00%
2025-12-11 19:30:51,267 [trainer.py] => All params: 126094051
2025-12-11 19:30:51,273 [trainer.py] => Trainable params: 187396
2025-12-11 19:30:51,273 [inflora.py] => Learning on 168-172
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_v.42.weight', 'image_encoder.blocks.3.attn.lora_B_v.42.weight', 'image_encoder.blocks.6.attn.lora_B_v.42.weight', 'image_encoder.blocks.9.attn.lora_B_v.42.weight', 'image_encoder.blocks.5.attn.lora_B_v.42.weight', 'image_encoder.blocks.8.attn.lora_B_v.42.weight', 'image_encoder.blocks.1.attn.lora_B_k.42.weight', 'image_encoder.blocks.8.attn.lora_B_k.42.weight', 'image_encoder.blocks.11.attn.lora_B_k.42.weight', 'image_encoder.blocks.4.attn.lora_B_v.42.weight', 'image_encoder.blocks.2.attn.lora_B_v.42.weight', 'image_encoder.blocks.0.attn.lora_B_k.42.weight', 'image_encoder.blocks.10.attn.lora_B_k.42.weight', 'image_encoder.blocks.6.attn.lora_B_k.42.weight', 'classifier_pool.42.weight', 'image_encoder.blocks.7.attn.lora_B_k.42.weight', 'classifier_pool.42.bias', 'image_encoder.blocks.10.attn.lora_B_v.42.weight', 'image_encoder.blocks.5.attn.lora_B_k.42.weight', 'image_encoder.blocks.2.attn.lora_B_k.42.weight', 'image_encoder.blocks.3.attn.lora_B_k.42.weight', 'image_encoder.blocks.4.attn.lora_B_k.42.weight', 'image_encoder.blocks.9.attn.lora_B_k.42.weight', 'image_encoder.blocks.11.attn.lora_B_v.42.weight', 'image_encoder.blocks.7.attn.lora_B_v.42.weight', 'image_encoder.blocks.0.attn.lora_B_v.42.weight'}
2025-12-11 19:34:23,032 [inflora.py] => Task 42, Epoch 50/50 => Loss 0.085, Train_accy 97.56
Threshold:  0.9968
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 16/768 type remove
Layer 2 : 54/768 type remove
Layer 3 : 114/768 type remove
Layer 4 : 177/768 type remove
Layer 5 : 242/768 type remove
Layer 6 : 255/768 type remove
Layer 7 : 300/768 type remove
Layer 8 : 350/768 type remove
Layer 9 : 293/768 type retain
Layer 10 : 244/768 type retain
Layer 11 : 324/768 type retain
Layer 12 : 226/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:34:32,317 [trainer.py] => Time:221.0434591770172
5072 5072
5072 5072
2025-12-11 19:34:46,796 [trainer.py] => Time:14.47898530960083
2025-12-11 19:34:46,797 [inflora.py] => Exemplar size: 0
2025-12-11 19:34:46,797 [trainer.py] => CNN: {'total': np.float64(57.31), '00-03': np.float64(60.65), '04-07': np.float64(56.55), '08-11': np.float64(57.89), '12-15': np.float64(78.18), '16-19': np.float64(71.43), '20-23': np.float64(70.32), '24-27': np.float64(71.95), '28-31': np.float64(41.36), '32-35': np.float64(54.67), '36-39': np.float64(66.34), '40-43': np.float64(41.86), '44-47': np.float64(40.74), '48-51': np.float64(54.2), '52-55': np.float64(32.79), '56-59': np.float64(42.11), '60-63': np.float64(69.39), '64-67': np.float64(51.02), '68-71': np.float64(31.96), '72-75': np.float64(45.76), '76-79': np.float64(43.64), '80-83': np.float64(46.32), '84-87': np.float64(42.11), '88-91': np.float64(76.0), '92-95': np.float64(45.0), '96-99': np.float64(48.55), '100-103': np.float64(58.47), '104-107': np.float64(18.05), '108-111': np.float64(64.57), '112-115': np.float64(77.17), '116-119': np.float64(76.14), '120-123': np.float64(66.67), '124-127': np.float64(42.16), '128-131': np.float64(45.97), '132-135': np.float64(73.21), '136-139': np.float64(75.49), '140-143': np.float64(56.84), '144-147': np.float64(67.12), '148-151': np.float64(25.35), '152-155': np.float64(67.82), '156-159': np.float64(60.5), '160-163': np.float64(82.24), '164-167': np.float64(78.23), '168-171': np.float64(67.63), 'old': np.float64(57.02), 'new': np.float64(67.63)}
2025-12-11 19:34:46,797 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41), np.float64(55.85), np.float64(57.31)]
2025-12-11 19:34:46,797 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22), np.float64(91.49), np.float64(91.5)]
2025-12-11 19:34:46,797 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696, 0.565984188120819, 0.581230283911672]
2025-12-11 19:35:04,019 [trainer.py] => W-NCM: {'00-03': 59.354838709677416, '04-07': 61.37931034482759, '08-11': 60.526315789473685, '12-15': 81.81818181818183, '16-19': 68.25396825396825, '20-23': 70.77625570776256, '24-27': 64.63414634146342, '28-31': 58.1151832460733, '32-35': 74.66666666666667, '36-39': 72.27722772277228, '40-43': 65.11627906976744, '44-47': 59.25925925925925, '48-51': 77.09923664122137, '52-55': 67.21311475409836, '56-59': 70.52631578947368, '60-63': 68.02721088435374, '64-67': 73.46938775510205, '68-71': 63.91752577319587, '72-75': 44.91525423728814, '76-79': 62.42424242424243, '80-83': 57.89473684210527, '84-87': 73.68421052631578, '88-91': 81.0, '92-95': 62.5, '96-99': 58.95953757225434, '100-103': 61.86440677966102, '104-107': 60.902255639097746, '108-111': 76.37795275590551, '112-115': 83.69565217391305, '116-119': 86.36363636363636, '120-123': 80.34188034188034, '124-127': 55.88235294117647, '128-131': 57.25806451612904, '132-135': 74.10714285714286, '136-139': 78.43137254901961, '140-143': 74.73684210526315, '144-147': 79.45205479452055, '148-151': 64.7887323943662, '152-155': 73.5632183908046, '156-159': 80.67226890756302, '160-163': 89.7196261682243, '164-167': 89.79591836734694, '168-171': 90.64748201438849}
2025-12-11 19:35:04,019 [trainer.py] => Ave Acc (W-NCM): 70.15%
2025-12-11 19:35:04,019 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 59.35% (best 83.23%); T2: W-NCM 61.38% (best 93.79%); T3: W-NCM 60.53% (best 84.21%); T4: W-NCM 81.82% (best 92.73%); T5: W-NCM 68.25% (best 95.24%); T6: W-NCM 70.78% (best 92.24%); T7: W-NCM 64.63% (best 89.02%); T8: W-NCM 58.12% (best 91.62%); T9: W-NCM 74.67% (best 96.00%); T10: W-NCM 72.28% (best 92.08%); T11: W-NCM 65.12% (best 76.74%); T12: W-NCM 59.26% (best 75.93%); T13: W-NCM 77.10% (best 95.42%); T14: W-NCM 67.21% (best 85.25%); T15: W-NCM 70.53% (best 90.53%); T16: W-NCM 68.03% (best 91.84%); T17: W-NCM 73.47% (best 91.84%); T18: W-NCM 63.92% (best 87.63%); T19: W-NCM 44.92% (best 92.37%); T20: W-NCM 62.42% (best 84.85%); T21: W-NCM 57.89% (best 88.42%); T22: W-NCM 73.68% (best 88.72%); T23: W-NCM 81.00% (best 94.00%); T24: W-NCM 62.50% (best 90.00%); T25: W-NCM 58.96% (best 87.28%); T26: W-NCM 61.86% (best 88.14%); T27: W-NCM 60.90% (best 78.95%); T28: W-NCM 76.38% (best 93.70%); T29: W-NCM 83.70% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 80.34% (best 90.60%); T32: W-NCM 55.88% (best 79.41%); T33: W-NCM 57.26% (best 87.90%); T34: W-NCM 74.11% (best 88.39%); T35: W-NCM 78.43% (best 92.16%); T36: W-NCM 74.74% (best 91.58%); T37: W-NCM 79.45% (best 90.41%); T38: W-NCM 64.79% (best 85.92%); T39: W-NCM 73.56% (best 87.36%); T40: W-NCM 80.67% (best 88.24%); T41: W-NCM 89.72% (best 94.39%); T42: W-NCM 89.80% (best 91.16%); T43: W-NCM 90.65% (best 90.65%)
2025-12-11 19:35:04,019 [trainer.py] => Average forgetting (W-NCM): 19.61% | Max forgetting (W-NCM): 47.46%
2025-12-11 19:35:04,026 [trainer.py] => All params: 126094051
2025-12-11 19:35:04,032 [trainer.py] => Trainable params: 187396
2025-12-11 19:35:04,032 [inflora.py] => Learning on 172-176
Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_k.43.weight', 'image_encoder.blocks.5.attn.lora_B_v.43.weight', 'classifier_pool.43.bias', 'image_encoder.blocks.6.attn.lora_B_v.43.weight', 'classifier_pool.43.weight', 'image_encoder.blocks.11.attn.lora_B_k.43.weight', 'image_encoder.blocks.8.attn.lora_B_k.43.weight', 'image_encoder.blocks.6.attn.lora_B_k.43.weight', 'image_encoder.blocks.7.attn.lora_B_v.43.weight', 'image_encoder.blocks.10.attn.lora_B_k.43.weight', 'image_encoder.blocks.5.attn.lora_B_k.43.weight', 'image_encoder.blocks.1.attn.lora_B_v.43.weight', 'image_encoder.blocks.2.attn.lora_B_v.43.weight', 'image_encoder.blocks.9.attn.lora_B_v.43.weight', 'image_encoder.blocks.9.attn.lora_B_k.43.weight', 'image_encoder.blocks.2.attn.lora_B_k.43.weight', 'image_encoder.blocks.7.attn.lora_B_k.43.weight', 'image_encoder.blocks.0.attn.lora_B_k.43.weight', 'image_encoder.blocks.0.attn.lora_B_v.43.weight', 'image_encoder.blocks.8.attn.lora_B_v.43.weight', 'image_encoder.blocks.4.attn.lora_B_k.43.weight', 'image_encoder.blocks.11.attn.lora_B_v.43.weight', 'image_encoder.blocks.1.attn.lora_B_k.43.weight', 'image_encoder.blocks.10.attn.lora_B_v.43.weight', 'image_encoder.blocks.4.attn.lora_B_v.43.weight', 'image_encoder.blocks.3.attn.lora_B_v.43.weight'}
2025-12-11 19:38:04,362 [inflora.py] => Task 43, Epoch 50/50 => Loss 0.078, Train_accy 96.75
Threshold:  0.9972
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 16/768 type remove
Layer 2 : 55/768 type remove
Layer 3 : 115/768 type remove
Layer 4 : 180/768 type remove
Layer 5 : 247/768 type remove
Layer 6 : 261/768 type remove
Layer 7 : 306/768 type remove
Layer 8 : 364/768 type remove
Layer 9 : 286/768 type retain
Layer 10 : 237/768 type retain
Layer 11 : 318/768 type retain
Layer 12 : 219/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:38:13,092 [trainer.py] => Time:189.06001234054565
5201 5201
5201 5201
2025-12-11 19:38:27,881 [trainer.py] => Time:14.787999629974365
2025-12-11 19:38:27,881 [inflora.py] => Exemplar size: 0
2025-12-11 19:38:27,881 [trainer.py] => CNN: {'total': np.float64(57.95), '00-03': np.float64(65.81), '04-07': np.float64(57.24), '08-11': np.float64(55.26), '12-15': np.float64(80.0), '16-19': np.float64(71.43), '20-23': np.float64(69.41), '24-27': np.float64(73.78), '28-31': np.float64(41.36), '32-35': np.float64(56.0), '36-39': np.float64(66.34), '40-43': np.float64(43.02), '44-47': np.float64(42.59), '48-51': np.float64(49.62), '52-55': np.float64(39.34), '56-59': np.float64(41.05), '60-63': np.float64(68.71), '64-67': np.float64(46.94), '68-71': np.float64(35.05), '72-75': np.float64(46.61), '76-79': np.float64(42.42), '80-83': np.float64(49.47), '84-87': np.float64(42.86), '88-91': np.float64(74.0), '92-95': np.float64(49.17), '96-99': np.float64(49.13), '100-103': np.float64(56.78), '104-107': np.float64(18.05), '108-111': np.float64(62.2), '112-115': np.float64(76.09), '116-119': np.float64(77.27), '120-123': np.float64(64.96), '124-127': np.float64(38.24), '128-131': np.float64(47.58), '132-135': np.float64(71.43), '136-139': np.float64(75.49), '140-143': np.float64(57.89), '144-147': np.float64(64.38), '148-151': np.float64(25.35), '152-155': np.float64(68.97), '156-159': np.float64(60.5), '160-163': np.float64(80.37), '164-167': np.float64(78.91), '168-171': np.float64(67.63), '172-175': np.float64(77.52), 'old': np.float64(57.45), 'new': np.float64(77.52)}
2025-12-11 19:38:27,882 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41), np.float64(55.85), np.float64(57.31), np.float64(57.95)]
2025-12-11 19:38:27,882 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22), np.float64(91.49), np.float64(91.5), np.float64(91.91)]
2025-12-11 19:38:27,882 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696, 0.565984188120819, 0.581230283911672, 0.587194770236493]
2025-12-11 19:38:44,826 [trainer.py] => W-NCM: {'00-03': 61.935483870967744, '04-07': 60.689655172413794, '08-11': 62.28070175438597, '12-15': 80.9090909090909, '16-19': 69.04761904761905, '20-23': 69.86301369863014, '24-27': 64.63414634146342, '28-31': 61.25654450261781, '32-35': 74.66666666666667, '36-39': 70.29702970297029, '40-43': 70.93023255813954, '44-47': 62.96296296296296, '48-51': 78.62595419847328, '52-55': 72.1311475409836, '56-59': 74.73684210526315, '60-63': 72.10884353741497, '64-67': 75.51020408163265, '68-71': 63.91752577319587, '72-75': 49.152542372881356, '76-79': 64.24242424242425, '80-83': 62.10526315789474, '84-87': 75.93984962406014, '88-91': 82.0, '92-95': 62.5, '96-99': 60.69364161849711, '100-103': 61.86440677966102, '104-107': 63.1578947368421, '108-111': 77.95275590551181, '112-115': 83.69565217391305, '116-119': 86.36363636363636, '120-123': 81.19658119658119, '124-127': 55.88235294117647, '128-131': 53.2258064516129, '132-135': 69.64285714285714, '136-139': 77.45098039215686, '140-143': 73.68421052631578, '144-147': 82.1917808219178, '148-151': 63.38028169014085, '152-155': 72.41379310344827, '156-159': 78.99159663865547, '160-163': 88.78504672897196, '164-167': 87.75510204081633, '168-171': 88.48920863309353, '172-175': 97.67441860465115}
2025-12-11 19:38:44,826 [trainer.py] => Ave Acc (W-NCM): 71.52%
2025-12-11 19:38:44,827 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 61.94% (best 83.23%); T2: W-NCM 60.69% (best 93.79%); T3: W-NCM 62.28% (best 84.21%); T4: W-NCM 80.91% (best 92.73%); T5: W-NCM 69.05% (best 95.24%); T6: W-NCM 69.86% (best 92.24%); T7: W-NCM 64.63% (best 89.02%); T8: W-NCM 61.26% (best 91.62%); T9: W-NCM 74.67% (best 96.00%); T10: W-NCM 70.30% (best 92.08%); T11: W-NCM 70.93% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 78.63% (best 95.42%); T14: W-NCM 72.13% (best 85.25%); T15: W-NCM 74.74% (best 90.53%); T16: W-NCM 72.11% (best 91.84%); T17: W-NCM 75.51% (best 91.84%); T18: W-NCM 63.92% (best 87.63%); T19: W-NCM 49.15% (best 92.37%); T20: W-NCM 64.24% (best 84.85%); T21: W-NCM 62.11% (best 88.42%); T22: W-NCM 75.94% (best 88.72%); T23: W-NCM 82.00% (best 94.00%); T24: W-NCM 62.50% (best 90.00%); T25: W-NCM 60.69% (best 87.28%); T26: W-NCM 61.86% (best 88.14%); T27: W-NCM 63.16% (best 78.95%); T28: W-NCM 77.95% (best 93.70%); T29: W-NCM 83.70% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 81.20% (best 90.60%); T32: W-NCM 55.88% (best 79.41%); T33: W-NCM 53.23% (best 87.90%); T34: W-NCM 69.64% (best 88.39%); T35: W-NCM 77.45% (best 92.16%); T36: W-NCM 73.68% (best 91.58%); T37: W-NCM 82.19% (best 90.41%); T38: W-NCM 63.38% (best 85.92%); T39: W-NCM 72.41% (best 87.36%); T40: W-NCM 78.99% (best 88.24%); T41: W-NCM 88.79% (best 94.39%); T42: W-NCM 87.76% (best 91.16%); T43: W-NCM 88.49% (best 90.65%); T44: W-NCM 97.67% (best 97.67%)
2025-12-11 19:38:44,827 [trainer.py] => Average forgetting (W-NCM): 18.39% | Max forgetting (W-NCM): 43.22%
2025-12-11 19:38:44,833 [trainer.py] => All params: 126094051
2025-12-11 19:38:44,839 [trainer.py] => Trainable params: 187396
2025-12-11 19:38:44,840 [inflora.py] => Learning on 176-180
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.44.weight', 'image_encoder.blocks.11.attn.lora_B_v.44.weight', 'image_encoder.blocks.2.attn.lora_B_v.44.weight', 'image_encoder.blocks.8.attn.lora_B_k.44.weight', 'image_encoder.blocks.0.attn.lora_B_v.44.weight', 'image_encoder.blocks.4.attn.lora_B_k.44.weight', 'image_encoder.blocks.6.attn.lora_B_v.44.weight', 'image_encoder.blocks.9.attn.lora_B_k.44.weight', 'image_encoder.blocks.10.attn.lora_B_v.44.weight', 'image_encoder.blocks.5.attn.lora_B_v.44.weight', 'image_encoder.blocks.3.attn.lora_B_k.44.weight', 'classifier_pool.44.bias', 'image_encoder.blocks.5.attn.lora_B_k.44.weight', 'image_encoder.blocks.6.attn.lora_B_k.44.weight', 'image_encoder.blocks.1.attn.lora_B_k.44.weight', 'image_encoder.blocks.3.attn.lora_B_v.44.weight', 'image_encoder.blocks.10.attn.lora_B_k.44.weight', 'classifier_pool.44.weight', 'image_encoder.blocks.2.attn.lora_B_k.44.weight', 'image_encoder.blocks.7.attn.lora_B_v.44.weight', 'image_encoder.blocks.7.attn.lora_B_k.44.weight', 'image_encoder.blocks.9.attn.lora_B_v.44.weight', 'image_encoder.blocks.4.attn.lora_B_v.44.weight', 'image_encoder.blocks.11.attn.lora_B_k.44.weight', 'image_encoder.blocks.8.attn.lora_B_v.44.weight', 'image_encoder.blocks.1.attn.lora_B_v.44.weight'}
2025-12-11 19:41:42,815 [inflora.py] => Task 44, Epoch 50/50 => Loss 0.136, Train_accy 96.27
Threshold:  0.9976
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 17/768 type remove
Layer 2 : 57/768 type remove
Layer 3 : 124/768 type remove
Layer 4 : 195/768 type remove
Layer 5 : 265/768 type remove
Layer 6 : 280/768 type remove
Layer 7 : 330/768 type remove
Layer 8 : 374/768 type retain
Layer 9 : 260/768 type retain
Layer 10 : 216/768 type retain
Layer 11 : 287/768 type retain
Layer 12 : 184/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:41:51,398 [trainer.py] => Time:186.5581817626953
5306 5306
5306 5306
2025-12-11 19:42:06,502 [trainer.py] => Time:15.10434603691101
2025-12-11 19:42:06,503 [inflora.py] => Exemplar size: 0
2025-12-11 19:42:06,503 [trainer.py] => CNN: {'total': np.float64(57.58), '00-03': np.float64(64.52), '04-07': np.float64(56.55), '08-11': np.float64(55.26), '12-15': np.float64(78.18), '16-19': np.float64(70.63), '20-23': np.float64(67.58), '24-27': np.float64(73.78), '28-31': np.float64(41.36), '32-35': np.float64(54.67), '36-39': np.float64(67.33), '40-43': np.float64(46.51), '44-47': np.float64(42.59), '48-51': np.float64(49.62), '52-55': np.float64(34.43), '56-59': np.float64(46.32), '60-63': np.float64(69.39), '64-67': np.float64(40.82), '68-71': np.float64(30.93), '72-75': np.float64(48.31), '76-79': np.float64(40.61), '80-83': np.float64(45.79), '84-87': np.float64(42.86), '88-91': np.float64(73.0), '92-95': np.float64(46.67), '96-99': np.float64(48.55), '100-103': np.float64(56.78), '104-107': np.float64(17.29), '108-111': np.float64(62.2), '112-115': np.float64(76.09), '116-119': np.float64(77.27), '120-123': np.float64(64.96), '124-127': np.float64(40.2), '128-131': np.float64(48.39), '132-135': np.float64(68.75), '136-139': np.float64(74.51), '140-143': np.float64(56.84), '144-147': np.float64(64.38), '148-151': np.float64(21.13), '152-155': np.float64(71.26), '156-159': np.float64(63.03), '160-163': np.float64(77.57), '164-167': np.float64(78.91), '168-171': np.float64(67.63), '172-175': np.float64(76.74), '176-179': np.float64(66.67), 'old': np.float64(57.39), 'new': np.float64(66.67)}
2025-12-11 19:42:06,503 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41), np.float64(55.85), np.float64(57.31), np.float64(57.95), np.float64(57.58)]
2025-12-11 19:42:06,503 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22), np.float64(91.49), np.float64(91.5), np.float64(91.91), np.float64(91.8)]
2025-12-11 19:42:06,503 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696, 0.565984188120819, 0.581230283911672, 0.587194770236493, 0.582548058801357]
2025-12-11 19:42:23,683 [trainer.py] => W-NCM: {'00-03': 63.2258064516129, '04-07': 63.44827586206897, '08-11': 62.28070175438597, '12-15': 80.9090909090909, '16-19': 71.42857142857143, '20-23': 72.6027397260274, '24-27': 62.80487804878049, '28-31': 60.73298429319372, '32-35': 74.66666666666667, '36-39': 70.29702970297029, '40-43': 69.76744186046511, '44-47': 66.66666666666666, '48-51': 77.09923664122137, '52-55': 68.85245901639344, '56-59': 73.68421052631578, '60-63': 70.06802721088435, '64-67': 73.46938775510205, '68-71': 63.91752577319587, '72-75': 51.69491525423729, '76-79': 63.63636363636363, '80-83': 62.63157894736842, '84-87': 75.18796992481202, '88-91': 82.0, '92-95': 62.5, '96-99': 60.69364161849711, '100-103': 62.71186440677966, '104-107': 61.65413533834586, '108-111': 76.37795275590551, '112-115': 85.86956521739131, '116-119': 87.5, '120-123': 81.19658119658119, '124-127': 55.88235294117647, '128-131': 54.03225806451613, '132-135': 71.42857142857143, '136-139': 77.45098039215686, '140-143': 73.68421052631578, '144-147': 82.1917808219178, '148-151': 61.97183098591549, '152-155': 72.41379310344827, '156-159': 76.47058823529412, '160-163': 86.91588785046729, '164-167': 87.07482993197279, '168-171': 88.48920863309353, '172-175': 96.89922480620154, '176-179': 90.47619047619048}
2025-12-11 19:42:23,684 [trainer.py] => Ave Acc (W-NCM): 71.89%
2025-12-11 19:42:23,684 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 63.23% (best 83.23%); T2: W-NCM 63.45% (best 93.79%); T3: W-NCM 62.28% (best 84.21%); T4: W-NCM 80.91% (best 92.73%); T5: W-NCM 71.43% (best 95.24%); T6: W-NCM 72.60% (best 92.24%); T7: W-NCM 62.80% (best 89.02%); T8: W-NCM 60.73% (best 91.62%); T9: W-NCM 74.67% (best 96.00%); T10: W-NCM 70.30% (best 92.08%); T11: W-NCM 69.77% (best 76.74%); T12: W-NCM 66.67% (best 75.93%); T13: W-NCM 77.10% (best 95.42%); T14: W-NCM 68.85% (best 85.25%); T15: W-NCM 73.68% (best 90.53%); T16: W-NCM 70.07% (best 91.84%); T17: W-NCM 73.47% (best 91.84%); T18: W-NCM 63.92% (best 87.63%); T19: W-NCM 51.69% (best 92.37%); T20: W-NCM 63.64% (best 84.85%); T21: W-NCM 62.63% (best 88.42%); T22: W-NCM 75.19% (best 88.72%); T23: W-NCM 82.00% (best 94.00%); T24: W-NCM 62.50% (best 90.00%); T25: W-NCM 60.69% (best 87.28%); T26: W-NCM 62.71% (best 88.14%); T27: W-NCM 61.65% (best 78.95%); T28: W-NCM 76.38% (best 93.70%); T29: W-NCM 85.87% (best 93.48%); T30: W-NCM 87.50% (best 96.59%); T31: W-NCM 81.20% (best 90.60%); T32: W-NCM 55.88% (best 79.41%); T33: W-NCM 54.03% (best 87.90%); T34: W-NCM 71.43% (best 88.39%); T35: W-NCM 77.45% (best 92.16%); T36: W-NCM 73.68% (best 91.58%); T37: W-NCM 82.19% (best 90.41%); T38: W-NCM 61.97% (best 85.92%); T39: W-NCM 72.41% (best 87.36%); T40: W-NCM 76.47% (best 88.24%); T41: W-NCM 86.92% (best 94.39%); T42: W-NCM 87.07% (best 91.16%); T43: W-NCM 88.49% (best 90.65%); T44: W-NCM 96.90% (best 97.67%); T45: W-NCM 90.48% (best 90.48%)
2025-12-11 19:42:23,684 [trainer.py] => Average forgetting (W-NCM): 18.03% | Max forgetting (W-NCM): 40.68%
2025-12-11 19:42:23,691 [trainer.py] => All params: 126094051
2025-12-11 19:42:23,697 [trainer.py] => Trainable params: 187396
2025-12-11 19:42:23,697 [inflora.py] => Learning on 180-184
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_k.45.weight', 'image_encoder.blocks.0.attn.lora_B_k.45.weight', 'classifier_pool.45.bias', 'image_encoder.blocks.4.attn.lora_B_k.45.weight', 'image_encoder.blocks.7.attn.lora_B_v.45.weight', 'image_encoder.blocks.3.attn.lora_B_v.45.weight', 'image_encoder.blocks.0.attn.lora_B_v.45.weight', 'image_encoder.blocks.5.attn.lora_B_k.45.weight', 'image_encoder.blocks.8.attn.lora_B_k.45.weight', 'image_encoder.blocks.9.attn.lora_B_v.45.weight', 'image_encoder.blocks.8.attn.lora_B_v.45.weight', 'image_encoder.blocks.11.attn.lora_B_v.45.weight', 'image_encoder.blocks.7.attn.lora_B_k.45.weight', 'image_encoder.blocks.4.attn.lora_B_v.45.weight', 'image_encoder.blocks.2.attn.lora_B_v.45.weight', 'image_encoder.blocks.1.attn.lora_B_k.45.weight', 'image_encoder.blocks.6.attn.lora_B_k.45.weight', 'image_encoder.blocks.1.attn.lora_B_v.45.weight', 'image_encoder.blocks.10.attn.lora_B_v.45.weight', 'image_encoder.blocks.3.attn.lora_B_k.45.weight', 'image_encoder.blocks.5.attn.lora_B_v.45.weight', 'image_encoder.blocks.10.attn.lora_B_k.45.weight', 'classifier_pool.45.weight', 'image_encoder.blocks.9.attn.lora_B_k.45.weight', 'image_encoder.blocks.11.attn.lora_B_k.45.weight', 'image_encoder.blocks.6.attn.lora_B_v.45.weight'}
2025-12-11 19:45:59,861 [inflora.py] => Task 45, Epoch 50/50 => Loss 0.108, Train_accy 96.48
Threshold:  0.998
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 21/768 type remove
Layer 2 : 66/768 type remove
Layer 3 : 138/768 type remove
Layer 4 : 216/768 type remove
Layer 5 : 293/768 type remove
Layer 6 : 312/768 type remove
Layer 7 : 365/768 type remove
Layer 8 : 341/768 type retain
Layer 9 : 226/768 type retain
Layer 10 : 179/768 type retain
Layer 11 : 236/768 type retain
Layer 12 : 147/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:46:09,094 [trainer.py] => Time:225.3967890739441
5441 5441
5441 5441
2025-12-11 19:46:24,556 [trainer.py] => Time:15.462052345275879
2025-12-11 19:46:24,556 [inflora.py] => Exemplar size: 0
2025-12-11 19:46:24,557 [trainer.py] => CNN: {'total': np.float64(58.15), '00-03': np.float64(67.74), '04-07': np.float64(57.24), '08-11': np.float64(57.89), '12-15': np.float64(77.27), '16-19': np.float64(70.63), '20-23': np.float64(69.41), '24-27': np.float64(73.78), '28-31': np.float64(40.31), '32-35': np.float64(56.0), '36-39': np.float64(68.32), '40-43': np.float64(45.35), '44-47': np.float64(42.59), '48-51': np.float64(50.38), '52-55': np.float64(36.07), '56-59': np.float64(45.26), '60-63': np.float64(72.11), '64-67': np.float64(44.9), '68-71': np.float64(31.96), '72-75': np.float64(47.46), '76-79': np.float64(41.82), '80-83': np.float64(48.42), '84-87': np.float64(45.11), '88-91': np.float64(73.0), '92-95': np.float64(50.0), '96-99': np.float64(49.71), '100-103': np.float64(60.17), '104-107': np.float64(18.8), '108-111': np.float64(64.57), '112-115': np.float64(75.0), '116-119': np.float64(75.0), '120-123': np.float64(64.96), '124-127': np.float64(42.16), '128-131': np.float64(47.58), '132-135': np.float64(66.96), '136-139': np.float64(74.51), '140-143': np.float64(57.89), '144-147': np.float64(64.38), '148-151': np.float64(22.54), '152-155': np.float64(72.41), '156-159': np.float64(60.5), '160-163': np.float64(75.7), '164-167': np.float64(78.23), '168-171': np.float64(66.91), '172-175': np.float64(76.74), '176-179': np.float64(64.76), '180-183': np.float64(56.3), 'old': np.float64(58.2), 'new': np.float64(56.3)}
2025-12-11 19:46:24,557 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41), np.float64(55.85), np.float64(57.31), np.float64(57.95), np.float64(57.58), np.float64(58.15)]
2025-12-11 19:46:24,557 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22), np.float64(91.49), np.float64(91.5), np.float64(91.91), np.float64(91.8), np.float64(92.12)]
2025-12-11 19:46:24,557 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696, 0.565984188120819, 0.581230283911672, 0.587194770236493, 0.582548058801357, 0.5884947619922808]
2025-12-11 19:46:42,522 [trainer.py] => W-NCM: {'00-03': 69.03225806451613, '04-07': 62.758620689655174, '08-11': 64.91228070175438, '12-15': 84.54545454545455, '16-19': 72.22222222222221, '20-23': 73.51598173515981, '24-27': 67.6829268292683, '28-31': 62.82722513089005, '32-35': 74.66666666666667, '36-39': 74.25742574257426, '40-43': 69.76744186046511, '44-47': 62.96296296296296, '48-51': 77.86259541984732, '52-55': 73.77049180327869, '56-59': 80.0, '60-63': 72.78911564625851, '64-67': 77.55102040816327, '68-71': 63.91752577319587, '72-75': 55.08474576271186, '76-79': 66.66666666666666, '80-83': 64.21052631578948, '84-87': 75.18796992481202, '88-91': 83.0, '92-95': 67.5, '96-99': 63.005780346820806, '100-103': 65.2542372881356, '104-107': 66.16541353383458, '108-111': 78.74015748031496, '112-115': 84.78260869565217, '116-119': 86.36363636363636, '120-123': 80.34188034188034, '124-127': 57.84313725490197, '128-131': 55.64516129032258, '132-135': 69.64285714285714, '136-139': 76.47058823529412, '140-143': 73.68421052631578, '144-147': 83.56164383561644, '148-151': 63.38028169014085, '152-155': 74.71264367816092, '156-159': 78.15126050420169, '160-163': 85.98130841121495, '164-167': 86.39455782312925, '168-171': 87.76978417266187, '172-175': 94.57364341085271, '176-179': 88.57142857142857, '180-183': 86.66666666666667}
2025-12-11 19:46:42,522 [trainer.py] => Ave Acc (W-NCM): 73.57%
2025-12-11 19:46:42,522 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 69.03% (best 83.23%); T2: W-NCM 62.76% (best 93.79%); T3: W-NCM 64.91% (best 84.21%); T4: W-NCM 84.55% (best 92.73%); T5: W-NCM 72.22% (best 95.24%); T6: W-NCM 73.52% (best 92.24%); T7: W-NCM 67.68% (best 89.02%); T8: W-NCM 62.83% (best 91.62%); T9: W-NCM 74.67% (best 96.00%); T10: W-NCM 74.26% (best 92.08%); T11: W-NCM 69.77% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 77.86% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 80.00% (best 90.53%); T16: W-NCM 72.79% (best 91.84%); T17: W-NCM 77.55% (best 91.84%); T18: W-NCM 63.92% (best 87.63%); T19: W-NCM 55.08% (best 92.37%); T20: W-NCM 66.67% (best 84.85%); T21: W-NCM 64.21% (best 88.42%); T22: W-NCM 75.19% (best 88.72%); T23: W-NCM 83.00% (best 94.00%); T24: W-NCM 67.50% (best 90.00%); T25: W-NCM 63.01% (best 87.28%); T26: W-NCM 65.25% (best 88.14%); T27: W-NCM 66.17% (best 78.95%); T28: W-NCM 78.74% (best 93.70%); T29: W-NCM 84.78% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 80.34% (best 90.60%); T32: W-NCM 57.84% (best 79.41%); T33: W-NCM 55.65% (best 87.90%); T34: W-NCM 69.64% (best 88.39%); T35: W-NCM 76.47% (best 92.16%); T36: W-NCM 73.68% (best 91.58%); T37: W-NCM 83.56% (best 90.41%); T38: W-NCM 63.38% (best 85.92%); T39: W-NCM 74.71% (best 87.36%); T40: W-NCM 78.15% (best 88.24%); T41: W-NCM 85.98% (best 94.39%); T42: W-NCM 86.39% (best 91.16%); T43: W-NCM 87.77% (best 90.65%); T44: W-NCM 94.57% (best 97.67%); T45: W-NCM 88.57% (best 90.48%); T46: W-NCM 86.67% (best 86.67%)
2025-12-11 19:46:42,522 [trainer.py] => Average forgetting (W-NCM): 16.23% | Max forgetting (W-NCM): 37.29%
2025-12-11 19:46:42,529 [trainer.py] => All params: 126094051
2025-12-11 19:46:42,535 [trainer.py] => Trainable params: 187396
2025-12-11 19:46:42,536 [inflora.py] => Learning on 184-188
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_k.46.weight', 'image_encoder.blocks.7.attn.lora_B_v.46.weight', 'image_encoder.blocks.10.attn.lora_B_k.46.weight', 'image_encoder.blocks.7.attn.lora_B_k.46.weight', 'image_encoder.blocks.9.attn.lora_B_k.46.weight', 'image_encoder.blocks.5.attn.lora_B_v.46.weight', 'image_encoder.blocks.10.attn.lora_B_v.46.weight', 'image_encoder.blocks.11.attn.lora_B_k.46.weight', 'image_encoder.blocks.4.attn.lora_B_v.46.weight', 'classifier_pool.46.weight', 'image_encoder.blocks.9.attn.lora_B_v.46.weight', 'image_encoder.blocks.3.attn.lora_B_v.46.weight', 'image_encoder.blocks.0.attn.lora_B_k.46.weight', 'image_encoder.blocks.1.attn.lora_B_k.46.weight', 'image_encoder.blocks.8.attn.lora_B_k.46.weight', 'image_encoder.blocks.8.attn.lora_B_v.46.weight', 'classifier_pool.46.bias', 'image_encoder.blocks.0.attn.lora_B_v.46.weight', 'image_encoder.blocks.1.attn.lora_B_v.46.weight', 'image_encoder.blocks.5.attn.lora_B_k.46.weight', 'image_encoder.blocks.11.attn.lora_B_v.46.weight', 'image_encoder.blocks.3.attn.lora_B_k.46.weight', 'image_encoder.blocks.6.attn.lora_B_v.46.weight', 'image_encoder.blocks.4.attn.lora_B_k.46.weight', 'image_encoder.blocks.2.attn.lora_B_v.46.weight', 'image_encoder.blocks.2.attn.lora_B_k.46.weight'}
2025-12-11 19:50:23,081 [inflora.py] => Task 46, Epoch 50/50 => Loss 0.095, Train_accy 96.88
Threshold:  0.9984
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 21/768 type remove
Layer 2 : 74/768 type remove
Layer 3 : 148/768 type remove
Layer 4 : 235/768 type remove
Layer 5 : 317/768 type remove
Layer 6 : 340/768 type remove
Layer 7 : 371/768 type retain
Layer 8 : 307/768 type retain
Layer 9 : 196/768 type retain
Layer 10 : 153/768 type retain
Layer 11 : 204/768 type retain
Layer 12 : 124/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:50:32,484 [trainer.py] => Time:229.9489233493805
5592 5592
5592 5592
2025-12-11 19:50:48,364 [trainer.py] => Time:15.879071712493896
2025-12-11 19:50:48,364 [inflora.py] => Exemplar size: 0
2025-12-11 19:50:48,365 [trainer.py] => CNN: {'total': np.float64(58.64), '00-03': np.float64(68.39), '04-07': np.float64(58.62), '08-11': np.float64(59.65), '12-15': np.float64(78.18), '16-19': np.float64(69.05), '20-23': np.float64(68.95), '24-27': np.float64(73.78), '28-31': np.float64(41.88), '32-35': np.float64(57.33), '36-39': np.float64(69.31), '40-43': np.float64(50.0), '44-47': np.float64(42.59), '48-51': np.float64(52.67), '52-55': np.float64(37.7), '56-59': np.float64(47.37), '60-63': np.float64(72.11), '64-67': np.float64(42.86), '68-71': np.float64(36.08), '72-75': np.float64(44.92), '76-79': np.float64(44.85), '80-83': np.float64(48.95), '84-87': np.float64(50.38), '88-91': np.float64(73.0), '92-95': np.float64(48.33), '96-99': np.float64(49.13), '100-103': np.float64(60.17), '104-107': np.float64(18.8), '108-111': np.float64(61.42), '112-115': np.float64(73.91), '116-119': np.float64(73.86), '120-123': np.float64(64.96), '124-127': np.float64(43.14), '128-131': np.float64(46.77), '132-135': np.float64(67.86), '136-139': np.float64(75.49), '140-143': np.float64(55.79), '144-147': np.float64(64.38), '148-151': np.float64(16.9), '152-155': np.float64(71.26), '156-159': np.float64(58.82), '160-163': np.float64(75.7), '164-167': np.float64(76.87), '168-171': np.float64(68.35), '172-175': np.float64(75.97), '176-179': np.float64(63.81), '180-183': np.float64(57.04), '184-187': np.float64(66.89), 'old': np.float64(58.41), 'new': np.float64(66.89)}
2025-12-11 19:50:48,365 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41), np.float64(55.85), np.float64(57.31), np.float64(57.95), np.float64(57.58), np.float64(58.15), np.float64(58.64)]
2025-12-11 19:50:48,365 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22), np.float64(91.49), np.float64(91.5), np.float64(91.91), np.float64(91.8), np.float64(92.12), np.float64(92.13)]
2025-12-11 19:50:48,365 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696, 0.565984188120819, 0.581230283911672, 0.587194770236493, 0.582548058801357, 0.5884947619922808, 0.5931688125894135]
2025-12-11 19:51:06,799 [trainer.py] => W-NCM: {'00-03': 69.03225806451613, '04-07': 65.51724137931035, '08-11': 68.42105263157895, '12-15': 82.72727272727273, '16-19': 72.22222222222221, '20-23': 75.79908675799086, '24-27': 67.6829268292683, '28-31': 65.44502617801047, '32-35': 76.0, '36-39': 73.26732673267327, '40-43': 69.76744186046511, '44-47': 64.81481481481481, '48-51': 77.86259541984732, '52-55': 73.77049180327869, '56-59': 80.0, '60-63': 72.10884353741497, '64-67': 77.55102040816327, '68-71': 67.0103092783505, '72-75': 53.38983050847458, '76-79': 68.48484848484848, '80-83': 64.73684210526316, '84-87': 74.43609022556392, '88-91': 83.0, '92-95': 65.0, '96-99': 64.16184971098265, '100-103': 64.40677966101694, '104-107': 66.16541353383458, '108-111': 79.52755905511812, '112-115': 84.78260869565217, '116-119': 86.36363636363636, '120-123': 79.48717948717949, '124-127': 57.84313725490197, '128-131': 56.451612903225815, '132-135': 69.64285714285714, '136-139': 75.49019607843137, '140-143': 73.68421052631578, '144-147': 86.3013698630137, '148-151': 66.19718309859155, '152-155': 71.26436781609196, '156-159': 76.47058823529412, '160-163': 85.04672897196261, '164-167': 87.07482993197279, '168-171': 87.76978417266187, '172-175': 94.57364341085271, '176-179': 88.57142857142857, '180-183': 83.7037037037037, '184-187': 85.43046357615894}
2025-12-11 19:51:06,800 [trainer.py] => Ave Acc (W-NCM): 74.01%
2025-12-11 19:51:06,800 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 69.03% (best 83.23%); T2: W-NCM 65.52% (best 93.79%); T3: W-NCM 68.42% (best 84.21%); T4: W-NCM 82.73% (best 92.73%); T5: W-NCM 72.22% (best 95.24%); T6: W-NCM 75.80% (best 92.24%); T7: W-NCM 67.68% (best 89.02%); T8: W-NCM 65.45% (best 91.62%); T9: W-NCM 76.00% (best 96.00%); T10: W-NCM 73.27% (best 92.08%); T11: W-NCM 69.77% (best 76.74%); T12: W-NCM 64.81% (best 75.93%); T13: W-NCM 77.86% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 80.00% (best 90.53%); T16: W-NCM 72.11% (best 91.84%); T17: W-NCM 77.55% (best 91.84%); T18: W-NCM 67.01% (best 87.63%); T19: W-NCM 53.39% (best 92.37%); T20: W-NCM 68.48% (best 84.85%); T21: W-NCM 64.74% (best 88.42%); T22: W-NCM 74.44% (best 88.72%); T23: W-NCM 83.00% (best 94.00%); T24: W-NCM 65.00% (best 90.00%); T25: W-NCM 64.16% (best 87.28%); T26: W-NCM 64.41% (best 88.14%); T27: W-NCM 66.17% (best 78.95%); T28: W-NCM 79.53% (best 93.70%); T29: W-NCM 84.78% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 79.49% (best 90.60%); T32: W-NCM 57.84% (best 79.41%); T33: W-NCM 56.45% (best 87.90%); T34: W-NCM 69.64% (best 88.39%); T35: W-NCM 75.49% (best 92.16%); T36: W-NCM 73.68% (best 91.58%); T37: W-NCM 86.30% (best 90.41%); T38: W-NCM 66.20% (best 85.92%); T39: W-NCM 71.26% (best 87.36%); T40: W-NCM 76.47% (best 88.24%); T41: W-NCM 85.05% (best 94.39%); T42: W-NCM 87.07% (best 91.16%); T43: W-NCM 87.77% (best 90.65%); T44: W-NCM 94.57% (best 97.67%); T45: W-NCM 88.57% (best 90.48%); T46: W-NCM 83.70% (best 86.67%); T47: W-NCM 85.43% (best 85.43%)
2025-12-11 19:51:06,800 [trainer.py] => Average forgetting (W-NCM): 15.69% | Max forgetting (W-NCM): 38.98%
2025-12-11 19:51:06,806 [trainer.py] => All params: 126094051
2025-12-11 19:51:06,813 [trainer.py] => Trainable params: 187396
2025-12-11 19:51:06,813 [inflora.py] => Learning on 188-192
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_k.47.weight', 'image_encoder.blocks.4.attn.lora_B_k.47.weight', 'classifier_pool.47.weight', 'image_encoder.blocks.3.attn.lora_B_k.47.weight', 'image_encoder.blocks.9.attn.lora_B_k.47.weight', 'image_encoder.blocks.3.attn.lora_B_v.47.weight', 'image_encoder.blocks.6.attn.lora_B_k.47.weight', 'image_encoder.blocks.0.attn.lora_B_k.47.weight', 'image_encoder.blocks.10.attn.lora_B_v.47.weight', 'image_encoder.blocks.5.attn.lora_B_k.47.weight', 'image_encoder.blocks.7.attn.lora_B_v.47.weight', 'image_encoder.blocks.9.attn.lora_B_v.47.weight', 'image_encoder.blocks.11.attn.lora_B_v.47.weight', 'image_encoder.blocks.11.attn.lora_B_k.47.weight', 'image_encoder.blocks.8.attn.lora_B_k.47.weight', 'image_encoder.blocks.5.attn.lora_B_v.47.weight', 'image_encoder.blocks.6.attn.lora_B_v.47.weight', 'image_encoder.blocks.1.attn.lora_B_k.47.weight', 'image_encoder.blocks.4.attn.lora_B_v.47.weight', 'image_encoder.blocks.8.attn.lora_B_v.47.weight', 'image_encoder.blocks.2.attn.lora_B_v.47.weight', 'image_encoder.blocks.10.attn.lora_B_k.47.weight', 'classifier_pool.47.bias', 'image_encoder.blocks.7.attn.lora_B_k.47.weight', 'image_encoder.blocks.0.attn.lora_B_v.47.weight', 'image_encoder.blocks.1.attn.lora_B_v.47.weight'}
2025-12-11 19:55:20,478 [inflora.py] => Task 47, Epoch 50/50 => Loss 0.109, Train_accy 95.70
Threshold:  0.9988
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 26/768 type remove
Layer 2 : 80/768 type remove
Layer 3 : 163/768 type remove
Layer 4 : 260/768 type remove
Layer 5 : 347/768 type remove
Layer 6 : 373/768 type remove
Layer 7 : 335/768 type retain
Layer 8 : 272/768 type retain
Layer 9 : 170/768 type retain
Layer 10 : 131/768 type retain
Layer 11 : 175/768 type retain
Layer 12 : 106/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:55:30,497 [trainer.py] => Time:263.68442130088806
5771 5771
5771 5771
2025-12-11 19:55:46,917 [trainer.py] => Time:16.41921329498291
2025-12-11 19:55:46,917 [inflora.py] => Exemplar size: 0
2025-12-11 19:55:46,917 [trainer.py] => CNN: {'total': np.float64(59.09), '00-03': np.float64(68.39), '04-07': np.float64(61.38), '08-11': np.float64(61.4), '12-15': np.float64(77.27), '16-19': np.float64(69.84), '20-23': np.float64(67.12), '24-27': np.float64(73.78), '28-31': np.float64(43.98), '32-35': np.float64(61.33), '36-39': np.float64(70.3), '40-43': np.float64(45.35), '44-47': np.float64(42.59), '48-51': np.float64(51.91), '52-55': np.float64(37.7), '56-59': np.float64(49.47), '60-63': np.float64(70.07), '64-67': np.float64(42.86), '68-71': np.float64(35.05), '72-75': np.float64(44.92), '76-79': np.float64(46.06), '80-83': np.float64(53.68), '84-87': np.float64(51.88), '88-91': np.float64(73.0), '92-95': np.float64(47.5), '96-99': np.float64(46.82), '100-103': np.float64(62.71), '104-107': np.float64(18.8), '108-111': np.float64(59.06), '112-115': np.float64(75.0), '116-119': np.float64(72.73), '120-123': np.float64(64.96), '124-127': np.float64(43.14), '128-131': np.float64(46.77), '132-135': np.float64(65.18), '136-139': np.float64(72.55), '140-143': np.float64(56.84), '144-147': np.float64(63.01), '148-151': np.float64(19.72), '152-155': np.float64(72.41), '156-159': np.float64(57.98), '160-163': np.float64(74.77), '164-167': np.float64(76.19), '168-171': np.float64(69.06), '172-175': np.float64(75.97), '176-179': np.float64(63.81), '180-183': np.float64(59.26), '184-187': np.float64(67.55), '188-191': np.float64(67.6), 'old': np.float64(58.82), 'new': np.float64(67.6)}
2025-12-11 19:55:46,917 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41), np.float64(55.85), np.float64(57.31), np.float64(57.95), np.float64(57.58), np.float64(58.15), np.float64(58.64), np.float64(59.09)]
2025-12-11 19:55:46,917 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22), np.float64(91.49), np.float64(91.5), np.float64(91.91), np.float64(91.8), np.float64(92.12), np.float64(92.13), np.float64(92.29)]
2025-12-11 19:55:46,918 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696, 0.565984188120819, 0.581230283911672, 0.587194770236493, 0.582548058801357, 0.5884947619922808, 0.5931688125894135, 0.596776988390227]
2025-12-11 19:56:06,225 [trainer.py] => W-NCM: {'00-03': 72.25806451612902, '04-07': 66.89655172413794, '08-11': 67.54385964912281, '12-15': 84.54545454545455, '16-19': 75.39682539682539, '20-23': 74.88584474885845, '24-27': 69.51219512195121, '28-31': 64.92146596858639, '32-35': 76.0, '36-39': 73.26732673267327, '40-43': 69.76744186046511, '44-47': 62.96296296296296, '48-51': 80.91603053435115, '52-55': 73.77049180327869, '56-59': 81.05263157894737, '60-63': 72.10884353741497, '64-67': 75.51020408163265, '68-71': 70.10309278350515, '72-75': 53.38983050847458, '76-79': 68.48484848484848, '80-83': 66.84210526315789, '84-87': 77.44360902255639, '88-91': 83.0, '92-95': 65.0, '96-99': 62.42774566473989, '100-103': 70.33898305084746, '104-107': 69.17293233082707, '108-111': 81.88976377952756, '112-115': 83.69565217391305, '116-119': 86.36363636363636, '120-123': 79.48717948717949, '124-127': 58.82352941176471, '128-131': 56.451612903225815, '132-135': 69.64285714285714, '136-139': 76.47058823529412, '140-143': 72.63157894736842, '144-147': 86.3013698630137, '148-151': 67.6056338028169, '152-155': 71.26436781609196, '156-159': 78.15126050420169, '160-163': 83.17757009345794, '164-167': 85.03401360544217, '168-171': 85.61151079136691, '172-175': 93.02325581395348, '176-179': 88.57142857142857, '180-183': 83.7037037037037, '184-187': 83.44370860927152, '188-191': 84.91620111731844}
2025-12-11 19:56:06,226 [trainer.py] => Ave Acc (W-NCM): 74.66%
2025-12-11 19:56:06,226 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 72.26% (best 83.23%); T2: W-NCM 66.90% (best 93.79%); T3: W-NCM 67.54% (best 84.21%); T4: W-NCM 84.55% (best 92.73%); T5: W-NCM 75.40% (best 95.24%); T6: W-NCM 74.89% (best 92.24%); T7: W-NCM 69.51% (best 89.02%); T8: W-NCM 64.92% (best 91.62%); T9: W-NCM 76.00% (best 96.00%); T10: W-NCM 73.27% (best 92.08%); T11: W-NCM 69.77% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 80.92% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 81.05% (best 90.53%); T16: W-NCM 72.11% (best 91.84%); T17: W-NCM 75.51% (best 91.84%); T18: W-NCM 70.10% (best 87.63%); T19: W-NCM 53.39% (best 92.37%); T20: W-NCM 68.48% (best 84.85%); T21: W-NCM 66.84% (best 88.42%); T22: W-NCM 77.44% (best 88.72%); T23: W-NCM 83.00% (best 94.00%); T24: W-NCM 65.00% (best 90.00%); T25: W-NCM 62.43% (best 87.28%); T26: W-NCM 70.34% (best 88.14%); T27: W-NCM 69.17% (best 78.95%); T28: W-NCM 81.89% (best 93.70%); T29: W-NCM 83.70% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 79.49% (best 90.60%); T32: W-NCM 58.82% (best 79.41%); T33: W-NCM 56.45% (best 87.90%); T34: W-NCM 69.64% (best 88.39%); T35: W-NCM 76.47% (best 92.16%); T36: W-NCM 72.63% (best 91.58%); T37: W-NCM 86.30% (best 90.41%); T38: W-NCM 67.61% (best 85.92%); T39: W-NCM 71.26% (best 87.36%); T40: W-NCM 78.15% (best 88.24%); T41: W-NCM 83.18% (best 94.39%); T42: W-NCM 85.03% (best 91.16%); T43: W-NCM 85.61% (best 90.65%); T44: W-NCM 93.02% (best 97.67%); T45: W-NCM 88.57% (best 90.48%); T46: W-NCM 83.70% (best 86.67%); T47: W-NCM 83.44% (best 85.43%); T48: W-NCM 84.92% (best 84.92%)
2025-12-11 19:56:06,226 [trainer.py] => Average forgetting (W-NCM): 14.92% | Max forgetting (W-NCM): 38.98%
2025-12-11 19:56:06,233 [trainer.py] => All params: 126094051
2025-12-11 19:56:06,239 [trainer.py] => Trainable params: 187396
2025-12-11 19:56:06,239 [inflora.py] => Learning on 192-196
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.48.weight', 'image_encoder.blocks.10.attn.lora_B_k.48.weight', 'image_encoder.blocks.6.attn.lora_B_v.48.weight', 'image_encoder.blocks.7.attn.lora_B_k.48.weight', 'image_encoder.blocks.4.attn.lora_B_v.48.weight', 'image_encoder.blocks.5.attn.lora_B_k.48.weight', 'image_encoder.blocks.7.attn.lora_B_v.48.weight', 'image_encoder.blocks.5.attn.lora_B_v.48.weight', 'image_encoder.blocks.9.attn.lora_B_k.48.weight', 'image_encoder.blocks.9.attn.lora_B_v.48.weight', 'classifier_pool.48.weight', 'image_encoder.blocks.3.attn.lora_B_k.48.weight', 'image_encoder.blocks.10.attn.lora_B_v.48.weight', 'image_encoder.blocks.2.attn.lora_B_k.48.weight', 'image_encoder.blocks.2.attn.lora_B_v.48.weight', 'image_encoder.blocks.1.attn.lora_B_v.48.weight', 'classifier_pool.48.bias', 'image_encoder.blocks.8.attn.lora_B_v.48.weight', 'image_encoder.blocks.0.attn.lora_B_k.48.weight', 'image_encoder.blocks.11.attn.lora_B_k.48.weight', 'image_encoder.blocks.1.attn.lora_B_k.48.weight', 'image_encoder.blocks.8.attn.lora_B_k.48.weight', 'image_encoder.blocks.6.attn.lora_B_k.48.weight', 'image_encoder.blocks.11.attn.lora_B_v.48.weight', 'image_encoder.blocks.3.attn.lora_B_v.48.weight', 'image_encoder.blocks.0.attn.lora_B_v.48.weight'}
2025-12-11 19:58:32,433 [inflora.py] => Task 48, Epoch 50/50 => Loss 0.084, Train_accy 97.37
Threshold:  0.9992
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 51/768 type remove
Layer 2 : 94/768 type remove
Layer 3 : 188/768 type remove
Layer 4 : 294/768 type remove
Layer 5 : 383/768 type retain
Layer 6 : 352/768 type retain
Layer 7 : 295/768 type retain
Layer 8 : 237/768 type retain
Layer 9 : 139/768 type retain
Layer 10 : 101/768 type retain
Layer 11 : 130/768 type retain
Layer 12 : 72/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 19:58:40,674 [trainer.py] => Time:154.435405254364
5854 5854
5854 5854
2025-12-11 19:58:57,231 [trainer.py] => Time:16.555993795394897
2025-12-11 19:58:57,231 [inflora.py] => Exemplar size: 0
2025-12-11 19:58:57,231 [trainer.py] => CNN: {'total': np.float64(59.26), '00-03': np.float64(70.97), '04-07': np.float64(61.38), '08-11': np.float64(63.16), '12-15': np.float64(79.09), '16-19': np.float64(70.63), '20-23': np.float64(68.04), '24-27': np.float64(74.39), '28-31': np.float64(42.41), '32-35': np.float64(60.0), '36-39': np.float64(70.3), '40-43': np.float64(46.51), '44-47': np.float64(40.74), '48-51': np.float64(52.67), '52-55': np.float64(39.34), '56-59': np.float64(51.58), '60-63': np.float64(70.07), '64-67': np.float64(42.86), '68-71': np.float64(36.08), '72-75': np.float64(44.07), '76-79': np.float64(46.06), '80-83': np.float64(54.74), '84-87': np.float64(52.63), '88-91': np.float64(73.0), '92-95': np.float64(48.33), '96-99': np.float64(46.82), '100-103': np.float64(61.86), '104-107': np.float64(18.8), '108-111': np.float64(59.84), '112-115': np.float64(73.91), '116-119': np.float64(72.73), '120-123': np.float64(64.96), '124-127': np.float64(42.16), '128-131': np.float64(47.58), '132-135': np.float64(63.39), '136-139': np.float64(72.55), '140-143': np.float64(56.84), '144-147': np.float64(61.64), '148-151': np.float64(19.72), '152-155': np.float64(72.41), '156-159': np.float64(57.98), '160-163': np.float64(74.77), '164-167': np.float64(76.87), '168-171': np.float64(70.5), '172-175': np.float64(75.19), '176-179': np.float64(63.81), '180-183': np.float64(60.0), '184-187': np.float64(68.21), '188-191': np.float64(69.27), '192-195': np.float64(48.19), 'old': np.float64(59.42), 'new': np.float64(48.19)}
2025-12-11 19:58:57,231 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41), np.float64(55.85), np.float64(57.31), np.float64(57.95), np.float64(57.58), np.float64(58.15), np.float64(58.64), np.float64(59.09), np.float64(59.26)]
2025-12-11 19:58:57,232 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22), np.float64(91.49), np.float64(91.5), np.float64(91.91), np.float64(91.8), np.float64(92.12), np.float64(92.13), np.float64(92.29), np.float64(92.19)]
2025-12-11 19:58:57,232 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696, 0.565984188120819, 0.581230283911672, 0.587194770236493, 0.582548058801357, 0.5884947619922808, 0.5931688125894135, 0.596776988390227, 0.5980526135975401]
2025-12-11 19:59:15,756 [trainer.py] => W-NCM: {'00-03': 70.3225806451613, '04-07': 65.51724137931035, '08-11': 66.66666666666666, '12-15': 82.72727272727273, '16-19': 75.39682539682539, '20-23': 74.42922374429224, '24-27': 68.90243902439023, '28-31': 64.92146596858639, '32-35': 73.33333333333333, '36-39': 72.27722772277228, '40-43': 69.76744186046511, '44-47': 62.96296296296296, '48-51': 79.38931297709924, '52-55': 72.1311475409836, '56-59': 81.05263157894737, '60-63': 73.46938775510205, '64-67': 73.46938775510205, '68-71': 65.97938144329896, '72-75': 53.38983050847458, '76-79': 68.48484848484848, '80-83': 67.89473684210526, '84-87': 76.69172932330827, '88-91': 83.0, '92-95': 63.33333333333333, '96-99': 60.69364161849711, '100-103': 65.2542372881356, '104-107': 69.92481203007519, '108-111': 81.10236220472441, '112-115': 82.6086956521739, '116-119': 86.36363636363636, '120-123': 79.48717948717949, '124-127': 56.86274509803921, '128-131': 55.64516129032258, '132-135': 68.75, '136-139': 76.47058823529412, '140-143': 73.68421052631578, '144-147': 83.56164383561644, '148-151': 64.7887323943662, '152-155': 73.5632183908046, '156-159': 76.47058823529412, '160-163': 82.2429906542056, '164-167': 85.03401360544217, '168-171': 83.45323741007195, '172-175': 93.7984496124031, '176-179': 83.80952380952381, '180-183': 80.74074074074075, '184-187': 82.11920529801324, '188-191': 83.79888268156425, '192-195': 80.72289156626506}
2025-12-11 19:59:15,757 [trainer.py] => Ave Acc (W-NCM): 73.81%
2025-12-11 19:59:15,757 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 70.32% (best 83.23%); T2: W-NCM 65.52% (best 93.79%); T3: W-NCM 66.67% (best 84.21%); T4: W-NCM 82.73% (best 92.73%); T5: W-NCM 75.40% (best 95.24%); T6: W-NCM 74.43% (best 92.24%); T7: W-NCM 68.90% (best 89.02%); T8: W-NCM 64.92% (best 91.62%); T9: W-NCM 73.33% (best 96.00%); T10: W-NCM 72.28% (best 92.08%); T11: W-NCM 69.77% (best 76.74%); T12: W-NCM 62.96% (best 75.93%); T13: W-NCM 79.39% (best 95.42%); T14: W-NCM 72.13% (best 85.25%); T15: W-NCM 81.05% (best 90.53%); T16: W-NCM 73.47% (best 91.84%); T17: W-NCM 73.47% (best 91.84%); T18: W-NCM 65.98% (best 87.63%); T19: W-NCM 53.39% (best 92.37%); T20: W-NCM 68.48% (best 84.85%); T21: W-NCM 67.89% (best 88.42%); T22: W-NCM 76.69% (best 88.72%); T23: W-NCM 83.00% (best 94.00%); T24: W-NCM 63.33% (best 90.00%); T25: W-NCM 60.69% (best 87.28%); T26: W-NCM 65.25% (best 88.14%); T27: W-NCM 69.92% (best 78.95%); T28: W-NCM 81.10% (best 93.70%); T29: W-NCM 82.61% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 79.49% (best 90.60%); T32: W-NCM 56.86% (best 79.41%); T33: W-NCM 55.65% (best 87.90%); T34: W-NCM 68.75% (best 88.39%); T35: W-NCM 76.47% (best 92.16%); T36: W-NCM 73.68% (best 91.58%); T37: W-NCM 83.56% (best 90.41%); T38: W-NCM 64.79% (best 85.92%); T39: W-NCM 73.56% (best 87.36%); T40: W-NCM 76.47% (best 88.24%); T41: W-NCM 82.24% (best 94.39%); T42: W-NCM 85.03% (best 91.16%); T43: W-NCM 83.45% (best 90.65%); T44: W-NCM 93.80% (best 97.67%); T45: W-NCM 83.81% (best 90.48%); T46: W-NCM 80.74% (best 86.67%); T47: W-NCM 82.12% (best 85.43%); T48: W-NCM 83.80% (best 84.92%); T49: W-NCM 80.72% (best 80.72%)
2025-12-11 19:59:15,757 [trainer.py] => Average forgetting (W-NCM): 15.61% | Max forgetting (W-NCM): 38.98%
2025-12-11 19:59:15,764 [trainer.py] => All params: 126094051
2025-12-11 19:59:15,770 [trainer.py] => Trainable params: 187396
2025-12-11 19:59:15,770 [inflora.py] => Learning on 196-200
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_k.49.weight', 'image_encoder.blocks.4.attn.lora_B_v.49.weight', 'image_encoder.blocks.1.attn.lora_B_v.49.weight', 'image_encoder.blocks.9.attn.lora_B_v.49.weight', 'image_encoder.blocks.3.attn.lora_B_v.49.weight', 'image_encoder.blocks.4.attn.lora_B_k.49.weight', 'classifier_pool.49.weight', 'image_encoder.blocks.2.attn.lora_B_v.49.weight', 'image_encoder.blocks.5.attn.lora_B_v.49.weight', 'classifier_pool.49.bias', 'image_encoder.blocks.10.attn.lora_B_v.49.weight', 'image_encoder.blocks.6.attn.lora_B_v.49.weight', 'image_encoder.blocks.6.attn.lora_B_k.49.weight', 'image_encoder.blocks.5.attn.lora_B_k.49.weight', 'image_encoder.blocks.3.attn.lora_B_k.49.weight', 'image_encoder.blocks.10.attn.lora_B_k.49.weight', 'image_encoder.blocks.0.attn.lora_B_k.49.weight', 'image_encoder.blocks.0.attn.lora_B_v.49.weight', 'image_encoder.blocks.8.attn.lora_B_v.49.weight', 'image_encoder.blocks.1.attn.lora_B_k.49.weight', 'image_encoder.blocks.8.attn.lora_B_k.49.weight', 'image_encoder.blocks.11.attn.lora_B_k.49.weight', 'image_encoder.blocks.11.attn.lora_B_v.49.weight', 'image_encoder.blocks.7.attn.lora_B_k.49.weight', 'image_encoder.blocks.9.attn.lora_B_k.49.weight', 'image_encoder.blocks.7.attn.lora_B_v.49.weight'}
2025-12-11 20:02:48,280 [inflora.py] => Task 49, Epoch 50/50 => Loss 0.103, Train_accy 96.70
Threshold:  0.9996
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 52/768 type remove
Layer 2 : 117/768 type remove
Layer 3 : 231/768 type remove
Layer 4 : 358/768 type remove
Layer 5 : 307/768 type retain
Layer 6 : 273/768 type retain
Layer 7 : 220/768 type retain
Layer 8 : 169/768 type retain
Layer 9 : 84/768 type retain
Layer 10 : 53/768 type retain
Layer 11 : 71/768 type retain
Layer 12 : 32/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 20:02:57,135 [trainer.py] => Time:221.36423087120056
6000 6000
6000 6000
2025-12-11 20:03:14,138 [trainer.py] => Time:17.00303626060486
2025-12-11 20:03:14,138 [inflora.py] => Exemplar size: 0
2025-12-11 20:03:14,138 [trainer.py] => CNN: {'total': np.float64(58.78), '00-03': np.float64(68.39), '04-07': np.float64(60.0), '08-11': np.float64(61.4), '12-15': np.float64(78.18), '16-19': np.float64(70.63), '20-23': np.float64(67.58), '24-27': np.float64(74.39), '28-31': np.float64(43.46), '32-35': np.float64(61.33), '36-39': np.float64(70.3), '40-43': np.float64(46.51), '44-47': np.float64(40.74), '48-51': np.float64(49.62), '52-55': np.float64(36.07), '56-59': np.float64(52.63), '60-63': np.float64(71.43), '64-67': np.float64(42.86), '68-71': np.float64(35.05), '72-75': np.float64(43.22), '76-79': np.float64(46.06), '80-83': np.float64(52.63), '84-87': np.float64(51.13), '88-91': np.float64(73.0), '92-95': np.float64(46.67), '96-99': np.float64(47.4), '100-103': np.float64(61.02), '104-107': np.float64(21.05), '108-111': np.float64(60.63), '112-115': np.float64(76.09), '116-119': np.float64(72.73), '120-123': np.float64(64.96), '124-127': np.float64(41.18), '128-131': np.float64(48.39), '132-135': np.float64(64.29), '136-139': np.float64(74.51), '140-143': np.float64(55.79), '144-147': np.float64(64.38), '148-151': np.float64(18.31), '152-155': np.float64(72.41), '156-159': np.float64(57.14), '160-163': np.float64(74.77), '164-167': np.float64(76.19), '168-171': np.float64(66.91), '172-175': np.float64(74.42), '176-179': np.float64(63.81), '180-183': np.float64(57.04), '184-187': np.float64(66.89), '188-191': np.float64(65.36), '192-195': np.float64(45.78), '196-199': np.float64(63.01), 'old': np.float64(58.68), 'new': np.float64(63.01)}
2025-12-11 20:03:14,139 [trainer.py] => CNN top1 curve: [np.float64(90.32), np.float64(82.67), np.float64(80.43), np.float64(80.53), np.float64(78.46), np.float64(77.22), np.float64(78.32), np.float64(75.25), np.float64(73.52), np.float64(73.57), np.float64(70.79), np.float64(69.22), np.float64(69.96), np.float64(68.13), np.float64(69.68), np.float64(68.69), np.float64(66.34), np.float64(65.94), np.float64(64.25), np.float64(62.67), np.float64(63.32), np.float64(63.28), np.float64(63.48), np.float64(62.36), np.float64(61.91), np.float64(63.05), np.float64(61.6), np.float64(60.48), np.float64(59.63), np.float64(59.7), np.float64(58.54), np.float64(57.29), np.float64(57.11), np.float64(55.95), np.float64(55.9), np.float64(56.06), np.float64(55.66), np.float64(55.87), np.float64(54.39), np.float64(54.71), np.float64(55.41), np.float64(55.85), np.float64(57.31), np.float64(57.95), np.float64(57.58), np.float64(58.15), np.float64(58.64), np.float64(59.09), np.float64(59.26), np.float64(58.78)]
2025-12-11 20:03:14,139 [trainer.py] => CNN top1 with task curve: [np.float64(90.32), np.float64(90.33), np.float64(90.1), np.float64(91.6), np.float64(92.0), np.float64(92.17), np.float64(92.55), np.float64(93.14), np.float64(92.84), np.float64(93.07), np.float64(92.66), np.float64(91.56), np.float64(91.86), np.float64(91.92), np.float64(92.56), np.float64(92.3), np.float64(92.19), np.float64(91.79), np.float64(92.0), np.float64(92.01), np.float64(92.02), np.float64(92.59), np.float64(92.75), np.float64(91.99), np.float64(92.34), np.float64(92.37), np.float64(91.99), np.float64(92.19), np.float64(92.39), np.float64(92.47), np.float64(92.28), np.float64(91.81), np.float64(91.92), np.float64(91.67), np.float64(91.76), np.float64(91.96), np.float64(91.69), np.float64(91.46), np.float64(90.92), np.float64(91.19), np.float64(91.22), np.float64(91.49), np.float64(91.5), np.float64(91.91), np.float64(91.8), np.float64(92.12), np.float64(92.13), np.float64(92.29), np.float64(92.19), np.float64(92.37)]
2025-12-11 20:03:14,139 [trainer.py] => CNN top1 task curve: [1.0, 0.8966666666666666, 0.8623188405797102, 0.851145038167939, 0.823076923076923, 0.8032220943613348, 0.8034849951597289, 0.7728758169934641, 0.7582755966127791, 0.7535714285714286, 0.7288021534320323, 0.7103896103896103, 0.7145421903052065, 0.6968822170900693, 0.7142857142857143, 0.6995947315096251, 0.6772120612951062, 0.6726415094339623, 0.6550491510277033, 0.640033291718685, 0.6440416505977632, 0.6438004402054291, 0.6443736730360934, 0.6327223353699932, 0.6274446938121193, 0.637936360827927, 0.6252225519287834, 0.6113811838718902, 0.6021175814990248, 0.6040250203970629, 0.5911966262519768, 0.579312114989733, 0.5778606965174129, 0.5672797676669894, 0.5663675011809164, 0.568029568029568, 0.5633802816901409, 0.5658394813324391, 0.5504385964912281, 0.5546056849754221, 0.5612202256581696, 0.565984188120819, 0.581230283911672, 0.587194770236493, 0.582548058801357, 0.5884947619922808, 0.5931688125894135, 0.596776988390227, 0.5980526135975401, 0.5931666666666666]
2025-12-11 20:03:33,577 [trainer.py] => W-NCM: {'00-03': 69.03225806451613, '04-07': 64.82758620689654, '08-11': 65.78947368421053, '12-15': 82.72727272727273, '16-19': 75.39682539682539, '20-23': 76.71232876712328, '24-27': 65.85365853658537, '28-31': 63.87434554973822, '32-35': 77.33333333333333, '36-39': 73.26732673267327, '40-43': 66.27906976744185, '44-47': 66.66666666666666, '48-51': 78.62595419847328, '52-55': 73.77049180327869, '56-59': 80.0, '60-63': 74.14965986394559, '64-67': 75.51020408163265, '68-71': 67.0103092783505, '72-75': 53.38983050847458, '76-79': 67.87878787878789, '80-83': 65.78947368421053, '84-87': 75.93984962406014, '88-91': 83.0, '92-95': 64.16666666666667, '96-99': 58.95953757225434, '100-103': 68.64406779661016, '104-107': 69.17293233082707, '108-111': 80.31496062992126, '112-115': 81.52173913043478, '116-119': 86.36363636363636, '120-123': 78.63247863247864, '124-127': 55.88235294117647, '128-131': 54.03225806451613, '132-135': 69.64285714285714, '136-139': 76.47058823529412, '140-143': 73.68421052631578, '144-147': 84.93150684931507, '148-151': 66.19718309859155, '152-155': 72.41379310344827, '156-159': 76.47058823529412, '160-163': 81.30841121495327, '164-167': 80.95238095238095, '168-171': 83.45323741007195, '172-175': 93.02325581395348, '176-179': 83.80952380952381, '180-183': 80.0, '184-187': 81.45695364238411, '188-191': 83.24022346368714, '192-195': 77.10843373493977, '196-199': 90.41095890410958}
2025-12-11 20:03:33,578 [trainer.py] => Ave Acc (W-NCM): 73.90%
2025-12-11 20:03:33,578 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 69.03% (best 83.23%); T2: W-NCM 64.83% (best 93.79%); T3: W-NCM 65.79% (best 84.21%); T4: W-NCM 82.73% (best 92.73%); T5: W-NCM 75.40% (best 95.24%); T6: W-NCM 76.71% (best 92.24%); T7: W-NCM 65.85% (best 89.02%); T8: W-NCM 63.87% (best 91.62%); T9: W-NCM 77.33% (best 96.00%); T10: W-NCM 73.27% (best 92.08%); T11: W-NCM 66.28% (best 76.74%); T12: W-NCM 66.67% (best 75.93%); T13: W-NCM 78.63% (best 95.42%); T14: W-NCM 73.77% (best 85.25%); T15: W-NCM 80.00% (best 90.53%); T16: W-NCM 74.15% (best 91.84%); T17: W-NCM 75.51% (best 91.84%); T18: W-NCM 67.01% (best 87.63%); T19: W-NCM 53.39% (best 92.37%); T20: W-NCM 67.88% (best 84.85%); T21: W-NCM 65.79% (best 88.42%); T22: W-NCM 75.94% (best 88.72%); T23: W-NCM 83.00% (best 94.00%); T24: W-NCM 64.17% (best 90.00%); T25: W-NCM 58.96% (best 87.28%); T26: W-NCM 68.64% (best 88.14%); T27: W-NCM 69.17% (best 78.95%); T28: W-NCM 80.31% (best 93.70%); T29: W-NCM 81.52% (best 93.48%); T30: W-NCM 86.36% (best 96.59%); T31: W-NCM 78.63% (best 90.60%); T32: W-NCM 55.88% (best 79.41%); T33: W-NCM 54.03% (best 87.90%); T34: W-NCM 69.64% (best 88.39%); T35: W-NCM 76.47% (best 92.16%); T36: W-NCM 73.68% (best 91.58%); T37: W-NCM 84.93% (best 90.41%); T38: W-NCM 66.20% (best 85.92%); T39: W-NCM 72.41% (best 87.36%); T40: W-NCM 76.47% (best 88.24%); T41: W-NCM 81.31% (best 94.39%); T42: W-NCM 80.95% (best 91.16%); T43: W-NCM 83.45% (best 90.65%); T44: W-NCM 93.02% (best 97.67%); T45: W-NCM 83.81% (best 90.48%); T46: W-NCM 80.00% (best 86.67%); T47: W-NCM 81.46% (best 85.43%); T48: W-NCM 83.24% (best 84.92%); T49: W-NCM 77.11% (best 80.72%); T50: W-NCM 90.41% (best 90.41%)
2025-12-11 20:03:33,578 [trainer.py] => Average forgetting (W-NCM): 15.53% | Max forgetting (W-NCM): 38.98%
2025-12-11 20:03:33,579 [trainer.py] => 
===== Summary =====
2025-12-11 20:03:33,579 [trainer.py] => Final average accuracy: 58.78%
2025-12-11 20:03:33,579 [trainer.py] => Average accuracy over tasks: 64.49%
2025-12-11 20:03:33,579 [trainer.py] => Final average forgetting: 9.79%
2025-12-11 20:03:33,579 [trainer.py] => Final max forgetting: 25.19%
2025-12-11 20:03:33,579 [trainer.py] => W-NCM final average accuracy: 73.90%
2025-12-11 20:03:33,579 [trainer.py] => W-NCM average accuracy over tasks: 75.32%
2025-12-11 20:03:33,579 [trainer.py] => W-NCM final average forgetting: 15.53%
2025-12-11 20:03:33,579 [trainer.py] => W-NCM final max forgetting: 38.98%
