logs/cifar100/2_2_sip/InfLoRA/adam/10/0.95_1.0-0.0005/42
2025-12-11 14:31:18,010 [trainer.py] => config: configs/cifar100_50tasks_inflora_seed42.json
2025-12-11 14:31:18,011 [trainer.py] => device: [device(type='cuda', index=0)]
2025-12-11 14:31:18,011 [trainer.py] => prefix: reproduce
2025-12-11 14:31:18,011 [trainer.py] => dataset: cifar100
2025-12-11 14:31:18,011 [trainer.py] => data_path: data/
2025-12-11 14:31:18,011 [trainer.py] => memory_size: 0
2025-12-11 14:31:18,011 [trainer.py] => memory_per_class: 0
2025-12-11 14:31:18,011 [trainer.py] => fixed_memory: True
2025-12-11 14:31:18,011 [trainer.py] => shuffle: False
2025-12-11 14:31:18,011 [trainer.py] => init_cls: 2
2025-12-11 14:31:18,011 [trainer.py] => increment: 2
2025-12-11 14:31:18,011 [trainer.py] => model_name: InfLoRA
2025-12-11 14:31:18,011 [trainer.py] => net_type: sip
2025-12-11 14:31:18,011 [trainer.py] => embd_dim: 768
2025-12-11 14:31:18,011 [trainer.py] => num_heads: 12
2025-12-11 14:31:18,011 [trainer.py] => total_sessions: 50
2025-12-11 14:31:18,011 [trainer.py] => seed: 42
2025-12-11 14:31:18,011 [trainer.py] => EPSILON: 1e-08
2025-12-11 14:31:18,012 [trainer.py] => init_epoch: 20
2025-12-11 14:31:18,012 [trainer.py] => optim: adam
2025-12-11 14:31:18,012 [trainer.py] => init_lr: 0.0005
2025-12-11 14:31:18,012 [trainer.py] => init_lr_decay: 0.1
2025-12-11 14:31:18,012 [trainer.py] => init_weight_decay: 0.0
2025-12-11 14:31:18,012 [trainer.py] => epochs: 20
2025-12-11 14:31:18,012 [trainer.py] => lrate: 0.0005
2025-12-11 14:31:18,012 [trainer.py] => lrate_decay: 0.1
2025-12-11 14:31:18,012 [trainer.py] => batch_size: 128
2025-12-11 14:31:18,012 [trainer.py] => weight_decay: 0.0
2025-12-11 14:31:18,012 [trainer.py] => rank: 10
2025-12-11 14:31:18,012 [trainer.py] => lamb: 0.95
2025-12-11 14:31:18,012 [trainer.py] => lame: 1.0
2025-12-11 14:31:18,012 [trainer.py] => num_workers: 8
2025-12-11 14:31:18,012 [trainer.py] => use_wncm: True
2025-12-11 14:31:18,012 [trainer.py] => wncm_lambda: 0.07
2025-12-11 14:31:19,859 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
Loading ViT weights from local checkpoint: /leonardo/home/userexternal/lli00001/vit_b16_in21k.pth
Loaded 152 keys, missing 2402, unexpected 0
2025-12-11 14:31:22,117 [whitened_ncm_head.py] => WhitenedNCM: Using CPU
2025-12-11 14:31:22,124 [trainer.py] => All params: 125940251
2025-12-11 14:31:22,131 [trainer.py] => Trainable params: 125940251
2025-12-11 14:31:22,131 [inflora.py] => Learning on 0-2
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight'}
2025-12-11 14:33:28,298 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.009, Train_accy 99.50
Threshold:  0.95
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 6/768 type remove
Layer 2 : 9/768 type remove
Layer 3 : 10/768 type remove
Layer 4 : 10/768 type remove
Layer 5 : 9/768 type remove
Layer 6 : 10/768 type remove
Layer 7 : 12/768 type remove
Layer 8 : 14/768 type remove
Layer 9 : 10/768 type remove
Layer 10 : 5/768 type remove
Layer 11 : 3/768 type remove
Layer 12 : 2/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:33:36,340 [trainer.py] => Time:134.2094783782959
200 200
200 200
2025-12-11 14:33:37,484 [trainer.py] => Time:1.1434664726257324
2025-12-11 14:33:37,484 [inflora.py] => Exemplar size: 0
2025-12-11 14:33:37,484 [trainer.py] => CNN: {'total': np.float64(100.0), '00-01': np.float64(100.0), 'old': 0, 'new': np.float64(100.0)}
2025-12-11 14:33:37,484 [trainer.py] => CNN top1 curve: [np.float64(100.0)]
2025-12-11 14:33:37,484 [trainer.py] => CNN top1 with task curve: [np.float64(100.0)]
2025-12-11 14:33:37,484 [trainer.py] => CNN top1 task curve: [1.0]
2025-12-11 14:33:41,855 [trainer.py] => W-NCM: {'00-01': 100.0}
2025-12-11 14:33:41,855 [trainer.py] => Ave Acc (W-NCM): 100.00%
2025-12-11 14:33:41,855 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 100.00% (best 100.00%)
2025-12-11 14:33:41,855 [trainer.py] => Average forgetting (W-NCM): 0.00% | Max forgetting (W-NCM): 0.00%
2025-12-11 14:33:42,524 [trainer.py] => All params: 125940251
2025-12-11 14:33:42,530 [trainer.py] => Trainable params: 185858
2025-12-11 14:33:42,530 [inflora.py] => Learning on 2-4
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_k.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.19.weight', 'image_encoder.blocks.0.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_v.1.weight', 'image_encoder.blocks.4.attn.lora_B_v.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.13.weight', 'image_encoder.blocks.6.attn.lora_B_k.17.weight', 'image_encoder.blocks.7.attn.lora_B_v.18.weight', 'image_encoder.blocks.9.attn.lora_B_k.19.weight', 'image_encoder.blocks.10.attn.lora_B_v.14.weight', 'image_encoder.blocks.8.attn.lora_B_v.17.weight', 'image_encoder.blocks.8.attn.lora_B_v.19.weight', 'image_encoder.blocks.9.attn.lora_B_k.11.weight', 'image_encoder.blocks.4.attn.lora_B_k.11.weight', 'image_encoder.blocks.5.attn.lora_B_v.18.weight', 'image_encoder.blocks.7.attn.lora_B_k.18.weight', 'image_encoder.blocks.3.attn.lora_B_v.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.12.weight', 'image_encoder.blocks.4.attn.lora_B_v.17.weight', 'image_encoder.blocks.10.attn.lora_B_k.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_v.17.weight', 'image_encoder.blocks.9.attn.lora_B_k.14.weight', 'image_encoder.blocks.7.attn.lora_B_v.16.weight', 'image_encoder.blocks.10.attn.lora_B_k.11.weight', 'image_encoder.blocks.11.attn.lora_B_v.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_v.14.weight', 'image_encoder.blocks.6.attn.lora_B_k.14.weight', 'image_encoder.blocks.9.attn.lora_B_v.16.weight', 'image_encoder.blocks.5.attn.lora_B_v.16.weight', 'image_encoder.blocks.9.attn.lora_B_v.10.weight', 'image_encoder.blocks.11.attn.lora_B_v.18.weight', 'image_encoder.blocks.2.attn.lora_B_v.19.weight', 'image_encoder.blocks.6.attn.lora_B_k.16.weight', 'image_encoder.blocks.9.attn.lora_B_k.17.weight', 'image_encoder.blocks.10.attn.lora_B_v.12.weight', 'image_encoder.blocks.9.attn.lora_B_v.1.weight', 'image_encoder.blocks.1.attn.lora_B_v.16.weight', 'image_encoder.blocks.0.attn.lora_B_k.10.weight', 'image_encoder.blocks.4.attn.lora_B_k.18.weight', 'image_encoder.blocks.7.attn.lora_B_v.12.weight', 'image_encoder.blocks.3.attn.lora_B_k.14.weight', 'image_encoder.blocks.5.attn.lora_B_k.14.weight', 'image_encoder.blocks.6.attn.lora_B_k.19.weight', 'image_encoder.blocks.8.attn.lora_B_k.10.weight', 'image_encoder.blocks.1.attn.lora_B_v.14.weight', 'image_encoder.blocks.11.attn.lora_B_k.11.weight', 'image_encoder.blocks.1.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_v.13.weight', 'image_encoder.blocks.7.attn.lora_B_v.15.weight', 'image_encoder.blocks.2.attn.lora_B_k.12.weight', 'image_encoder.blocks.3.attn.lora_B_v.1.weight', 'image_encoder.blocks.9.attn.lora_B_k.16.weight', 'image_encoder.blocks.10.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.17.weight', 'image_encoder.blocks.2.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_k.17.weight', 'image_encoder.blocks.11.attn.lora_B_v.13.weight', 'image_encoder.blocks.0.attn.lora_B_v.19.weight', 'classifier_pool.14.bias', 'classifier_pool.16.weight', 'classifier_pool.11.bias', 'image_encoder.blocks.10.attn.lora_B_k.10.weight', 'image_encoder.blocks.1.attn.lora_B_k.14.weight', 'image_encoder.blocks.5.attn.lora_B_v.11.weight', 'image_encoder.blocks.7.attn.lora_B_k.11.weight', 'image_encoder.blocks.5.attn.lora_B_k.16.weight', 'classifier_pool.17.weight', 'image_encoder.blocks.0.attn.lora_B_k.12.weight', 'image_encoder.blocks.2.attn.lora_B_k.1.weight', 'classifier_pool.12.weight', 'image_encoder.blocks.11.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_v.10.weight', 'image_encoder.blocks.2.attn.lora_B_k.13.weight', 'image_encoder.blocks.9.attn.lora_B_k.15.weight', 'image_encoder.blocks.6.attn.lora_B_v.13.weight', 'classifier_pool.14.weight', 'image_encoder.blocks.6.attn.lora_B_v.12.weight', 'image_encoder.blocks.6.attn.lora_B_k.15.weight', 'image_encoder.blocks.1.attn.lora_B_v.12.weight', 'image_encoder.blocks.2.attn.lora_B_v.1.weight', 'classifier_pool.12.bias', 'image_encoder.blocks.1.attn.lora_B_v.13.weight', 'image_encoder.blocks.10.attn.lora_B_k.15.weight', 'image_encoder.blocks.1.attn.lora_B_k.16.weight', 'image_encoder.blocks.4.attn.lora_B_k.15.weight', 'image_encoder.blocks.9.attn.lora_B_k.13.weight', 'image_encoder.blocks.2.attn.lora_B_k.19.weight', 'classifier_pool.15.weight', 'image_encoder.blocks.3.attn.lora_B_k.16.weight', 'classifier_pool.18.weight', 'image_encoder.blocks.9.attn.lora_B_v.12.weight', 'classifier_pool.1.bias', 'image_encoder.blocks.3.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_v.19.weight', 'image_encoder.blocks.2.attn.lora_B_v.15.weight', 'image_encoder.blocks.0.attn.lora_B_v.1.weight', 'image_encoder.blocks.5.attn.lora_B_k.19.weight', 'image_encoder.blocks.4.attn.lora_B_v.14.weight', 'image_encoder.blocks.8.attn.lora_B_v.11.weight', 'image_encoder.blocks.8.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_k.1.weight', 'image_encoder.blocks.9.attn.lora_B_k.18.weight', 'image_encoder.blocks.11.attn.lora_B_k.10.weight', 'image_encoder.blocks.1.attn.lora_B_k.13.weight', 'image_encoder.blocks.7.attn.lora_B_v.19.weight', 'image_encoder.blocks.3.attn.lora_B_v.15.weight', 'image_encoder.blocks.1.attn.lora_B_v.18.weight', 'image_encoder.blocks.8.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_k.12.weight', 'image_encoder.blocks.0.attn.lora_B_k.17.weight', 'image_encoder.blocks.1.attn.lora_B_v.11.weight', 'image_encoder.blocks.0.attn.lora_B_v.15.weight', 'classifier_pool.10.bias', 'image_encoder.blocks.10.attn.lora_B_k.18.weight', 'image_encoder.blocks.6.attn.lora_B_k.10.weight', 'image_encoder.blocks.2.attn.lora_B_k.15.weight', 'image_encoder.blocks.6.attn.lora_B_v.16.weight', 'classifier_pool.16.bias', 'image_encoder.blocks.1.attn.lora_B_v.10.weight', 'image_encoder.blocks.9.attn.lora_B_k.1.weight', 'image_encoder.blocks.0.attn.lora_B_v.13.weight', 'image_encoder.blocks.0.attn.lora_B_v.18.weight', 'image_encoder.blocks.7.attn.lora_B_v.14.weight', 'image_encoder.blocks.0.attn.lora_B_v.12.weight', 'image_encoder.blocks.4.attn.lora_B_k.16.weight', 'image_encoder.blocks.5.attn.lora_B_k.15.weight', 'image_encoder.blocks.8.attn.lora_B_v.18.weight', 'image_encoder.blocks.10.attn.lora_B_v.15.weight', 'classifier_pool.18.bias', 'image_encoder.blocks.8.attn.lora_B_v.12.weight', 'image_encoder.blocks.3.attn.lora_B_v.14.weight', 'image_encoder.blocks.7.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.14.weight', 'image_encoder.blocks.11.attn.lora_B_k.17.weight', 'classifier_pool.19.bias', 'image_encoder.blocks.2.attn.lora_B_k.10.weight', 'image_encoder.blocks.6.attn.lora_B_k.12.weight', 'image_encoder.blocks.7.attn.lora_B_k.15.weight', 'image_encoder.blocks.10.attn.lora_B_v.19.weight', 'image_encoder.blocks.11.attn.lora_B_k.1.weight', 'image_encoder.blocks.4.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_v.17.weight', 'image_encoder.blocks.2.attn.lora_B_v.13.weight', 'image_encoder.blocks.4.attn.lora_B_v.10.weight', 'image_encoder.blocks.5.attn.lora_B_v.10.weight', 'image_encoder.blocks.4.attn.lora_B_v.15.weight', 'image_encoder.blocks.11.attn.lora_B_v.19.weight', 'image_encoder.blocks.6.attn.lora_B_k.11.weight', 'image_encoder.blocks.8.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_v.10.weight', 'image_encoder.blocks.0.attn.lora_B_k.19.weight', 'image_encoder.blocks.5.attn.lora_B_v.15.weight', 'image_encoder.blocks.10.attn.lora_B_k.14.weight', 'classifier_pool.17.bias', 'image_encoder.blocks.3.attn.lora_B_k.11.weight', 'image_encoder.blocks.1.attn.lora_B_k.11.weight', 'image_encoder.blocks.2.attn.lora_B_v.11.weight', 'image_encoder.blocks.9.attn.lora_B_v.19.weight', 'image_encoder.blocks.4.attn.lora_B_v.12.weight', 'image_encoder.blocks.8.attn.lora_B_k.15.weight', 'classifier_pool.13.weight', 'image_encoder.blocks.4.attn.lora_B_k.17.weight', 'image_encoder.blocks.3.attn.lora_B_k.15.weight', 'image_encoder.blocks.5.attn.lora_B_k.1.weight', 'image_encoder.blocks.8.attn.lora_B_v.15.weight', 'classifier_pool.11.weight', 'classifier_pool.13.bias', 'image_encoder.blocks.7.attn.lora_B_v.1.weight', 'image_encoder.blocks.7.attn.lora_B_v.11.weight', 'image_encoder.blocks.10.attn.lora_B_k.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.1.weight', 'image_encoder.blocks.1.attn.lora_B_k.18.weight', 'image_encoder.blocks.8.attn.lora_B_v.13.weight', 'image_encoder.blocks.2.attn.lora_B_k.17.weight', 'image_encoder.blocks.2.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_k.13.weight', 'image_encoder.blocks.6.attn.lora_B_v.17.weight', 'image_encoder.blocks.8.attn.lora_B_k.13.weight', 'image_encoder.blocks.9.attn.lora_B_v.13.weight', 'image_encoder.blocks.9.attn.lora_B_v.15.weight', 'image_encoder.blocks.0.attn.lora_B_k.14.weight', 'image_encoder.blocks.1.attn.lora_B_v.15.weight', 'image_encoder.blocks.6.attn.lora_B_v.19.weight', 'image_encoder.blocks.10.attn.lora_B_v.16.weight', 'image_encoder.blocks.0.attn.lora_B_k.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.19.weight', 'image_encoder.blocks.7.attn.lora_B_k.12.weight', 'image_encoder.blocks.5.attn.lora_B_v.17.weight', 'image_encoder.blocks.3.attn.lora_B_k.18.weight', 'image_encoder.blocks.8.attn.lora_B_k.11.weight', 'image_encoder.blocks.0.attn.lora_B_v.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.16.weight', 'image_encoder.blocks.6.attn.lora_B_v.18.weight', 'image_encoder.blocks.6.attn.lora_B_v.11.weight', 'image_encoder.blocks.9.attn.lora_B_k.10.weight', 'image_encoder.blocks.5.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_k.14.weight', 'image_encoder.blocks.6.attn.lora_B_v.15.weight', 'image_encoder.blocks.8.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.11.weight', 'image_encoder.blocks.9.attn.lora_B_v.17.weight', 'image_encoder.blocks.10.attn.lora_B_v.10.weight', 'image_encoder.blocks.11.attn.lora_B_k.12.weight', 'image_encoder.blocks.11.attn.lora_B_v.12.weight', 'image_encoder.blocks.0.attn.lora_B_k.18.weight', 'image_encoder.blocks.0.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_v.18.weight', 'image_encoder.blocks.1.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_v.16.weight', 'image_encoder.blocks.8.attn.lora_B_k.18.weight', 'image_encoder.blocks.10.attn.lora_B_v.13.weight', 'image_encoder.blocks.2.attn.lora_B_v.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.17.weight', 'image_encoder.blocks.3.attn.lora_B_k.10.weight', 'image_encoder.blocks.4.attn.lora_B_k.10.weight', 'image_encoder.blocks.3.attn.lora_B_v.18.weight', 'image_encoder.blocks.10.attn.lora_B_k.17.weight', 'image_encoder.blocks.2.attn.lora_B_k.18.weight', 'image_encoder.blocks.11.attn.lora_B_v.14.weight', 'image_encoder.blocks.3.attn.lora_B_k.19.weight', 'image_encoder.blocks.1.attn.lora_B_v.19.weight', 'image_encoder.blocks.0.attn.lora_B_k.11.weight', 'image_encoder.blocks.1.attn.lora_B_v.17.weight', 'image_encoder.blocks.6.attn.lora_B_k.13.weight', 'image_encoder.blocks.6.attn.lora_B_k.18.weight', 'image_encoder.blocks.7.attn.lora_B_k.14.weight', 'image_encoder.blocks.3.attn.lora_B_v.12.weight', 'image_encoder.blocks.9.attn.lora_B_v.11.weight', 'image_encoder.blocks.5.attn.lora_B_k.11.weight', 'image_encoder.blocks.10.attn.lora_B_k.19.weight', 'image_encoder.blocks.10.attn.lora_B_v.11.weight', 'image_encoder.blocks.11.attn.lora_B_k.15.weight', 'image_encoder.blocks.1.attn.lora_B_k.12.weight', 'image_encoder.blocks.6.attn.lora_B_v.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.14.weight', 'image_encoder.blocks.3.attn.lora_B_v.16.weight', 'image_encoder.blocks.10.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_k.16.weight', 'image_encoder.blocks.4.attn.lora_B_k.19.weight', 'image_encoder.blocks.7.attn.lora_B_k.10.weight', 'classifier_pool.10.weight', 'image_encoder.blocks.5.attn.lora_B_k.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.18.weight', 'image_encoder.blocks.3.attn.lora_B_k.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.13.weight', 'image_encoder.blocks.1.attn.lora_B_k.15.weight', 'classifier_pool.1.weight', 'image_encoder.blocks.7.attn.lora_B_v.10.weight', 'image_encoder.blocks.3.attn.lora_B_k.13.weight', 'image_encoder.blocks.0.attn.lora_B_k.15.weight', 'image_encoder.blocks.5.attn.lora_B_k.10.weight', 'image_encoder.blocks.2.attn.lora_B_v.12.weight', 'image_encoder.blocks.7.attn.lora_B_k.13.weight', 'image_encoder.blocks.2.attn.lora_B_k.16.weight', 'image_encoder.blocks.7.attn.lora_B_k.19.weight', 'image_encoder.blocks.9.attn.lora_B_v.18.weight', 'classifier_pool.15.bias', 'image_encoder.blocks.5.attn.lora_B_v.14.weight', 'image_encoder.blocks.5.attn.lora_B_v.1.weight', 'image_encoder.blocks.8.attn.lora_B_v.16.weight', 'image_encoder.blocks.7.attn.lora_B_v.17.weight', 'image_encoder.blocks.2.attn.lora_B_v.18.weight', 'image_encoder.blocks.8.attn.lora_B_k.12.weight', 'image_encoder.blocks.8.attn.lora_B_v.10.weight', 'image_encoder.blocks.10.attn.lora_B_k.12.weight', 'image_encoder.blocks.11.attn.lora_B_v.15.weight', 'classifier_pool.19.weight', 'image_encoder.blocks.9.attn.lora_B_v.14.weight', 'image_encoder.blocks.4.attn.lora_B_v.11.weight', 'image_encoder.blocks.2.attn.lora_B_k.14.weight', 'image_encoder.blocks.11.attn.lora_B_k.13.weight', 'image_encoder.blocks.2.attn.lora_B_v.16.weight', 'image_encoder.blocks.7.attn.lora_B_k.16.weight', 'image_encoder.blocks.1.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.18.weight', 'image_encoder.blocks.3.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_k.1.weight', 'image_encoder.blocks.1.attn.lora_B_k.10.weight', 'image_encoder.blocks.5.attn.lora_B_k.12.weight', 'image_encoder.blocks.5.attn.lora_B_v.12.weight', 'image_encoder.blocks.11.attn.lora_B_v.16.weight', 'image_encoder.blocks.9.attn.lora_B_k.12.weight', 'image_encoder.blocks.8.attn.lora_B_k.1.weight', 'image_encoder.blocks.5.attn.lora_B_k.18.weight'}
2025-12-11 14:35:47,137 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.023, Train_accy 99.00
Threshold:  0.951
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 13/768 type remove
Layer 4 : 13/768 type remove
Layer 5 : 11/768 type remove
Layer 6 : 14/768 type remove
Layer 7 : 17/768 type remove
Layer 8 : 22/768 type remove
Layer 9 : 20/768 type remove
Layer 10 : 14/768 type remove
Layer 11 : 7/768 type remove
Layer 12 : 7/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:35:56,711 [trainer.py] => Time:134.1814193725586
400 400
400 400
2025-12-11 14:35:58,307 [trainer.py] => Time:1.5952627658843994
2025-12-11 14:35:58,307 [inflora.py] => Exemplar size: 0
2025-12-11 14:35:58,307 [trainer.py] => CNN: {'total': np.float64(98.25), '00-01': np.float64(100.0), '02-03': np.float64(96.5), 'old': np.float64(100.0), 'new': np.float64(96.5)}
2025-12-11 14:35:58,307 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25)]
2025-12-11 14:35:58,307 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0)]
2025-12-11 14:35:58,307 [trainer.py] => CNN top1 task curve: [1.0, 0.9825]
2025-12-11 14:36:03,193 [trainer.py] => W-NCM: {'00-01': 100.0, '02-03': 100.0}
2025-12-11 14:36:03,193 [trainer.py] => Ave Acc (W-NCM): 100.00%
2025-12-11 14:36:03,193 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 100.00% (best 100.00%); T2: W-NCM 100.00% (best 100.00%)
2025-12-11 14:36:03,193 [trainer.py] => Average forgetting (W-NCM): 0.00% | Max forgetting (W-NCM): 0.00%
2025-12-11 14:36:03,904 [trainer.py] => All params: 125940251
2025-12-11 14:36:03,910 [trainer.py] => Trainable params: 2044438
2025-12-11 14:36:03,910 [inflora.py] => Learning on 4-6
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.26.weight', 'image_encoder.blocks.1.attn.lora_B_v.2.weight', 'image_encoder.blocks.11.attn.lora_B_v.25.weight', 'image_encoder.blocks.9.attn.lora_B_v.24.weight', 'image_encoder.blocks.3.attn.lora_B_v.21.weight', 'image_encoder.blocks.2.attn.lora_B_v.24.weight', 'image_encoder.blocks.7.attn.lora_B_k.25.weight', 'image_encoder.blocks.5.attn.lora_B_k.2.weight', 'image_encoder.blocks.7.attn.lora_B_k.22.weight', 'image_encoder.blocks.10.attn.lora_B_k.27.weight', 'image_encoder.blocks.10.attn.lora_B_v.21.weight', 'image_encoder.blocks.10.attn.lora_B_v.23.weight', 'image_encoder.blocks.1.attn.lora_B_k.20.weight', 'image_encoder.blocks.0.attn.lora_B_v.28.weight', 'image_encoder.blocks.9.attn.lora_B_k.29.weight', 'image_encoder.blocks.1.attn.lora_B_k.27.weight', 'image_encoder.blocks.11.attn.lora_B_k.25.weight', 'classifier_pool.22.bias', 'image_encoder.blocks.10.attn.lora_B_k.23.weight', 'classifier_pool.22.weight', 'image_encoder.blocks.0.attn.lora_B_k.2.weight', 'image_encoder.blocks.1.attn.lora_B_v.28.weight', 'image_encoder.blocks.8.attn.lora_B_k.29.weight', 'image_encoder.blocks.11.attn.lora_B_k.27.weight', 'classifier_pool.26.weight', 'classifier_pool.20.bias', 'image_encoder.blocks.10.attn.lora_B_k.24.weight', 'image_encoder.blocks.3.attn.lora_B_v.2.weight', 'image_encoder.blocks.4.attn.lora_B_k.20.weight', 'image_encoder.blocks.7.attn.lora_B_k.27.weight', 'image_encoder.blocks.8.attn.lora_B_k.26.weight', 'image_encoder.blocks.8.attn.lora_B_k.27.weight', 'image_encoder.blocks.9.attn.lora_B_v.23.weight', 'image_encoder.blocks.4.attn.lora_B_k.2.weight', 'classifier_pool.27.weight', 'image_encoder.blocks.7.attn.lora_B_v.28.weight', 'classifier_pool.28.weight', 'image_encoder.blocks.0.attn.lora_B_v.23.weight', 'image_encoder.blocks.2.attn.lora_B_k.25.weight', 'image_encoder.blocks.7.attn.lora_B_k.28.weight', 'image_encoder.blocks.8.attn.lora_B_v.29.weight', 'image_encoder.blocks.6.attn.lora_B_k.24.weight', 'image_encoder.blocks.9.attn.lora_B_v.26.weight', 'classifier_pool.21.weight', 'image_encoder.blocks.6.attn.lora_B_v.27.weight', 'classifier_pool.21.bias', 'image_encoder.blocks.9.attn.lora_B_k.21.weight', 'image_encoder.blocks.4.attn.lora_B_v.29.weight', 'image_encoder.blocks.11.attn.lora_B_v.26.weight', 'image_encoder.blocks.6.attn.lora_B_k.21.weight', 'image_encoder.blocks.2.attn.lora_B_k.21.weight', 'image_encoder.blocks.11.attn.lora_B_k.29.weight', 'image_encoder.blocks.6.attn.lora_B_k.23.weight', 'image_encoder.blocks.4.attn.lora_B_v.22.weight', 'image_encoder.blocks.3.attn.lora_B_v.22.weight', 'image_encoder.blocks.5.attn.lora_B_v.26.weight', 'image_encoder.blocks.7.attn.lora_B_v.29.weight', 'image_encoder.blocks.6.attn.lora_B_k.27.weight', 'image_encoder.blocks.1.attn.lora_B_k.21.weight', 'image_encoder.blocks.10.attn.lora_B_k.22.weight', 'image_encoder.blocks.9.attn.lora_B_k.2.weight', 'image_encoder.blocks.10.attn.lora_B_k.21.weight', 'image_encoder.blocks.7.attn.lora_B_k.21.weight', 'image_encoder.blocks.9.attn.lora_B_v.29.weight', 'image_encoder.blocks.1.attn.lora_B_k.28.weight', 'image_encoder.blocks.1.attn.lora_B_v.24.weight', 'image_encoder.blocks.8.attn.lora_B_k.28.weight', 'image_encoder.blocks.8.attn.lora_B_v.23.weight', 'image_encoder.blocks.6.attn.lora_B_k.29.weight', 'image_encoder.blocks.10.attn.lora_B_k.20.weight', 'image_encoder.blocks.4.attn.lora_B_v.25.weight', 'image_encoder.blocks.0.attn.lora_B_v.20.weight', 'image_encoder.blocks.3.attn.lora_B_k.25.weight', 'image_encoder.blocks.1.attn.lora_B_v.27.weight', 'image_encoder.blocks.3.attn.lora_B_v.26.weight', 'image_encoder.blocks.8.attn.lora_B_k.24.weight', 'image_encoder.blocks.8.attn.lora_B_v.27.weight', 'image_encoder.blocks.1.attn.lora_B_k.26.weight', 'image_encoder.blocks.10.attn.lora_B_k.29.weight', 'image_encoder.blocks.6.attn.lora_B_k.26.weight', 'image_encoder.blocks.9.attn.lora_B_k.23.weight', 'image_encoder.blocks.4.attn.lora_B_v.23.weight', 'image_encoder.blocks.7.attn.lora_B_v.24.weight', 'image_encoder.blocks.2.attn.lora_B_k.29.weight', 'image_encoder.blocks.3.attn.lora_B_k.23.weight', 'image_encoder.blocks.4.attn.lora_B_v.26.weight', 'image_encoder.blocks.5.attn.lora_B_v.25.weight', 'image_encoder.blocks.7.attn.lora_B_v.21.weight', 'image_encoder.blocks.9.attn.lora_B_k.22.weight', 'image_encoder.blocks.5.attn.lora_B_k.23.weight', 'image_encoder.blocks.10.attn.lora_B_v.2.weight', 'image_encoder.blocks.10.attn.lora_B_v.25.weight', 'image_encoder.blocks.2.attn.lora_B_k.20.weight', 'image_encoder.blocks.3.attn.lora_B_v.24.weight', 'image_encoder.blocks.9.attn.lora_B_v.2.weight', 'classifier_pool.26.bias', 'image_encoder.blocks.0.attn.lora_B_k.25.weight', 'classifier_pool.27.bias', 'classifier_pool.2.bias', 'image_encoder.blocks.9.attn.lora_B_k.27.weight', 'image_encoder.blocks.8.attn.lora_B_k.21.weight', 'image_encoder.blocks.2.attn.lora_B_k.23.weight', 'image_encoder.blocks.1.attn.lora_B_v.29.weight', 'image_encoder.blocks.4.attn.lora_B_k.27.weight', 'image_encoder.blocks.8.attn.lora_B_v.28.weight', 'image_encoder.blocks.11.attn.lora_B_k.21.weight', 'image_encoder.blocks.2.attn.lora_B_v.21.weight', 'image_encoder.blocks.8.attn.lora_B_v.24.weight', 'image_encoder.blocks.0.attn.lora_B_v.27.weight', 'image_encoder.blocks.11.attn.lora_B_k.28.weight', 'image_encoder.blocks.3.attn.lora_B_k.24.weight', 'image_encoder.blocks.4.attn.lora_B_v.21.weight', 'image_encoder.blocks.2.attn.lora_B_k.22.weight', 'image_encoder.blocks.1.attn.lora_B_k.23.weight', 'image_encoder.blocks.3.attn.lora_B_k.20.weight', 'image_encoder.blocks.3.attn.lora_B_v.23.weight', 'image_encoder.blocks.8.attn.lora_B_k.2.weight', 'image_encoder.blocks.0.attn.lora_B_v.29.weight', 'image_encoder.blocks.0.attn.lora_B_k.21.weight', 'image_encoder.blocks.1.attn.lora_B_v.25.weight', 'image_encoder.blocks.9.attn.lora_B_k.25.weight', 'image_encoder.blocks.3.attn.lora_B_v.20.weight', 'image_encoder.blocks.5.attn.lora_B_v.2.weight', 'image_encoder.blocks.9.attn.lora_B_v.20.weight', 'image_encoder.blocks.10.attn.lora_B_k.25.weight', 'image_encoder.blocks.5.attn.lora_B_v.29.weight', 'image_encoder.blocks.2.attn.lora_B_k.24.weight', 'image_encoder.blocks.6.attn.lora_B_v.2.weight', 'image_encoder.blocks.6.attn.lora_B_v.21.weight', 'image_encoder.blocks.8.attn.lora_B_v.25.weight', 'image_encoder.blocks.1.attn.lora_B_k.25.weight', 'image_encoder.blocks.9.attn.lora_B_v.22.weight', 'image_encoder.blocks.2.attn.lora_B_v.27.weight', 'image_encoder.blocks.5.attn.lora_B_k.24.weight', 'image_encoder.blocks.4.attn.lora_B_v.24.weight', 'image_encoder.blocks.0.attn.lora_B_v.21.weight', 'image_encoder.blocks.2.attn.lora_B_v.20.weight', 'image_encoder.blocks.2.attn.lora_B_k.28.weight', 'image_encoder.blocks.2.attn.lora_B_k.26.weight', 'image_encoder.blocks.9.attn.lora_B_k.20.weight', 'image_encoder.blocks.11.attn.lora_B_k.26.weight', 'image_encoder.blocks.3.attn.lora_B_k.28.weight', 'image_encoder.blocks.11.attn.lora_B_v.22.weight', 'image_encoder.blocks.5.attn.lora_B_v.24.weight', 'image_encoder.blocks.9.attn.lora_B_v.21.weight', 'image_encoder.blocks.4.attn.lora_B_v.28.weight', 'image_encoder.blocks.11.attn.lora_B_k.22.weight', 'image_encoder.blocks.11.attn.lora_B_v.24.weight', 'image_encoder.blocks.10.attn.lora_B_v.22.weight', 'classifier_pool.24.weight', 'image_encoder.blocks.4.attn.lora_B_k.23.weight', 'image_encoder.blocks.0.attn.lora_B_v.2.weight', 'image_encoder.blocks.3.attn.lora_B_k.27.weight', 'image_encoder.blocks.0.attn.lora_B_v.26.weight', 'image_encoder.blocks.5.attn.lora_B_v.21.weight', 'classifier_pool.25.bias', 'image_encoder.blocks.2.attn.lora_B_k.2.weight', 'image_encoder.blocks.9.attn.lora_B_k.28.weight', 'image_encoder.blocks.1.attn.lora_B_v.20.weight', 'image_encoder.blocks.4.attn.lora_B_k.28.weight', 'image_encoder.blocks.2.attn.lora_B_v.25.weight', 'image_encoder.blocks.2.attn.lora_B_v.23.weight', 'image_encoder.blocks.5.attn.lora_B_k.29.weight', 'image_encoder.blocks.7.attn.lora_B_k.23.weight', 'image_encoder.blocks.1.attn.lora_B_k.24.weight', 'image_encoder.blocks.11.attn.lora_B_v.28.weight', 'image_encoder.blocks.10.attn.lora_B_v.24.weight', 'image_encoder.blocks.11.attn.lora_B_v.23.weight', 'classifier_pool.23.bias', 'image_encoder.blocks.6.attn.lora_B_v.28.weight', 'classifier_pool.29.bias', 'image_encoder.blocks.0.attn.lora_B_k.24.weight', 'image_encoder.blocks.9.attn.lora_B_v.27.weight', 'image_encoder.blocks.11.attn.lora_B_k.20.weight', 'image_encoder.blocks.8.attn.lora_B_k.22.weight', 'image_encoder.blocks.7.attn.lora_B_v.20.weight', 'image_encoder.blocks.7.attn.lora_B_v.22.weight', 'image_encoder.blocks.11.attn.lora_B_v.21.weight', 'image_encoder.blocks.7.attn.lora_B_v.26.weight', 'image_encoder.blocks.3.attn.lora_B_k.22.weight', 'image_encoder.blocks.2.attn.lora_B_v.22.weight', 'image_encoder.blocks.6.attn.lora_B_k.25.weight', 'image_encoder.blocks.6.attn.lora_B_v.26.weight', 'image_encoder.blocks.8.attn.lora_B_k.23.weight', 'image_encoder.blocks.3.attn.lora_B_k.21.weight', 'image_encoder.blocks.0.attn.lora_B_k.20.weight', 'image_encoder.blocks.2.attn.lora_B_k.27.weight', 'image_encoder.blocks.2.attn.lora_B_v.28.weight', 'image_encoder.blocks.6.attn.lora_B_k.2.weight', 'image_encoder.blocks.11.attn.lora_B_k.24.weight', 'image_encoder.blocks.7.attn.lora_B_k.20.weight', 'image_encoder.blocks.11.attn.lora_B_v.2.weight', 'classifier_pool.25.weight', 'image_encoder.blocks.1.attn.lora_B_v.21.weight', 'image_encoder.blocks.5.attn.lora_B_k.26.weight', 'image_encoder.blocks.7.attn.lora_B_k.29.weight', 'image_encoder.blocks.7.attn.lora_B_k.24.weight', 'image_encoder.blocks.5.attn.lora_B_k.20.weight', 'image_encoder.blocks.3.attn.lora_B_v.29.weight', 'image_encoder.blocks.1.attn.lora_B_k.29.weight', 'image_encoder.blocks.0.attn.lora_B_k.22.weight', 'image_encoder.blocks.5.attn.lora_B_v.28.weight', 'image_encoder.blocks.6.attn.lora_B_v.20.weight', 'image_encoder.blocks.7.attn.lora_B_k.26.weight', 'image_encoder.blocks.8.attn.lora_B_v.22.weight', 'image_encoder.blocks.2.attn.lora_B_v.29.weight', 'image_encoder.blocks.5.attn.lora_B_k.21.weight', 'image_encoder.blocks.4.attn.lora_B_v.20.weight', 'classifier_pool.2.weight', 'image_encoder.blocks.9.attn.lora_B_v.25.weight', 'image_encoder.blocks.0.attn.lora_B_k.26.weight', 'image_encoder.blocks.6.attn.lora_B_v.22.weight', 'image_encoder.blocks.10.attn.lora_B_v.27.weight', 'image_encoder.blocks.4.attn.lora_B_k.24.weight', 'image_encoder.blocks.5.attn.lora_B_v.27.weight', 'image_encoder.blocks.3.attn.lora_B_k.2.weight', 'image_encoder.blocks.8.attn.lora_B_v.2.weight', 'classifier_pool.20.weight', 'classifier_pool.28.bias', 'image_encoder.blocks.5.attn.lora_B_k.27.weight', 'image_encoder.blocks.1.attn.lora_B_v.23.weight', 'image_encoder.blocks.6.attn.lora_B_v.24.weight', 'image_encoder.blocks.7.attn.lora_B_v.23.weight', 'classifier_pool.29.weight', 'image_encoder.blocks.8.attn.lora_B_v.26.weight', 'image_encoder.blocks.3.attn.lora_B_v.28.weight', 'image_encoder.blocks.11.attn.lora_B_v.27.weight', 'image_encoder.blocks.0.attn.lora_B_k.29.weight', 'image_encoder.blocks.11.attn.lora_B_v.29.weight', 'image_encoder.blocks.3.attn.lora_B_k.29.weight', 'image_encoder.blocks.8.attn.lora_B_k.25.weight', 'image_encoder.blocks.9.attn.lora_B_v.28.weight', 'image_encoder.blocks.10.attn.lora_B_v.26.weight', 'classifier_pool.23.weight', 'image_encoder.blocks.0.attn.lora_B_k.28.weight', 'image_encoder.blocks.4.attn.lora_B_k.21.weight', 'image_encoder.blocks.6.attn.lora_B_k.22.weight', 'image_encoder.blocks.5.attn.lora_B_k.22.weight', 'classifier_pool.24.bias', 'image_encoder.blocks.11.attn.lora_B_v.20.weight', 'image_encoder.blocks.9.attn.lora_B_k.26.weight', 'image_encoder.blocks.1.attn.lora_B_v.26.weight', 'image_encoder.blocks.3.attn.lora_B_v.25.weight', 'image_encoder.blocks.4.attn.lora_B_k.29.weight', 'image_encoder.blocks.5.attn.lora_B_v.20.weight', 'image_encoder.blocks.8.attn.lora_B_k.20.weight', 'image_encoder.blocks.4.attn.lora_B_k.25.weight', 'image_encoder.blocks.1.attn.lora_B_k.22.weight', 'image_encoder.blocks.3.attn.lora_B_k.26.weight', 'image_encoder.blocks.5.attn.lora_B_k.28.weight', 'image_encoder.blocks.4.attn.lora_B_v.27.weight', 'image_encoder.blocks.5.attn.lora_B_v.22.weight', 'image_encoder.blocks.0.attn.lora_B_v.25.weight', 'image_encoder.blocks.5.attn.lora_B_v.23.weight', 'image_encoder.blocks.6.attn.lora_B_v.23.weight', 'image_encoder.blocks.7.attn.lora_B_v.27.weight', 'image_encoder.blocks.2.attn.lora_B_v.26.weight', 'image_encoder.blocks.9.attn.lora_B_k.24.weight', 'image_encoder.blocks.10.attn.lora_B_v.28.weight', 'image_encoder.blocks.0.attn.lora_B_v.24.weight', 'image_encoder.blocks.4.attn.lora_B_v.2.weight', 'image_encoder.blocks.8.attn.lora_B_v.21.weight', 'image_encoder.blocks.10.attn.lora_B_v.20.weight', 'image_encoder.blocks.10.attn.lora_B_k.2.weight', 'image_encoder.blocks.2.attn.lora_B_v.2.weight', 'image_encoder.blocks.1.attn.lora_B_k.2.weight', 'image_encoder.blocks.6.attn.lora_B_v.25.weight', 'image_encoder.blocks.0.attn.lora_B_k.23.weight', 'image_encoder.blocks.10.attn.lora_B_v.29.weight', 'image_encoder.blocks.7.attn.lora_B_v.25.weight', 'image_encoder.blocks.6.attn.lora_B_k.20.weight', 'image_encoder.blocks.5.attn.lora_B_k.25.weight', 'image_encoder.blocks.6.attn.lora_B_k.28.weight', 'image_encoder.blocks.10.attn.lora_B_k.26.weight', 'image_encoder.blocks.4.attn.lora_B_k.22.weight', 'image_encoder.blocks.7.attn.lora_B_v.2.weight', 'image_encoder.blocks.11.attn.lora_B_k.2.weight', 'image_encoder.blocks.6.attn.lora_B_v.29.weight', 'image_encoder.blocks.0.attn.lora_B_v.22.weight', 'image_encoder.blocks.10.attn.lora_B_k.28.weight', 'image_encoder.blocks.8.attn.lora_B_v.20.weight', 'image_encoder.blocks.0.attn.lora_B_k.27.weight', 'image_encoder.blocks.7.attn.lora_B_k.2.weight', 'image_encoder.blocks.11.attn.lora_B_k.23.weight', 'image_encoder.blocks.3.attn.lora_B_v.27.weight', 'image_encoder.blocks.1.attn.lora_B_v.22.weight'}
2025-12-11 14:38:08,685 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.019, Train_accy 99.10
Threshold:  0.952
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 14/768 type remove
Layer 4 : 14/768 type remove
Layer 5 : 14/768 type remove
Layer 6 : 17/768 type remove
Layer 7 : 20/768 type remove
Layer 8 : 27/768 type remove
Layer 9 : 25/768 type remove
Layer 10 : 19/768 type remove
Layer 11 : 9/768 type remove
Layer 12 : 10/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:38:18,497 [trainer.py] => Time:134.58655285835266
600 600
600 600
2025-12-11 14:38:20,615 [trainer.py] => Time:2.1183905601501465
2025-12-11 14:38:20,616 [inflora.py] => Exemplar size: 0
2025-12-11 14:38:20,616 [trainer.py] => CNN: {'total': np.float64(92.83), '00-01': np.float64(99.5), '02-03': np.float64(90.0), '04-05': np.float64(89.0), 'old': np.float64(94.75), 'new': np.float64(89.0)}
2025-12-11 14:38:20,616 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83)]
2025-12-11 14:38:20,616 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0)]
2025-12-11 14:38:20,616 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333]
2025-12-11 14:38:26,090 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 87.5, '04-05': 100.0}
2025-12-11 14:38:26,090 [trainer.py] => Ave Acc (W-NCM): 95.67%
2025-12-11 14:38:26,090 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 87.50% (best 100.00%); T3: W-NCM 100.00% (best 100.00%)
2025-12-11 14:38:26,090 [trainer.py] => Average forgetting (W-NCM): 6.50% | Max forgetting (W-NCM): 12.50%
2025-12-11 14:38:27,332 [trainer.py] => All params: 125940251
2025-12-11 14:38:27,338 [trainer.py] => Trainable params: 2044438
2025-12-11 14:38:27,338 [inflora.py] => Learning on 6-8
Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_v.38.weight', 'image_encoder.blocks.11.attn.lora_B_k.37.weight', 'image_encoder.blocks.11.attn.lora_B_v.39.weight', 'image_encoder.blocks.6.attn.lora_B_k.37.weight', 'image_encoder.blocks.1.attn.lora_B_v.32.weight', 'image_encoder.blocks.2.attn.lora_B_v.30.weight', 'image_encoder.blocks.5.attn.lora_B_k.34.weight', 'image_encoder.blocks.7.attn.lora_B_v.30.weight', 'classifier_pool.31.weight', 'image_encoder.blocks.11.attn.lora_B_k.34.weight', 'image_encoder.blocks.5.attn.lora_B_k.3.weight', 'image_encoder.blocks.8.attn.lora_B_v.31.weight', 'image_encoder.blocks.9.attn.lora_B_v.33.weight', 'image_encoder.blocks.3.attn.lora_B_v.38.weight', 'image_encoder.blocks.3.attn.lora_B_k.39.weight', 'image_encoder.blocks.5.attn.lora_B_k.33.weight', 'image_encoder.blocks.5.attn.lora_B_k.37.weight', 'image_encoder.blocks.11.attn.lora_B_v.34.weight', 'image_encoder.blocks.7.attn.lora_B_k.37.weight', 'image_encoder.blocks.2.attn.lora_B_v.32.weight', 'image_encoder.blocks.10.attn.lora_B_k.32.weight', 'image_encoder.blocks.6.attn.lora_B_v.31.weight', 'image_encoder.blocks.7.attn.lora_B_k.33.weight', 'image_encoder.blocks.3.attn.lora_B_k.31.weight', 'image_encoder.blocks.9.attn.lora_B_k.35.weight', 'image_encoder.blocks.0.attn.lora_B_k.33.weight', 'image_encoder.blocks.0.attn.lora_B_k.34.weight', 'image_encoder.blocks.1.attn.lora_B_v.35.weight', 'image_encoder.blocks.5.attn.lora_B_k.32.weight', 'image_encoder.blocks.7.attn.lora_B_v.33.weight', 'image_encoder.blocks.4.attn.lora_B_k.34.weight', 'image_encoder.blocks.4.attn.lora_B_k.38.weight', 'image_encoder.blocks.1.attn.lora_B_v.37.weight', 'image_encoder.blocks.8.attn.lora_B_k.34.weight', 'image_encoder.blocks.8.attn.lora_B_v.35.weight', 'image_encoder.blocks.10.attn.lora_B_v.33.weight', 'image_encoder.blocks.3.attn.lora_B_k.33.weight', 'image_encoder.blocks.1.attn.lora_B_k.36.weight', 'classifier_pool.39.bias', 'image_encoder.blocks.1.attn.lora_B_k.30.weight', 'image_encoder.blocks.2.attn.lora_B_k.3.weight', 'image_encoder.blocks.11.attn.lora_B_k.3.weight', 'image_encoder.blocks.6.attn.lora_B_k.35.weight', 'image_encoder.blocks.10.attn.lora_B_v.32.weight', 'image_encoder.blocks.0.attn.lora_B_v.3.weight', 'image_encoder.blocks.5.attn.lora_B_k.38.weight', 'image_encoder.blocks.8.attn.lora_B_v.37.weight', 'image_encoder.blocks.9.attn.lora_B_v.32.weight', 'image_encoder.blocks.11.attn.lora_B_k.32.weight', 'image_encoder.blocks.10.attn.lora_B_k.34.weight', 'image_encoder.blocks.8.attn.lora_B_v.34.weight', 'image_encoder.blocks.0.attn.lora_B_k.31.weight', 'image_encoder.blocks.7.attn.lora_B_k.31.weight', 'image_encoder.blocks.2.attn.lora_B_v.39.weight', 'image_encoder.blocks.8.attn.lora_B_v.39.weight', 'image_encoder.blocks.3.attn.lora_B_k.36.weight', 'image_encoder.blocks.8.attn.lora_B_k.33.weight', 'image_encoder.blocks.8.attn.lora_B_v.33.weight', 'image_encoder.blocks.2.attn.lora_B_v.33.weight', 'image_encoder.blocks.10.attn.lora_B_v.39.weight', 'classifier_pool.38.bias', 'image_encoder.blocks.10.attn.lora_B_k.31.weight', 'image_encoder.blocks.1.attn.lora_B_v.36.weight', 'image_encoder.blocks.0.attn.lora_B_v.36.weight', 'image_encoder.blocks.1.attn.lora_B_k.39.weight', 'classifier_pool.34.weight', 'image_encoder.blocks.6.attn.lora_B_k.32.weight', 'image_encoder.blocks.6.attn.lora_B_v.35.weight', 'image_encoder.blocks.9.attn.lora_B_v.3.weight', 'image_encoder.blocks.0.attn.lora_B_k.39.weight', 'image_encoder.blocks.3.attn.lora_B_k.35.weight', 'image_encoder.blocks.6.attn.lora_B_v.34.weight', 'image_encoder.blocks.9.attn.lora_B_k.38.weight', 'image_encoder.blocks.6.attn.lora_B_v.37.weight', 'image_encoder.blocks.10.attn.lora_B_k.33.weight', 'image_encoder.blocks.0.attn.lora_B_v.34.weight', 'image_encoder.blocks.10.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_v.3.weight', 'image_encoder.blocks.1.attn.lora_B_v.31.weight', 'image_encoder.blocks.4.attn.lora_B_v.36.weight', 'image_encoder.blocks.6.attn.lora_B_k.38.weight', 'image_encoder.blocks.9.attn.lora_B_v.35.weight', 'image_encoder.blocks.11.attn.lora_B_k.36.weight', 'classifier_pool.34.bias', 'image_encoder.blocks.0.attn.lora_B_v.35.weight', 'image_encoder.blocks.2.attn.lora_B_v.31.weight', 'image_encoder.blocks.11.attn.lora_B_v.38.weight', 'image_encoder.blocks.11.attn.lora_B_k.33.weight', 'classifier_pool.31.bias', 'classifier_pool.37.weight', 'image_encoder.blocks.4.attn.lora_B_v.34.weight', 'image_encoder.blocks.10.attn.lora_B_k.3.weight', 'classifier_pool.3.weight', 'image_encoder.blocks.8.attn.lora_B_k.36.weight', 'image_encoder.blocks.4.attn.lora_B_k.39.weight', 'image_encoder.blocks.5.attn.lora_B_v.37.weight', 'image_encoder.blocks.5.attn.lora_B_v.38.weight', 'image_encoder.blocks.4.attn.lora_B_v.30.weight', 'image_encoder.blocks.10.attn.lora_B_k.35.weight', 'image_encoder.blocks.6.attn.lora_B_v.36.weight', 'image_encoder.blocks.9.attn.lora_B_k.36.weight', 'classifier_pool.33.bias', 'image_encoder.blocks.1.attn.lora_B_v.33.weight', 'image_encoder.blocks.9.attn.lora_B_k.34.weight', 'image_encoder.blocks.9.attn.lora_B_k.30.weight', 'classifier_pool.35.weight', 'image_encoder.blocks.0.attn.lora_B_k.37.weight', 'image_encoder.blocks.7.attn.lora_B_k.30.weight', 'image_encoder.blocks.0.attn.lora_B_v.30.weight', 'image_encoder.blocks.5.attn.lora_B_v.32.weight', 'classifier_pool.32.bias', 'image_encoder.blocks.4.attn.lora_B_v.31.weight', 'image_encoder.blocks.2.attn.lora_B_v.36.weight', 'image_encoder.blocks.5.attn.lora_B_v.39.weight', 'image_encoder.blocks.7.attn.lora_B_v.39.weight', 'image_encoder.blocks.4.attn.lora_B_v.39.weight', 'image_encoder.blocks.5.attn.lora_B_v.35.weight', 'image_encoder.blocks.8.attn.lora_B_k.31.weight', 'image_encoder.blocks.7.attn.lora_B_v.35.weight', 'classifier_pool.38.weight', 'image_encoder.blocks.8.attn.lora_B_v.32.weight', 'classifier_pool.30.bias', 'image_encoder.blocks.3.attn.lora_B_v.33.weight', 'image_encoder.blocks.10.attn.lora_B_k.30.weight', 'image_encoder.blocks.4.attn.lora_B_k.37.weight', 'image_encoder.blocks.2.attn.lora_B_k.32.weight', 'image_encoder.blocks.6.attn.lora_B_v.38.weight', 'image_encoder.blocks.11.attn.lora_B_v.3.weight', 'image_encoder.blocks.11.attn.lora_B_v.30.weight', 'image_encoder.blocks.9.attn.lora_B_v.37.weight', 'image_encoder.blocks.4.attn.lora_B_v.33.weight', 'image_encoder.blocks.1.attn.lora_B_k.31.weight', 'image_encoder.blocks.6.attn.lora_B_k.36.weight', 'image_encoder.blocks.10.attn.lora_B_k.37.weight', 'image_encoder.blocks.2.attn.lora_B_v.35.weight', 'image_encoder.blocks.11.attn.lora_B_k.39.weight', 'image_encoder.blocks.8.attn.lora_B_k.39.weight', 'image_encoder.blocks.7.attn.lora_B_k.3.weight', 'image_encoder.blocks.10.attn.lora_B_v.36.weight', 'image_encoder.blocks.7.attn.lora_B_v.32.weight', 'image_encoder.blocks.11.attn.lora_B_v.36.weight', 'image_encoder.blocks.2.attn.lora_B_k.38.weight', 'classifier_pool.36.weight', 'image_encoder.blocks.9.attn.lora_B_v.39.weight', 'image_encoder.blocks.3.attn.lora_B_k.3.weight', 'image_encoder.blocks.2.attn.lora_B_k.39.weight', 'image_encoder.blocks.7.attn.lora_B_v.34.weight', 'image_encoder.blocks.8.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_v.39.weight', 'image_encoder.blocks.3.attn.lora_B_v.30.weight', 'image_encoder.blocks.2.attn.lora_B_k.30.weight', 'image_encoder.blocks.2.attn.lora_B_v.3.weight', 'image_encoder.blocks.10.attn.lora_B_k.36.weight', 'image_encoder.blocks.5.attn.lora_B_k.39.weight', 'image_encoder.blocks.10.attn.lora_B_v.3.weight', 'image_encoder.blocks.11.attn.lora_B_v.32.weight', 'image_encoder.blocks.10.attn.lora_B_v.37.weight', 'image_encoder.blocks.2.attn.lora_B_k.33.weight', 'image_encoder.blocks.9.attn.lora_B_k.39.weight', 'classifier_pool.33.weight', 'image_encoder.blocks.9.attn.lora_B_k.37.weight', 'image_encoder.blocks.7.attn.lora_B_k.35.weight', 'image_encoder.blocks.0.attn.lora_B_k.38.weight', 'image_encoder.blocks.2.attn.lora_B_k.31.weight', 'image_encoder.blocks.4.attn.lora_B_k.31.weight', 'image_encoder.blocks.4.attn.lora_B_v.35.weight', 'image_encoder.blocks.1.attn.lora_B_v.39.weight', 'image_encoder.blocks.3.attn.lora_B_k.34.weight', 'image_encoder.blocks.4.attn.lora_B_k.3.weight', 'image_encoder.blocks.4.attn.lora_B_k.32.weight', 'image_encoder.blocks.4.attn.lora_B_k.36.weight', 'image_encoder.blocks.5.attn.lora_B_k.36.weight', 'image_encoder.blocks.1.attn.lora_B_k.37.weight', 'image_encoder.blocks.3.attn.lora_B_v.36.weight', 'image_encoder.blocks.7.attn.lora_B_k.34.weight', 'image_encoder.blocks.9.attn.lora_B_k.32.weight', 'image_encoder.blocks.11.attn.lora_B_v.33.weight', 'classifier_pool.32.weight', 'image_encoder.blocks.2.attn.lora_B_k.35.weight', 'image_encoder.blocks.10.attn.lora_B_v.34.weight', 'image_encoder.blocks.7.attn.lora_B_v.36.weight', 'image_encoder.blocks.8.attn.lora_B_k.35.weight', 'image_encoder.blocks.4.attn.lora_B_v.32.weight', 'image_encoder.blocks.2.attn.lora_B_v.37.weight', 'image_encoder.blocks.6.attn.lora_B_k.3.weight', 'image_encoder.blocks.0.attn.lora_B_k.30.weight', 'image_encoder.blocks.8.attn.lora_B_v.36.weight', 'image_encoder.blocks.6.attn.lora_B_v.32.weight', 'classifier_pool.39.weight', 'image_encoder.blocks.9.attn.lora_B_v.38.weight', 'image_encoder.blocks.5.attn.lora_B_v.30.weight', 'image_encoder.blocks.0.attn.lora_B_v.38.weight', 'image_encoder.blocks.2.attn.lora_B_k.34.weight', 'image_encoder.blocks.2.attn.lora_B_v.34.weight', 'image_encoder.blocks.5.attn.lora_B_v.31.weight', 'image_encoder.blocks.9.attn.lora_B_k.33.weight', 'image_encoder.blocks.1.attn.lora_B_k.3.weight', 'image_encoder.blocks.1.attn.lora_B_v.3.weight', 'image_encoder.blocks.1.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_v.35.weight', 'image_encoder.blocks.9.attn.lora_B_v.36.weight', 'image_encoder.blocks.0.attn.lora_B_v.33.weight', 'image_encoder.blocks.10.attn.lora_B_k.38.weight', 'image_encoder.blocks.10.attn.lora_B_v.31.weight', 'image_encoder.blocks.2.attn.lora_B_v.38.weight', 'image_encoder.blocks.3.attn.lora_B_k.30.weight', 'image_encoder.blocks.9.attn.lora_B_v.31.weight', 'image_encoder.blocks.0.attn.lora_B_v.37.weight', 'classifier_pool.30.weight', 'image_encoder.blocks.7.attn.lora_B_k.38.weight', 'image_encoder.blocks.0.attn.lora_B_v.31.weight', 'image_encoder.blocks.1.attn.lora_B_k.34.weight', 'image_encoder.blocks.5.attn.lora_B_v.34.weight', 'classifier_pool.35.bias', 'image_encoder.blocks.0.attn.lora_B_k.36.weight', 'image_encoder.blocks.1.attn.lora_B_v.38.weight', 'image_encoder.blocks.9.attn.lora_B_v.30.weight', 'image_encoder.blocks.6.attn.lora_B_k.30.weight', 'image_encoder.blocks.4.attn.lora_B_k.35.weight', 'image_encoder.blocks.0.attn.lora_B_k.35.weight', 'image_encoder.blocks.2.attn.lora_B_k.36.weight', 'image_encoder.blocks.6.attn.lora_B_k.33.weight', 'image_encoder.blocks.5.attn.lora_B_v.33.weight', 'image_encoder.blocks.8.attn.lora_B_k.30.weight', 'image_encoder.blocks.8.attn.lora_B_k.3.weight', 'image_encoder.blocks.10.attn.lora_B_k.39.weight', 'image_encoder.blocks.11.attn.lora_B_k.30.weight', 'image_encoder.blocks.11.attn.lora_B_v.37.weight', 'image_encoder.blocks.7.attn.lora_B_v.31.weight', 'image_encoder.blocks.9.attn.lora_B_k.3.weight', 'image_encoder.blocks.7.attn.lora_B_k.39.weight', 'image_encoder.blocks.4.attn.lora_B_v.3.weight', 'image_encoder.blocks.7.attn.lora_B_v.3.weight', 'image_encoder.blocks.1.attn.lora_B_k.33.weight', 'image_encoder.blocks.4.attn.lora_B_k.30.weight', 'image_encoder.blocks.6.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_k.32.weight', 'image_encoder.blocks.1.attn.lora_B_v.34.weight', 'image_encoder.blocks.3.attn.lora_B_v.31.weight', 'image_encoder.blocks.0.attn.lora_B_k.3.weight', 'classifier_pool.3.bias', 'image_encoder.blocks.3.attn.lora_B_k.38.weight', 'image_encoder.blocks.7.attn.lora_B_v.37.weight', 'image_encoder.blocks.5.attn.lora_B_k.35.weight', 'image_encoder.blocks.7.attn.lora_B_v.38.weight', 'image_encoder.blocks.6.attn.lora_B_v.3.weight', 'image_encoder.blocks.3.attn.lora_B_k.37.weight', 'image_encoder.blocks.11.attn.lora_B_v.35.weight', 'image_encoder.blocks.6.attn.lora_B_v.39.weight', 'image_encoder.blocks.5.attn.lora_B_v.36.weight', 'image_encoder.blocks.8.attn.lora_B_v.38.weight', 'image_encoder.blocks.0.attn.lora_B_v.39.weight', 'image_encoder.blocks.3.attn.lora_B_v.34.weight', 'image_encoder.blocks.4.attn.lora_B_v.37.weight', 'image_encoder.blocks.1.attn.lora_B_k.38.weight', 'image_encoder.blocks.8.attn.lora_B_k.37.weight', 'image_encoder.blocks.3.attn.lora_B_v.37.weight', 'image_encoder.blocks.5.attn.lora_B_k.31.weight', 'image_encoder.blocks.6.attn.lora_B_k.34.weight', 'image_encoder.blocks.2.attn.lora_B_k.37.weight', 'image_encoder.blocks.5.attn.lora_B_k.30.weight', 'image_encoder.blocks.7.attn.lora_B_k.36.weight', 'image_encoder.blocks.0.attn.lora_B_v.32.weight', 'image_encoder.blocks.8.attn.lora_B_k.38.weight', 'image_encoder.blocks.8.attn.lora_B_v.3.weight', 'image_encoder.blocks.9.attn.lora_B_k.31.weight', 'image_encoder.blocks.1.attn.lora_B_k.32.weight', 'image_encoder.blocks.6.attn.lora_B_k.31.weight', 'image_encoder.blocks.1.attn.lora_B_k.35.weight', 'image_encoder.blocks.11.attn.lora_B_k.31.weight', 'image_encoder.blocks.4.attn.lora_B_v.38.weight', 'image_encoder.blocks.9.attn.lora_B_v.34.weight', 'image_encoder.blocks.11.attn.lora_B_k.35.weight', 'classifier_pool.37.bias', 'image_encoder.blocks.4.attn.lora_B_k.33.weight', 'image_encoder.blocks.0.attn.lora_B_k.32.weight', 'image_encoder.blocks.3.attn.lora_B_v.32.weight', 'image_encoder.blocks.8.attn.lora_B_k.32.weight', 'image_encoder.blocks.10.attn.lora_B_v.35.weight', 'image_encoder.blocks.5.attn.lora_B_v.3.weight', 'classifier_pool.36.bias', 'image_encoder.blocks.6.attn.lora_B_k.39.weight', 'image_encoder.blocks.11.attn.lora_B_v.31.weight', 'image_encoder.blocks.11.attn.lora_B_k.38.weight', 'image_encoder.blocks.7.attn.lora_B_k.32.weight', 'image_encoder.blocks.6.attn.lora_B_v.33.weight'}
2025-12-11 14:40:32,127 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.058, Train_accy 98.10
Threshold:  0.953
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 16/768 type remove
Layer 4 : 15/768 type remove
Layer 5 : 17/768 type remove
Layer 6 : 19/768 type remove
Layer 7 : 22/768 type remove
Layer 8 : 34/768 type remove
Layer 9 : 29/768 type remove
Layer 10 : 23/768 type remove
Layer 11 : 11/768 type remove
Layer 12 : 13/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:40:41,842 [trainer.py] => Time:134.50305581092834
800 800
800 800
2025-12-11 14:40:44,550 [trainer.py] => Time:2.70818829536438
2025-12-11 14:40:44,550 [inflora.py] => Exemplar size: 0
2025-12-11 14:40:44,550 [trainer.py] => CNN: {'total': np.float64(88.38), '00-01': np.float64(99.5), '02-03': np.float64(92.5), '04-05': np.float64(89.0), '06-07': np.float64(72.5), 'old': np.float64(93.67), 'new': np.float64(72.5)}
2025-12-11 14:40:44,550 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38)]
2025-12-11 14:40:44,550 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5)]
2025-12-11 14:40:44,550 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375]
2025-12-11 14:40:50,458 [trainer.py] => W-NCM: {'00-01': 100.0, '02-03': 95.0, '04-05': 99.5, '06-07': 98.0}
2025-12-11 14:40:50,458 [trainer.py] => Ave Acc (W-NCM): 98.12%
2025-12-11 14:40:50,458 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 100.00% (best 100.00%); T2: W-NCM 95.00% (best 100.00%); T3: W-NCM 99.50% (best 100.00%); T4: W-NCM 98.00% (best 98.00%)
2025-12-11 14:40:50,458 [trainer.py] => Average forgetting (W-NCM): 1.83% | Max forgetting (W-NCM): 5.00%
2025-12-11 14:40:51,157 [trainer.py] => All params: 125940251
2025-12-11 14:40:51,163 [trainer.py] => Trainable params: 2044438
2025-12-11 14:40:51,163 [inflora.py] => Learning on 8-10
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.45.weight', 'classifier_pool.46.weight', 'image_encoder.blocks.2.attn.lora_B_k.45.weight', 'classifier_pool.4.weight', 'image_encoder.blocks.6.attn.lora_B_v.41.weight', 'image_encoder.blocks.11.attn.lora_B_v.46.weight', 'image_encoder.blocks.1.attn.lora_B_k.46.weight', 'image_encoder.blocks.6.attn.lora_B_k.49.weight', 'image_encoder.blocks.8.attn.lora_B_v.44.weight', 'image_encoder.blocks.2.attn.lora_B_v.46.weight', 'image_encoder.blocks.6.attn.lora_B_v.44.weight', 'image_encoder.blocks.9.attn.lora_B_k.4.weight', 'image_encoder.blocks.9.attn.lora_B_v.41.weight', 'image_encoder.blocks.9.attn.lora_B_v.44.weight', 'image_encoder.blocks.1.attn.lora_B_v.48.weight', 'image_encoder.blocks.6.attn.lora_B_k.46.weight', 'image_encoder.blocks.10.attn.lora_B_v.49.weight', 'image_encoder.blocks.10.attn.lora_B_v.47.weight', 'image_encoder.blocks.10.attn.lora_B_k.46.weight', 'image_encoder.blocks.9.attn.lora_B_k.43.weight', 'image_encoder.blocks.2.attn.lora_B_v.4.weight', 'image_encoder.blocks.6.attn.lora_B_v.43.weight', 'image_encoder.blocks.7.attn.lora_B_k.45.weight', 'image_encoder.blocks.7.attn.lora_B_k.49.weight', 'image_encoder.blocks.10.attn.lora_B_k.4.weight', 'image_encoder.blocks.11.attn.lora_B_k.44.weight', 'image_encoder.blocks.11.attn.lora_B_v.47.weight', 'image_encoder.blocks.2.attn.lora_B_v.49.weight', 'image_encoder.blocks.8.attn.lora_B_k.40.weight', 'image_encoder.blocks.7.attn.lora_B_v.41.weight', 'classifier_pool.4.bias', 'image_encoder.blocks.3.attn.lora_B_v.43.weight', 'image_encoder.blocks.8.attn.lora_B_k.49.weight', 'image_encoder.blocks.3.attn.lora_B_k.49.weight', 'image_encoder.blocks.8.attn.lora_B_k.42.weight', 'image_encoder.blocks.5.attn.lora_B_k.46.weight', 'image_encoder.blocks.8.attn.lora_B_k.48.weight', 'image_encoder.blocks.10.attn.lora_B_v.40.weight', 'image_encoder.blocks.1.attn.lora_B_v.43.weight', 'image_encoder.blocks.8.attn.lora_B_k.46.weight', 'image_encoder.blocks.0.attn.lora_B_k.44.weight', 'image_encoder.blocks.2.attn.lora_B_v.47.weight', 'image_encoder.blocks.6.attn.lora_B_k.48.weight', 'image_encoder.blocks.7.attn.lora_B_v.44.weight', 'image_encoder.blocks.7.attn.lora_B_v.49.weight', 'image_encoder.blocks.10.attn.lora_B_k.40.weight', 'image_encoder.blocks.0.attn.lora_B_k.45.weight', 'image_encoder.blocks.1.attn.lora_B_v.41.weight', 'image_encoder.blocks.7.attn.lora_B_k.43.weight', 'image_encoder.blocks.8.attn.lora_B_k.4.weight', 'image_encoder.blocks.3.attn.lora_B_v.45.weight', 'image_encoder.blocks.8.attn.lora_B_k.45.weight', 'image_encoder.blocks.1.attn.lora_B_k.40.weight', 'classifier_pool.49.bias', 'image_encoder.blocks.8.attn.lora_B_v.40.weight', 'image_encoder.blocks.3.attn.lora_B_k.43.weight', 'classifier_pool.49.weight', 'image_encoder.blocks.0.attn.lora_B_k.46.weight', 'image_encoder.blocks.4.attn.lora_B_v.48.weight', 'classifier_pool.42.bias', 'image_encoder.blocks.5.attn.lora_B_v.43.weight', 'image_encoder.blocks.10.attn.lora_B_k.45.weight', 'image_encoder.blocks.5.attn.lora_B_k.42.weight', 'image_encoder.blocks.4.attn.lora_B_v.49.weight', 'image_encoder.blocks.3.attn.lora_B_k.4.weight', 'image_encoder.blocks.0.attn.lora_B_v.4.weight', 'image_encoder.blocks.6.attn.lora_B_v.47.weight', 'image_encoder.blocks.10.attn.lora_B_v.48.weight', 'image_encoder.blocks.11.attn.lora_B_k.4.weight', 'image_encoder.blocks.2.attn.lora_B_k.44.weight', 'classifier_pool.43.bias', 'image_encoder.blocks.2.attn.lora_B_k.49.weight', 'image_encoder.blocks.2.attn.lora_B_k.47.weight', 'image_encoder.blocks.2.attn.lora_B_k.41.weight', 'image_encoder.blocks.3.attn.lora_B_k.42.weight', 'image_encoder.blocks.0.attn.lora_B_v.40.weight', 'image_encoder.blocks.3.attn.lora_B_v.47.weight', 'image_encoder.blocks.9.attn.lora_B_v.48.weight', 'classifier_pool.45.bias', 'image_encoder.blocks.0.attn.lora_B_k.48.weight', 'image_encoder.blocks.8.attn.lora_B_v.46.weight', 'image_encoder.blocks.7.attn.lora_B_k.40.weight', 'image_encoder.blocks.10.attn.lora_B_k.44.weight', 'image_encoder.blocks.2.attn.lora_B_k.40.weight', 'image_encoder.blocks.3.attn.lora_B_v.41.weight', 'image_encoder.blocks.6.attn.lora_B_v.42.weight', 'image_encoder.blocks.9.attn.lora_B_k.46.weight', 'image_encoder.blocks.7.attn.lora_B_k.4.weight', 'image_encoder.blocks.6.attn.lora_B_k.44.weight', 'image_encoder.blocks.4.attn.lora_B_k.40.weight', 'image_encoder.blocks.3.attn.lora_B_k.40.weight', 'image_encoder.blocks.4.attn.lora_B_v.44.weight', 'image_encoder.blocks.6.attn.lora_B_k.43.weight', 'image_encoder.blocks.6.attn.lora_B_k.40.weight', 'image_encoder.blocks.9.attn.lora_B_k.47.weight', 'image_encoder.blocks.6.attn.lora_B_k.47.weight', 'image_encoder.blocks.11.attn.lora_B_v.44.weight', 'image_encoder.blocks.0.attn.lora_B_v.48.weight', 'image_encoder.blocks.3.attn.lora_B_v.44.weight', 'image_encoder.blocks.10.attn.lora_B_v.41.weight', 'image_encoder.blocks.9.attn.lora_B_v.42.weight', 'classifier_pool.44.bias', 'image_encoder.blocks.11.attn.lora_B_v.4.weight', 'image_encoder.blocks.8.attn.lora_B_v.41.weight', 'image_encoder.blocks.1.attn.lora_B_k.49.weight', 'image_encoder.blocks.7.attn.lora_B_v.45.weight', 'image_encoder.blocks.1.attn.lora_B_k.45.weight', 'image_encoder.blocks.4.attn.lora_B_v.46.weight', 'image_encoder.blocks.1.attn.lora_B_v.4.weight', 'image_encoder.blocks.6.attn.lora_B_k.45.weight', 'image_encoder.blocks.10.attn.lora_B_v.42.weight', 'image_encoder.blocks.5.attn.lora_B_k.40.weight', 'image_encoder.blocks.6.attn.lora_B_k.41.weight', 'image_encoder.blocks.9.attn.lora_B_k.40.weight', 'image_encoder.blocks.0.attn.lora_B_v.44.weight', 'image_encoder.blocks.6.attn.lora_B_k.42.weight', 'image_encoder.blocks.5.attn.lora_B_v.44.weight', 'image_encoder.blocks.6.attn.lora_B_v.45.weight', 'image_encoder.blocks.9.attn.lora_B_v.47.weight', 'image_encoder.blocks.2.attn.lora_B_k.43.weight', 'image_encoder.blocks.2.attn.lora_B_v.43.weight', 'image_encoder.blocks.1.attn.lora_B_k.48.weight', 'image_encoder.blocks.10.attn.lora_B_k.48.weight', 'image_encoder.blocks.4.attn.lora_B_k.49.weight', 'image_encoder.blocks.10.attn.lora_B_k.49.weight', 'image_encoder.blocks.1.attn.lora_B_v.44.weight', 'image_encoder.blocks.4.attn.lora_B_v.47.weight', 'image_encoder.blocks.6.attn.lora_B_v.48.weight', 'image_encoder.blocks.1.attn.lora_B_v.42.weight', 'image_encoder.blocks.4.attn.lora_B_v.41.weight', 'image_encoder.blocks.8.attn.lora_B_v.47.weight', 'image_encoder.blocks.4.attn.lora_B_k.45.weight', 'image_encoder.blocks.0.attn.lora_B_v.47.weight', 'image_encoder.blocks.3.attn.lora_B_k.47.weight', 'image_encoder.blocks.3.attn.lora_B_v.49.weight', 'image_encoder.blocks.9.attn.lora_B_k.41.weight', 'image_encoder.blocks.4.attn.lora_B_v.43.weight', 'image_encoder.blocks.9.attn.lora_B_k.42.weight', 'image_encoder.blocks.1.attn.lora_B_k.44.weight', 'image_encoder.blocks.6.attn.lora_B_k.4.weight', 'image_encoder.blocks.7.attn.lora_B_k.47.weight', 'image_encoder.blocks.7.attn.lora_B_v.4.weight', 'image_encoder.blocks.2.attn.lora_B_k.4.weight', 'image_encoder.blocks.3.attn.lora_B_k.44.weight', 'image_encoder.blocks.4.attn.lora_B_v.40.weight', 'image_encoder.blocks.0.attn.lora_B_v.42.weight', 'image_encoder.blocks.4.attn.lora_B_k.41.weight', 'classifier_pool.47.bias', 'image_encoder.blocks.6.attn.lora_B_v.49.weight', 'image_encoder.blocks.5.attn.lora_B_k.48.weight', 'image_encoder.blocks.11.attn.lora_B_v.49.weight', 'classifier_pool.45.weight', 'image_encoder.blocks.0.attn.lora_B_k.47.weight', 'image_encoder.blocks.1.attn.lora_B_k.41.weight', 'image_encoder.blocks.8.attn.lora_B_k.43.weight', 'image_encoder.blocks.0.attn.lora_B_k.40.weight', 'image_encoder.blocks.2.attn.lora_B_v.45.weight', 'image_encoder.blocks.4.attn.lora_B_v.42.weight', 'image_encoder.blocks.7.attn.lora_B_v.40.weight', 'image_encoder.blocks.4.attn.lora_B_k.42.weight', 'image_encoder.blocks.11.attn.lora_B_k.46.weight', 'classifier_pool.48.weight', 'image_encoder.blocks.8.attn.lora_B_v.49.weight', 'image_encoder.blocks.11.attn.lora_B_v.45.weight', 'image_encoder.blocks.3.attn.lora_B_v.46.weight', 'image_encoder.blocks.1.attn.lora_B_v.45.weight', 'image_encoder.blocks.3.attn.lora_B_k.41.weight', 'image_encoder.blocks.8.attn.lora_B_k.41.weight', 'image_encoder.blocks.11.attn.lora_B_v.48.weight', 'image_encoder.blocks.1.attn.lora_B_k.4.weight', 'image_encoder.blocks.10.attn.lora_B_v.45.weight', 'image_encoder.blocks.7.attn.lora_B_k.46.weight', 'image_encoder.blocks.7.attn.lora_B_v.48.weight', 'classifier_pool.40.bias', 'image_encoder.blocks.11.attn.lora_B_k.49.weight', 'image_encoder.blocks.11.attn.lora_B_v.40.weight', 'image_encoder.blocks.0.attn.lora_B_k.4.weight', 'image_encoder.blocks.1.attn.lora_B_k.43.weight', 'image_encoder.blocks.1.attn.lora_B_k.47.weight', 'image_encoder.blocks.10.attn.lora_B_v.43.weight', 'classifier_pool.40.weight', 'classifier_pool.41.weight', 'image_encoder.blocks.10.attn.lora_B_k.42.weight', 'image_encoder.blocks.5.attn.lora_B_v.4.weight', 'image_encoder.blocks.5.attn.lora_B_v.42.weight', 'image_encoder.blocks.0.attn.lora_B_k.41.weight', 'image_encoder.blocks.3.attn.lora_B_k.48.weight', 'image_encoder.blocks.2.attn.lora_B_k.46.weight', 'image_encoder.blocks.5.attn.lora_B_v.49.weight', 'image_encoder.blocks.3.attn.lora_B_v.42.weight', 'image_encoder.blocks.8.attn.lora_B_v.42.weight', 'image_encoder.blocks.8.attn.lora_B_v.43.weight', 'image_encoder.blocks.1.attn.lora_B_v.49.weight', 'image_encoder.blocks.7.attn.lora_B_v.47.weight', 'image_encoder.blocks.0.attn.lora_B_v.45.weight', 'image_encoder.blocks.3.attn.lora_B_v.4.weight', 'image_encoder.blocks.10.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_v.48.weight', 'image_encoder.blocks.6.attn.lora_B_v.40.weight', 'image_encoder.blocks.6.attn.lora_B_v.4.weight', 'image_encoder.blocks.9.attn.lora_B_k.48.weight', 'image_encoder.blocks.11.attn.lora_B_k.40.weight', 'image_encoder.blocks.10.attn.lora_B_v.44.weight', 'image_encoder.blocks.3.attn.lora_B_v.48.weight', 'image_encoder.blocks.6.attn.lora_B_v.46.weight', 'image_encoder.blocks.11.attn.lora_B_v.42.weight', 'image_encoder.blocks.5.attn.lora_B_v.46.weight', 'image_encoder.blocks.2.attn.lora_B_v.41.weight', 'image_encoder.blocks.7.attn.lora_B_k.41.weight', 'image_encoder.blocks.7.attn.lora_B_k.44.weight', 'image_encoder.blocks.1.attn.lora_B_v.46.weight', 'classifier_pool.47.weight', 'image_encoder.blocks.0.attn.lora_B_v.41.weight', 'image_encoder.blocks.4.attn.lora_B_k.48.weight', 'image_encoder.blocks.5.attn.lora_B_k.4.weight', 'image_encoder.blocks.7.attn.lora_B_k.42.weight', 'image_encoder.blocks.4.attn.lora_B_k.44.weight', 'image_encoder.blocks.10.attn.lora_B_v.46.weight', 'image_encoder.blocks.3.attn.lora_B_k.45.weight', 'image_encoder.blocks.10.attn.lora_B_k.47.weight', 'image_encoder.blocks.2.attn.lora_B_k.42.weight', 'image_encoder.blocks.8.attn.lora_B_v.48.weight', 'image_encoder.blocks.11.attn.lora_B_k.41.weight', 'image_encoder.blocks.9.attn.lora_B_v.43.weight', 'image_encoder.blocks.2.attn.lora_B_v.44.weight', 'image_encoder.blocks.4.attn.lora_B_k.4.weight', 'image_encoder.blocks.9.attn.lora_B_v.49.weight', 'image_encoder.blocks.8.attn.lora_B_k.47.weight', 'image_encoder.blocks.11.attn.lora_B_k.45.weight', 'classifier_pool.48.bias', 'image_encoder.blocks.4.attn.lora_B_k.47.weight', 'image_encoder.blocks.5.attn.lora_B_v.45.weight', 'image_encoder.blocks.8.attn.lora_B_k.44.weight', 'image_encoder.blocks.5.attn.lora_B_k.49.weight', 'image_encoder.blocks.3.attn.lora_B_v.40.weight', 'image_encoder.blocks.5.attn.lora_B_v.41.weight', 'image_encoder.blocks.10.attn.lora_B_v.4.weight', 'image_encoder.blocks.9.attn.lora_B_v.46.weight', 'image_encoder.blocks.7.attn.lora_B_k.48.weight', 'image_encoder.blocks.0.attn.lora_B_v.49.weight', 'image_encoder.blocks.7.attn.lora_B_v.42.weight', 'image_encoder.blocks.0.attn.lora_B_v.43.weight', 'image_encoder.blocks.4.attn.lora_B_k.46.weight', 'image_encoder.blocks.11.attn.lora_B_v.43.weight', 'image_encoder.blocks.11.attn.lora_B_k.47.weight', 'classifier_pool.46.bias', 'image_encoder.blocks.8.attn.lora_B_v.45.weight', 'image_encoder.blocks.5.attn.lora_B_k.45.weight', 'image_encoder.blocks.11.attn.lora_B_k.43.weight', 'image_encoder.blocks.2.attn.lora_B_v.48.weight', 'image_encoder.blocks.11.attn.lora_B_k.42.weight', 'image_encoder.blocks.1.attn.lora_B_k.42.weight', 'image_encoder.blocks.0.attn.lora_B_k.43.weight', 'classifier_pool.43.weight', 'image_encoder.blocks.5.attn.lora_B_v.40.weight', 'image_encoder.blocks.11.attn.lora_B_k.48.weight', 'image_encoder.blocks.9.attn.lora_B_k.44.weight', 'image_encoder.blocks.7.attn.lora_B_v.43.weight', 'classifier_pool.41.bias', 'image_encoder.blocks.0.attn.lora_B_v.46.weight', 'image_encoder.blocks.0.attn.lora_B_k.42.weight', 'image_encoder.blocks.4.attn.lora_B_k.43.weight', 'image_encoder.blocks.5.attn.lora_B_k.43.weight', 'image_encoder.blocks.9.attn.lora_B_k.49.weight', 'image_encoder.blocks.0.attn.lora_B_k.49.weight', 'image_encoder.blocks.2.attn.lora_B_v.42.weight', 'image_encoder.blocks.2.attn.lora_B_k.48.weight', 'image_encoder.blocks.4.attn.lora_B_v.4.weight', 'image_encoder.blocks.11.attn.lora_B_v.41.weight', 'image_encoder.blocks.3.attn.lora_B_k.46.weight', 'classifier_pool.44.weight', 'image_encoder.blocks.1.attn.lora_B_v.40.weight', 'image_encoder.blocks.5.attn.lora_B_k.44.weight', 'image_encoder.blocks.9.attn.lora_B_v.40.weight', 'image_encoder.blocks.10.attn.lora_B_k.43.weight', 'image_encoder.blocks.1.attn.lora_B_v.47.weight', 'image_encoder.blocks.2.attn.lora_B_v.40.weight', 'image_encoder.blocks.5.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_v.47.weight', 'image_encoder.blocks.9.attn.lora_B_k.45.weight', 'image_encoder.blocks.7.attn.lora_B_v.46.weight', 'image_encoder.blocks.5.attn.lora_B_k.47.weight', 'image_encoder.blocks.8.attn.lora_B_v.4.weight', 'classifier_pool.42.weight', 'image_encoder.blocks.9.attn.lora_B_v.45.weight', 'image_encoder.blocks.9.attn.lora_B_v.4.weight'}
2025-12-11 14:42:56,266 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.017, Train_accy 99.30
Threshold:  0.954
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 17/768 type remove
Layer 4 : 17/768 type remove
Layer 5 : 19/768 type remove
Layer 6 : 21/768 type remove
Layer 7 : 26/768 type remove
Layer 8 : 39/768 type remove
Layer 9 : 34/768 type remove
Layer 10 : 27/768 type remove
Layer 11 : 13/768 type remove
Layer 12 : 16/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:43:05,839 [trainer.py] => Time:134.67565822601318
1000 1000
1000 1000
2025-12-11 14:43:08,985 [trainer.py] => Time:3.1452698707580566
2025-12-11 14:43:08,985 [inflora.py] => Exemplar size: 0
2025-12-11 14:43:08,985 [trainer.py] => CNN: {'total': np.float64(91.1), '00-01': np.float64(99.0), '02-03': np.float64(91.0), '04-05': np.float64(91.0), '06-07': np.float64(75.5), '08-09': np.float64(99.0), 'old': np.float64(89.12), 'new': np.float64(99.0)}
2025-12-11 14:43:08,985 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1)]
2025-12-11 14:43:08,985 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7)]
2025-12-11 14:43:08,985 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911]
2025-12-11 14:43:15,409 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 93.0, '04-05': 100.0, '06-07': 98.5, '08-09': 100.0}
2025-12-11 14:43:15,410 [trainer.py] => Ave Acc (W-NCM): 98.20%
2025-12-11 14:43:15,410 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 93.00% (best 100.00%); T3: W-NCM 100.00% (best 100.00%); T4: W-NCM 98.50% (best 98.50%); T5: W-NCM 100.00% (best 100.00%)
2025-12-11 14:43:15,410 [trainer.py] => Average forgetting (W-NCM): 1.88% | Max forgetting (W-NCM): 7.00%
2025-12-11 14:43:16,106 [trainer.py] => All params: 125940251
2025-12-11 14:43:16,112 [trainer.py] => Trainable params: 2044438
2025-12-11 14:43:16,112 [inflora.py] => Learning on 10-12
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_k.5.weight', 'image_encoder.blocks.10.attn.lora_B_v.5.weight', 'image_encoder.blocks.11.attn.lora_B_v.5.weight', 'image_encoder.blocks.5.attn.lora_B_v.5.weight', 'image_encoder.blocks.6.attn.lora_B_k.5.weight', 'classifier_pool.5.weight', 'image_encoder.blocks.11.attn.lora_B_k.5.weight', 'image_encoder.blocks.4.attn.lora_B_v.5.weight', 'image_encoder.blocks.8.attn.lora_B_k.5.weight', 'image_encoder.blocks.7.attn.lora_B_v.5.weight', 'image_encoder.blocks.7.attn.lora_B_k.5.weight', 'image_encoder.blocks.6.attn.lora_B_v.5.weight', 'image_encoder.blocks.2.attn.lora_B_v.5.weight', 'image_encoder.blocks.3.attn.lora_B_v.5.weight', 'image_encoder.blocks.4.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_k.5.weight', 'image_encoder.blocks.3.attn.lora_B_k.5.weight', 'image_encoder.blocks.1.attn.lora_B_v.5.weight', 'image_encoder.blocks.9.attn.lora_B_v.5.weight', 'image_encoder.blocks.10.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_v.5.weight', 'image_encoder.blocks.9.attn.lora_B_k.5.weight', 'image_encoder.blocks.1.attn.lora_B_k.5.weight', 'classifier_pool.5.bias', 'image_encoder.blocks.5.attn.lora_B_k.5.weight', 'image_encoder.blocks.8.attn.lora_B_v.5.weight'}
2025-12-11 14:45:21,031 [inflora.py] => Task 5, Epoch 20/20 => Loss 0.026, Train_accy 98.90
Threshold:  0.955
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 18/768 type remove
Layer 4 : 18/768 type remove
Layer 5 : 20/768 type remove
Layer 6 : 22/768 type remove
Layer 7 : 27/768 type remove
Layer 8 : 40/768 type remove
Layer 9 : 35/768 type remove
Layer 10 : 29/768 type remove
Layer 11 : 15/768 type remove
Layer 12 : 21/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:45:30,871 [trainer.py] => Time:134.75830721855164
1200 1200
1200 1200
2025-12-11 14:45:34,576 [trainer.py] => Time:3.7053322792053223
2025-12-11 14:45:34,576 [inflora.py] => Exemplar size: 0
2025-12-11 14:45:34,576 [trainer.py] => CNN: {'total': np.float64(86.42), '00-01': np.float64(97.5), '02-03': np.float64(77.5), '04-05': np.float64(95.0), '06-07': np.float64(74.5), '08-09': np.float64(97.5), '10-11': np.float64(76.5), 'old': np.float64(88.4), 'new': np.float64(76.5)}
2025-12-11 14:45:34,576 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42)]
2025-12-11 14:45:34,576 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67)]
2025-12-11 14:45:34,577 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666]
2025-12-11 14:45:41,513 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 51.0, '04-05': 100.0, '06-07': 98.0, '08-09': 99.0, '10-11': 100.0}
2025-12-11 14:45:41,513 [trainer.py] => Ave Acc (W-NCM): 91.25%
2025-12-11 14:45:41,513 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 51.00% (best 100.00%); T3: W-NCM 100.00% (best 100.00%); T4: W-NCM 98.00% (best 98.50%); T5: W-NCM 99.00% (best 100.00%); T6: W-NCM 100.00% (best 100.00%)
2025-12-11 14:45:41,513 [trainer.py] => Average forgetting (W-NCM): 10.20% | Max forgetting (W-NCM): 49.00%
2025-12-11 14:45:42,409 [trainer.py] => All params: 125940251
2025-12-11 14:45:42,415 [trainer.py] => Trainable params: 185858
2025-12-11 14:45:42,415 [inflora.py] => Learning on 12-14
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_k.6.weight', 'image_encoder.blocks.10.attn.lora_B_k.6.weight', 'image_encoder.blocks.1.attn.lora_B_v.6.weight', 'image_encoder.blocks.11.attn.lora_B_v.6.weight', 'image_encoder.blocks.4.attn.lora_B_v.6.weight', 'image_encoder.blocks.6.attn.lora_B_v.6.weight', 'image_encoder.blocks.9.attn.lora_B_v.6.weight', 'image_encoder.blocks.4.attn.lora_B_k.6.weight', 'image_encoder.blocks.5.attn.lora_B_v.6.weight', 'image_encoder.blocks.5.attn.lora_B_k.6.weight', 'image_encoder.blocks.6.attn.lora_B_k.6.weight', 'image_encoder.blocks.0.attn.lora_B_k.6.weight', 'image_encoder.blocks.0.attn.lora_B_v.6.weight', 'image_encoder.blocks.2.attn.lora_B_v.6.weight', 'classifier_pool.6.weight', 'image_encoder.blocks.2.attn.lora_B_k.6.weight', 'image_encoder.blocks.1.attn.lora_B_k.6.weight', 'image_encoder.blocks.3.attn.lora_B_v.6.weight', 'classifier_pool.6.bias', 'image_encoder.blocks.7.attn.lora_B_k.6.weight', 'image_encoder.blocks.8.attn.lora_B_k.6.weight', 'image_encoder.blocks.7.attn.lora_B_v.6.weight', 'image_encoder.blocks.11.attn.lora_B_k.6.weight', 'image_encoder.blocks.3.attn.lora_B_k.6.weight', 'image_encoder.blocks.10.attn.lora_B_v.6.weight', 'image_encoder.blocks.8.attn.lora_B_v.6.weight'}
2025-12-11 14:47:47,678 [inflora.py] => Task 6, Epoch 20/20 => Loss 0.050, Train_accy 97.80
Threshold:  0.956
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 19/768 type remove
Layer 4 : 20/768 type remove
Layer 5 : 23/768 type remove
Layer 6 : 26/768 type remove
Layer 7 : 30/768 type remove
Layer 8 : 44/768 type remove
Layer 9 : 40/768 type remove
Layer 10 : 34/768 type remove
Layer 11 : 18/768 type remove
Layer 12 : 23/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:47:57,458 [trainer.py] => Time:135.04308557510376
1400 1400
1400 1400
2025-12-11 14:48:01,663 [trainer.py] => Time:4.2042436599731445
2025-12-11 14:48:01,663 [inflora.py] => Exemplar size: 0
2025-12-11 14:48:01,663 [trainer.py] => CNN: {'total': np.float64(87.57), '00-01': np.float64(98.5), '02-03': np.float64(79.0), '04-05': np.float64(95.0), '06-07': np.float64(71.0), '08-09': np.float64(97.0), '10-11': np.float64(77.0), '12-13': np.float64(95.5), 'old': np.float64(86.25), 'new': np.float64(95.5)}
2025-12-11 14:48:01,663 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57)]
2025-12-11 14:48:01,663 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71)]
2025-12-11 14:48:01,663 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714]
2025-12-11 14:48:09,122 [trainer.py] => W-NCM: {'00-01': 100.0, '02-03': 59.0, '04-05': 99.5, '06-07': 98.5, '08-09': 98.5, '10-11': 98.5, '12-13': 99.5}
2025-12-11 14:48:09,122 [trainer.py] => Ave Acc (W-NCM): 93.36%
2025-12-11 14:48:09,122 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 100.00% (best 100.00%); T2: W-NCM 59.00% (best 100.00%); T3: W-NCM 99.50% (best 100.00%); T4: W-NCM 98.50% (best 98.50%); T5: W-NCM 98.50% (best 100.00%); T6: W-NCM 98.50% (best 100.00%); T7: W-NCM 99.50% (best 99.50%)
2025-12-11 14:48:09,122 [trainer.py] => Average forgetting (W-NCM): 7.42% | Max forgetting (W-NCM): 41.00%
2025-12-11 14:48:09,807 [trainer.py] => All params: 125940251
2025-12-11 14:48:09,813 [trainer.py] => Trainable params: 185858
2025-12-11 14:48:09,813 [inflora.py] => Learning on 14-16
Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_v.7.weight', 'classifier_pool.7.bias', 'image_encoder.blocks.4.attn.lora_B_k.7.weight', 'image_encoder.blocks.2.attn.lora_B_v.7.weight', 'image_encoder.blocks.11.attn.lora_B_v.7.weight', 'classifier_pool.7.weight', 'image_encoder.blocks.7.attn.lora_B_v.7.weight', 'image_encoder.blocks.10.attn.lora_B_k.7.weight', 'image_encoder.blocks.9.attn.lora_B_k.7.weight', 'image_encoder.blocks.4.attn.lora_B_v.7.weight', 'image_encoder.blocks.5.attn.lora_B_v.7.weight', 'image_encoder.blocks.5.attn.lora_B_k.7.weight', 'image_encoder.blocks.3.attn.lora_B_v.7.weight', 'image_encoder.blocks.11.attn.lora_B_k.7.weight', 'image_encoder.blocks.1.attn.lora_B_v.7.weight', 'image_encoder.blocks.3.attn.lora_B_k.7.weight', 'image_encoder.blocks.6.attn.lora_B_v.7.weight', 'image_encoder.blocks.0.attn.lora_B_k.7.weight', 'image_encoder.blocks.6.attn.lora_B_k.7.weight', 'image_encoder.blocks.2.attn.lora_B_k.7.weight', 'image_encoder.blocks.9.attn.lora_B_v.7.weight', 'image_encoder.blocks.0.attn.lora_B_v.7.weight', 'image_encoder.blocks.8.attn.lora_B_v.7.weight', 'image_encoder.blocks.1.attn.lora_B_k.7.weight', 'image_encoder.blocks.8.attn.lora_B_k.7.weight', 'image_encoder.blocks.7.attn.lora_B_k.7.weight'}
2025-12-11 14:50:14,961 [inflora.py] => Task 7, Epoch 20/20 => Loss 0.031, Train_accy 99.00
Threshold:  0.957
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 20/768 type remove
Layer 4 : 21/768 type remove
Layer 5 : 25/768 type remove
Layer 6 : 29/768 type remove
Layer 7 : 33/768 type remove
Layer 8 : 49/768 type remove
Layer 9 : 47/768 type remove
Layer 10 : 41/768 type remove
Layer 11 : 21/768 type remove
Layer 12 : 25/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:50:24,711 [trainer.py] => Time:134.89776587486267
1600 1600
1600 1600
2025-12-11 14:50:29,413 [trainer.py] => Time:4.701630592346191
2025-12-11 14:50:29,413 [inflora.py] => Exemplar size: 0
2025-12-11 14:50:29,413 [trainer.py] => CNN: {'total': np.float64(88.12), '00-01': np.float64(99.5), '02-03': np.float64(83.0), '04-05': np.float64(91.5), '06-07': np.float64(70.0), '08-09': np.float64(98.5), '10-11': np.float64(76.0), '12-13': np.float64(94.0), '14-15': np.float64(92.5), 'old': np.float64(87.5), 'new': np.float64(92.5)}
2025-12-11 14:50:29,413 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12)]
2025-12-11 14:50:29,413 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75)]
2025-12-11 14:50:29,413 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125]
2025-12-11 14:50:37,410 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 78.0, '04-05': 99.0, '06-07': 97.5, '08-09': 99.0, '10-11': 92.5, '12-13': 99.5, '14-15': 98.5}
2025-12-11 14:50:37,410 [trainer.py] => Ave Acc (W-NCM): 95.44%
2025-12-11 14:50:37,410 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 78.00% (best 100.00%); T3: W-NCM 99.00% (best 100.00%); T4: W-NCM 97.50% (best 98.50%); T5: W-NCM 99.00% (best 100.00%); T6: W-NCM 92.50% (best 100.00%); T7: W-NCM 99.50% (best 99.50%); T8: W-NCM 98.50% (best 98.50%)
2025-12-11 14:50:37,410 [trainer.py] => Average forgetting (W-NCM): 4.71% | Max forgetting (W-NCM): 22.00%
2025-12-11 14:50:38,234 [trainer.py] => All params: 125940251
2025-12-11 14:50:38,240 [trainer.py] => Trainable params: 185858
2025-12-11 14:50:38,240 [inflora.py] => Learning on 16-18
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_k.8.weight', 'image_encoder.blocks.5.attn.lora_B_v.8.weight', 'image_encoder.blocks.0.attn.lora_B_k.8.weight', 'image_encoder.blocks.3.attn.lora_B_v.8.weight', 'image_encoder.blocks.7.attn.lora_B_k.8.weight', 'image_encoder.blocks.6.attn.lora_B_v.8.weight', 'image_encoder.blocks.0.attn.lora_B_v.8.weight', 'image_encoder.blocks.1.attn.lora_B_k.8.weight', 'image_encoder.blocks.9.attn.lora_B_k.8.weight', 'image_encoder.blocks.10.attn.lora_B_v.8.weight', 'image_encoder.blocks.2.attn.lora_B_k.8.weight', 'image_encoder.blocks.11.attn.lora_B_v.8.weight', 'image_encoder.blocks.4.attn.lora_B_v.8.weight', 'image_encoder.blocks.8.attn.lora_B_v.8.weight', 'classifier_pool.8.bias', 'image_encoder.blocks.11.attn.lora_B_k.8.weight', 'image_encoder.blocks.3.attn.lora_B_k.8.weight', 'image_encoder.blocks.5.attn.lora_B_k.8.weight', 'image_encoder.blocks.1.attn.lora_B_v.8.weight', 'image_encoder.blocks.8.attn.lora_B_k.8.weight', 'image_encoder.blocks.9.attn.lora_B_v.8.weight', 'image_encoder.blocks.4.attn.lora_B_k.8.weight', 'image_encoder.blocks.2.attn.lora_B_v.8.weight', 'image_encoder.blocks.10.attn.lora_B_k.8.weight', 'image_encoder.blocks.7.attn.lora_B_v.8.weight', 'classifier_pool.8.weight'}
2025-12-11 14:52:43,412 [inflora.py] => Task 8, Epoch 20/20 => Loss 0.017, Train_accy 99.50
Threshold:  0.958
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 21/768 type remove
Layer 4 : 22/768 type remove
Layer 5 : 27/768 type remove
Layer 6 : 32/768 type remove
Layer 7 : 37/768 type remove
Layer 8 : 53/768 type remove
Layer 9 : 53/768 type remove
Layer 10 : 45/768 type remove
Layer 11 : 24/768 type remove
Layer 12 : 28/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:52:53,083 [trainer.py] => Time:134.84254002571106
1800 1800
1800 1800
2025-12-11 14:52:58,340 [trainer.py] => Time:5.256580591201782
2025-12-11 14:52:58,340 [inflora.py] => Exemplar size: 0
2025-12-11 14:52:58,340 [trainer.py] => CNN: {'total': np.float64(87.78), '00-01': np.float64(99.0), '02-03': np.float64(87.0), '04-05': np.float64(87.5), '06-07': np.float64(74.0), '08-09': np.float64(98.0), '10-11': np.float64(73.5), '12-13': np.float64(90.5), '14-15': np.float64(94.0), '16-17': np.float64(86.5), 'old': np.float64(87.94), 'new': np.float64(86.5)}
2025-12-11 14:52:58,340 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78)]
2025-12-11 14:52:58,340 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67)]
2025-12-11 14:52:58,340 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778]
2025-12-11 14:53:06,868 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 76.0, '04-05': 99.0, '06-07': 97.0, '08-09': 97.5, '10-11': 90.5, '12-13': 99.0, '14-15': 98.5, '16-17': 99.5}
2025-12-11 14:53:06,868 [trainer.py] => Ave Acc (W-NCM): 95.17%
2025-12-11 14:53:06,868 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 76.00% (best 100.00%); T3: W-NCM 99.00% (best 100.00%); T4: W-NCM 97.00% (best 98.50%); T5: W-NCM 97.50% (best 100.00%); T6: W-NCM 90.50% (best 100.00%); T7: W-NCM 99.00% (best 99.50%); T8: W-NCM 98.50% (best 98.50%); T9: W-NCM 99.50% (best 99.50%)
2025-12-11 14:53:06,868 [trainer.py] => Average forgetting (W-NCM): 4.94% | Max forgetting (W-NCM): 24.00%
2025-12-11 14:53:07,567 [trainer.py] => All params: 125940251
2025-12-11 14:53:07,573 [trainer.py] => Trainable params: 185858
2025-12-11 14:53:07,573 [inflora.py] => Learning on 18-20
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.9.weight', 'image_encoder.blocks.5.attn.lora_B_k.9.weight', 'image_encoder.blocks.8.attn.lora_B_k.9.weight', 'image_encoder.blocks.10.attn.lora_B_k.9.weight', 'image_encoder.blocks.9.attn.lora_B_v.9.weight', 'image_encoder.blocks.6.attn.lora_B_k.9.weight', 'image_encoder.blocks.4.attn.lora_B_k.9.weight', 'image_encoder.blocks.11.attn.lora_B_v.9.weight', 'image_encoder.blocks.7.attn.lora_B_v.9.weight', 'image_encoder.blocks.10.attn.lora_B_v.9.weight', 'classifier_pool.9.weight', 'image_encoder.blocks.3.attn.lora_B_v.9.weight', 'image_encoder.blocks.4.attn.lora_B_v.9.weight', 'image_encoder.blocks.1.attn.lora_B_k.9.weight', 'image_encoder.blocks.3.attn.lora_B_k.9.weight', 'image_encoder.blocks.5.attn.lora_B_v.9.weight', 'image_encoder.blocks.2.attn.lora_B_v.9.weight', 'image_encoder.blocks.9.attn.lora_B_k.9.weight', 'image_encoder.blocks.0.attn.lora_B_k.9.weight', 'image_encoder.blocks.11.attn.lora_B_k.9.weight', 'classifier_pool.9.bias', 'image_encoder.blocks.7.attn.lora_B_k.9.weight', 'image_encoder.blocks.0.attn.lora_B_v.9.weight', 'image_encoder.blocks.1.attn.lora_B_v.9.weight', 'image_encoder.blocks.2.attn.lora_B_k.9.weight', 'image_encoder.blocks.8.attn.lora_B_v.9.weight'}
2025-12-11 14:55:12,927 [inflora.py] => Task 9, Epoch 20/20 => Loss 0.034, Train_accy 98.60
Threshold:  0.959
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 22/768 type remove
Layer 4 : 24/768 type remove
Layer 5 : 30/768 type remove
Layer 6 : 35/768 type remove
Layer 7 : 41/768 type remove
Layer 8 : 60/768 type remove
Layer 9 : 60/768 type remove
Layer 10 : 51/768 type remove
Layer 11 : 27/768 type remove
Layer 12 : 31/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:55:22,683 [trainer.py] => Time:135.10945010185242
2000 2000
2000 2000
2025-12-11 14:55:28,396 [trainer.py] => Time:5.7126030921936035
2025-12-11 14:55:28,396 [inflora.py] => Exemplar size: 0
2025-12-11 14:55:28,396 [trainer.py] => CNN: {'total': np.float64(87.7), '00-01': np.float64(97.5), '02-03': np.float64(86.5), '04-05': np.float64(90.0), '06-07': np.float64(74.5), '08-09': np.float64(97.0), '10-11': np.float64(74.0), '12-13': np.float64(92.0), '14-15': np.float64(94.0), '16-17': np.float64(85.5), '18-19': np.float64(86.0), 'old': np.float64(87.89), 'new': np.float64(86.0)}
2025-12-11 14:55:28,396 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7)]
2025-12-11 14:55:28,396 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75)]
2025-12-11 14:55:28,396 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877]
2025-12-11 14:55:37,381 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 75.0, '04-05': 99.5, '06-07': 97.0, '08-09': 98.5, '10-11': 95.0, '12-13': 99.5, '14-15': 97.5, '16-17': 98.5, '18-19': 99.0}
2025-12-11 14:55:37,382 [trainer.py] => Ave Acc (W-NCM): 95.90%
2025-12-11 14:55:37,382 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 75.00% (best 100.00%); T3: W-NCM 99.50% (best 100.00%); T4: W-NCM 97.00% (best 98.50%); T5: W-NCM 98.50% (best 100.00%); T6: W-NCM 95.00% (best 100.00%); T7: W-NCM 99.50% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 98.50% (best 99.50%); T10: W-NCM 99.00% (best 99.00%)
2025-12-11 14:55:37,382 [trainer.py] => Average forgetting (W-NCM): 4.00% | Max forgetting (W-NCM): 25.00%
2025-12-11 14:55:38,071 [trainer.py] => All params: 125940251
2025-12-11 14:55:38,077 [trainer.py] => Trainable params: 185858
2025-12-11 14:55:38,077 [inflora.py] => Learning on 20-22
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.10.weight', 'image_encoder.blocks.4.attn.lora_B_v.10.weight', 'image_encoder.blocks.2.attn.lora_B_v.10.weight', 'image_encoder.blocks.3.attn.lora_B_k.10.weight', 'image_encoder.blocks.5.attn.lora_B_v.10.weight', 'image_encoder.blocks.4.attn.lora_B_k.10.weight', 'image_encoder.blocks.3.attn.lora_B_v.10.weight', 'image_encoder.blocks.11.attn.lora_B_v.10.weight', 'image_encoder.blocks.9.attn.lora_B_k.10.weight', 'classifier_pool.10.weight', 'image_encoder.blocks.7.attn.lora_B_k.10.weight', 'image_encoder.blocks.9.attn.lora_B_v.10.weight', 'image_encoder.blocks.11.attn.lora_B_k.10.weight', 'image_encoder.blocks.0.attn.lora_B_k.10.weight', 'image_encoder.blocks.7.attn.lora_B_v.10.weight', 'image_encoder.blocks.5.attn.lora_B_k.10.weight', 'image_encoder.blocks.8.attn.lora_B_k.10.weight', 'classifier_pool.10.bias', 'image_encoder.blocks.6.attn.lora_B_k.10.weight', 'image_encoder.blocks.1.attn.lora_B_v.10.weight', 'image_encoder.blocks.10.attn.lora_B_k.10.weight', 'image_encoder.blocks.0.attn.lora_B_v.10.weight', 'image_encoder.blocks.1.attn.lora_B_k.10.weight', 'image_encoder.blocks.2.attn.lora_B_k.10.weight', 'image_encoder.blocks.8.attn.lora_B_v.10.weight', 'image_encoder.blocks.10.attn.lora_B_v.10.weight'}
2025-12-11 14:57:43,433 [inflora.py] => Task 10, Epoch 20/20 => Loss 0.009, Train_accy 99.70
Threshold:  0.96
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 23/768 type remove
Layer 4 : 26/768 type remove
Layer 5 : 32/768 type remove
Layer 6 : 38/768 type remove
Layer 7 : 43/768 type remove
Layer 8 : 63/768 type remove
Layer 9 : 64/768 type remove
Layer 10 : 55/768 type remove
Layer 11 : 31/768 type remove
Layer 12 : 33/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 14:57:53,104 [trainer.py] => Time:135.0263819694519
2200 2200
2200 2200
2025-12-11 14:57:59,397 [trainer.py] => Time:6.29280948638916
2025-12-11 14:57:59,397 [inflora.py] => Exemplar size: 0
2025-12-11 14:57:59,397 [trainer.py] => CNN: {'total': np.float64(86.64), '00-01': np.float64(97.0), '02-03': np.float64(77.0), '04-05': np.float64(91.5), '06-07': np.float64(69.0), '08-09': np.float64(96.5), '10-11': np.float64(76.0), '12-13': np.float64(91.5), '14-15': np.float64(95.0), '16-17': np.float64(89.0), '18-19': np.float64(85.5), '20-21': np.float64(85.0), 'old': np.float64(86.8), 'new': np.float64(85.0)}
2025-12-11 14:57:59,397 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64)]
2025-12-11 14:57:59,397 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68)]
2025-12-11 14:57:59,397 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363]
2025-12-11 14:58:08,885 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 72.5, '04-05': 98.0, '06-07': 96.5, '08-09': 98.5, '10-11': 95.0, '12-13': 99.0, '14-15': 97.5, '16-17': 98.5, '18-19': 99.0, '20-21': 99.5}
2025-12-11 14:58:08,885 [trainer.py] => Ave Acc (W-NCM): 95.77%
2025-12-11 14:58:08,885 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 72.50% (best 100.00%); T3: W-NCM 98.00% (best 100.00%); T4: W-NCM 96.50% (best 98.50%); T5: W-NCM 98.50% (best 100.00%); T6: W-NCM 95.00% (best 100.00%); T7: W-NCM 99.00% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 98.50% (best 99.50%); T10: W-NCM 99.00% (best 99.00%); T11: W-NCM 99.50% (best 99.50%)
2025-12-11 14:58:08,885 [trainer.py] => Average forgetting (W-NCM): 4.10% | Max forgetting (W-NCM): 27.50%
2025-12-11 14:58:09,576 [trainer.py] => All params: 125940251
2025-12-11 14:58:09,582 [trainer.py] => Trainable params: 185858
2025-12-11 14:58:09,582 [inflora.py] => Learning on 22-24
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_v.11.weight', 'image_encoder.blocks.6.attn.lora_B_k.11.weight', 'image_encoder.blocks.0.attn.lora_B_k.11.weight', 'image_encoder.blocks.9.attn.lora_B_k.11.weight', 'image_encoder.blocks.4.attn.lora_B_k.11.weight', 'image_encoder.blocks.9.attn.lora_B_v.11.weight', 'image_encoder.blocks.10.attn.lora_B_v.11.weight', 'image_encoder.blocks.5.attn.lora_B_k.11.weight', 'image_encoder.blocks.3.attn.lora_B_k.11.weight', 'image_encoder.blocks.1.attn.lora_B_k.11.weight', 'image_encoder.blocks.2.attn.lora_B_v.11.weight', 'image_encoder.blocks.10.attn.lora_B_k.11.weight', 'image_encoder.blocks.0.attn.lora_B_v.11.weight', 'image_encoder.blocks.8.attn.lora_B_v.11.weight', 'classifier_pool.11.weight', 'image_encoder.blocks.7.attn.lora_B_v.11.weight', 'image_encoder.blocks.1.attn.lora_B_v.11.weight', 'image_encoder.blocks.11.attn.lora_B_k.11.weight', 'image_encoder.blocks.4.attn.lora_B_v.11.weight', 'classifier_pool.11.bias', 'image_encoder.blocks.8.attn.lora_B_k.11.weight', 'image_encoder.blocks.3.attn.lora_B_v.11.weight', 'image_encoder.blocks.5.attn.lora_B_v.11.weight', 'image_encoder.blocks.7.attn.lora_B_k.11.weight', 'image_encoder.blocks.6.attn.lora_B_v.11.weight', 'image_encoder.blocks.2.attn.lora_B_k.11.weight'}
2025-12-11 15:00:15,327 [inflora.py] => Task 11, Epoch 20/20 => Loss 0.010, Train_accy 99.70
Threshold:  0.961
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 24/768 type remove
Layer 4 : 27/768 type remove
Layer 5 : 33/768 type remove
Layer 6 : 39/768 type remove
Layer 7 : 46/768 type remove
Layer 8 : 68/768 type remove
Layer 9 : 69/768 type remove
Layer 10 : 58/768 type remove
Layer 11 : 33/768 type remove
Layer 12 : 36/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:00:25,312 [trainer.py] => Time:135.73009514808655
2400 2400
2400 2400
2025-12-11 15:00:32,075 [trainer.py] => Time:6.7621142864227295
2025-12-11 15:00:32,075 [inflora.py] => Exemplar size: 0
2025-12-11 15:00:32,075 [trainer.py] => CNN: {'total': np.float64(85.04), '00-01': np.float64(94.0), '02-03': np.float64(78.0), '04-05': np.float64(90.0), '06-07': np.float64(63.0), '08-09': np.float64(89.5), '10-11': np.float64(71.5), '12-13': np.float64(92.5), '14-15': np.float64(94.5), '16-17': np.float64(85.5), '18-19': np.float64(85.5), '20-21': np.float64(83.5), '22-23': np.float64(93.0), 'old': np.float64(84.32), 'new': np.float64(93.0)}
2025-12-11 15:00:32,075 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04)]
2025-12-11 15:00:32,075 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58)]
2025-12-11 15:00:32,075 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667]
2025-12-11 15:00:42,102 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 72.5, '04-05': 98.0, '06-07': 96.5, '08-09': 98.5, '10-11': 95.0, '12-13': 97.0, '14-15': 97.5, '16-17': 96.5, '18-19': 98.5, '20-21': 99.5, '22-23': 99.0}
2025-12-11 15:00:42,103 [trainer.py] => Ave Acc (W-NCM): 95.67%
2025-12-11 15:00:42,103 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 72.50% (best 100.00%); T3: W-NCM 98.00% (best 100.00%); T4: W-NCM 96.50% (best 98.50%); T5: W-NCM 98.50% (best 100.00%); T6: W-NCM 95.00% (best 100.00%); T7: W-NCM 97.00% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 96.50% (best 99.50%); T10: W-NCM 98.50% (best 99.00%); T11: W-NCM 99.50% (best 99.50%); T12: W-NCM 99.00% (best 99.00%)
2025-12-11 15:00:42,103 [trainer.py] => Average forgetting (W-NCM): 4.14% | Max forgetting (W-NCM): 27.50%
2025-12-11 15:00:42,787 [trainer.py] => All params: 125940251
2025-12-11 15:00:42,793 [trainer.py] => Trainable params: 185858
2025-12-11 15:00:42,793 [inflora.py] => Learning on 24-26
Parameters to be updated: {'classifier_pool.12.weight', 'image_encoder.blocks.6.attn.lora_B_v.12.weight', 'image_encoder.blocks.1.attn.lora_B_v.12.weight', 'classifier_pool.12.bias', 'image_encoder.blocks.3.attn.lora_B_v.12.weight', 'image_encoder.blocks.3.attn.lora_B_k.12.weight', 'image_encoder.blocks.9.attn.lora_B_v.12.weight', 'image_encoder.blocks.1.attn.lora_B_k.12.weight', 'image_encoder.blocks.4.attn.lora_B_v.12.weight', 'image_encoder.blocks.10.attn.lora_B_v.12.weight', 'image_encoder.blocks.7.attn.lora_B_v.12.weight', 'image_encoder.blocks.4.attn.lora_B_k.12.weight', 'image_encoder.blocks.2.attn.lora_B_v.12.weight', 'image_encoder.blocks.2.attn.lora_B_k.12.weight', 'image_encoder.blocks.8.attn.lora_B_k.12.weight', 'image_encoder.blocks.10.attn.lora_B_k.12.weight', 'image_encoder.blocks.7.attn.lora_B_k.12.weight', 'image_encoder.blocks.0.attn.lora_B_v.12.weight', 'image_encoder.blocks.8.attn.lora_B_v.12.weight', 'image_encoder.blocks.5.attn.lora_B_k.12.weight', 'image_encoder.blocks.5.attn.lora_B_v.12.weight', 'image_encoder.blocks.6.attn.lora_B_k.12.weight', 'image_encoder.blocks.9.attn.lora_B_k.12.weight', 'image_encoder.blocks.0.attn.lora_B_k.12.weight', 'image_encoder.blocks.11.attn.lora_B_k.12.weight', 'image_encoder.blocks.11.attn.lora_B_v.12.weight'}
2025-12-11 15:02:48,339 [inflora.py] => Task 12, Epoch 20/20 => Loss 0.033, Train_accy 99.00
Threshold:  0.962
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 25/768 type remove
Layer 4 : 28/768 type remove
Layer 5 : 37/768 type remove
Layer 6 : 44/768 type remove
Layer 7 : 50/768 type remove
Layer 8 : 73/768 type remove
Layer 9 : 75/768 type remove
Layer 10 : 62/768 type remove
Layer 11 : 36/768 type remove
Layer 12 : 38/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:02:58,014 [trainer.py] => Time:135.22081232070923
2600 2600
2600 2600
2025-12-11 15:03:05,360 [trainer.py] => Time:7.346313953399658
2025-12-11 15:03:05,361 [inflora.py] => Exemplar size: 0
2025-12-11 15:03:05,361 [trainer.py] => CNN: {'total': np.float64(83.81), '00-01': np.float64(94.5), '02-03': np.float64(82.0), '04-05': np.float64(89.5), '06-07': np.float64(62.0), '08-09': np.float64(93.0), '10-11': np.float64(67.0), '12-13': np.float64(87.5), '14-15': np.float64(90.5), '16-17': np.float64(87.5), '18-19': np.float64(88.5), '20-21': np.float64(85.0), '22-23': np.float64(92.5), '24-25': np.float64(70.0), 'old': np.float64(84.96), 'new': np.float64(70.0)}
2025-12-11 15:03:05,361 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81)]
2025-12-11 15:03:05,361 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77)]
2025-12-11 15:03:05,361 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923]
2025-12-11 15:03:15,946 [trainer.py] => W-NCM: {'00-01': 99.0, '02-03': 81.5, '04-05': 91.5, '06-07': 88.0, '08-09': 98.5, '10-11': 91.0, '12-13': 96.5, '14-15': 98.0, '16-17': 97.0, '18-19': 98.5, '20-21': 95.5, '22-23': 98.5, '24-25': 98.0}
2025-12-11 15:03:15,946 [trainer.py] => Ave Acc (W-NCM): 94.73%
2025-12-11 15:03:15,946 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.00% (best 100.00%); T2: W-NCM 81.50% (best 100.00%); T3: W-NCM 91.50% (best 100.00%); T4: W-NCM 88.00% (best 98.50%); T5: W-NCM 98.50% (best 100.00%); T6: W-NCM 91.00% (best 100.00%); T7: W-NCM 96.50% (best 99.50%); T8: W-NCM 98.00% (best 98.50%); T9: W-NCM 97.00% (best 99.50%); T10: W-NCM 98.50% (best 99.00%); T11: W-NCM 95.50% (best 99.50%); T12: W-NCM 98.50% (best 99.00%); T13: W-NCM 98.00% (best 98.00%)
2025-12-11 15:03:15,946 [trainer.py] => Average forgetting (W-NCM): 5.00% | Max forgetting (W-NCM): 18.50%
2025-12-11 15:03:16,638 [trainer.py] => All params: 125940251
2025-12-11 15:03:16,645 [trainer.py] => Trainable params: 185858
2025-12-11 15:03:16,645 [inflora.py] => Learning on 26-28
Parameters to be updated: {'image_encoder.blocks.5.attn.lora_B_v.13.weight', 'image_encoder.blocks.2.attn.lora_B_k.13.weight', 'image_encoder.blocks.10.attn.lora_B_v.13.weight', 'image_encoder.blocks.6.attn.lora_B_v.13.weight', 'image_encoder.blocks.2.attn.lora_B_v.13.weight', 'image_encoder.blocks.1.attn.lora_B_v.13.weight', 'image_encoder.blocks.9.attn.lora_B_k.13.weight', 'image_encoder.blocks.6.attn.lora_B_k.13.weight', 'image_encoder.blocks.10.attn.lora_B_k.13.weight', 'classifier_pool.13.weight', 'image_encoder.blocks.5.attn.lora_B_k.13.weight', 'classifier_pool.13.bias', 'image_encoder.blocks.1.attn.lora_B_k.13.weight', 'image_encoder.blocks.8.attn.lora_B_v.13.weight', 'image_encoder.blocks.0.attn.lora_B_k.13.weight', 'image_encoder.blocks.4.attn.lora_B_k.13.weight', 'image_encoder.blocks.9.attn.lora_B_v.13.weight', 'image_encoder.blocks.8.attn.lora_B_k.13.weight', 'image_encoder.blocks.3.attn.lora_B_k.13.weight', 'image_encoder.blocks.7.attn.lora_B_k.13.weight', 'image_encoder.blocks.3.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_v.13.weight', 'image_encoder.blocks.0.attn.lora_B_v.13.weight', 'image_encoder.blocks.11.attn.lora_B_k.13.weight', 'image_encoder.blocks.7.attn.lora_B_v.13.weight', 'image_encoder.blocks.4.attn.lora_B_v.13.weight'}
2025-12-11 15:05:22,355 [inflora.py] => Task 13, Epoch 20/20 => Loss 0.055, Train_accy 97.20
Threshold:  0.963
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 26/768 type remove
Layer 4 : 29/768 type remove
Layer 5 : 39/768 type remove
Layer 6 : 48/768 type remove
Layer 7 : 54/768 type remove
Layer 8 : 78/768 type remove
Layer 9 : 82/768 type remove
Layer 10 : 68/768 type remove
Layer 11 : 39/768 type remove
Layer 12 : 40/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:05:32,313 [trainer.py] => Time:135.66875076293945
2800 2800
2800 2800
2025-12-11 15:05:40,158 [trainer.py] => Time:7.8442299365997314
2025-12-11 15:05:40,158 [inflora.py] => Exemplar size: 0
2025-12-11 15:05:40,158 [trainer.py] => CNN: {'total': np.float64(83.29), '00-01': np.float64(96.5), '02-03': np.float64(80.0), '04-05': np.float64(87.0), '06-07': np.float64(57.0), '08-09': np.float64(95.5), '10-11': np.float64(66.5), '12-13': np.float64(85.5), '14-15': np.float64(91.0), '16-17': np.float64(86.0), '18-19': np.float64(89.0), '20-21': np.float64(82.5), '22-23': np.float64(91.0), '24-25': np.float64(72.5), '26-27': np.float64(86.0), 'old': np.float64(83.08), 'new': np.float64(86.0)}
2025-12-11 15:05:40,158 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29)]
2025-12-11 15:05:40,158 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75)]
2025-12-11 15:05:40,158 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429]
2025-12-11 15:05:51,229 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 85.5, '04-05': 90.0, '06-07': 89.0, '08-09': 98.5, '10-11': 85.0, '12-13': 96.0, '14-15': 97.5, '16-17': 98.5, '18-19': 98.5, '20-21': 95.0, '22-23': 98.0, '24-25': 97.0, '26-27': 99.0}
2025-12-11 15:05:51,229 [trainer.py] => Ave Acc (W-NCM): 94.79%
2025-12-11 15:05:51,229 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 85.50% (best 100.00%); T3: W-NCM 90.00% (best 100.00%); T4: W-NCM 89.00% (best 98.50%); T5: W-NCM 98.50% (best 100.00%); T6: W-NCM 85.00% (best 100.00%); T7: W-NCM 96.00% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 98.50% (best 99.50%); T10: W-NCM 98.50% (best 99.00%); T11: W-NCM 95.00% (best 99.50%); T12: W-NCM 98.00% (best 99.00%); T13: W-NCM 97.00% (best 98.00%); T14: W-NCM 99.00% (best 99.00%)
2025-12-11 15:05:51,229 [trainer.py] => Average forgetting (W-NCM): 4.88% | Max forgetting (W-NCM): 15.00%
2025-12-11 15:05:51,921 [trainer.py] => All params: 125940251
2025-12-11 15:05:51,928 [trainer.py] => Trainable params: 185858
2025-12-11 15:05:51,928 [inflora.py] => Learning on 28-30
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_v.14.weight', 'classifier_pool.14.weight', 'image_encoder.blocks.11.attn.lora_B_v.14.weight', 'image_encoder.blocks.10.attn.lora_B_v.14.weight', 'image_encoder.blocks.7.attn.lora_B_k.14.weight', 'image_encoder.blocks.10.attn.lora_B_k.14.weight', 'image_encoder.blocks.9.attn.lora_B_k.14.weight', 'image_encoder.blocks.8.attn.lora_B_k.14.weight', 'image_encoder.blocks.6.attn.lora_B_v.14.weight', 'image_encoder.blocks.6.attn.lora_B_k.14.weight', 'image_encoder.blocks.4.attn.lora_B_v.14.weight', 'image_encoder.blocks.8.attn.lora_B_v.14.weight', 'image_encoder.blocks.2.attn.lora_B_v.14.weight', 'image_encoder.blocks.3.attn.lora_B_k.14.weight', 'image_encoder.blocks.5.attn.lora_B_k.14.weight', 'image_encoder.blocks.0.attn.lora_B_k.14.weight', 'image_encoder.blocks.1.attn.lora_B_v.14.weight', 'image_encoder.blocks.5.attn.lora_B_v.14.weight', 'classifier_pool.14.bias', 'image_encoder.blocks.9.attn.lora_B_v.14.weight', 'image_encoder.blocks.7.attn.lora_B_v.14.weight', 'image_encoder.blocks.2.attn.lora_B_k.14.weight', 'image_encoder.blocks.11.attn.lora_B_k.14.weight', 'image_encoder.blocks.3.attn.lora_B_v.14.weight', 'image_encoder.blocks.1.attn.lora_B_k.14.weight', 'image_encoder.blocks.4.attn.lora_B_k.14.weight'}
2025-12-11 15:07:57,721 [inflora.py] => Task 14, Epoch 20/20 => Loss 0.026, Train_accy 98.90
Threshold:  0.964
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 27/768 type remove
Layer 4 : 30/768 type remove
Layer 5 : 40/768 type remove
Layer 6 : 50/768 type remove
Layer 7 : 57/768 type remove
Layer 8 : 81/768 type remove
Layer 9 : 86/768 type remove
Layer 10 : 73/768 type remove
Layer 11 : 42/768 type remove
Layer 12 : 43/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:08:07,444 [trainer.py] => Time:135.5167260169983
3000 3000
3000 3000
2025-12-11 15:08:15,807 [trainer.py] => Time:8.362306594848633
2025-12-11 15:08:15,807 [inflora.py] => Exemplar size: 0
2025-12-11 15:08:15,807 [trainer.py] => CNN: {'total': np.float64(82.87), '00-01': np.float64(97.5), '02-03': np.float64(81.0), '04-05': np.float64(83.5), '06-07': np.float64(57.0), '08-09': np.float64(96.5), '10-11': np.float64(64.0), '12-13': np.float64(86.0), '14-15': np.float64(91.0), '16-17': np.float64(84.5), '18-19': np.float64(85.0), '20-21': np.float64(82.5), '22-23': np.float64(89.0), '24-25': np.float64(74.5), '26-27': np.float64(84.0), '28-29': np.float64(87.0), 'old': np.float64(82.57), 'new': np.float64(87.0)}
2025-12-11 15:08:15,807 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87)]
2025-12-11 15:08:15,807 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7)]
2025-12-11 15:08:15,808 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667]
2025-12-11 15:08:27,352 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 86.5, '04-05': 90.0, '06-07': 91.5, '08-09': 98.5, '10-11': 64.0, '12-13': 97.0, '14-15': 97.5, '16-17': 96.0, '18-19': 96.0, '20-21': 93.5, '22-23': 97.0, '24-25': 95.0, '26-27': 97.0, '28-29': 97.5}
2025-12-11 15:08:27,352 [trainer.py] => Ave Acc (W-NCM): 93.10%
2025-12-11 15:08:27,352 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 86.50% (best 100.00%); T3: W-NCM 90.00% (best 100.00%); T4: W-NCM 91.50% (best 98.50%); T5: W-NCM 98.50% (best 100.00%); T6: W-NCM 64.00% (best 100.00%); T7: W-NCM 97.00% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 96.00% (best 99.50%); T10: W-NCM 96.00% (best 99.00%); T11: W-NCM 93.50% (best 99.50%); T12: W-NCM 97.00% (best 99.00%); T13: W-NCM 95.00% (best 98.00%); T14: W-NCM 97.00% (best 99.00%); T15: W-NCM 97.50% (best 97.50%)
2025-12-11 15:08:27,353 [trainer.py] => Average forgetting (W-NCM): 6.54% | Max forgetting (W-NCM): 36.00%
2025-12-11 15:08:28,194 [trainer.py] => All params: 125940251
2025-12-11 15:08:28,200 [trainer.py] => Trainable params: 185858
2025-12-11 15:08:28,200 [inflora.py] => Learning on 30-32
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_k.15.weight', 'image_encoder.blocks.4.attn.lora_B_v.15.weight', 'image_encoder.blocks.6.attn.lora_B_k.15.weight', 'image_encoder.blocks.10.attn.lora_B_k.15.weight', 'image_encoder.blocks.4.attn.lora_B_k.15.weight', 'classifier_pool.15.weight', 'image_encoder.blocks.5.attn.lora_B_v.15.weight', 'image_encoder.blocks.11.attn.lora_B_k.15.weight', 'image_encoder.blocks.2.attn.lora_B_v.15.weight', 'image_encoder.blocks.8.attn.lora_B_k.15.weight', 'image_encoder.blocks.3.attn.lora_B_k.15.weight', 'image_encoder.blocks.8.attn.lora_B_v.15.weight', 'image_encoder.blocks.3.attn.lora_B_v.15.weight', 'image_encoder.blocks.1.attn.lora_B_k.15.weight', 'image_encoder.blocks.9.attn.lora_B_v.15.weight', 'image_encoder.blocks.0.attn.lora_B_k.15.weight', 'image_encoder.blocks.0.attn.lora_B_v.15.weight', 'image_encoder.blocks.1.attn.lora_B_v.15.weight', 'classifier_pool.15.bias', 'image_encoder.blocks.7.attn.lora_B_v.15.weight', 'image_encoder.blocks.2.attn.lora_B_k.15.weight', 'image_encoder.blocks.11.attn.lora_B_v.15.weight', 'image_encoder.blocks.5.attn.lora_B_k.15.weight', 'image_encoder.blocks.10.attn.lora_B_v.15.weight', 'image_encoder.blocks.7.attn.lora_B_k.15.weight', 'image_encoder.blocks.6.attn.lora_B_v.15.weight'}
2025-12-11 15:10:33,755 [inflora.py] => Task 15, Epoch 20/20 => Loss 0.017, Train_accy 99.40
Threshold:  0.965
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 28/768 type remove
Layer 4 : 32/768 type remove
Layer 5 : 42/768 type remove
Layer 6 : 52/768 type remove
Layer 7 : 60/768 type remove
Layer 8 : 84/768 type remove
Layer 9 : 89/768 type remove
Layer 10 : 76/768 type remove
Layer 11 : 45/768 type remove
Layer 12 : 45/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:10:43,437 [trainer.py] => Time:135.23604536056519
3200 3200
3200 3200
2025-12-11 15:10:52,252 [trainer.py] => Time:8.815169334411621
2025-12-11 15:10:52,252 [inflora.py] => Exemplar size: 0
2025-12-11 15:10:52,252 [trainer.py] => CNN: {'total': np.float64(82.41), '00-01': np.float64(94.5), '02-03': np.float64(84.0), '04-05': np.float64(88.0), '06-07': np.float64(54.0), '08-09': np.float64(93.0), '10-11': np.float64(63.5), '12-13': np.float64(85.0), '14-15': np.float64(90.5), '16-17': np.float64(85.0), '18-19': np.float64(85.0), '20-21': np.float64(82.5), '22-23': np.float64(88.5), '24-25': np.float64(72.0), '26-27': np.float64(82.0), '28-29': np.float64(83.0), '30-31': np.float64(88.0), 'old': np.float64(82.03), 'new': np.float64(88.0)}
2025-12-11 15:10:52,252 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41)]
2025-12-11 15:10:52,252 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78)]
2025-12-11 15:10:52,252 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625]
2025-12-11 15:11:04,316 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 78.0, '04-05': 93.0, '06-07': 91.0, '08-09': 99.5, '10-11': 82.5, '12-13': 97.0, '14-15': 96.5, '16-17': 95.5, '18-19': 95.5, '20-21': 95.0, '22-23': 97.5, '24-25': 96.0, '26-27': 94.0, '28-29': 93.0, '30-31': 98.5}
2025-12-11 15:11:04,317 [trainer.py] => Ave Acc (W-NCM): 93.88%
2025-12-11 15:11:04,317 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 78.00% (best 100.00%); T3: W-NCM 93.00% (best 100.00%); T4: W-NCM 91.00% (best 98.50%); T5: W-NCM 99.50% (best 100.00%); T6: W-NCM 82.50% (best 100.00%); T7: W-NCM 97.00% (best 99.50%); T8: W-NCM 96.50% (best 98.50%); T9: W-NCM 95.50% (best 99.50%); T10: W-NCM 95.50% (best 99.00%); T11: W-NCM 95.00% (best 99.50%); T12: W-NCM 97.50% (best 99.00%); T13: W-NCM 96.00% (best 98.00%); T14: W-NCM 94.00% (best 99.00%); T15: W-NCM 93.00% (best 97.50%); T16: W-NCM 98.50% (best 98.50%)
2025-12-11 15:11:04,317 [trainer.py] => Average forgetting (W-NCM): 5.63% | Max forgetting (W-NCM): 22.00%
2025-12-11 15:11:05,014 [trainer.py] => All params: 125940251
2025-12-11 15:11:05,021 [trainer.py] => Trainable params: 185858
2025-12-11 15:11:05,021 [inflora.py] => Learning on 32-34
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.16.weight', 'image_encoder.blocks.4.attn.lora_B_v.16.weight', 'image_encoder.blocks.8.attn.lora_B_k.16.weight', 'image_encoder.blocks.1.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_k.16.weight', 'image_encoder.blocks.7.attn.lora_B_v.16.weight', 'image_encoder.blocks.10.attn.lora_B_k.16.weight', 'image_encoder.blocks.3.attn.lora_B_v.16.weight', 'image_encoder.blocks.11.attn.lora_B_k.16.weight', 'image_encoder.blocks.9.attn.lora_B_v.16.weight', 'image_encoder.blocks.5.attn.lora_B_v.16.weight', 'image_encoder.blocks.6.attn.lora_B_k.16.weight', 'image_encoder.blocks.1.attn.lora_B_v.16.weight', 'image_encoder.blocks.2.attn.lora_B_k.16.weight', 'image_encoder.blocks.10.attn.lora_B_v.16.weight', 'image_encoder.blocks.9.attn.lora_B_k.16.weight', 'image_encoder.blocks.8.attn.lora_B_v.16.weight', 'classifier_pool.16.bias', 'image_encoder.blocks.6.attn.lora_B_v.16.weight', 'classifier_pool.16.weight', 'image_encoder.blocks.4.attn.lora_B_k.16.weight', 'image_encoder.blocks.0.attn.lora_B_v.16.weight', 'image_encoder.blocks.2.attn.lora_B_v.16.weight', 'image_encoder.blocks.7.attn.lora_B_k.16.weight', 'image_encoder.blocks.11.attn.lora_B_v.16.weight', 'image_encoder.blocks.5.attn.lora_B_k.16.weight'}
2025-12-11 15:13:10,891 [inflora.py] => Task 16, Epoch 20/20 => Loss 0.033, Train_accy 99.00
Threshold:  0.966
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 29/768 type remove
Layer 4 : 33/768 type remove
Layer 5 : 43/768 type remove
Layer 6 : 55/768 type remove
Layer 7 : 63/768 type remove
Layer 8 : 87/768 type remove
Layer 9 : 93/768 type remove
Layer 10 : 81/768 type remove
Layer 11 : 47/768 type remove
Layer 12 : 48/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:13:20,700 [trainer.py] => Time:135.67882561683655
3400 3400
3400 3400
2025-12-11 15:13:30,039 [trainer.py] => Time:9.339557647705078
2025-12-11 15:13:30,040 [inflora.py] => Exemplar size: 0
2025-12-11 15:13:30,040 [trainer.py] => CNN: {'total': np.float64(81.71), '00-01': np.float64(89.0), '02-03': np.float64(80.0), '04-05': np.float64(88.0), '06-07': np.float64(52.5), '08-09': np.float64(89.5), '10-11': np.float64(68.0), '12-13': np.float64(83.0), '14-15': np.float64(87.5), '16-17': np.float64(82.0), '18-19': np.float64(83.0), '20-21': np.float64(84.0), '22-23': np.float64(85.5), '24-25': np.float64(70.0), '26-27': np.float64(82.0), '28-29': np.float64(83.5), '30-31': np.float64(91.5), '32-33': np.float64(90.0), 'old': np.float64(81.19), 'new': np.float64(90.0)}
2025-12-11 15:13:30,040 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71)]
2025-12-11 15:13:30,040 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68)]
2025-12-11 15:13:30,040 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117]
2025-12-11 15:13:42,577 [trainer.py] => W-NCM: {'00-01': 96.5, '02-03': 72.5, '04-05': 89.5, '06-07': 90.0, '08-09': 99.0, '10-11': 85.5, '12-13': 93.5, '14-15': 96.5, '16-17': 94.5, '18-19': 92.5, '20-21': 97.0, '22-23': 93.0, '24-25': 95.5, '26-27': 93.0, '28-29': 92.0, '30-31': 97.5, '32-33': 98.0}
2025-12-11 15:13:42,577 [trainer.py] => Ave Acc (W-NCM): 92.71%
2025-12-11 15:13:42,577 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 96.50% (best 100.00%); T2: W-NCM 72.50% (best 100.00%); T3: W-NCM 89.50% (best 100.00%); T4: W-NCM 90.00% (best 98.50%); T5: W-NCM 99.00% (best 100.00%); T6: W-NCM 85.50% (best 100.00%); T7: W-NCM 93.50% (best 99.50%); T8: W-NCM 96.50% (best 98.50%); T9: W-NCM 94.50% (best 99.50%); T10: W-NCM 92.50% (best 99.00%); T11: W-NCM 97.00% (best 99.50%); T12: W-NCM 93.00% (best 99.00%); T13: W-NCM 95.50% (best 98.00%); T14: W-NCM 93.00% (best 99.00%); T15: W-NCM 92.00% (best 97.50%); T16: W-NCM 97.50% (best 98.50%); T17: W-NCM 98.00% (best 98.00%)
2025-12-11 15:13:42,577 [trainer.py] => Average forgetting (W-NCM): 6.78% | Max forgetting (W-NCM): 27.50%
2025-12-11 15:13:43,272 [trainer.py] => All params: 125940251
2025-12-11 15:13:43,279 [trainer.py] => Trainable params: 185858
2025-12-11 15:13:43,279 [inflora.py] => Learning on 34-36
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_v.17.weight', 'image_encoder.blocks.1.attn.lora_B_k.17.weight', 'image_encoder.blocks.6.attn.lora_B_k.17.weight', 'image_encoder.blocks.0.attn.lora_B_v.17.weight', 'image_encoder.blocks.10.attn.lora_B_k.17.weight', 'image_encoder.blocks.8.attn.lora_B_v.17.weight', 'image_encoder.blocks.1.attn.lora_B_v.17.weight', 'classifier_pool.17.weight', 'image_encoder.blocks.4.attn.lora_B_v.17.weight', 'classifier_pool.17.bias', 'image_encoder.blocks.3.attn.lora_B_v.17.weight', 'image_encoder.blocks.3.attn.lora_B_k.17.weight', 'image_encoder.blocks.4.attn.lora_B_k.17.weight', 'image_encoder.blocks.9.attn.lora_B_k.17.weight', 'image_encoder.blocks.2.attn.lora_B_k.17.weight', 'image_encoder.blocks.6.attn.lora_B_v.17.weight', 'image_encoder.blocks.8.attn.lora_B_k.17.weight', 'image_encoder.blocks.0.attn.lora_B_k.17.weight', 'image_encoder.blocks.10.attn.lora_B_v.17.weight', 'image_encoder.blocks.7.attn.lora_B_k.17.weight', 'image_encoder.blocks.7.attn.lora_B_v.17.weight', 'image_encoder.blocks.2.attn.lora_B_v.17.weight', 'image_encoder.blocks.5.attn.lora_B_v.17.weight', 'image_encoder.blocks.11.attn.lora_B_k.17.weight', 'image_encoder.blocks.5.attn.lora_B_k.17.weight', 'image_encoder.blocks.9.attn.lora_B_v.17.weight'}
2025-12-11 15:15:49,079 [inflora.py] => Task 17, Epoch 20/20 => Loss 0.018, Train_accy 99.30
Threshold:  0.967
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 31/768 type remove
Layer 4 : 35/768 type remove
Layer 5 : 47/768 type remove
Layer 6 : 59/768 type remove
Layer 7 : 68/768 type remove
Layer 8 : 93/768 type remove
Layer 9 : 102/768 type remove
Layer 10 : 91/768 type remove
Layer 11 : 53/768 type remove
Layer 12 : 50/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:15:58,726 [trainer.py] => Time:135.44687461853027
3600 3600
3600 3600
2025-12-11 15:16:08,633 [trainer.py] => Time:9.907490015029907
2025-12-11 15:16:08,633 [inflora.py] => Exemplar size: 0
2025-12-11 15:16:08,634 [trainer.py] => CNN: {'total': np.float64(78.0), '00-01': np.float64(89.5), '02-03': np.float64(77.0), '04-05': np.float64(90.0), '06-07': np.float64(49.0), '08-09': np.float64(89.0), '10-11': np.float64(44.5), '12-13': np.float64(81.0), '14-15': np.float64(84.0), '16-17': np.float64(78.0), '18-19': np.float64(74.5), '20-21': np.float64(82.5), '22-23': np.float64(86.0), '24-25': np.float64(71.0), '26-27': np.float64(82.0), '28-29': np.float64(85.0), '30-31': np.float64(86.0), '32-33': np.float64(89.5), '34-35': np.float64(65.5), 'old': np.float64(78.74), 'new': np.float64(65.5)}
2025-12-11 15:16:08,634 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0)]
2025-12-11 15:16:08,634 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69)]
2025-12-11 15:16:08,634 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78]
2025-12-11 15:16:21,681 [trainer.py] => W-NCM: {'00-01': 98.5, '02-03': 62.5, '04-05': 92.0, '06-07': 90.0, '08-09': 99.0, '10-11': 38.0, '12-13': 94.5, '14-15': 98.0, '16-17': 95.5, '18-19': 92.5, '20-21': 97.0, '22-23': 94.5, '24-25': 94.5, '26-27': 93.5, '28-29': 92.5, '30-31': 96.5, '32-33': 98.0, '34-35': 98.5}
2025-12-11 15:16:21,681 [trainer.py] => Ave Acc (W-NCM): 90.31%
2025-12-11 15:16:21,681 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 98.50% (best 100.00%); T2: W-NCM 62.50% (best 100.00%); T3: W-NCM 92.00% (best 100.00%); T4: W-NCM 90.00% (best 98.50%); T5: W-NCM 99.00% (best 100.00%); T6: W-NCM 38.00% (best 100.00%); T7: W-NCM 94.50% (best 99.50%); T8: W-NCM 98.00% (best 98.50%); T9: W-NCM 95.50% (best 99.50%); T10: W-NCM 92.50% (best 99.00%); T11: W-NCM 97.00% (best 99.50%); T12: W-NCM 94.50% (best 99.00%); T13: W-NCM 94.50% (best 98.00%); T14: W-NCM 93.50% (best 99.00%); T15: W-NCM 92.50% (best 97.50%); T16: W-NCM 96.50% (best 98.50%); T17: W-NCM 98.00% (best 98.00%); T18: W-NCM 98.50% (best 98.50%)
2025-12-11 15:16:21,681 [trainer.py] => Average forgetting (W-NCM): 9.26% | Max forgetting (W-NCM): 62.00%
2025-12-11 15:16:22,421 [trainer.py] => All params: 125940251
2025-12-11 15:16:22,427 [trainer.py] => Trainable params: 185858
2025-12-11 15:16:22,427 [inflora.py] => Learning on 36-38
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.18.weight', 'image_encoder.blocks.4.attn.lora_B_v.18.weight', 'image_encoder.blocks.8.attn.lora_B_k.18.weight', 'image_encoder.blocks.7.attn.lora_B_v.18.weight', 'image_encoder.blocks.3.attn.lora_B_v.18.weight', 'image_encoder.blocks.2.attn.lora_B_k.18.weight', 'image_encoder.blocks.6.attn.lora_B_k.18.weight', 'image_encoder.blocks.7.attn.lora_B_k.18.weight', 'image_encoder.blocks.5.attn.lora_B_v.18.weight', 'classifier_pool.18.weight', 'image_encoder.blocks.11.attn.lora_B_v.18.weight', 'image_encoder.blocks.11.attn.lora_B_k.18.weight', 'image_encoder.blocks.9.attn.lora_B_k.18.weight', 'image_encoder.blocks.1.attn.lora_B_k.18.weight', 'image_encoder.blocks.1.attn.lora_B_v.18.weight', 'image_encoder.blocks.4.attn.lora_B_k.18.weight', 'image_encoder.blocks.9.attn.lora_B_v.18.weight', 'image_encoder.blocks.10.attn.lora_B_k.18.weight', 'image_encoder.blocks.2.attn.lora_B_v.18.weight', 'image_encoder.blocks.0.attn.lora_B_v.18.weight', 'image_encoder.blocks.8.attn.lora_B_v.18.weight', 'classifier_pool.18.bias', 'image_encoder.blocks.3.attn.lora_B_k.18.weight', 'image_encoder.blocks.10.attn.lora_B_v.18.weight', 'image_encoder.blocks.6.attn.lora_B_v.18.weight', 'image_encoder.blocks.5.attn.lora_B_k.18.weight'}
2025-12-11 15:18:28,402 [inflora.py] => Task 18, Epoch 20/20 => Loss 0.013, Train_accy 99.50
Threshold:  0.968
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 32/768 type remove
Layer 4 : 36/768 type remove
Layer 5 : 50/768 type remove
Layer 6 : 63/768 type remove
Layer 7 : 71/768 type remove
Layer 8 : 97/768 type remove
Layer 9 : 110/768 type remove
Layer 10 : 99/768 type remove
Layer 11 : 57/768 type remove
Layer 12 : 53/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:18:38,394 [trainer.py] => Time:135.96698188781738
3800 3800
3800 3800
2025-12-11 15:18:48,794 [trainer.py] => Time:10.399436950683594
2025-12-11 15:18:48,794 [inflora.py] => Exemplar size: 0
2025-12-11 15:18:48,794 [trainer.py] => CNN: {'total': np.float64(77.58), '00-01': np.float64(86.5), '02-03': np.float64(77.0), '04-05': np.float64(91.0), '06-07': np.float64(48.0), '08-09': np.float64(84.0), '10-11': np.float64(44.0), '12-13': np.float64(77.0), '14-15': np.float64(82.5), '16-17': np.float64(80.0), '18-19': np.float64(77.5), '20-21': np.float64(81.0), '22-23': np.float64(83.5), '24-25': np.float64(70.5), '26-27': np.float64(80.0), '28-29': np.float64(85.0), '30-31': np.float64(87.5), '32-33': np.float64(89.0), '34-35': np.float64(62.0), '36-37': np.float64(88.0), 'old': np.float64(77.0), 'new': np.float64(88.0)}
2025-12-11 15:18:48,794 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58)]
2025-12-11 15:18:48,794 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66)]
2025-12-11 15:18:48,794 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105]
2025-12-11 15:19:02,410 [trainer.py] => W-NCM: {'00-01': 98.5, '02-03': 68.0, '04-05': 91.0, '06-07': 89.5, '08-09': 99.0, '10-11': 42.0, '12-13': 92.5, '14-15': 97.5, '16-17': 91.0, '18-19': 95.0, '20-21': 96.5, '22-23': 95.5, '24-25': 96.5, '26-27': 93.0, '28-29': 92.5, '30-31': 96.5, '32-33': 97.5, '34-35': 99.0, '36-37': 99.5}
2025-12-11 15:19:02,410 [trainer.py] => Ave Acc (W-NCM): 91.08%
2025-12-11 15:19:02,410 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 98.50% (best 100.00%); T2: W-NCM 68.00% (best 100.00%); T3: W-NCM 91.00% (best 100.00%); T4: W-NCM 89.50% (best 98.50%); T5: W-NCM 99.00% (best 100.00%); T6: W-NCM 42.00% (best 100.00%); T7: W-NCM 92.50% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 91.00% (best 99.50%); T10: W-NCM 95.00% (best 99.00%); T11: W-NCM 96.50% (best 99.50%); T12: W-NCM 95.50% (best 99.00%); T13: W-NCM 96.50% (best 98.00%); T14: W-NCM 93.00% (best 99.00%); T15: W-NCM 92.50% (best 97.50%); T16: W-NCM 96.50% (best 98.50%); T17: W-NCM 97.50% (best 98.00%); T18: W-NCM 99.00% (best 99.00%); T19: W-NCM 99.50% (best 99.50%)
2025-12-11 15:19:02,410 [trainer.py] => Average forgetting (W-NCM): 8.47% | Max forgetting (W-NCM): 58.00%
2025-12-11 15:19:03,097 [trainer.py] => All params: 125940251
2025-12-11 15:19:03,103 [trainer.py] => Trainable params: 185858
2025-12-11 15:19:03,103 [inflora.py] => Learning on 38-40
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_k.19.weight', 'image_encoder.blocks.11.attn.lora_B_v.19.weight', 'image_encoder.blocks.3.attn.lora_B_k.19.weight', 'image_encoder.blocks.1.attn.lora_B_v.19.weight', 'image_encoder.blocks.8.attn.lora_B_v.19.weight', 'image_encoder.blocks.11.attn.lora_B_k.19.weight', 'image_encoder.blocks.2.attn.lora_B_k.19.weight', 'image_encoder.blocks.3.attn.lora_B_v.19.weight', 'image_encoder.blocks.10.attn.lora_B_k.19.weight', 'image_encoder.blocks.0.attn.lora_B_k.19.weight', 'image_encoder.blocks.9.attn.lora_B_v.19.weight', 'image_encoder.blocks.4.attn.lora_B_v.19.weight', 'image_encoder.blocks.4.attn.lora_B_k.19.weight', 'image_encoder.blocks.5.attn.lora_B_k.19.weight', 'image_encoder.blocks.2.attn.lora_B_v.19.weight', 'image_encoder.blocks.7.attn.lora_B_v.19.weight', 'image_encoder.blocks.6.attn.lora_B_k.19.weight', 'image_encoder.blocks.7.attn.lora_B_k.19.weight', 'image_encoder.blocks.1.attn.lora_B_k.19.weight', 'image_encoder.blocks.6.attn.lora_B_v.19.weight', 'image_encoder.blocks.0.attn.lora_B_v.19.weight', 'classifier_pool.19.weight', 'image_encoder.blocks.5.attn.lora_B_v.19.weight', 'classifier_pool.19.bias', 'image_encoder.blocks.10.attn.lora_B_v.19.weight', 'image_encoder.blocks.8.attn.lora_B_k.19.weight'}
2025-12-11 15:21:09,105 [inflora.py] => Task 19, Epoch 20/20 => Loss 0.011, Train_accy 99.70
Threshold:  0.969
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 17/768 type remove
Layer 3 : 33/768 type remove
Layer 4 : 38/768 type remove
Layer 5 : 51/768 type remove
Layer 6 : 64/768 type remove
Layer 7 : 74/768 type remove
Layer 8 : 107/768 type remove
Layer 9 : 121/768 type remove
Layer 10 : 107/768 type remove
Layer 11 : 61/768 type remove
Layer 12 : 56/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:21:18,771 [trainer.py] => Time:135.66788911819458
4000 4000
4000 4000
2025-12-11 15:21:29,755 [trainer.py] => Time:10.983768939971924
2025-12-11 15:21:29,755 [inflora.py] => Exemplar size: 0
2025-12-11 15:21:29,755 [trainer.py] => CNN: {'total': np.float64(76.6), '00-01': np.float64(90.0), '02-03': np.float64(79.5), '04-05': np.float64(85.0), '06-07': np.float64(46.0), '08-09': np.float64(88.5), '10-11': np.float64(50.5), '12-13': np.float64(80.0), '14-15': np.float64(81.0), '16-17': np.float64(82.0), '18-19': np.float64(71.5), '20-21': np.float64(73.0), '22-23': np.float64(72.0), '24-25': np.float64(73.5), '26-27': np.float64(75.0), '28-29': np.float64(81.5), '30-31': np.float64(71.5), '32-33': np.float64(85.5), '34-35': np.float64(68.0), '36-37': np.float64(88.5), '38-39': np.float64(89.5), 'old': np.float64(75.92), 'new': np.float64(89.5)}
2025-12-11 15:21:29,755 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6)]
2025-12-11 15:21:29,755 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65)]
2025-12-11 15:21:29,756 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766]
2025-12-11 15:21:43,901 [trainer.py] => W-NCM: {'00-01': 99.0, '02-03': 71.5, '04-05': 89.0, '06-07': 92.5, '08-09': 99.5, '10-11': 34.0, '12-13': 90.5, '14-15': 97.5, '16-17': 91.5, '18-19': 92.5, '20-21': 95.0, '22-23': 95.0, '24-25': 95.0, '26-27': 91.0, '28-29': 92.5, '30-31': 93.5, '32-33': 95.5, '34-35': 97.5, '36-37': 99.0, '38-39': 99.0}
2025-12-11 15:21:43,902 [trainer.py] => Ave Acc (W-NCM): 90.53%
2025-12-11 15:21:43,902 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.00% (best 100.00%); T2: W-NCM 71.50% (best 100.00%); T3: W-NCM 89.00% (best 100.00%); T4: W-NCM 92.50% (best 98.50%); T5: W-NCM 99.50% (best 100.00%); T6: W-NCM 34.00% (best 100.00%); T7: W-NCM 90.50% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 91.50% (best 99.50%); T10: W-NCM 92.50% (best 99.00%); T11: W-NCM 95.00% (best 99.50%); T12: W-NCM 95.00% (best 99.00%); T13: W-NCM 95.00% (best 98.00%); T14: W-NCM 91.00% (best 99.00%); T15: W-NCM 92.50% (best 97.50%); T16: W-NCM 93.50% (best 98.50%); T17: W-NCM 95.50% (best 98.00%); T18: W-NCM 97.50% (best 99.00%); T19: W-NCM 99.00% (best 99.50%); T20: W-NCM 99.00% (best 99.00%)
2025-12-11 15:21:43,902 [trainer.py] => Average forgetting (W-NCM): 9.03% | Max forgetting (W-NCM): 66.00%
2025-12-11 15:21:44,644 [trainer.py] => All params: 125940251
2025-12-11 15:21:44,650 [trainer.py] => Trainable params: 185858
2025-12-11 15:21:44,650 [inflora.py] => Learning on 40-42
Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_k.20.weight', 'image_encoder.blocks.1.attn.lora_B_k.20.weight', 'image_encoder.blocks.1.attn.lora_B_v.20.weight', 'image_encoder.blocks.11.attn.lora_B_v.20.weight', 'classifier_pool.20.bias', 'image_encoder.blocks.4.attn.lora_B_k.20.weight', 'image_encoder.blocks.5.attn.lora_B_v.20.weight', 'image_encoder.blocks.8.attn.lora_B_k.20.weight', 'image_encoder.blocks.11.attn.lora_B_k.20.weight', 'image_encoder.blocks.7.attn.lora_B_v.20.weight', 'image_encoder.blocks.3.attn.lora_B_k.20.weight', 'image_encoder.blocks.3.attn.lora_B_v.20.weight', 'image_encoder.blocks.10.attn.lora_B_v.20.weight', 'image_encoder.blocks.0.attn.lora_B_k.20.weight', 'image_encoder.blocks.7.attn.lora_B_k.20.weight', 'image_encoder.blocks.9.attn.lora_B_v.20.weight', 'image_encoder.blocks.6.attn.lora_B_k.20.weight', 'image_encoder.blocks.5.attn.lora_B_k.20.weight', 'image_encoder.blocks.6.attn.lora_B_v.20.weight', 'image_encoder.blocks.4.attn.lora_B_v.20.weight', 'image_encoder.blocks.2.attn.lora_B_v.20.weight', 'image_encoder.blocks.8.attn.lora_B_v.20.weight', 'image_encoder.blocks.10.attn.lora_B_k.20.weight', 'image_encoder.blocks.9.attn.lora_B_k.20.weight', 'image_encoder.blocks.0.attn.lora_B_v.20.weight', 'classifier_pool.20.weight'}
2025-12-11 15:23:50,845 [inflora.py] => Task 20, Epoch 20/20 => Loss 0.041, Train_accy 98.50
Threshold:  0.97
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 17/768 type remove
Layer 3 : 34/768 type remove
Layer 4 : 39/768 type remove
Layer 5 : 52/768 type remove
Layer 6 : 65/768 type remove
Layer 7 : 76/768 type remove
Layer 8 : 110/768 type remove
Layer 9 : 124/768 type remove
Layer 10 : 111/768 type remove
Layer 11 : 64/768 type remove
Layer 12 : 58/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:24:00,656 [trainer.py] => Time:136.00598454475403
4200 4200
4200 4200
2025-12-11 15:24:12,108 [trainer.py] => Time:11.451560258865356
2025-12-11 15:24:12,108 [inflora.py] => Exemplar size: 0
2025-12-11 15:24:12,108 [trainer.py] => CNN: {'total': np.float64(76.76), '00-01': np.float64(90.5), '02-03': np.float64(79.5), '04-05': np.float64(85.0), '06-07': np.float64(51.5), '08-09': np.float64(87.0), '10-11': np.float64(58.5), '12-13': np.float64(85.0), '14-15': np.float64(83.5), '16-17': np.float64(76.5), '18-19': np.float64(74.0), '20-21': np.float64(74.5), '22-23': np.float64(71.5), '24-25': np.float64(70.0), '26-27': np.float64(71.5), '28-29': np.float64(83.0), '30-31': np.float64(78.0), '32-33': np.float64(81.0), '34-35': np.float64(54.5), '36-37': np.float64(82.5), '38-39': np.float64(86.5), '40-41': np.float64(88.0), 'old': np.float64(76.2), 'new': np.float64(88.0)}
2025-12-11 15:24:12,108 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76)]
2025-12-11 15:24:12,108 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57)]
2025-12-11 15:24:12,108 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476]
2025-12-11 15:24:26,799 [trainer.py] => W-NCM: {'00-01': 99.0, '02-03': 75.5, '04-05': 92.0, '06-07': 94.0, '08-09': 97.0, '10-11': 54.50000000000001, '12-13': 93.0, '14-15': 96.5, '16-17': 87.5, '18-19': 94.0, '20-21': 97.0, '22-23': 95.5, '24-25': 91.0, '26-27': 91.0, '28-29': 94.0, '30-31': 94.5, '32-33': 94.5, '34-35': 96.5, '36-37': 98.0, '38-39': 97.0, '40-41': 98.5}
2025-12-11 15:24:26,799 [trainer.py] => Ave Acc (W-NCM): 91.93%
2025-12-11 15:24:26,799 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.00% (best 100.00%); T2: W-NCM 75.50% (best 100.00%); T3: W-NCM 92.00% (best 100.00%); T4: W-NCM 94.00% (best 98.50%); T5: W-NCM 97.00% (best 100.00%); T6: W-NCM 54.50% (best 100.00%); T7: W-NCM 93.00% (best 99.50%); T8: W-NCM 96.50% (best 98.50%); T9: W-NCM 87.50% (best 99.50%); T10: W-NCM 94.00% (best 99.00%); T11: W-NCM 97.00% (best 99.50%); T12: W-NCM 95.50% (best 99.00%); T13: W-NCM 91.00% (best 98.00%); T14: W-NCM 91.00% (best 99.00%); T15: W-NCM 94.00% (best 97.50%); T16: W-NCM 94.50% (best 98.50%); T17: W-NCM 94.50% (best 98.00%); T18: W-NCM 96.50% (best 99.00%); T19: W-NCM 98.00% (best 99.50%); T20: W-NCM 97.00% (best 99.00%); T21: W-NCM 98.50% (best 98.50%)
2025-12-11 15:24:26,799 [trainer.py] => Average forgetting (W-NCM): 7.50% | Max forgetting (W-NCM): 45.50%
2025-12-11 15:24:27,498 [trainer.py] => All params: 125940251
2025-12-11 15:24:27,504 [trainer.py] => Trainable params: 185858
2025-12-11 15:24:27,504 [inflora.py] => Learning on 42-44
Parameters to be updated: {'image_encoder.blocks.7.attn.lora_B_v.21.weight', 'image_encoder.blocks.3.attn.lora_B_v.21.weight', 'image_encoder.blocks.5.attn.lora_B_v.21.weight', 'image_encoder.blocks.10.attn.lora_B_v.21.weight', 'image_encoder.blocks.4.attn.lora_B_k.21.weight', 'image_encoder.blocks.8.attn.lora_B_k.21.weight', 'image_encoder.blocks.11.attn.lora_B_k.21.weight', 'image_encoder.blocks.2.attn.lora_B_v.21.weight', 'image_encoder.blocks.4.attn.lora_B_v.21.weight', 'image_encoder.blocks.0.attn.lora_B_k.21.weight', 'image_encoder.blocks.8.attn.lora_B_v.21.weight', 'classifier_pool.21.weight', 'image_encoder.blocks.3.attn.lora_B_k.21.weight', 'classifier_pool.21.bias', 'image_encoder.blocks.9.attn.lora_B_k.21.weight', 'image_encoder.blocks.6.attn.lora_B_k.21.weight', 'image_encoder.blocks.2.attn.lora_B_k.21.weight', 'image_encoder.blocks.1.attn.lora_B_v.21.weight', 'image_encoder.blocks.6.attn.lora_B_v.21.weight', 'image_encoder.blocks.1.attn.lora_B_k.21.weight', 'image_encoder.blocks.5.attn.lora_B_k.21.weight', 'image_encoder.blocks.10.attn.lora_B_k.21.weight', 'image_encoder.blocks.7.attn.lora_B_k.21.weight', 'image_encoder.blocks.0.attn.lora_B_v.21.weight', 'image_encoder.blocks.11.attn.lora_B_v.21.weight', 'image_encoder.blocks.9.attn.lora_B_v.21.weight'}
2025-12-11 15:26:33,533 [inflora.py] => Task 21, Epoch 20/20 => Loss 0.067, Train_accy 97.80
Threshold:  0.971
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 18/768 type remove
Layer 3 : 35/768 type remove
Layer 4 : 42/768 type remove
Layer 5 : 54/768 type remove
Layer 6 : 68/768 type remove
Layer 7 : 80/768 type remove
Layer 8 : 114/768 type remove
Layer 9 : 128/768 type remove
Layer 10 : 114/768 type remove
Layer 11 : 68/768 type remove
Layer 12 : 60/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:26:43,310 [trainer.py] => Time:135.80607771873474
4400 4400
4400 4400
2025-12-11 15:26:55,346 [trainer.py] => Time:12.035480260848999
2025-12-11 15:26:55,346 [inflora.py] => Exemplar size: 0
2025-12-11 15:26:55,346 [trainer.py] => CNN: {'total': np.float64(75.02), '00-01': np.float64(89.5), '02-03': np.float64(82.5), '04-05': np.float64(85.0), '06-07': np.float64(53.0), '08-09': np.float64(86.0), '10-11': np.float64(50.5), '12-13': np.float64(76.0), '14-15': np.float64(83.5), '16-17': np.float64(80.5), '18-19': np.float64(76.0), '20-21': np.float64(74.0), '22-23': np.float64(68.5), '24-25': np.float64(72.5), '26-27': np.float64(71.0), '28-29': np.float64(79.0), '30-31': np.float64(79.5), '32-33': np.float64(82.5), '34-35': np.float64(57.5), '36-37': np.float64(80.0), '38-39': np.float64(87.5), '40-41': np.float64(86.0), '42-43': np.float64(50.0), 'old': np.float64(76.21), 'new': np.float64(50.0)}
2025-12-11 15:26:55,346 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02)]
2025-12-11 15:26:55,346 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55)]
2025-12-11 15:26:55,346 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727]
2025-12-11 15:27:10,476 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 73.0, '04-05': 87.0, '06-07': 94.5, '08-09': 98.0, '10-11': 44.5, '12-13': 94.0, '14-15': 97.5, '16-17': 92.0, '18-19': 97.0, '20-21': 97.0, '22-23': 95.0, '24-25': 91.0, '26-27': 91.5, '28-29': 90.5, '30-31': 92.5, '32-33': 94.5, '34-35': 96.5, '36-37': 98.0, '38-39': 95.5, '40-41': 98.5, '42-43': 96.0}
2025-12-11 15:27:10,476 [trainer.py] => Ave Acc (W-NCM): 91.52%
2025-12-11 15:27:10,476 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 73.00% (best 100.00%); T3: W-NCM 87.00% (best 100.00%); T4: W-NCM 94.50% (best 98.50%); T5: W-NCM 98.00% (best 100.00%); T6: W-NCM 44.50% (best 100.00%); T7: W-NCM 94.00% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 92.00% (best 99.50%); T10: W-NCM 97.00% (best 99.00%); T11: W-NCM 97.00% (best 99.50%); T12: W-NCM 95.00% (best 99.00%); T13: W-NCM 91.00% (best 98.00%); T14: W-NCM 91.50% (best 99.00%); T15: W-NCM 90.50% (best 97.50%); T16: W-NCM 92.50% (best 98.50%); T17: W-NCM 94.50% (best 98.00%); T18: W-NCM 96.50% (best 99.00%); T19: W-NCM 98.00% (best 99.50%); T20: W-NCM 95.50% (best 99.00%); T21: W-NCM 98.50% (best 98.50%); T22: W-NCM 96.00% (best 96.00%)
2025-12-11 15:27:10,476 [trainer.py] => Average forgetting (W-NCM): 7.76% | Max forgetting (W-NCM): 55.50%
2025-12-11 15:27:11,173 [trainer.py] => All params: 125940251
2025-12-11 15:27:11,179 [trainer.py] => Trainable params: 185858
2025-12-11 15:27:11,179 [inflora.py] => Learning on 44-46
Parameters to be updated: {'image_encoder.blocks.7.attn.lora_B_k.22.weight', 'image_encoder.blocks.6.attn.lora_B_k.22.weight', 'classifier_pool.22.bias', 'image_encoder.blocks.5.attn.lora_B_k.22.weight', 'classifier_pool.22.weight', 'image_encoder.blocks.1.attn.lora_B_k.22.weight', 'image_encoder.blocks.5.attn.lora_B_v.22.weight', 'image_encoder.blocks.8.attn.lora_B_k.22.weight', 'image_encoder.blocks.2.attn.lora_B_k.22.weight', 'image_encoder.blocks.7.attn.lora_B_v.22.weight', 'image_encoder.blocks.3.attn.lora_B_k.22.weight', 'image_encoder.blocks.2.attn.lora_B_v.22.weight', 'image_encoder.blocks.9.attn.lora_B_v.22.weight', 'image_encoder.blocks.4.attn.lora_B_v.22.weight', 'image_encoder.blocks.3.attn.lora_B_v.22.weight', 'image_encoder.blocks.4.attn.lora_B_k.22.weight', 'image_encoder.blocks.0.attn.lora_B_k.22.weight', 'image_encoder.blocks.8.attn.lora_B_v.22.weight', 'image_encoder.blocks.10.attn.lora_B_k.22.weight', 'image_encoder.blocks.0.attn.lora_B_v.22.weight', 'image_encoder.blocks.6.attn.lora_B_v.22.weight', 'image_encoder.blocks.11.attn.lora_B_v.22.weight', 'image_encoder.blocks.1.attn.lora_B_v.22.weight', 'image_encoder.blocks.11.attn.lora_B_k.22.weight', 'image_encoder.blocks.10.attn.lora_B_v.22.weight', 'image_encoder.blocks.9.attn.lora_B_k.22.weight'}
2025-12-11 15:29:17,166 [inflora.py] => Task 22, Epoch 20/20 => Loss 0.048, Train_accy 98.20
Threshold:  0.972
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 18/768 type remove
Layer 3 : 36/768 type remove
Layer 4 : 43/768 type remove
Layer 5 : 56/768 type remove
Layer 6 : 70/768 type remove
Layer 7 : 83/768 type remove
Layer 8 : 120/768 type remove
Layer 9 : 135/768 type remove
Layer 10 : 122/768 type remove
Layer 11 : 72/768 type remove
Layer 12 : 63/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:29:26,962 [trainer.py] => Time:135.7822868824005
4600 4600
4600 4600
2025-12-11 15:29:39,472 [trainer.py] => Time:12.510508298873901
2025-12-11 15:29:39,472 [inflora.py] => Exemplar size: 0
2025-12-11 15:29:39,473 [trainer.py] => CNN: {'total': np.float64(76.54), '00-01': np.float64(92.0), '02-03': np.float64(82.5), '04-05': np.float64(87.0), '06-07': np.float64(56.5), '08-09': np.float64(91.0), '10-11': np.float64(59.0), '12-13': np.float64(83.5), '14-15': np.float64(85.0), '16-17': np.float64(79.0), '18-19': np.float64(80.5), '20-21': np.float64(77.0), '22-23': np.float64(61.0), '24-25': np.float64(69.5), '26-27': np.float64(78.0), '28-29': np.float64(82.5), '30-31': np.float64(83.5), '32-33': np.float64(86.0), '34-35': np.float64(55.0), '36-37': np.float64(82.0), '38-39': np.float64(87.5), '40-41': np.float64(87.0), '42-43': np.float64(50.5), '44-45': np.float64(65.0), 'old': np.float64(77.07), 'new': np.float64(65.0)}
2025-12-11 15:29:39,473 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54)]
2025-12-11 15:29:39,473 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57)]
2025-12-11 15:29:39,473 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957]
2025-12-11 15:29:55,037 [trainer.py] => W-NCM: {'00-01': 99.0, '02-03': 78.0, '04-05': 89.0, '06-07': 93.5, '08-09': 99.0, '10-11': 48.5, '12-13': 93.5, '14-15': 96.0, '16-17': 94.0, '18-19': 91.0, '20-21': 96.5, '22-23': 95.0, '24-25': 92.0, '26-27': 85.0, '28-29': 93.0, '30-31': 95.0, '32-33': 95.5, '34-35': 94.5, '36-37': 97.5, '38-39': 95.0, '40-41': 97.5, '42-43': 93.5, '44-45': 95.5}
2025-12-11 15:29:55,037 [trainer.py] => Ave Acc (W-NCM): 91.61%
2025-12-11 15:29:55,037 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.00% (best 100.00%); T2: W-NCM 78.00% (best 100.00%); T3: W-NCM 89.00% (best 100.00%); T4: W-NCM 93.50% (best 98.50%); T5: W-NCM 99.00% (best 100.00%); T6: W-NCM 48.50% (best 100.00%); T7: W-NCM 93.50% (best 99.50%); T8: W-NCM 96.00% (best 98.50%); T9: W-NCM 94.00% (best 99.50%); T10: W-NCM 91.00% (best 99.00%); T11: W-NCM 96.50% (best 99.50%); T12: W-NCM 95.00% (best 99.00%); T13: W-NCM 92.00% (best 98.00%); T14: W-NCM 85.00% (best 99.00%); T15: W-NCM 93.00% (best 97.50%); T16: W-NCM 95.00% (best 98.50%); T17: W-NCM 95.50% (best 98.00%); T18: W-NCM 94.50% (best 99.00%); T19: W-NCM 97.50% (best 99.50%); T20: W-NCM 95.00% (best 99.00%); T21: W-NCM 97.50% (best 98.50%); T22: W-NCM 93.50% (best 96.00%); T23: W-NCM 95.50% (best 95.50%)
2025-12-11 15:29:55,037 [trainer.py] => Average forgetting (W-NCM): 7.50% | Max forgetting (W-NCM): 51.50%
2025-12-11 15:29:55,730 [trainer.py] => All params: 125940251
2025-12-11 15:29:55,736 [trainer.py] => Trainable params: 185858
2025-12-11 15:29:55,736 [inflora.py] => Learning on 46-48
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.23.weight', 'image_encoder.blocks.5.attn.lora_B_k.23.weight', 'image_encoder.blocks.10.attn.lora_B_v.23.weight', 'classifier_pool.23.weight', 'image_encoder.blocks.2.attn.lora_B_v.23.weight', 'image_encoder.blocks.7.attn.lora_B_k.23.weight', 'image_encoder.blocks.10.attn.lora_B_k.23.weight', 'image_encoder.blocks.2.attn.lora_B_k.23.weight', 'image_encoder.blocks.11.attn.lora_B_v.23.weight', 'classifier_pool.23.bias', 'image_encoder.blocks.9.attn.lora_B_v.23.weight', 'image_encoder.blocks.5.attn.lora_B_v.23.weight', 'image_encoder.blocks.6.attn.lora_B_v.23.weight', 'image_encoder.blocks.0.attn.lora_B_v.23.weight', 'image_encoder.blocks.1.attn.lora_B_k.23.weight', 'image_encoder.blocks.3.attn.lora_B_v.23.weight', 'image_encoder.blocks.8.attn.lora_B_k.23.weight', 'image_encoder.blocks.0.attn.lora_B_k.23.weight', 'image_encoder.blocks.6.attn.lora_B_k.23.weight', 'image_encoder.blocks.8.attn.lora_B_v.23.weight', 'image_encoder.blocks.11.attn.lora_B_k.23.weight', 'image_encoder.blocks.7.attn.lora_B_v.23.weight', 'image_encoder.blocks.1.attn.lora_B_v.23.weight', 'image_encoder.blocks.9.attn.lora_B_k.23.weight', 'image_encoder.blocks.4.attn.lora_B_v.23.weight', 'image_encoder.blocks.3.attn.lora_B_k.23.weight'}
2025-12-11 15:32:01,996 [inflora.py] => Task 23, Epoch 20/20 => Loss 0.014, Train_accy 99.40
Threshold:  0.973
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 19/768 type remove
Layer 3 : 37/768 type remove
Layer 4 : 44/768 type remove
Layer 5 : 57/768 type remove
Layer 6 : 71/768 type remove
Layer 7 : 85/768 type remove
Layer 8 : 123/768 type remove
Layer 9 : 138/768 type remove
Layer 10 : 125/768 type remove
Layer 11 : 75/768 type remove
Layer 12 : 66/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:32:11,796 [trainer.py] => Time:136.05951404571533
4800 4800
4800 4800
2025-12-11 15:32:24,807 [trainer.py] => Time:13.01112699508667
2025-12-11 15:32:24,807 [inflora.py] => Exemplar size: 0
2025-12-11 15:32:24,807 [trainer.py] => CNN: {'total': np.float64(73.1), '00-01': np.float64(82.5), '02-03': np.float64(73.0), '04-05': np.float64(87.0), '06-07': np.float64(53.5), '08-09': np.float64(88.5), '10-11': np.float64(66.5), '12-13': np.float64(84.0), '14-15': np.float64(84.0), '16-17': np.float64(67.5), '18-19': np.float64(80.0), '20-21': np.float64(73.0), '22-23': np.float64(75.5), '24-25': np.float64(67.0), '26-27': np.float64(75.0), '28-29': np.float64(83.5), '30-31': np.float64(78.0), '32-33': np.float64(78.0), '34-35': np.float64(50.5), '36-37': np.float64(73.5), '38-39': np.float64(82.0), '40-41': np.float64(87.0), '42-43': np.float64(43.5), '44-45': np.float64(61.0), '46-47': np.float64(60.5), 'old': np.float64(73.65), 'new': np.float64(60.5)}
2025-12-11 15:32:24,807 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1)]
2025-12-11 15:32:24,807 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54)]
2025-12-11 15:32:24,807 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667]
2025-12-11 15:32:40,981 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 73.0, '04-05': 90.5, '06-07': 94.0, '08-09': 97.5, '10-11': 54.50000000000001, '12-13': 96.0, '14-15': 96.0, '16-17': 91.5, '18-19': 93.5, '20-21': 94.5, '22-23': 96.5, '24-25': 88.5, '26-27': 87.0, '28-29': 88.5, '30-31': 95.5, '32-33': 86.0, '34-35': 82.5, '36-37': 94.5, '38-39': 93.5, '40-41': 96.5, '42-43': 92.0, '44-45': 93.5, '46-47': 100.0}
2025-12-11 15:32:40,982 [trainer.py] => Ave Acc (W-NCM): 90.62%
2025-12-11 15:32:40,982 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 73.00% (best 100.00%); T3: W-NCM 90.50% (best 100.00%); T4: W-NCM 94.00% (best 98.50%); T5: W-NCM 97.50% (best 100.00%); T6: W-NCM 54.50% (best 100.00%); T7: W-NCM 96.00% (best 99.50%); T8: W-NCM 96.00% (best 98.50%); T9: W-NCM 91.50% (best 99.50%); T10: W-NCM 93.50% (best 99.00%); T11: W-NCM 94.50% (best 99.50%); T12: W-NCM 96.50% (best 99.00%); T13: W-NCM 88.50% (best 98.00%); T14: W-NCM 87.00% (best 99.00%); T15: W-NCM 88.50% (best 97.50%); T16: W-NCM 95.50% (best 98.50%); T17: W-NCM 86.00% (best 98.00%); T18: W-NCM 82.50% (best 99.00%); T19: W-NCM 94.50% (best 99.50%); T20: W-NCM 93.50% (best 99.00%); T21: W-NCM 96.50% (best 98.50%); T22: W-NCM 92.00% (best 96.00%); T23: W-NCM 93.50% (best 95.50%); T24: W-NCM 100.00% (best 100.00%)
2025-12-11 15:32:40,982 [trainer.py] => Average forgetting (W-NCM): 8.57% | Max forgetting (W-NCM): 45.50%
2025-12-11 15:32:41,674 [trainer.py] => All params: 125940251
2025-12-11 15:32:41,681 [trainer.py] => Trainable params: 185858
2025-12-11 15:32:41,681 [inflora.py] => Learning on 48-50
Parameters to be updated: {'classifier_pool.24.weight', 'image_encoder.blocks.9.attn.lora_B_v.24.weight', 'image_encoder.blocks.2.attn.lora_B_v.24.weight', 'image_encoder.blocks.3.attn.lora_B_v.24.weight', 'classifier_pool.24.bias', 'image_encoder.blocks.1.attn.lora_B_k.24.weight', 'image_encoder.blocks.10.attn.lora_B_v.24.weight', 'image_encoder.blocks.10.attn.lora_B_k.24.weight', 'image_encoder.blocks.8.attn.lora_B_v.24.weight', 'image_encoder.blocks.0.attn.lora_B_k.24.weight', 'image_encoder.blocks.3.attn.lora_B_k.24.weight', 'image_encoder.blocks.9.attn.lora_B_k.24.weight', 'image_encoder.blocks.0.attn.lora_B_v.24.weight', 'image_encoder.blocks.6.attn.lora_B_k.24.weight', 'image_encoder.blocks.11.attn.lora_B_k.24.weight', 'image_encoder.blocks.2.attn.lora_B_k.24.weight', 'image_encoder.blocks.7.attn.lora_B_k.24.weight', 'image_encoder.blocks.5.attn.lora_B_k.24.weight', 'image_encoder.blocks.4.attn.lora_B_v.24.weight', 'image_encoder.blocks.1.attn.lora_B_v.24.weight', 'image_encoder.blocks.4.attn.lora_B_k.24.weight', 'image_encoder.blocks.5.attn.lora_B_v.24.weight', 'image_encoder.blocks.8.attn.lora_B_k.24.weight', 'image_encoder.blocks.6.attn.lora_B_v.24.weight', 'image_encoder.blocks.11.attn.lora_B_v.24.weight', 'image_encoder.blocks.7.attn.lora_B_v.24.weight'}
2025-12-11 15:34:48,055 [inflora.py] => Task 24, Epoch 20/20 => Loss 0.023, Train_accy 99.20
Threshold:  0.974
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 19/768 type remove
Layer 3 : 38/768 type remove
Layer 4 : 46/768 type remove
Layer 5 : 59/768 type remove
Layer 6 : 73/768 type remove
Layer 7 : 88/768 type remove
Layer 8 : 126/768 type remove
Layer 9 : 142/768 type remove
Layer 10 : 129/768 type remove
Layer 11 : 78/768 type remove
Layer 12 : 69/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:34:57,820 [trainer.py] => Time:136.13964676856995
5000 5000
5000 5000
2025-12-11 15:35:11,437 [trainer.py] => Time:13.615786790847778
2025-12-11 15:35:11,437 [inflora.py] => Exemplar size: 0
2025-12-11 15:35:11,437 [trainer.py] => CNN: {'total': np.float64(73.52), '00-01': np.float64(89.0), '02-03': np.float64(79.5), '04-05': np.float64(81.5), '06-07': np.float64(49.5), '08-09': np.float64(84.5), '10-11': np.float64(53.0), '12-13': np.float64(77.0), '14-15': np.float64(83.0), '16-17': np.float64(81.5), '18-19': np.float64(79.5), '20-21': np.float64(66.5), '22-23': np.float64(63.0), '24-25': np.float64(70.5), '26-27': np.float64(76.0), '28-29': np.float64(77.0), '30-31': np.float64(80.5), '32-33': np.float64(78.5), '34-35': np.float64(53.5), '36-37': np.float64(75.0), '38-39': np.float64(87.5), '40-41': np.float64(83.5), '42-43': np.float64(48.0), '44-45': np.float64(63.5), '46-47': np.float64(62.5), '48-49': np.float64(94.5), 'old': np.float64(72.65), 'new': np.float64(94.5)}
2025-12-11 15:35:11,437 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52)]
2025-12-11 15:35:11,437 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52)]
2025-12-11 15:35:11,437 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352]
2025-12-11 15:35:28,163 [trainer.py] => W-NCM: {'00-01': 99.5, '02-03': 78.5, '04-05': 91.5, '06-07': 93.5, '08-09': 95.5, '10-11': 43.0, '12-13': 93.5, '14-15': 95.5, '16-17': 94.0, '18-19': 92.0, '20-21': 94.5, '22-23': 83.5, '24-25': 88.0, '26-27': 85.5, '28-29': 92.0, '30-31': 96.0, '32-33': 80.5, '34-35': 88.5, '36-37': 94.5, '38-39': 95.0, '40-41': 95.5, '42-43': 91.5, '44-45': 93.5, '46-47': 97.5, '48-49': 99.0}
2025-12-11 15:35:28,164 [trainer.py] => Ave Acc (W-NCM): 90.06%
2025-12-11 15:35:28,164 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 99.50% (best 100.00%); T2: W-NCM 78.50% (best 100.00%); T3: W-NCM 91.50% (best 100.00%); T4: W-NCM 93.50% (best 98.50%); T5: W-NCM 95.50% (best 100.00%); T6: W-NCM 43.00% (best 100.00%); T7: W-NCM 93.50% (best 99.50%); T8: W-NCM 95.50% (best 98.50%); T9: W-NCM 94.00% (best 99.50%); T10: W-NCM 92.00% (best 99.00%); T11: W-NCM 94.50% (best 99.50%); T12: W-NCM 83.50% (best 99.00%); T13: W-NCM 88.00% (best 98.00%); T14: W-NCM 85.50% (best 99.00%); T15: W-NCM 92.00% (best 97.50%); T16: W-NCM 96.00% (best 98.50%); T17: W-NCM 80.50% (best 98.00%); T18: W-NCM 88.50% (best 99.00%); T19: W-NCM 94.50% (best 99.50%); T20: W-NCM 95.00% (best 99.00%); T21: W-NCM 95.50% (best 98.50%); T22: W-NCM 91.50% (best 96.00%); T23: W-NCM 93.50% (best 95.50%); T24: W-NCM 97.50% (best 100.00%); T25: W-NCM 99.00% (best 99.00%)
2025-12-11 15:35:28,164 [trainer.py] => Average forgetting (W-NCM): 9.15% | Max forgetting (W-NCM): 57.00%
2025-12-11 15:35:28,859 [trainer.py] => All params: 125940251
2025-12-11 15:35:28,865 [trainer.py] => Trainable params: 185858
2025-12-11 15:35:28,866 [inflora.py] => Learning on 50-52
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_v.25.weight', 'image_encoder.blocks.7.attn.lora_B_k.25.weight', 'image_encoder.blocks.8.attn.lora_B_k.25.weight', 'classifier_pool.25.bias', 'image_encoder.blocks.0.attn.lora_B_k.25.weight', 'image_encoder.blocks.2.attn.lora_B_v.25.weight', 'image_encoder.blocks.11.attn.lora_B_k.25.weight', 'image_encoder.blocks.3.attn.lora_B_v.25.weight', 'image_encoder.blocks.4.attn.lora_B_k.25.weight', 'image_encoder.blocks.0.attn.lora_B_v.25.weight', 'image_encoder.blocks.2.attn.lora_B_k.25.weight', 'image_encoder.blocks.6.attn.lora_B_k.25.weight', 'image_encoder.blocks.1.attn.lora_B_v.25.weight', 'image_encoder.blocks.9.attn.lora_B_k.25.weight', 'image_encoder.blocks.6.attn.lora_B_v.25.weight', 'image_encoder.blocks.10.attn.lora_B_k.25.weight', 'classifier_pool.25.weight', 'image_encoder.blocks.7.attn.lora_B_v.25.weight', 'image_encoder.blocks.8.attn.lora_B_v.25.weight', 'image_encoder.blocks.5.attn.lora_B_k.25.weight', 'image_encoder.blocks.1.attn.lora_B_k.25.weight', 'image_encoder.blocks.9.attn.lora_B_v.25.weight', 'image_encoder.blocks.4.attn.lora_B_v.25.weight', 'image_encoder.blocks.3.attn.lora_B_k.25.weight', 'image_encoder.blocks.10.attn.lora_B_v.25.weight', 'image_encoder.blocks.5.attn.lora_B_v.25.weight'}
2025-12-11 15:37:35,056 [inflora.py] => Task 25, Epoch 20/20 => Loss 0.049, Train_accy 98.20
Threshold:  0.975
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 19/768 type remove
Layer 3 : 39/768 type remove
Layer 4 : 48/768 type remove
Layer 5 : 62/768 type remove
Layer 6 : 76/768 type remove
Layer 7 : 91/768 type remove
Layer 8 : 130/768 type remove
Layer 9 : 148/768 type remove
Layer 10 : 137/768 type remove
Layer 11 : 83/768 type remove
Layer 12 : 72/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:37:44,891 [trainer.py] => Time:136.024986743927
5200 5200
5200 5200
2025-12-11 15:37:59,034 [trainer.py] => Time:14.143610000610352
2025-12-11 15:37:59,035 [inflora.py] => Exemplar size: 0
2025-12-11 15:37:59,035 [trainer.py] => CNN: {'total': np.float64(73.56), '00-01': np.float64(94.5), '02-03': np.float64(82.5), '04-05': np.float64(72.0), '06-07': np.float64(47.5), '08-09': np.float64(89.0), '10-11': np.float64(50.5), '12-13': np.float64(75.5), '14-15': np.float64(83.5), '16-17': np.float64(85.5), '18-19': np.float64(83.0), '20-21': np.float64(67.5), '22-23': np.float64(49.0), '24-25': np.float64(71.5), '26-27': np.float64(72.0), '28-29': np.float64(76.5), '30-31': np.float64(79.0), '32-33': np.float64(75.0), '34-35': np.float64(57.5), '36-37': np.float64(75.0), '38-39': np.float64(90.0), '40-41': np.float64(86.0), '42-43': np.float64(45.5), '44-45': np.float64(64.5), '46-47': np.float64(63.0), '48-49': np.float64(87.5), '50-51': np.float64(89.5), 'old': np.float64(72.92), 'new': np.float64(89.5)}
2025-12-11 15:37:59,035 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56)]
2025-12-11 15:37:59,035 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52)]
2025-12-11 15:37:59,035 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231]
2025-12-11 15:38:16,222 [trainer.py] => W-NCM: {'00-01': 98.0, '02-03': 82.0, '04-05': 74.0, '06-07': 93.5, '08-09': 94.5, '10-11': 26.0, '12-13': 91.0, '14-15': 94.0, '16-17': 92.5, '18-19': 89.0, '20-21': 92.0, '22-23': 81.0, '24-25': 86.0, '26-27': 83.5, '28-29': 93.0, '30-31': 93.5, '32-33': 75.5, '34-35': 88.5, '36-37': 81.5, '38-39': 94.0, '40-41': 93.5, '42-43': 87.5, '44-45': 91.0, '46-47': 96.0, '48-49': 98.0, '50-51': 99.0}
2025-12-11 15:38:16,223 [trainer.py] => Ave Acc (W-NCM): 87.23%
2025-12-11 15:38:16,223 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 98.00% (best 100.00%); T2: W-NCM 82.00% (best 100.00%); T3: W-NCM 74.00% (best 100.00%); T4: W-NCM 93.50% (best 98.50%); T5: W-NCM 94.50% (best 100.00%); T6: W-NCM 26.00% (best 100.00%); T7: W-NCM 91.00% (best 99.50%); T8: W-NCM 94.00% (best 98.50%); T9: W-NCM 92.50% (best 99.50%); T10: W-NCM 89.00% (best 99.00%); T11: W-NCM 92.00% (best 99.50%); T12: W-NCM 81.00% (best 99.00%); T13: W-NCM 86.00% (best 98.00%); T14: W-NCM 83.50% (best 99.00%); T15: W-NCM 93.00% (best 97.50%); T16: W-NCM 93.50% (best 98.50%); T17: W-NCM 75.50% (best 98.00%); T18: W-NCM 88.50% (best 99.00%); T19: W-NCM 81.50% (best 99.50%); T20: W-NCM 94.00% (best 99.00%); T21: W-NCM 93.50% (best 98.50%); T22: W-NCM 87.50% (best 96.00%); T23: W-NCM 91.00% (best 95.50%); T24: W-NCM 96.00% (best 100.00%); T25: W-NCM 98.00% (best 99.00%); T26: W-NCM 99.00% (best 99.00%)
2025-12-11 15:38:16,223 [trainer.py] => Average forgetting (W-NCM): 12.08% | Max forgetting (W-NCM): 74.00%
2025-12-11 15:38:16,919 [trainer.py] => All params: 125940251
2025-12-11 15:38:16,925 [trainer.py] => Trainable params: 185858
2025-12-11 15:38:16,926 [inflora.py] => Learning on 52-54
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_k.26.weight', 'image_encoder.blocks.10.attn.lora_B_v.26.weight', 'image_encoder.blocks.0.attn.lora_B_v.26.weight', 'classifier_pool.26.bias', 'classifier_pool.26.weight', 'image_encoder.blocks.9.attn.lora_B_k.26.weight', 'image_encoder.blocks.1.attn.lora_B_v.26.weight', 'image_encoder.blocks.8.attn.lora_B_k.26.weight', 'image_encoder.blocks.3.attn.lora_B_k.26.weight', 'image_encoder.blocks.2.attn.lora_B_v.26.weight', 'image_encoder.blocks.7.attn.lora_B_v.26.weight', 'image_encoder.blocks.9.attn.lora_B_v.26.weight', 'image_encoder.blocks.6.attn.lora_B_v.26.weight', 'image_encoder.blocks.11.attn.lora_B_v.26.weight', 'image_encoder.blocks.5.attn.lora_B_k.26.weight', 'image_encoder.blocks.10.attn.lora_B_k.26.weight', 'image_encoder.blocks.5.attn.lora_B_v.26.weight', 'image_encoder.blocks.7.attn.lora_B_k.26.weight', 'image_encoder.blocks.0.attn.lora_B_k.26.weight', 'image_encoder.blocks.2.attn.lora_B_k.26.weight', 'image_encoder.blocks.3.attn.lora_B_v.26.weight', 'image_encoder.blocks.11.attn.lora_B_k.26.weight', 'image_encoder.blocks.1.attn.lora_B_k.26.weight', 'image_encoder.blocks.6.attn.lora_B_k.26.weight', 'image_encoder.blocks.8.attn.lora_B_v.26.weight', 'image_encoder.blocks.4.attn.lora_B_v.26.weight'}
2025-12-11 15:40:23,478 [inflora.py] => Task 26, Epoch 20/20 => Loss 0.001, Train_accy 100.00
Threshold:  0.976
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 20/768 type remove
Layer 3 : 40/768 type remove
Layer 4 : 51/768 type remove
Layer 5 : 67/768 type remove
Layer 6 : 85/768 type remove
Layer 7 : 101/768 type remove
Layer 8 : 142/768 type remove
Layer 9 : 155/768 type remove
Layer 10 : 141/768 type remove
Layer 11 : 86/768 type remove
Layer 12 : 75/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:40:33,554 [trainer.py] => Time:136.62868905067444
5400 5400
5400 5400
2025-12-11 15:40:48,228 [trainer.py] => Time:14.673459768295288
2025-12-11 15:40:48,228 [inflora.py] => Exemplar size: 0
2025-12-11 15:40:48,228 [trainer.py] => CNN: {'total': np.float64(73.89), '00-01': np.float64(93.0), '02-03': np.float64(83.5), '04-05': np.float64(76.5), '06-07': np.float64(52.0), '08-09': np.float64(89.5), '10-11': np.float64(51.0), '12-13': np.float64(77.0), '14-15': np.float64(84.5), '16-17': np.float64(78.0), '18-19': np.float64(81.5), '20-21': np.float64(70.0), '22-23': np.float64(66.5), '24-25': np.float64(66.0), '26-27': np.float64(77.5), '28-29': np.float64(77.0), '30-31': np.float64(82.5), '32-33': np.float64(74.5), '34-35': np.float64(53.0), '36-37': np.float64(77.5), '38-39': np.float64(89.0), '40-41': np.float64(83.5), '42-43': np.float64(42.5), '44-45': np.float64(64.5), '46-47': np.float64(44.0), '48-49': np.float64(85.0), '50-51': np.float64(84.5), '52-53': np.float64(91.0), 'old': np.float64(73.23), 'new': np.float64(91.0)}
2025-12-11 15:40:48,228 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89)]
2025-12-11 15:40:48,228 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48)]
2025-12-11 15:40:48,228 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889]
2025-12-11 15:41:05,963 [trainer.py] => W-NCM: {'00-01': 97.5, '02-03': 85.0, '04-05': 80.5, '06-07': 94.0, '08-09': 94.5, '10-11': 37.5, '12-13': 94.0, '14-15': 93.5, '16-17': 94.0, '18-19': 91.5, '20-21': 93.5, '22-23': 86.5, '24-25': 89.5, '26-27': 84.5, '28-29': 93.0, '30-31': 94.5, '32-33': 73.5, '34-35': 91.0, '36-37': 88.0, '38-39': 94.0, '40-41': 94.5, '42-43': 86.5, '44-45': 91.5, '46-47': 64.5, '48-49': 97.5, '50-51': 99.0, '52-53': 100.0}
2025-12-11 15:41:05,963 [trainer.py] => Ave Acc (W-NCM): 88.28%
2025-12-11 15:41:05,963 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 97.50% (best 100.00%); T2: W-NCM 85.00% (best 100.00%); T3: W-NCM 80.50% (best 100.00%); T4: W-NCM 94.00% (best 98.50%); T5: W-NCM 94.50% (best 100.00%); T6: W-NCM 37.50% (best 100.00%); T7: W-NCM 94.00% (best 99.50%); T8: W-NCM 93.50% (best 98.50%); T9: W-NCM 94.00% (best 99.50%); T10: W-NCM 91.50% (best 99.00%); T11: W-NCM 93.50% (best 99.50%); T12: W-NCM 86.50% (best 99.00%); T13: W-NCM 89.50% (best 98.00%); T14: W-NCM 84.50% (best 99.00%); T15: W-NCM 93.00% (best 97.50%); T16: W-NCM 94.50% (best 98.50%); T17: W-NCM 73.50% (best 98.00%); T18: W-NCM 91.00% (best 99.00%); T19: W-NCM 88.00% (best 99.50%); T20: W-NCM 94.00% (best 99.00%); T21: W-NCM 94.50% (best 98.50%); T22: W-NCM 86.50% (best 96.00%); T23: W-NCM 91.50% (best 95.50%); T24: W-NCM 64.50% (best 100.00%); T25: W-NCM 97.50% (best 99.00%); T26: W-NCM 99.00% (best 99.00%); T27: W-NCM 100.00% (best 100.00%)
2025-12-11 15:41:05,963 [trainer.py] => Average forgetting (W-NCM): 11.02% | Max forgetting (W-NCM): 62.50%
2025-12-11 15:41:06,663 [trainer.py] => All params: 125940251
2025-12-11 15:41:06,669 [trainer.py] => Trainable params: 185858
2025-12-11 15:41:06,670 [inflora.py] => Learning on 54-56
Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_k.27.weight', 'image_encoder.blocks.10.attn.lora_B_k.27.weight', 'classifier_pool.27.bias', 'image_encoder.blocks.1.attn.lora_B_k.27.weight', 'image_encoder.blocks.9.attn.lora_B_k.27.weight', 'image_encoder.blocks.4.attn.lora_B_k.27.weight', 'image_encoder.blocks.7.attn.lora_B_k.27.weight', 'image_encoder.blocks.8.attn.lora_B_k.27.weight', 'image_encoder.blocks.0.attn.lora_B_v.27.weight', 'image_encoder.blocks.9.attn.lora_B_v.27.weight', 'image_encoder.blocks.11.attn.lora_B_v.27.weight', 'image_encoder.blocks.4.attn.lora_B_v.27.weight', 'image_encoder.blocks.7.attn.lora_B_v.27.weight', 'classifier_pool.27.weight', 'image_encoder.blocks.6.attn.lora_B_v.27.weight', 'image_encoder.blocks.2.attn.lora_B_k.27.weight', 'image_encoder.blocks.2.attn.lora_B_v.27.weight', 'image_encoder.blocks.6.attn.lora_B_k.27.weight', 'image_encoder.blocks.10.attn.lora_B_v.27.weight', 'image_encoder.blocks.0.attn.lora_B_k.27.weight', 'image_encoder.blocks.5.attn.lora_B_v.27.weight', 'image_encoder.blocks.8.attn.lora_B_v.27.weight', 'image_encoder.blocks.1.attn.lora_B_v.27.weight', 'image_encoder.blocks.5.attn.lora_B_k.27.weight', 'image_encoder.blocks.3.attn.lora_B_v.27.weight', 'image_encoder.blocks.11.attn.lora_B_k.27.weight'}
2025-12-11 15:43:13,251 [inflora.py] => Task 27, Epoch 20/20 => Loss 0.012, Train_accy 99.60
Threshold:  0.977
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 20/768 type remove
Layer 3 : 41/768 type remove
Layer 4 : 52/768 type remove
Layer 5 : 70/768 type remove
Layer 6 : 87/768 type remove
Layer 7 : 105/768 type remove
Layer 8 : 150/768 type remove
Layer 9 : 167/768 type remove
Layer 10 : 153/768 type remove
Layer 11 : 92/768 type remove
Layer 12 : 81/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:43:23,290 [trainer.py] => Time:136.62008237838745
5600 5600
5600 5600
2025-12-11 15:43:38,425 [trainer.py] => Time:15.13543152809143
2025-12-11 15:43:38,426 [inflora.py] => Exemplar size: 0
2025-12-11 15:43:38,426 [trainer.py] => CNN: {'total': np.float64(73.02), '00-01': np.float64(94.0), '02-03': np.float64(82.0), '04-05': np.float64(69.5), '06-07': np.float64(50.5), '08-09': np.float64(89.0), '10-11': np.float64(52.0), '12-13': np.float64(79.5), '14-15': np.float64(84.0), '16-17': np.float64(79.0), '18-19': np.float64(76.5), '20-21': np.float64(69.5), '22-23': np.float64(63.0), '24-25': np.float64(69.5), '26-27': np.float64(73.0), '28-29': np.float64(77.0), '30-31': np.float64(73.5), '32-33': np.float64(73.0), '34-35': np.float64(57.0), '36-37': np.float64(74.5), '38-39': np.float64(85.5), '40-41': np.float64(85.0), '42-43': np.float64(36.5), '44-45': np.float64(64.0), '46-47': np.float64(44.0), '48-49': np.float64(84.5), '50-51': np.float64(87.5), '52-53': np.float64(91.5), '54-55': np.float64(80.0), 'old': np.float64(72.76), 'new': np.float64(80.0)}
2025-12-11 15:43:38,426 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02)]
2025-12-11 15:43:38,426 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5)]
2025-12-11 15:43:38,426 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715]
2025-12-11 15:43:56,725 [trainer.py] => W-NCM: {'00-01': 98.0, '02-03': 71.0, '04-05': 61.5, '06-07': 95.5, '08-09': 93.0, '10-11': 36.0, '12-13': 92.5, '14-15': 94.5, '16-17': 93.0, '18-19': 88.0, '20-21': 87.5, '22-23': 85.0, '24-25': 88.0, '26-27': 83.0, '28-29': 88.0, '30-31': 90.5, '32-33': 72.0, '34-35': 92.0, '36-37': 89.5, '38-39': 93.0, '40-41': 94.5, '42-43': 84.0, '44-45': 89.5, '46-47': 66.0, '48-49': 96.5, '50-51': 96.5, '52-53': 100.0, '54-55': 98.5}
2025-12-11 15:43:56,725 [trainer.py] => Ave Acc (W-NCM): 86.32%
2025-12-11 15:43:56,725 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 98.00% (best 100.00%); T2: W-NCM 71.00% (best 100.00%); T3: W-NCM 61.50% (best 100.00%); T4: W-NCM 95.50% (best 98.50%); T5: W-NCM 93.00% (best 100.00%); T6: W-NCM 36.00% (best 100.00%); T7: W-NCM 92.50% (best 99.50%); T8: W-NCM 94.50% (best 98.50%); T9: W-NCM 93.00% (best 99.50%); T10: W-NCM 88.00% (best 99.00%); T11: W-NCM 87.50% (best 99.50%); T12: W-NCM 85.00% (best 99.00%); T13: W-NCM 88.00% (best 98.00%); T14: W-NCM 83.00% (best 99.00%); T15: W-NCM 88.00% (best 97.50%); T16: W-NCM 90.50% (best 98.50%); T17: W-NCM 72.00% (best 98.00%); T18: W-NCM 92.00% (best 99.00%); T19: W-NCM 89.50% (best 99.50%); T20: W-NCM 93.00% (best 99.00%); T21: W-NCM 94.50% (best 98.50%); T22: W-NCM 84.00% (best 96.00%); T23: W-NCM 89.50% (best 95.50%); T24: W-NCM 66.00% (best 100.00%); T25: W-NCM 96.50% (best 99.00%); T26: W-NCM 96.50% (best 99.00%); T27: W-NCM 100.00% (best 100.00%); T28: W-NCM 98.50% (best 98.50%)
2025-12-11 15:43:56,725 [trainer.py] => Average forgetting (W-NCM): 13.02% | Max forgetting (W-NCM): 64.00%
2025-12-11 15:43:57,418 [trainer.py] => All params: 125940251
2025-12-11 15:43:57,424 [trainer.py] => Trainable params: 185858
2025-12-11 15:43:57,424 [inflora.py] => Learning on 56-58
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_v.28.weight', 'image_encoder.blocks.9.attn.lora_B_k.28.weight', 'image_encoder.blocks.0.attn.lora_B_k.28.weight', 'image_encoder.blocks.0.attn.lora_B_v.28.weight', 'image_encoder.blocks.1.attn.lora_B_v.28.weight', 'image_encoder.blocks.11.attn.lora_B_v.28.weight', 'image_encoder.blocks.8.attn.lora_B_v.28.weight', 'image_encoder.blocks.6.attn.lora_B_v.28.weight', 'image_encoder.blocks.5.attn.lora_B_k.28.weight', 'image_encoder.blocks.11.attn.lora_B_k.28.weight', 'image_encoder.blocks.10.attn.lora_B_v.28.weight', 'image_encoder.blocks.7.attn.lora_B_v.28.weight', 'classifier_pool.28.weight', 'image_encoder.blocks.7.attn.lora_B_k.28.weight', 'image_encoder.blocks.2.attn.lora_B_v.28.weight', 'image_encoder.blocks.6.attn.lora_B_k.28.weight', 'image_encoder.blocks.5.attn.lora_B_v.28.weight', 'image_encoder.blocks.1.attn.lora_B_k.28.weight', 'image_encoder.blocks.8.attn.lora_B_k.28.weight', 'image_encoder.blocks.10.attn.lora_B_k.28.weight', 'image_encoder.blocks.2.attn.lora_B_k.28.weight', 'image_encoder.blocks.3.attn.lora_B_k.28.weight', 'image_encoder.blocks.4.attn.lora_B_v.28.weight', 'classifier_pool.28.bias', 'image_encoder.blocks.4.attn.lora_B_k.28.weight', 'image_encoder.blocks.3.attn.lora_B_v.28.weight'}
2025-12-11 15:46:04,016 [inflora.py] => Task 28, Epoch 20/20 => Loss 0.012, Train_accy 99.80
Threshold:  0.978
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 20/768 type remove
Layer 3 : 42/768 type remove
Layer 4 : 53/768 type remove
Layer 5 : 72/768 type remove
Layer 6 : 90/768 type remove
Layer 7 : 109/768 type remove
Layer 8 : 158/768 type remove
Layer 9 : 174/768 type remove
Layer 10 : 159/768 type remove
Layer 11 : 95/768 type remove
Layer 12 : 85/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:46:13,925 [trainer.py] => Time:136.50105094909668
5800 5800
5800 5800
2025-12-11 15:46:29,640 [trainer.py] => Time:15.714971542358398
2025-12-11 15:46:29,640 [inflora.py] => Exemplar size: 0
2025-12-11 15:46:29,640 [trainer.py] => CNN: {'total': np.float64(73.4), '00-01': np.float64(91.5), '02-03': np.float64(80.5), '04-05': np.float64(75.5), '06-07': np.float64(52.0), '08-09': np.float64(88.0), '10-11': np.float64(55.0), '12-13': np.float64(81.5), '14-15': np.float64(85.0), '16-17': np.float64(77.5), '18-19': np.float64(76.0), '20-21': np.float64(68.0), '22-23': np.float64(67.5), '24-25': np.float64(67.5), '26-27': np.float64(72.0), '28-29': np.float64(79.5), '30-31': np.float64(75.0), '32-33': np.float64(70.5), '34-35': np.float64(58.5), '36-37': np.float64(77.5), '38-39': np.float64(84.5), '40-41': np.float64(85.5), '42-43': np.float64(36.5), '44-45': np.float64(59.0), '46-47': np.float64(48.5), '48-49': np.float64(83.5), '50-51': np.float64(86.0), '52-53': np.float64(90.5), '54-55': np.float64(74.0), '56-57': np.float64(82.0), 'old': np.float64(73.09), 'new': np.float64(82.0)}
2025-12-11 15:46:29,641 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4)]
2025-12-11 15:46:29,641 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55)]
2025-12-11 15:46:29,641 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793]
2025-12-11 15:46:48,361 [trainer.py] => W-NCM: {'00-01': 95.5, '02-03': 75.0, '04-05': 69.5, '06-07': 95.0, '08-09': 92.5, '10-11': 39.0, '12-13': 92.0, '14-15': 95.0, '16-17': 94.0, '18-19': 91.5, '20-21': 91.0, '22-23': 87.0, '24-25': 90.5, '26-27': 84.0, '28-29': 89.0, '30-31': 92.0, '32-33': 76.5, '34-35': 94.0, '36-37': 90.5, '38-39': 94.0, '40-41': 95.5, '42-43': 87.5, '44-45': 90.0, '46-47': 69.5, '48-49': 96.5, '50-51': 94.5, '52-53': 98.0, '54-55': 98.0, '56-57': 98.5}
2025-12-11 15:46:48,361 [trainer.py] => Ave Acc (W-NCM): 88.12%
2025-12-11 15:46:48,361 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 95.50% (best 100.00%); T2: W-NCM 75.00% (best 100.00%); T3: W-NCM 69.50% (best 100.00%); T4: W-NCM 95.00% (best 98.50%); T5: W-NCM 92.50% (best 100.00%); T6: W-NCM 39.00% (best 100.00%); T7: W-NCM 92.00% (best 99.50%); T8: W-NCM 95.00% (best 98.50%); T9: W-NCM 94.00% (best 99.50%); T10: W-NCM 91.50% (best 99.00%); T11: W-NCM 91.00% (best 99.50%); T12: W-NCM 87.00% (best 99.00%); T13: W-NCM 90.50% (best 98.00%); T14: W-NCM 84.00% (best 99.00%); T15: W-NCM 89.00% (best 97.50%); T16: W-NCM 92.00% (best 98.50%); T17: W-NCM 76.50% (best 98.00%); T18: W-NCM 94.00% (best 99.00%); T19: W-NCM 90.50% (best 99.50%); T20: W-NCM 94.00% (best 99.00%); T21: W-NCM 95.50% (best 98.50%); T22: W-NCM 87.50% (best 96.00%); T23: W-NCM 90.00% (best 95.50%); T24: W-NCM 69.50% (best 100.00%); T25: W-NCM 96.50% (best 99.00%); T26: W-NCM 94.50% (best 99.00%); T27: W-NCM 98.00% (best 100.00%); T28: W-NCM 98.00% (best 98.50%); T29: W-NCM 98.50% (best 98.50%)
2025-12-11 15:46:48,361 [trainer.py] => Average forgetting (W-NCM): 11.12% | Max forgetting (W-NCM): 61.00%
2025-12-11 15:46:49,065 [trainer.py] => All params: 125940251
2025-12-11 15:46:49,072 [trainer.py] => Trainable params: 185858
2025-12-11 15:46:49,072 [inflora.py] => Learning on 58-60
Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.29.weight', 'image_encoder.blocks.3.attn.lora_B_k.29.weight', 'image_encoder.blocks.5.attn.lora_B_k.29.weight', 'image_encoder.blocks.9.attn.lora_B_k.29.weight', 'image_encoder.blocks.8.attn.lora_B_k.29.weight', 'image_encoder.blocks.1.attn.lora_B_v.29.weight', 'image_encoder.blocks.4.attn.lora_B_k.29.weight', 'classifier_pool.29.bias', 'image_encoder.blocks.8.attn.lora_B_v.29.weight', 'image_encoder.blocks.0.attn.lora_B_v.29.weight', 'image_encoder.blocks.4.attn.lora_B_v.29.weight', 'image_encoder.blocks.10.attn.lora_B_v.29.weight', 'image_encoder.blocks.11.attn.lora_B_k.29.weight', 'image_encoder.blocks.5.attn.lora_B_v.29.weight', 'image_encoder.blocks.7.attn.lora_B_k.29.weight', 'image_encoder.blocks.3.attn.lora_B_v.29.weight', 'image_encoder.blocks.1.attn.lora_B_k.29.weight', 'image_encoder.blocks.7.attn.lora_B_v.29.weight', 'image_encoder.blocks.2.attn.lora_B_v.29.weight', 'image_encoder.blocks.6.attn.lora_B_v.29.weight', 'image_encoder.blocks.9.attn.lora_B_v.29.weight', 'image_encoder.blocks.6.attn.lora_B_k.29.weight', 'image_encoder.blocks.10.attn.lora_B_k.29.weight', 'classifier_pool.29.weight', 'image_encoder.blocks.2.attn.lora_B_k.29.weight', 'image_encoder.blocks.11.attn.lora_B_v.29.weight'}
2025-12-11 15:48:55,510 [inflora.py] => Task 29, Epoch 20/20 => Loss 0.022, Train_accy 99.40
Threshold:  0.979
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 21/768 type remove
Layer 3 : 44/768 type remove
Layer 4 : 57/768 type remove
Layer 5 : 76/768 type remove
Layer 6 : 95/768 type remove
Layer 7 : 113/768 type remove
Layer 8 : 162/768 type remove
Layer 9 : 177/768 type remove
Layer 10 : 163/768 type remove
Layer 11 : 98/768 type remove
Layer 12 : 88/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:49:05,288 [trainer.py] => Time:136.21578288078308
6000 6000
6000 6000
2025-12-11 15:49:21,548 [trainer.py] => Time:16.259765625
2025-12-11 15:49:21,548 [inflora.py] => Exemplar size: 0
2025-12-11 15:49:21,548 [trainer.py] => CNN: {'total': np.float64(72.13), '00-01': np.float64(88.5), '02-03': np.float64(76.5), '04-05': np.float64(81.0), '06-07': np.float64(51.5), '08-09': np.float64(87.0), '10-11': np.float64(55.5), '12-13': np.float64(64.5), '14-15': np.float64(79.0), '16-17': np.float64(76.0), '18-19': np.float64(73.0), '20-21': np.float64(69.5), '22-23': np.float64(66.0), '24-25': np.float64(67.5), '26-27': np.float64(77.0), '28-29': np.float64(80.0), '30-31': np.float64(77.0), '32-33': np.float64(69.0), '34-35': np.float64(59.0), '36-37': np.float64(73.0), '38-39': np.float64(83.0), '40-41': np.float64(82.5), '42-43': np.float64(35.5), '44-45': np.float64(56.0), '46-47': np.float64(50.5), '48-49': np.float64(80.0), '50-51': np.float64(84.5), '52-53': np.float64(88.0), '54-55': np.float64(74.0), '56-57': np.float64(78.0), '58-59': np.float64(81.5), 'old': np.float64(71.81), 'new': np.float64(81.5)}
2025-12-11 15:49:21,548 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13)]
2025-12-11 15:49:21,548 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55)]
2025-12-11 15:49:21,548 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334]
2025-12-11 15:49:40,787 [trainer.py] => W-NCM: {'00-01': 95.5, '02-03': 71.5, '04-05': 73.5, '06-07': 94.5, '08-09': 93.0, '10-11': 40.0, '12-13': 82.0, '14-15': 94.0, '16-17': 92.5, '18-19': 88.0, '20-21': 91.0, '22-23': 83.0, '24-25': 89.5, '26-27': 84.0, '28-29': 91.0, '30-31': 93.0, '32-33': 67.5, '34-35': 91.0, '36-37': 87.5, '38-39': 94.0, '40-41': 95.5, '42-43': 88.0, '44-45': 91.0, '46-47': 66.0, '48-49': 96.5, '50-51': 94.0, '52-53': 79.0, '54-55': 96.0, '56-57': 96.5, '58-59': 96.0}
2025-12-11 15:49:40,787 [trainer.py] => Ave Acc (W-NCM): 86.48%
2025-12-11 15:49:40,787 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 95.50% (best 100.00%); T2: W-NCM 71.50% (best 100.00%); T3: W-NCM 73.50% (best 100.00%); T4: W-NCM 94.50% (best 98.50%); T5: W-NCM 93.00% (best 100.00%); T6: W-NCM 40.00% (best 100.00%); T7: W-NCM 82.00% (best 99.50%); T8: W-NCM 94.00% (best 98.50%); T9: W-NCM 92.50% (best 99.50%); T10: W-NCM 88.00% (best 99.00%); T11: W-NCM 91.00% (best 99.50%); T12: W-NCM 83.00% (best 99.00%); T13: W-NCM 89.50% (best 98.00%); T14: W-NCM 84.00% (best 99.00%); T15: W-NCM 91.00% (best 97.50%); T16: W-NCM 93.00% (best 98.50%); T17: W-NCM 67.50% (best 98.00%); T18: W-NCM 91.00% (best 99.00%); T19: W-NCM 87.50% (best 99.50%); T20: W-NCM 94.00% (best 99.00%); T21: W-NCM 95.50% (best 98.50%); T22: W-NCM 88.00% (best 96.00%); T23: W-NCM 91.00% (best 95.50%); T24: W-NCM 66.00% (best 100.00%); T25: W-NCM 96.50% (best 99.00%); T26: W-NCM 94.00% (best 99.00%); T27: W-NCM 79.00% (best 100.00%); T28: W-NCM 96.00% (best 98.50%); T29: W-NCM 96.50% (best 98.50%); T30: W-NCM 96.00% (best 96.00%)
2025-12-11 15:49:40,787 [trainer.py] => Average forgetting (W-NCM): 12.71% | Max forgetting (W-NCM): 60.00%
2025-12-11 15:49:41,484 [trainer.py] => All params: 125940251
2025-12-11 15:49:41,490 [trainer.py] => Trainable params: 185858
2025-12-11 15:49:41,491 [inflora.py] => Learning on 60-62
Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_v.30.weight', 'image_encoder.blocks.4.attn.lora_B_k.30.weight', 'image_encoder.blocks.6.attn.lora_B_v.30.weight', 'image_encoder.blocks.2.attn.lora_B_v.30.weight', 'image_encoder.blocks.8.attn.lora_B_v.30.weight', 'image_encoder.blocks.7.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_v.30.weight', 'image_encoder.blocks.2.attn.lora_B_k.30.weight', 'image_encoder.blocks.4.attn.lora_B_v.30.weight', 'image_encoder.blocks.9.attn.lora_B_k.30.weight', 'image_encoder.blocks.7.attn.lora_B_k.30.weight', 'image_encoder.blocks.0.attn.lora_B_v.30.weight', 'image_encoder.blocks.5.attn.lora_B_k.30.weight', 'image_encoder.blocks.0.attn.lora_B_k.30.weight', 'image_encoder.blocks.1.attn.lora_B_k.30.weight', 'image_encoder.blocks.5.attn.lora_B_v.30.weight', 'image_encoder.blocks.1.attn.lora_B_v.30.weight', 'classifier_pool.30.bias', 'image_encoder.blocks.10.attn.lora_B_k.30.weight', 'image_encoder.blocks.11.attn.lora_B_v.30.weight', 'image_encoder.blocks.3.attn.lora_B_k.30.weight', 'classifier_pool.30.weight', 'image_encoder.blocks.9.attn.lora_B_v.30.weight', 'image_encoder.blocks.6.attn.lora_B_k.30.weight', 'image_encoder.blocks.8.attn.lora_B_k.30.weight', 'image_encoder.blocks.11.attn.lora_B_k.30.weight'}
2025-12-11 15:51:48,180 [inflora.py] => Task 30, Epoch 20/20 => Loss 0.008, Train_accy 99.70
Threshold:  0.98
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 22/768 type remove
Layer 3 : 45/768 type remove
Layer 4 : 58/768 type remove
Layer 5 : 77/768 type remove
Layer 6 : 98/768 type remove
Layer 7 : 118/768 type remove
Layer 8 : 168/768 type remove
Layer 9 : 183/768 type remove
Layer 10 : 169/768 type remove
Layer 11 : 102/768 type remove
Layer 12 : 93/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:51:58,053 [trainer.py] => Time:136.56261157989502
6200 6200
6200 6200
2025-12-11 15:52:14,863 [trainer.py] => Time:16.809530019760132
2025-12-11 15:52:14,863 [inflora.py] => Exemplar size: 0
2025-12-11 15:52:14,863 [trainer.py] => CNN: {'total': np.float64(71.19), '00-01': np.float64(89.5), '02-03': np.float64(77.0), '04-05': np.float64(83.0), '06-07': np.float64(53.0), '08-09': np.float64(83.0), '10-11': np.float64(52.5), '12-13': np.float64(65.5), '14-15': np.float64(80.0), '16-17': np.float64(67.5), '18-19': np.float64(71.5), '20-21': np.float64(71.5), '22-23': np.float64(57.0), '24-25': np.float64(62.0), '26-27': np.float64(76.5), '28-29': np.float64(77.5), '30-31': np.float64(78.5), '32-33': np.float64(63.0), '34-35': np.float64(56.5), '36-37': np.float64(73.0), '38-39': np.float64(83.0), '40-41': np.float64(84.5), '42-43': np.float64(31.5), '44-45': np.float64(53.5), '46-47': np.float64(48.0), '48-49': np.float64(80.5), '50-51': np.float64(85.5), '52-53': np.float64(84.0), '54-55': np.float64(71.0), '56-57': np.float64(78.0), '58-59': np.float64(83.5), '60-61': np.float64(86.0), 'old': np.float64(70.7), 'new': np.float64(86.0)}
2025-12-11 15:52:14,863 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19)]
2025-12-11 15:52:14,863 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55)]
2025-12-11 15:52:14,864 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677]
2025-12-11 15:52:34,737 [trainer.py] => W-NCM: {'00-01': 95.0, '02-03': 76.5, '04-05': 74.0, '06-07': 94.0, '08-09': 94.5, '10-11': 22.5, '12-13': 82.0, '14-15': 94.5, '16-17': 91.0, '18-19': 90.0, '20-21': 93.0, '22-23': 70.5, '24-25': 89.5, '26-27': 86.0, '28-29': 92.5, '30-31': 93.5, '32-33': 66.5, '34-35': 91.0, '36-37': 88.0, '38-39': 93.5, '40-41': 96.0, '42-43': 87.5, '44-45': 90.0, '46-47': 67.0, '48-49': 95.5, '50-51': 93.0, '52-53': 81.5, '54-55': 96.0, '56-57': 96.5, '58-59': 93.0, '60-61': 98.5}
2025-12-11 15:52:34,738 [trainer.py] => Ave Acc (W-NCM): 86.21%
2025-12-11 15:52:34,738 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 95.00% (best 100.00%); T2: W-NCM 76.50% (best 100.00%); T3: W-NCM 74.00% (best 100.00%); T4: W-NCM 94.00% (best 98.50%); T5: W-NCM 94.50% (best 100.00%); T6: W-NCM 22.50% (best 100.00%); T7: W-NCM 82.00% (best 99.50%); T8: W-NCM 94.50% (best 98.50%); T9: W-NCM 91.00% (best 99.50%); T10: W-NCM 90.00% (best 99.00%); T11: W-NCM 93.00% (best 99.50%); T12: W-NCM 70.50% (best 99.00%); T13: W-NCM 89.50% (best 98.00%); T14: W-NCM 86.00% (best 99.00%); T15: W-NCM 92.50% (best 97.50%); T16: W-NCM 93.50% (best 98.50%); T17: W-NCM 66.50% (best 98.00%); T18: W-NCM 91.00% (best 99.00%); T19: W-NCM 88.00% (best 99.50%); T20: W-NCM 93.50% (best 99.00%); T21: W-NCM 96.00% (best 98.50%); T22: W-NCM 87.50% (best 96.00%); T23: W-NCM 90.00% (best 95.50%); T24: W-NCM 67.00% (best 100.00%); T25: W-NCM 95.50% (best 99.00%); T26: W-NCM 93.00% (best 99.00%); T27: W-NCM 81.50% (best 100.00%); T28: W-NCM 96.00% (best 98.50%); T29: W-NCM 96.50% (best 98.50%); T30: W-NCM 93.00% (best 96.00%); T31: W-NCM 98.50% (best 98.50%)
2025-12-11 15:52:34,738 [trainer.py] => Average forgetting (W-NCM): 12.97% | Max forgetting (W-NCM): 77.50%
2025-12-11 15:52:35,434 [trainer.py] => All params: 125940251
2025-12-11 15:52:35,441 [trainer.py] => Trainable params: 185858
2025-12-11 15:52:35,441 [inflora.py] => Learning on 62-64
Parameters to be updated: {'classifier_pool.31.weight', 'image_encoder.blocks.1.attn.lora_B_v.31.weight', 'image_encoder.blocks.8.attn.lora_B_v.31.weight', 'image_encoder.blocks.3.attn.lora_B_v.31.weight', 'image_encoder.blocks.2.attn.lora_B_v.31.weight', 'classifier_pool.31.bias', 'image_encoder.blocks.2.attn.lora_B_k.31.weight', 'image_encoder.blocks.4.attn.lora_B_k.31.weight', 'image_encoder.blocks.6.attn.lora_B_v.31.weight', 'image_encoder.blocks.3.attn.lora_B_k.31.weight', 'image_encoder.blocks.5.attn.lora_B_k.31.weight', 'image_encoder.blocks.9.attn.lora_B_k.31.weight', 'image_encoder.blocks.4.attn.lora_B_v.31.weight', 'image_encoder.blocks.6.attn.lora_B_k.31.weight', 'image_encoder.blocks.8.attn.lora_B_k.31.weight', 'image_encoder.blocks.5.attn.lora_B_v.31.weight', 'image_encoder.blocks.11.attn.lora_B_k.31.weight', 'image_encoder.blocks.0.attn.lora_B_k.31.weight', 'image_encoder.blocks.7.attn.lora_B_k.31.weight', 'image_encoder.blocks.10.attn.lora_B_v.31.weight', 'image_encoder.blocks.9.attn.lora_B_v.31.weight', 'image_encoder.blocks.1.attn.lora_B_k.31.weight', 'image_encoder.blocks.0.attn.lora_B_v.31.weight', 'image_encoder.blocks.10.attn.lora_B_k.31.weight', 'image_encoder.blocks.11.attn.lora_B_v.31.weight', 'image_encoder.blocks.7.attn.lora_B_v.31.weight'}
2025-12-11 15:54:42,423 [inflora.py] => Task 31, Epoch 20/20 => Loss 0.007, Train_accy 99.90
Threshold:  0.981
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 23/768 type remove
Layer 3 : 46/768 type remove
Layer 4 : 60/768 type remove
Layer 5 : 81/768 type remove
Layer 6 : 105/768 type remove
Layer 7 : 125/768 type remove
Layer 8 : 177/768 type remove
Layer 9 : 190/768 type remove
Layer 10 : 176/768 type remove
Layer 11 : 107/768 type remove
Layer 12 : 98/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:54:52,646 [trainer.py] => Time:137.2051465511322
6400 6400
6400 6400
2025-12-11 15:55:09,950 [trainer.py] => Time:17.30374526977539
2025-12-11 15:55:09,950 [inflora.py] => Exemplar size: 0
2025-12-11 15:55:09,950 [trainer.py] => CNN: {'total': np.float64(69.73), '00-01': np.float64(88.0), '02-03': np.float64(76.0), '04-05': np.float64(78.5), '06-07': np.float64(54.0), '08-09': np.float64(84.5), '10-11': np.float64(58.0), '12-13': np.float64(77.5), '14-15': np.float64(79.0), '16-17': np.float64(65.0), '18-19': np.float64(70.0), '20-21': np.float64(69.0), '22-23': np.float64(56.5), '24-25': np.float64(60.0), '26-27': np.float64(76.0), '28-29': np.float64(74.0), '30-31': np.float64(73.0), '32-33': np.float64(65.5), '34-35': np.float64(53.0), '36-37': np.float64(71.0), '38-39': np.float64(80.0), '40-41': np.float64(83.0), '42-43': np.float64(23.0), '44-45': np.float64(52.5), '46-47': np.float64(49.0), '48-49': np.float64(85.5), '50-51': np.float64(80.0), '52-53': np.float64(81.5), '54-55': np.float64(58.5), '56-57': np.float64(79.0), '58-59': np.float64(77.0), '60-61': np.float64(82.0), '62-63': np.float64(72.0), 'old': np.float64(69.66), 'new': np.float64(72.0)}
2025-12-11 15:55:09,950 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73)]
2025-12-11 15:55:09,950 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59)]
2025-12-11 15:55:09,950 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375]
2025-12-11 15:55:30,277 [trainer.py] => W-NCM: {'00-01': 96.5, '02-03': 80.0, '04-05': 74.0, '06-07': 93.5, '08-09': 95.5, '10-11': 33.0, '12-13': 84.0, '14-15': 94.0, '16-17': 92.0, '18-19': 89.0, '20-21': 94.0, '22-23': 75.0, '24-25': 87.5, '26-27': 85.0, '28-29': 90.0, '30-31': 94.0, '32-33': 75.0, '34-35': 90.5, '36-37': 89.0, '38-39': 94.0, '40-41': 95.0, '42-43': 85.0, '44-45': 90.0, '46-47': 71.5, '48-49': 95.5, '50-51': 92.0, '52-53': 83.5, '54-55': 92.0, '56-57': 97.0, '58-59': 91.0, '60-61': 98.5, '62-63': 97.0}
2025-12-11 15:55:30,277 [trainer.py] => Ave Acc (W-NCM): 87.30%
2025-12-11 15:55:30,277 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 96.50% (best 100.00%); T2: W-NCM 80.00% (best 100.00%); T3: W-NCM 74.00% (best 100.00%); T4: W-NCM 93.50% (best 98.50%); T5: W-NCM 95.50% (best 100.00%); T6: W-NCM 33.00% (best 100.00%); T7: W-NCM 84.00% (best 99.50%); T8: W-NCM 94.00% (best 98.50%); T9: W-NCM 92.00% (best 99.50%); T10: W-NCM 89.00% (best 99.00%); T11: W-NCM 94.00% (best 99.50%); T12: W-NCM 75.00% (best 99.00%); T13: W-NCM 87.50% (best 98.00%); T14: W-NCM 85.00% (best 99.00%); T15: W-NCM 90.00% (best 97.50%); T16: W-NCM 94.00% (best 98.50%); T17: W-NCM 75.00% (best 98.00%); T18: W-NCM 90.50% (best 99.00%); T19: W-NCM 89.00% (best 99.50%); T20: W-NCM 94.00% (best 99.00%); T21: W-NCM 95.00% (best 98.50%); T22: W-NCM 85.00% (best 96.00%); T23: W-NCM 90.00% (best 95.50%); T24: W-NCM 71.50% (best 100.00%); T25: W-NCM 95.50% (best 99.00%); T26: W-NCM 92.00% (best 99.00%); T27: W-NCM 83.50% (best 100.00%); T28: W-NCM 92.00% (best 98.50%); T29: W-NCM 97.00% (best 98.50%); T30: W-NCM 91.00% (best 96.00%); T31: W-NCM 98.50% (best 98.50%); T32: W-NCM 97.00% (best 97.00%)
2025-12-11 15:55:30,277 [trainer.py] => Average forgetting (W-NCM): 11.77% | Max forgetting (W-NCM): 67.00%
2025-12-11 15:55:30,985 [trainer.py] => All params: 125940251
2025-12-11 15:55:30,991 [trainer.py] => Trainable params: 185858
2025-12-11 15:55:30,991 [inflora.py] => Learning on 64-66
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_v.32.weight', 'image_encoder.blocks.3.attn.lora_B_k.32.weight', 'image_encoder.blocks.11.attn.lora_B_v.32.weight', 'image_encoder.blocks.7.attn.lora_B_k.32.weight', 'image_encoder.blocks.2.attn.lora_B_v.32.weight', 'image_encoder.blocks.10.attn.lora_B_k.32.weight', 'image_encoder.blocks.4.attn.lora_B_k.32.weight', 'classifier_pool.32.weight', 'image_encoder.blocks.5.attn.lora_B_k.32.weight', 'image_encoder.blocks.4.attn.lora_B_v.32.weight', 'image_encoder.blocks.5.attn.lora_B_v.32.weight', 'image_encoder.blocks.0.attn.lora_B_v.32.weight', 'classifier_pool.32.bias', 'image_encoder.blocks.6.attn.lora_B_v.32.weight', 'image_encoder.blocks.1.attn.lora_B_k.32.weight', 'image_encoder.blocks.10.attn.lora_B_v.32.weight', 'image_encoder.blocks.11.attn.lora_B_k.32.weight', 'image_encoder.blocks.9.attn.lora_B_v.32.weight', 'image_encoder.blocks.8.attn.lora_B_v.32.weight', 'image_encoder.blocks.2.attn.lora_B_k.32.weight', 'image_encoder.blocks.0.attn.lora_B_k.32.weight', 'image_encoder.blocks.3.attn.lora_B_v.32.weight', 'image_encoder.blocks.8.attn.lora_B_k.32.weight', 'image_encoder.blocks.7.attn.lora_B_v.32.weight', 'image_encoder.blocks.9.attn.lora_B_k.32.weight', 'image_encoder.blocks.6.attn.lora_B_k.32.weight'}
2025-12-11 15:57:37,753 [inflora.py] => Task 32, Epoch 20/20 => Loss 0.081, Train_accy 96.80
Threshold:  0.982
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 24/768 type remove
Layer 3 : 47/768 type remove
Layer 4 : 61/768 type remove
Layer 5 : 82/768 type remove
Layer 6 : 107/768 type remove
Layer 7 : 128/768 type remove
Layer 8 : 182/768 type remove
Layer 9 : 197/768 type remove
Layer 10 : 184/768 type remove
Layer 11 : 113/768 type remove
Layer 12 : 101/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 15:57:47,768 [trainer.py] => Time:136.77696657180786
6600 6600
6600 6600
2025-12-11 15:58:05,622 [trainer.py] => Time:17.853272199630737
2025-12-11 15:58:05,622 [inflora.py] => Exemplar size: 0
2025-12-11 15:58:05,622 [trainer.py] => CNN: {'total': np.float64(70.09), '00-01': np.float64(91.5), '02-03': np.float64(81.0), '04-05': np.float64(66.0), '06-07': np.float64(52.0), '08-09': np.float64(91.5), '10-11': np.float64(52.5), '12-13': np.float64(77.5), '14-15': np.float64(80.0), '16-17': np.float64(64.5), '18-19': np.float64(72.5), '20-21': np.float64(70.0), '22-23': np.float64(50.5), '24-25': np.float64(58.0), '26-27': np.float64(71.5), '28-29': np.float64(74.0), '30-31': np.float64(72.0), '32-33': np.float64(64.5), '34-35': np.float64(56.0), '36-37': np.float64(75.0), '38-39': np.float64(80.5), '40-41': np.float64(86.5), '42-43': np.float64(27.5), '44-45': np.float64(55.5), '46-47': np.float64(52.5), '48-49': np.float64(86.5), '50-51': np.float64(84.5), '52-53': np.float64(78.0), '54-55': np.float64(66.0), '56-57': np.float64(79.0), '58-59': np.float64(76.5), '60-61': np.float64(80.0), '62-63': np.float64(69.5), '64-65': np.float64(70.0), 'old': np.float64(70.09), 'new': np.float64(70.0)}
2025-12-11 15:58:05,622 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09)]
2025-12-11 15:58:05,622 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53)]
2025-12-11 15:58:05,622 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909]
2025-12-11 15:58:26,589 [trainer.py] => W-NCM: {'00-01': 97.0, '02-03': 84.0, '04-05': 74.0, '06-07': 92.5, '08-09': 95.0, '10-11': 29.5, '12-13': 88.0, '14-15': 94.5, '16-17': 92.5, '18-19': 91.5, '20-21': 94.5, '22-23': 81.5, '24-25': 86.5, '26-27': 85.5, '28-29': 91.5, '30-31': 94.0, '32-33': 78.5, '34-35': 92.0, '36-37': 88.5, '38-39': 92.0, '40-41': 96.0, '42-43': 85.5, '44-45': 91.0, '46-47': 71.0, '48-49': 96.5, '50-51': 91.0, '52-53': 87.5, '54-55': 90.5, '56-57': 98.0, '58-59': 88.5, '60-61': 98.0, '62-63': 96.0, '64-65': 95.0}
2025-12-11 15:58:26,590 [trainer.py] => Ave Acc (W-NCM): 88.11%
2025-12-11 15:58:26,590 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 97.00% (best 100.00%); T2: W-NCM 84.00% (best 100.00%); T3: W-NCM 74.00% (best 100.00%); T4: W-NCM 92.50% (best 98.50%); T5: W-NCM 95.00% (best 100.00%); T6: W-NCM 29.50% (best 100.00%); T7: W-NCM 88.00% (best 99.50%); T8: W-NCM 94.50% (best 98.50%); T9: W-NCM 92.50% (best 99.50%); T10: W-NCM 91.50% (best 99.00%); T11: W-NCM 94.50% (best 99.50%); T12: W-NCM 81.50% (best 99.00%); T13: W-NCM 86.50% (best 98.00%); T14: W-NCM 85.50% (best 99.00%); T15: W-NCM 91.50% (best 97.50%); T16: W-NCM 94.00% (best 98.50%); T17: W-NCM 78.50% (best 98.00%); T18: W-NCM 92.00% (best 99.00%); T19: W-NCM 88.50% (best 99.50%); T20: W-NCM 92.00% (best 99.00%); T21: W-NCM 96.00% (best 98.50%); T22: W-NCM 85.50% (best 96.00%); T23: W-NCM 91.00% (best 95.50%); T24: W-NCM 71.00% (best 100.00%); T25: W-NCM 96.50% (best 99.00%); T26: W-NCM 91.00% (best 99.00%); T27: W-NCM 87.50% (best 100.00%); T28: W-NCM 90.50% (best 98.50%); T29: W-NCM 98.00% (best 98.50%); T30: W-NCM 88.50% (best 96.00%); T31: W-NCM 98.00% (best 98.50%); T32: W-NCM 96.00% (best 97.00%); T33: W-NCM 95.00% (best 95.00%)
2025-12-11 15:58:26,590 [trainer.py] => Average forgetting (W-NCM): 10.81% | Max forgetting (W-NCM): 70.50%
2025-12-11 15:58:27,442 [trainer.py] => All params: 125940251
2025-12-11 15:58:27,448 [trainer.py] => Trainable params: 185858
2025-12-11 15:58:27,448 [inflora.py] => Learning on 66-68
Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_k.33.weight', 'image_encoder.blocks.10.attn.lora_B_k.33.weight', 'image_encoder.blocks.9.attn.lora_B_v.33.weight', 'image_encoder.blocks.2.attn.lora_B_k.33.weight', 'image_encoder.blocks.11.attn.lora_B_k.33.weight', 'image_encoder.blocks.5.attn.lora_B_k.33.weight', 'image_encoder.blocks.7.attn.lora_B_k.33.weight', 'classifier_pool.33.bias', 'image_encoder.blocks.0.attn.lora_B_k.33.weight', 'image_encoder.blocks.11.attn.lora_B_v.33.weight', 'image_encoder.blocks.7.attn.lora_B_v.33.weight', 'image_encoder.blocks.1.attn.lora_B_v.33.weight', 'image_encoder.blocks.10.attn.lora_B_v.33.weight', 'image_encoder.blocks.3.attn.lora_B_k.33.weight', 'classifier_pool.33.weight', 'image_encoder.blocks.9.attn.lora_B_k.33.weight', 'image_encoder.blocks.3.attn.lora_B_v.33.weight', 'image_encoder.blocks.0.attn.lora_B_v.33.weight', 'image_encoder.blocks.8.attn.lora_B_k.33.weight', 'image_encoder.blocks.8.attn.lora_B_v.33.weight', 'image_encoder.blocks.4.attn.lora_B_v.33.weight', 'image_encoder.blocks.2.attn.lora_B_v.33.weight', 'image_encoder.blocks.4.attn.lora_B_k.33.weight', 'image_encoder.blocks.6.attn.lora_B_k.33.weight', 'image_encoder.blocks.5.attn.lora_B_v.33.weight', 'image_encoder.blocks.6.attn.lora_B_v.33.weight'}
2025-12-11 16:00:34,555 [inflora.py] => Task 33, Epoch 20/20 => Loss 0.033, Train_accy 98.90
Threshold:  0.983
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 25/768 type remove
Layer 3 : 48/768 type remove
Layer 4 : 64/768 type remove
Layer 5 : 85/768 type remove
Layer 6 : 110/768 type remove
Layer 7 : 134/768 type remove
Layer 8 : 190/768 type remove
Layer 9 : 208/768 type remove
Layer 10 : 193/768 type remove
Layer 11 : 118/768 type remove
Layer 12 : 103/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:00:44,697 [trainer.py] => Time:137.24855279922485
6800 6800
6800 6800
2025-12-11 16:01:03,129 [trainer.py] => Time:18.43200445175171
2025-12-11 16:01:03,129 [inflora.py] => Exemplar size: 0
2025-12-11 16:01:03,129 [trainer.py] => CNN: {'total': np.float64(69.65), '00-01': np.float64(90.0), '02-03': np.float64(77.5), '04-05': np.float64(68.0), '06-07': np.float64(53.0), '08-09': np.float64(88.5), '10-11': np.float64(59.5), '12-13': np.float64(79.5), '14-15': np.float64(78.0), '16-17': np.float64(68.0), '18-19': np.float64(77.0), '20-21': np.float64(71.5), '22-23': np.float64(62.0), '24-25': np.float64(57.5), '26-27': np.float64(70.0), '28-29': np.float64(70.0), '30-31': np.float64(72.0), '32-33': np.float64(68.0), '34-35': np.float64(51.5), '36-37': np.float64(75.0), '38-39': np.float64(83.0), '40-41': np.float64(86.0), '42-43': np.float64(28.5), '44-45': np.float64(53.0), '46-47': np.float64(45.5), '48-49': np.float64(84.0), '50-51': np.float64(82.0), '52-53': np.float64(82.0), '54-55': np.float64(58.0), '56-57': np.float64(82.0), '58-59': np.float64(70.0), '60-61': np.float64(77.5), '62-63': np.float64(72.0), '64-65': np.float64(70.0), '66-67': np.float64(58.0), 'old': np.float64(70.0), 'new': np.float64(58.0)}
2025-12-11 16:01:03,129 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65)]
2025-12-11 16:01:03,129 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56)]
2025-12-11 16:01:03,129 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941]
2025-12-11 16:01:24,672 [trainer.py] => W-NCM: {'00-01': 97.5, '02-03': 84.5, '04-05': 77.5, '06-07': 94.0, '08-09': 95.5, '10-11': 37.0, '12-13': 88.0, '14-15': 95.0, '16-17': 93.5, '18-19': 94.0, '20-21': 95.0, '22-23': 82.5, '24-25': 87.5, '26-27': 84.5, '28-29': 92.0, '30-31': 91.5, '32-33': 73.5, '34-35': 89.5, '36-37': 89.0, '38-39': 93.0, '40-41': 95.0, '42-43': 87.5, '44-45': 90.5, '46-47': 72.5, '48-49': 95.5, '50-51': 92.0, '52-53': 84.0, '54-55': 88.5, '56-57': 97.0, '58-59': 89.5, '60-61': 95.5, '62-63': 92.0, '64-65': 92.5, '66-67': 99.0}
2025-12-11 16:01:24,673 [trainer.py] => Ave Acc (W-NCM): 88.40%
2025-12-11 16:01:24,673 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 97.50% (best 100.00%); T2: W-NCM 84.50% (best 100.00%); T3: W-NCM 77.50% (best 100.00%); T4: W-NCM 94.00% (best 98.50%); T5: W-NCM 95.50% (best 100.00%); T6: W-NCM 37.00% (best 100.00%); T7: W-NCM 88.00% (best 99.50%); T8: W-NCM 95.00% (best 98.50%); T9: W-NCM 93.50% (best 99.50%); T10: W-NCM 94.00% (best 99.00%); T11: W-NCM 95.00% (best 99.50%); T12: W-NCM 82.50% (best 99.00%); T13: W-NCM 87.50% (best 98.00%); T14: W-NCM 84.50% (best 99.00%); T15: W-NCM 92.00% (best 97.50%); T16: W-NCM 91.50% (best 98.50%); T17: W-NCM 73.50% (best 98.00%); T18: W-NCM 89.50% (best 99.00%); T19: W-NCM 89.00% (best 99.50%); T20: W-NCM 93.00% (best 99.00%); T21: W-NCM 95.00% (best 98.50%); T22: W-NCM 87.50% (best 96.00%); T23: W-NCM 90.50% (best 95.50%); T24: W-NCM 72.50% (best 100.00%); T25: W-NCM 95.50% (best 99.00%); T26: W-NCM 92.00% (best 99.00%); T27: W-NCM 84.00% (best 100.00%); T28: W-NCM 88.50% (best 98.50%); T29: W-NCM 97.00% (best 98.50%); T30: W-NCM 89.50% (best 96.00%); T31: W-NCM 95.50% (best 98.50%); T32: W-NCM 92.00% (best 97.00%); T33: W-NCM 92.50% (best 95.00%); T34: W-NCM 99.00% (best 99.00%)
2025-12-11 16:01:24,673 [trainer.py] => Average forgetting (W-NCM): 10.52% | Max forgetting (W-NCM): 63.00%
2025-12-11 16:01:25,481 [trainer.py] => All params: 125940251
2025-12-11 16:01:25,488 [trainer.py] => Trainable params: 185858
2025-12-11 16:01:25,488 [inflora.py] => Learning on 68-70
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.34.weight', 'image_encoder.blocks.0.attn.lora_B_v.34.weight', 'image_encoder.blocks.5.attn.lora_B_k.34.weight', 'image_encoder.blocks.7.attn.lora_B_v.34.weight', 'classifier_pool.34.bias', 'image_encoder.blocks.11.attn.lora_B_k.34.weight', 'image_encoder.blocks.1.attn.lora_B_v.34.weight', 'image_encoder.blocks.4.attn.lora_B_v.34.weight', 'image_encoder.blocks.11.attn.lora_B_v.34.weight', 'image_encoder.blocks.3.attn.lora_B_k.34.weight', 'image_encoder.blocks.7.attn.lora_B_k.34.weight', 'image_encoder.blocks.0.attn.lora_B_k.34.weight', 'image_encoder.blocks.9.attn.lora_B_k.34.weight', 'image_encoder.blocks.3.attn.lora_B_v.34.weight', 'image_encoder.blocks.4.attn.lora_B_k.34.weight', 'image_encoder.blocks.10.attn.lora_B_v.34.weight', 'image_encoder.blocks.8.attn.lora_B_k.34.weight', 'image_encoder.blocks.6.attn.lora_B_k.34.weight', 'image_encoder.blocks.2.attn.lora_B_k.34.weight', 'image_encoder.blocks.2.attn.lora_B_v.34.weight', 'image_encoder.blocks.10.attn.lora_B_k.34.weight', 'image_encoder.blocks.8.attn.lora_B_v.34.weight', 'image_encoder.blocks.9.attn.lora_B_v.34.weight', 'image_encoder.blocks.1.attn.lora_B_k.34.weight', 'image_encoder.blocks.5.attn.lora_B_v.34.weight', 'classifier_pool.34.weight'}
2025-12-11 16:03:32,391 [inflora.py] => Task 34, Epoch 20/20 => Loss 0.034, Train_accy 98.40
Threshold:  0.984
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 26/768 type remove
Layer 3 : 49/768 type remove
Layer 4 : 66/768 type remove
Layer 5 : 88/768 type remove
Layer 6 : 114/768 type remove
Layer 7 : 141/768 type remove
Layer 8 : 197/768 type remove
Layer 9 : 214/768 type remove
Layer 10 : 199/768 type remove
Layer 11 : 122/768 type remove
Layer 12 : 107/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:03:42,531 [trainer.py] => Time:137.04259967803955
7000 7000
7000 7000
2025-12-11 16:04:01,506 [trainer.py] => Time:18.974809169769287
2025-12-11 16:04:01,506 [inflora.py] => Exemplar size: 0
2025-12-11 16:04:01,506 [trainer.py] => CNN: {'total': np.float64(69.11), '00-01': np.float64(83.5), '02-03': np.float64(75.5), '04-05': np.float64(64.5), '06-07': np.float64(51.0), '08-09': np.float64(86.0), '10-11': np.float64(60.5), '12-13': np.float64(79.5), '14-15': np.float64(76.5), '16-17': np.float64(66.5), '18-19': np.float64(71.0), '20-21': np.float64(70.5), '22-23': np.float64(59.5), '24-25': np.float64(56.5), '26-27': np.float64(73.0), '28-29': np.float64(72.5), '30-31': np.float64(73.0), '32-33': np.float64(63.0), '34-35': np.float64(50.0), '36-37': np.float64(71.0), '38-39': np.float64(82.0), '40-41': np.float64(84.5), '42-43': np.float64(22.0), '44-45': np.float64(52.5), '46-47': np.float64(48.5), '48-49': np.float64(86.5), '50-51': np.float64(79.0), '52-53': np.float64(76.0), '54-55': np.float64(57.0), '56-57': np.float64(79.0), '58-59': np.float64(76.5), '60-61': np.float64(79.5), '62-63': np.float64(73.5), '64-65': np.float64(68.0), '66-67': np.float64(57.0), '68-69': np.float64(94.0), 'old': np.float64(68.38), 'new': np.float64(94.0)}
2025-12-11 16:04:01,506 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11)]
2025-12-11 16:04:01,506 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61)]
2025-12-11 16:04:01,506 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572]
2025-12-11 16:04:23,544 [trainer.py] => W-NCM: {'00-01': 96.5, '02-03': 81.5, '04-05': 78.0, '06-07': 93.5, '08-09': 95.5, '10-11': 44.0, '12-13': 87.0, '14-15': 95.5, '16-17': 91.5, '18-19': 93.0, '20-21': 95.5, '22-23': 87.5, '24-25': 88.5, '26-27': 88.0, '28-29': 88.5, '30-31': 93.0, '32-33': 77.0, '34-35': 90.5, '36-37': 90.0, '38-39': 91.0, '40-41': 95.0, '42-43': 90.5, '44-45': 91.5, '46-47': 75.5, '48-49': 95.5, '50-51': 91.5, '52-53': 83.5, '54-55': 86.5, '56-57': 96.5, '58-59': 88.5, '60-61': 90.5, '62-63': 92.0, '64-65': 92.0, '66-67': 98.0, '68-69': 99.5}
2025-12-11 16:04:23,544 [trainer.py] => Ave Acc (W-NCM): 88.91%
2025-12-11 16:04:23,545 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 96.50% (best 100.00%); T2: W-NCM 81.50% (best 100.00%); T3: W-NCM 78.00% (best 100.00%); T4: W-NCM 93.50% (best 98.50%); T5: W-NCM 95.50% (best 100.00%); T6: W-NCM 44.00% (best 100.00%); T7: W-NCM 87.00% (best 99.50%); T8: W-NCM 95.50% (best 98.50%); T9: W-NCM 91.50% (best 99.50%); T10: W-NCM 93.00% (best 99.00%); T11: W-NCM 95.50% (best 99.50%); T12: W-NCM 87.50% (best 99.00%); T13: W-NCM 88.50% (best 98.00%); T14: W-NCM 88.00% (best 99.00%); T15: W-NCM 88.50% (best 97.50%); T16: W-NCM 93.00% (best 98.50%); T17: W-NCM 77.00% (best 98.00%); T18: W-NCM 90.50% (best 99.00%); T19: W-NCM 90.00% (best 99.50%); T20: W-NCM 91.00% (best 99.00%); T21: W-NCM 95.00% (best 98.50%); T22: W-NCM 90.50% (best 96.00%); T23: W-NCM 91.50% (best 95.50%); T24: W-NCM 75.50% (best 100.00%); T25: W-NCM 95.50% (best 99.00%); T26: W-NCM 91.50% (best 99.00%); T27: W-NCM 83.50% (best 100.00%); T28: W-NCM 86.50% (best 98.50%); T29: W-NCM 96.50% (best 98.50%); T30: W-NCM 88.50% (best 96.00%); T31: W-NCM 90.50% (best 98.50%); T32: W-NCM 92.00% (best 97.00%); T33: W-NCM 92.00% (best 95.00%); T34: W-NCM 98.00% (best 99.00%); T35: W-NCM 99.50% (best 99.50%)
2025-12-11 16:04:23,545 [trainer.py] => Average forgetting (W-NCM): 10.00% | Max forgetting (W-NCM): 56.00%
2025-12-11 16:04:24,238 [trainer.py] => All params: 125940251
2025-12-11 16:04:24,244 [trainer.py] => Trainable params: 185858
2025-12-11 16:04:24,244 [inflora.py] => Learning on 70-72
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.35.weight', 'image_encoder.blocks.3.attn.lora_B_k.35.weight', 'image_encoder.blocks.9.attn.lora_B_v.35.weight', 'image_encoder.blocks.0.attn.lora_B_v.35.weight', 'image_encoder.blocks.5.attn.lora_B_k.35.weight', 'image_encoder.blocks.7.attn.lora_B_k.35.weight', 'classifier_pool.35.weight', 'image_encoder.blocks.11.attn.lora_B_v.35.weight', 'image_encoder.blocks.4.attn.lora_B_v.35.weight', 'image_encoder.blocks.10.attn.lora_B_k.35.weight', 'image_encoder.blocks.9.attn.lora_B_k.35.weight', 'image_encoder.blocks.1.attn.lora_B_v.35.weight', 'image_encoder.blocks.2.attn.lora_B_k.35.weight', 'image_encoder.blocks.8.attn.lora_B_v.35.weight', 'image_encoder.blocks.8.attn.lora_B_k.35.weight', 'image_encoder.blocks.6.attn.lora_B_k.35.weight', 'image_encoder.blocks.5.attn.lora_B_v.35.weight', 'image_encoder.blocks.7.attn.lora_B_v.35.weight', 'image_encoder.blocks.1.attn.lora_B_k.35.weight', 'image_encoder.blocks.3.attn.lora_B_v.35.weight', 'image_encoder.blocks.11.attn.lora_B_k.35.weight', 'classifier_pool.35.bias', 'image_encoder.blocks.2.attn.lora_B_v.35.weight', 'image_encoder.blocks.10.attn.lora_B_v.35.weight', 'image_encoder.blocks.4.attn.lora_B_k.35.weight', 'image_encoder.blocks.0.attn.lora_B_k.35.weight'}
2025-12-11 16:06:31,232 [inflora.py] => Task 35, Epoch 20/20 => Loss 0.003, Train_accy 100.00
Threshold:  0.985
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 27/768 type remove
Layer 3 : 50/768 type remove
Layer 4 : 68/768 type remove
Layer 5 : 91/768 type remove
Layer 6 : 120/768 type remove
Layer 7 : 149/768 type remove
Layer 8 : 203/768 type remove
Layer 9 : 220/768 type remove
Layer 10 : 205/768 type remove
Layer 11 : 128/768 type remove
Layer 12 : 117/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:06:41,499 [trainer.py] => Time:137.2544023990631
7200 7200
7200 7200
2025-12-11 16:07:00,992 [trainer.py] => Time:19.493334770202637
2025-12-11 16:07:00,992 [inflora.py] => Exemplar size: 0
2025-12-11 16:07:00,992 [trainer.py] => CNN: {'total': np.float64(67.76), '00-01': np.float64(80.5), '02-03': np.float64(69.5), '04-05': np.float64(63.0), '06-07': np.float64(49.5), '08-09': np.float64(84.5), '10-11': np.float64(62.5), '12-13': np.float64(76.0), '14-15': np.float64(75.5), '16-17': np.float64(61.5), '18-19': np.float64(70.0), '20-21': np.float64(71.0), '22-23': np.float64(54.0), '24-25': np.float64(60.0), '26-27': np.float64(72.0), '28-29': np.float64(68.0), '30-31': np.float64(73.5), '32-33': np.float64(63.5), '34-35': np.float64(49.5), '36-37': np.float64(72.5), '38-39': np.float64(81.0), '40-41': np.float64(84.0), '42-43': np.float64(22.0), '44-45': np.float64(51.0), '46-47': np.float64(45.0), '48-49': np.float64(81.5), '50-51': np.float64(76.5), '52-53': np.float64(78.5), '54-55': np.float64(56.0), '56-57': np.float64(78.0), '58-59': np.float64(71.5), '60-61': np.float64(76.0), '62-63': np.float64(72.0), '64-65': np.float64(64.5), '66-67': np.float64(48.0), '68-69': np.float64(93.0), '70-71': np.float64(84.5), 'old': np.float64(67.29), 'new': np.float64(84.5)}
2025-12-11 16:07:00,993 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76)]
2025-12-11 16:07:00,993 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56)]
2025-12-11 16:07:00,993 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889]
2025-12-11 16:07:23,440 [trainer.py] => W-NCM: {'00-01': 96.5, '02-03': 81.0, '04-05': 82.0, '06-07': 94.0, '08-09': 95.5, '10-11': 42.0, '12-13': 86.0, '14-15': 94.5, '16-17': 92.0, '18-19': 92.5, '20-21': 92.5, '22-23': 71.0, '24-25': 91.5, '26-27': 87.0, '28-29': 87.5, '30-31': 93.5, '32-33': 74.0, '34-35': 87.5, '36-37': 89.0, '38-39': 90.5, '40-41': 95.5, '42-43': 90.0, '44-45': 91.0, '46-47': 75.5, '48-49': 91.5, '50-51': 90.5, '52-53': 86.0, '54-55': 87.0, '56-57': 94.5, '58-59': 87.5, '60-61': 88.5, '62-63': 90.5, '64-65': 91.0, '66-67': 98.0, '68-69': 98.5, '70-71': 98.0}
2025-12-11 16:07:23,440 [trainer.py] => Ave Acc (W-NCM): 88.15%
2025-12-11 16:07:23,441 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 96.50% (best 100.00%); T2: W-NCM 81.00% (best 100.00%); T3: W-NCM 82.00% (best 100.00%); T4: W-NCM 94.00% (best 98.50%); T5: W-NCM 95.50% (best 100.00%); T6: W-NCM 42.00% (best 100.00%); T7: W-NCM 86.00% (best 99.50%); T8: W-NCM 94.50% (best 98.50%); T9: W-NCM 92.00% (best 99.50%); T10: W-NCM 92.50% (best 99.00%); T11: W-NCM 92.50% (best 99.50%); T12: W-NCM 71.00% (best 99.00%); T13: W-NCM 91.50% (best 98.00%); T14: W-NCM 87.00% (best 99.00%); T15: W-NCM 87.50% (best 97.50%); T16: W-NCM 93.50% (best 98.50%); T17: W-NCM 74.00% (best 98.00%); T18: W-NCM 87.50% (best 99.00%); T19: W-NCM 89.00% (best 99.50%); T20: W-NCM 90.50% (best 99.00%); T21: W-NCM 95.50% (best 98.50%); T22: W-NCM 90.00% (best 96.00%); T23: W-NCM 91.00% (best 95.50%); T24: W-NCM 75.50% (best 100.00%); T25: W-NCM 91.50% (best 99.00%); T26: W-NCM 90.50% (best 99.00%); T27: W-NCM 86.00% (best 100.00%); T28: W-NCM 87.00% (best 98.50%); T29: W-NCM 94.50% (best 98.50%); T30: W-NCM 87.50% (best 96.00%); T31: W-NCM 88.50% (best 98.50%); T32: W-NCM 90.50% (best 97.00%); T33: W-NCM 91.00% (best 95.00%); T34: W-NCM 98.00% (best 99.00%); T35: W-NCM 98.50% (best 99.50%); T36: W-NCM 98.00% (best 98.00%)
2025-12-11 16:07:23,441 [trainer.py] => Average forgetting (W-NCM): 10.76% | Max forgetting (W-NCM): 58.00%
2025-12-11 16:07:24,151 [trainer.py] => All params: 125940251
2025-12-11 16:07:24,157 [trainer.py] => Trainable params: 185858
2025-12-11 16:07:24,157 [inflora.py] => Learning on 72-74
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.36.weight', 'image_encoder.blocks.11.attn.lora_B_k.36.weight', 'image_encoder.blocks.10.attn.lora_B_k.36.weight', 'image_encoder.blocks.8.attn.lora_B_k.36.weight', 'image_encoder.blocks.4.attn.lora_B_k.36.weight', 'image_encoder.blocks.6.attn.lora_B_v.36.weight', 'image_encoder.blocks.9.attn.lora_B_k.36.weight', 'image_encoder.blocks.5.attn.lora_B_v.36.weight', 'image_encoder.blocks.5.attn.lora_B_k.36.weight', 'image_encoder.blocks.3.attn.lora_B_v.36.weight', 'image_encoder.blocks.7.attn.lora_B_v.36.weight', 'image_encoder.blocks.7.attn.lora_B_k.36.weight', 'image_encoder.blocks.1.attn.lora_B_k.36.weight', 'image_encoder.blocks.8.attn.lora_B_v.36.weight', 'image_encoder.blocks.2.attn.lora_B_v.36.weight', 'image_encoder.blocks.9.attn.lora_B_v.36.weight', 'image_encoder.blocks.3.attn.lora_B_k.36.weight', 'image_encoder.blocks.6.attn.lora_B_k.36.weight', 'image_encoder.blocks.0.attn.lora_B_k.36.weight', 'image_encoder.blocks.1.attn.lora_B_v.36.weight', 'image_encoder.blocks.0.attn.lora_B_v.36.weight', 'classifier_pool.36.bias', 'image_encoder.blocks.10.attn.lora_B_v.36.weight', 'image_encoder.blocks.2.attn.lora_B_k.36.weight', 'image_encoder.blocks.11.attn.lora_B_v.36.weight', 'classifier_pool.36.weight'}
2025-12-11 16:09:31,454 [inflora.py] => Task 36, Epoch 20/20 => Loss 0.091, Train_accy 96.60
Threshold:  0.986
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 28/768 type remove
Layer 3 : 52/768 type remove
Layer 4 : 71/768 type remove
Layer 5 : 95/768 type remove
Layer 6 : 128/768 type remove
Layer 7 : 159/768 type remove
Layer 8 : 217/768 type remove
Layer 9 : 241/768 type remove
Layer 10 : 222/768 type remove
Layer 11 : 139/768 type remove
Layer 12 : 122/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:09:41,715 [trainer.py] => Time:137.557368516922
7400 7400
7400 7400
2025-12-11 16:10:01,725 [trainer.py] => Time:20.010451078414917
2025-12-11 16:10:01,726 [inflora.py] => Exemplar size: 0
2025-12-11 16:10:01,726 [trainer.py] => CNN: {'total': np.float64(65.78), '00-01': np.float64(79.0), '02-03': np.float64(66.0), '04-05': np.float64(66.5), '06-07': np.float64(48.5), '08-09': np.float64(83.5), '10-11': np.float64(62.0), '12-13': np.float64(76.0), '14-15': np.float64(71.5), '16-17': np.float64(57.5), '18-19': np.float64(69.5), '20-21': np.float64(69.5), '22-23': np.float64(57.0), '24-25': np.float64(61.0), '26-27': np.float64(65.5), '28-29': np.float64(65.5), '30-31': np.float64(73.5), '32-33': np.float64(69.0), '34-35': np.float64(49.5), '36-37': np.float64(70.0), '38-39': np.float64(81.0), '40-41': np.float64(83.5), '42-43': np.float64(22.0), '44-45': np.float64(49.0), '46-47': np.float64(37.5), '48-49': np.float64(81.5), '50-51': np.float64(72.0), '52-53': np.float64(80.0), '54-55': np.float64(53.0), '56-57': np.float64(78.0), '58-59': np.float64(73.0), '60-61': np.float64(69.5), '62-63': np.float64(70.5), '64-65': np.float64(63.5), '66-67': np.float64(49.0), '68-69': np.float64(93.5), '70-71': np.float64(80.5), '72-73': np.float64(36.5), 'old': np.float64(66.6), 'new': np.float64(36.5)}
2025-12-11 16:10:01,726 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78)]
2025-12-11 16:10:01,726 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54)]
2025-12-11 16:10:01,726 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379]
2025-12-11 16:10:24,697 [trainer.py] => W-NCM: {'00-01': 96.5, '02-03': 79.5, '04-05': 76.5, '06-07': 93.5, '08-09': 94.5, '10-11': 56.00000000000001, '12-13': 87.0, '14-15': 95.0, '16-17': 91.5, '18-19': 93.0, '20-21': 93.5, '22-23': 78.0, '24-25': 88.5, '26-27': 82.5, '28-29': 88.5, '30-31': 90.0, '32-33': 74.0, '34-35': 84.5, '36-37': 91.0, '38-39': 92.0, '40-41': 96.0, '42-43': 85.5, '44-45': 90.5, '46-47': 76.0, '48-49': 92.5, '50-51': 91.5, '52-53': 84.0, '54-55': 80.5, '56-57': 95.5, '58-59': 86.0, '60-61': 88.5, '62-63': 89.5, '64-65': 90.0, '66-67': 94.0, '68-69': 98.0, '70-71': 96.5, '72-73': 93.5}
2025-12-11 16:10:24,697 [trainer.py] => Ave Acc (W-NCM): 87.93%
2025-12-11 16:10:24,697 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 96.50% (best 100.00%); T2: W-NCM 79.50% (best 100.00%); T3: W-NCM 76.50% (best 100.00%); T4: W-NCM 93.50% (best 98.50%); T5: W-NCM 94.50% (best 100.00%); T6: W-NCM 56.00% (best 100.00%); T7: W-NCM 87.00% (best 99.50%); T8: W-NCM 95.00% (best 98.50%); T9: W-NCM 91.50% (best 99.50%); T10: W-NCM 93.00% (best 99.00%); T11: W-NCM 93.50% (best 99.50%); T12: W-NCM 78.00% (best 99.00%); T13: W-NCM 88.50% (best 98.00%); T14: W-NCM 82.50% (best 99.00%); T15: W-NCM 88.50% (best 97.50%); T16: W-NCM 90.00% (best 98.50%); T17: W-NCM 74.00% (best 98.00%); T18: W-NCM 84.50% (best 99.00%); T19: W-NCM 91.00% (best 99.50%); T20: W-NCM 92.00% (best 99.00%); T21: W-NCM 96.00% (best 98.50%); T22: W-NCM 85.50% (best 96.00%); T23: W-NCM 90.50% (best 95.50%); T24: W-NCM 76.00% (best 100.00%); T25: W-NCM 92.50% (best 99.00%); T26: W-NCM 91.50% (best 99.00%); T27: W-NCM 84.00% (best 100.00%); T28: W-NCM 80.50% (best 98.50%); T29: W-NCM 95.50% (best 98.50%); T30: W-NCM 86.00% (best 96.00%); T31: W-NCM 88.50% (best 98.50%); T32: W-NCM 89.50% (best 97.00%); T33: W-NCM 90.00% (best 95.00%); T34: W-NCM 94.00% (best 99.00%); T35: W-NCM 98.00% (best 99.50%); T36: W-NCM 96.50% (best 98.00%); T37: W-NCM 93.50% (best 93.50%)
2025-12-11 16:10:24,697 [trainer.py] => Average forgetting (W-NCM): 10.83% | Max forgetting (W-NCM): 44.00%
2025-12-11 16:10:25,416 [trainer.py] => All params: 125940251
2025-12-11 16:10:25,423 [trainer.py] => Trainable params: 185858
2025-12-11 16:10:25,423 [inflora.py] => Learning on 74-76
Parameters to be updated: {'image_encoder.blocks.11.attn.lora_B_k.37.weight', 'image_encoder.blocks.6.attn.lora_B_v.37.weight', 'image_encoder.blocks.6.attn.lora_B_k.37.weight', 'image_encoder.blocks.10.attn.lora_B_v.37.weight', 'image_encoder.blocks.7.attn.lora_B_v.37.weight', 'classifier_pool.37.weight', 'image_encoder.blocks.9.attn.lora_B_k.37.weight', 'image_encoder.blocks.5.attn.lora_B_k.37.weight', 'image_encoder.blocks.7.attn.lora_B_k.37.weight', 'image_encoder.blocks.3.attn.lora_B_k.37.weight', 'image_encoder.blocks.5.attn.lora_B_v.37.weight', 'image_encoder.blocks.1.attn.lora_B_k.37.weight', 'image_encoder.blocks.4.attn.lora_B_v.37.weight', 'image_encoder.blocks.8.attn.lora_B_k.37.weight', 'image_encoder.blocks.1.attn.lora_B_v.37.weight', 'image_encoder.blocks.3.attn.lora_B_v.37.weight', 'image_encoder.blocks.0.attn.lora_B_k.37.weight', 'image_encoder.blocks.2.attn.lora_B_k.37.weight', 'image_encoder.blocks.2.attn.lora_B_v.37.weight', 'image_encoder.blocks.8.attn.lora_B_v.37.weight', 'image_encoder.blocks.4.attn.lora_B_k.37.weight', 'classifier_pool.37.bias', 'image_encoder.blocks.0.attn.lora_B_v.37.weight', 'image_encoder.blocks.9.attn.lora_B_v.37.weight', 'image_encoder.blocks.10.attn.lora_B_k.37.weight', 'image_encoder.blocks.11.attn.lora_B_v.37.weight'}
2025-12-11 16:12:32,675 [inflora.py] => Task 37, Epoch 20/20 => Loss 0.056, Train_accy 97.20
Threshold:  0.987
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 30/768 type remove
Layer 3 : 57/768 type remove
Layer 4 : 78/768 type remove
Layer 5 : 103/768 type remove
Layer 6 : 141/768 type remove
Layer 7 : 171/768 type remove
Layer 8 : 228/768 type remove
Layer 9 : 250/768 type remove
Layer 10 : 233/768 type remove
Layer 11 : 144/768 type remove
Layer 12 : 124/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:12:42,683 [trainer.py] => Time:137.25991702079773
7600 7600
7600 7600
2025-12-11 16:13:03,296 [trainer.py] => Time:20.612812995910645
2025-12-11 16:13:03,296 [inflora.py] => Exemplar size: 0
2025-12-11 16:13:03,296 [trainer.py] => CNN: {'total': np.float64(65.62), '00-01': np.float64(82.0), '02-03': np.float64(64.0), '04-05': np.float64(63.5), '06-07': np.float64(48.0), '08-09': np.float64(86.0), '10-11': np.float64(63.0), '12-13': np.float64(77.0), '14-15': np.float64(73.5), '16-17': np.float64(54.5), '18-19': np.float64(69.5), '20-21': np.float64(70.0), '22-23': np.float64(60.5), '24-25': np.float64(63.5), '26-27': np.float64(63.0), '28-29': np.float64(65.0), '30-31': np.float64(66.5), '32-33': np.float64(63.5), '34-35': np.float64(50.0), '36-37': np.float64(69.0), '38-39': np.float64(83.0), '40-41': np.float64(83.5), '42-43': np.float64(16.5), '44-45': np.float64(51.5), '46-47': np.float64(42.0), '48-49': np.float64(77.0), '50-51': np.float64(72.5), '52-53': np.float64(79.0), '54-55': np.float64(56.5), '56-57': np.float64(77.5), '58-59': np.float64(74.0), '60-61': np.float64(73.0), '62-63': np.float64(69.5), '64-65': np.float64(63.0), '66-67': np.float64(48.5), '68-69': np.float64(92.0), '70-71': np.float64(83.0), '72-73': np.float64(31.5), '74-75': np.float64(68.0), 'old': np.float64(65.55), 'new': np.float64(68.0)}
2025-12-11 16:13:03,296 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62)]
2025-12-11 16:13:03,296 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54)]
2025-12-11 16:13:03,296 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158]
2025-12-11 16:13:26,888 [trainer.py] => W-NCM: {'00-01': 97.0, '02-03': 78.0, '04-05': 75.0, '06-07': 94.0, '08-09': 95.0, '10-11': 44.5, '12-13': 87.0, '14-15': 93.5, '16-17': 91.0, '18-19': 89.0, '20-21': 91.5, '22-23': 80.0, '24-25': 88.5, '26-27': 87.0, '28-29': 90.5, '30-31': 91.5, '32-33': 74.0, '34-35': 88.0, '36-37': 92.0, '38-39': 92.0, '40-41': 95.5, '42-43': 85.5, '44-45': 90.0, '46-47': 74.5, '48-49': 93.5, '50-51': 82.5, '52-53': 87.5, '54-55': 83.5, '56-57': 95.5, '58-59': 87.0, '60-61': 89.0, '62-63': 88.5, '64-65': 88.5, '66-67': 95.0, '68-69': 97.5, '70-71': 96.0, '72-73': 91.0, '74-75': 96.0}
2025-12-11 16:13:26,888 [trainer.py] => Ave Acc (W-NCM): 87.78%
2025-12-11 16:13:26,888 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 97.00% (best 100.00%); T2: W-NCM 78.00% (best 100.00%); T3: W-NCM 75.00% (best 100.00%); T4: W-NCM 94.00% (best 98.50%); T5: W-NCM 95.00% (best 100.00%); T6: W-NCM 44.50% (best 100.00%); T7: W-NCM 87.00% (best 99.50%); T8: W-NCM 93.50% (best 98.50%); T9: W-NCM 91.00% (best 99.50%); T10: W-NCM 89.00% (best 99.00%); T11: W-NCM 91.50% (best 99.50%); T12: W-NCM 80.00% (best 99.00%); T13: W-NCM 88.50% (best 98.00%); T14: W-NCM 87.00% (best 99.00%); T15: W-NCM 90.50% (best 97.50%); T16: W-NCM 91.50% (best 98.50%); T17: W-NCM 74.00% (best 98.00%); T18: W-NCM 88.00% (best 99.00%); T19: W-NCM 92.00% (best 99.50%); T20: W-NCM 92.00% (best 99.00%); T21: W-NCM 95.50% (best 98.50%); T22: W-NCM 85.50% (best 96.00%); T23: W-NCM 90.00% (best 95.50%); T24: W-NCM 74.50% (best 100.00%); T25: W-NCM 93.50% (best 99.00%); T26: W-NCM 82.50% (best 99.00%); T27: W-NCM 87.50% (best 100.00%); T28: W-NCM 83.50% (best 98.50%); T29: W-NCM 95.50% (best 98.50%); T30: W-NCM 87.00% (best 96.00%); T31: W-NCM 89.00% (best 98.50%); T32: W-NCM 88.50% (best 97.00%); T33: W-NCM 88.50% (best 95.00%); T34: W-NCM 95.00% (best 99.00%); T35: W-NCM 97.50% (best 99.50%); T36: W-NCM 96.00% (best 98.00%); T37: W-NCM 91.00% (best 93.50%); T38: W-NCM 96.00% (best 96.00%)
2025-12-11 16:13:26,888 [trainer.py] => Average forgetting (W-NCM): 10.92% | Max forgetting (W-NCM): 55.50%
2025-12-11 16:13:27,587 [trainer.py] => All params: 125940251
2025-12-11 16:13:27,593 [trainer.py] => Trainable params: 185858
2025-12-11 16:13:27,593 [inflora.py] => Learning on 76-78
Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_v.38.weight', 'image_encoder.blocks.9.attn.lora_B_k.38.weight', 'image_encoder.blocks.6.attn.lora_B_k.38.weight', 'image_encoder.blocks.3.attn.lora_B_v.38.weight', 'image_encoder.blocks.11.attn.lora_B_v.38.weight', 'image_encoder.blocks.3.attn.lora_B_k.38.weight', 'image_encoder.blocks.7.attn.lora_B_v.38.weight', 'image_encoder.blocks.0.attn.lora_B_k.38.weight', 'image_encoder.blocks.5.attn.lora_B_v.38.weight', 'image_encoder.blocks.8.attn.lora_B_v.38.weight', 'image_encoder.blocks.4.attn.lora_B_k.38.weight', 'image_encoder.blocks.1.attn.lora_B_k.38.weight', 'image_encoder.blocks.8.attn.lora_B_k.38.weight', 'image_encoder.blocks.9.attn.lora_B_v.38.weight', 'image_encoder.blocks.0.attn.lora_B_v.38.weight', 'image_encoder.blocks.5.attn.lora_B_k.38.weight', 'classifier_pool.38.weight', 'image_encoder.blocks.4.attn.lora_B_v.38.weight', 'image_encoder.blocks.10.attn.lora_B_k.38.weight', 'image_encoder.blocks.2.attn.lora_B_v.38.weight', 'image_encoder.blocks.6.attn.lora_B_v.38.weight', 'image_encoder.blocks.7.attn.lora_B_k.38.weight', 'classifier_pool.38.bias', 'image_encoder.blocks.1.attn.lora_B_v.38.weight', 'image_encoder.blocks.11.attn.lora_B_k.38.weight', 'image_encoder.blocks.2.attn.lora_B_k.38.weight'}
2025-12-11 16:15:34,693 [inflora.py] => Task 38, Epoch 20/20 => Loss 0.017, Train_accy 99.70
Threshold:  0.988
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 30/768 type remove
Layer 3 : 58/768 type remove
Layer 4 : 81/768 type remove
Layer 5 : 108/768 type remove
Layer 6 : 147/768 type remove
Layer 7 : 181/768 type remove
Layer 8 : 245/768 type remove
Layer 9 : 266/768 type remove
Layer 10 : 255/768 type remove
Layer 11 : 154/768 type remove
Layer 12 : 142/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:15:44,667 [trainer.py] => Time:137.07354879379272
7800 7800
7800 7800
2025-12-11 16:16:05,786 [trainer.py] => Time:21.118715524673462
2025-12-11 16:16:05,786 [inflora.py] => Exemplar size: 0
2025-12-11 16:16:05,786 [trainer.py] => CNN: {'total': np.float64(67.79), '00-01': np.float64(87.0), '02-03': np.float64(68.5), '04-05': np.float64(69.5), '06-07': np.float64(49.5), '08-09': np.float64(86.5), '10-11': np.float64(61.5), '12-13': np.float64(73.5), '14-15': np.float64(76.5), '16-17': np.float64(67.5), '18-19': np.float64(68.5), '20-21': np.float64(67.5), '22-23': np.float64(57.5), '24-25': np.float64(65.5), '26-27': np.float64(70.5), '28-29': np.float64(70.0), '30-31': np.float64(74.5), '32-33': np.float64(69.0), '34-35': np.float64(51.0), '36-37': np.float64(71.5), '38-39': np.float64(81.5), '40-41': np.float64(83.0), '42-43': np.float64(26.0), '44-45': np.float64(51.5), '46-47': np.float64(46.0), '48-49': np.float64(83.5), '50-51': np.float64(75.0), '52-53': np.float64(84.5), '54-55': np.float64(64.5), '56-57': np.float64(77.0), '58-59': np.float64(67.0), '60-61': np.float64(74.0), '62-63': np.float64(69.5), '64-65': np.float64(62.0), '66-67': np.float64(51.5), '68-69': np.float64(86.5), '70-71': np.float64(86.5), '72-73': np.float64(24.5), '74-75': np.float64(70.0), '76-77': np.float64(74.5), 'old': np.float64(67.62), 'new': np.float64(74.5)}
2025-12-11 16:16:05,786 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79)]
2025-12-11 16:16:05,786 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5)]
2025-12-11 16:16:05,786 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179]
2025-12-11 16:16:29,850 [trainer.py] => W-NCM: {'00-01': 97.0, '02-03': 81.0, '04-05': 77.0, '06-07': 94.5, '08-09': 94.5, '10-11': 34.5, '12-13': 85.5, '14-15': 95.0, '16-17': 89.0, '18-19': 89.5, '20-21': 92.0, '22-23': 75.0, '24-25': 88.0, '26-27': 87.5, '28-29': 92.5, '30-31': 91.0, '32-33': 70.5, '34-35': 87.5, '36-37': 86.5, '38-39': 93.5, '40-41': 94.5, '42-43': 88.0, '44-45': 90.5, '46-47': 71.5, '48-49': 95.0, '50-51': 84.5, '52-53': 82.0, '54-55': 83.0, '56-57': 93.5, '58-59': 91.0, '60-61': 91.5, '62-63': 87.5, '64-65': 88.0, '66-67': 93.0, '68-69': 95.0, '70-71': 94.5, '72-73': 90.0, '74-75': 92.0, '76-77': 98.5}
2025-12-11 16:16:29,851 [trainer.py] => Ave Acc (W-NCM): 87.31%
2025-12-11 16:16:29,851 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 97.00% (best 100.00%); T2: W-NCM 81.00% (best 100.00%); T3: W-NCM 77.00% (best 100.00%); T4: W-NCM 94.50% (best 98.50%); T5: W-NCM 94.50% (best 100.00%); T6: W-NCM 34.50% (best 100.00%); T7: W-NCM 85.50% (best 99.50%); T8: W-NCM 95.00% (best 98.50%); T9: W-NCM 89.00% (best 99.50%); T10: W-NCM 89.50% (best 99.00%); T11: W-NCM 92.00% (best 99.50%); T12: W-NCM 75.00% (best 99.00%); T13: W-NCM 88.00% (best 98.00%); T14: W-NCM 87.50% (best 99.00%); T15: W-NCM 92.50% (best 97.50%); T16: W-NCM 91.00% (best 98.50%); T17: W-NCM 70.50% (best 98.00%); T18: W-NCM 87.50% (best 99.00%); T19: W-NCM 86.50% (best 99.50%); T20: W-NCM 93.50% (best 99.00%); T21: W-NCM 94.50% (best 98.50%); T22: W-NCM 88.00% (best 96.00%); T23: W-NCM 90.50% (best 95.50%); T24: W-NCM 71.50% (best 100.00%); T25: W-NCM 95.00% (best 99.00%); T26: W-NCM 84.50% (best 99.00%); T27: W-NCM 82.00% (best 100.00%); T28: W-NCM 83.00% (best 98.50%); T29: W-NCM 93.50% (best 98.50%); T30: W-NCM 91.00% (best 96.00%); T31: W-NCM 91.50% (best 98.50%); T32: W-NCM 87.50% (best 97.00%); T33: W-NCM 88.00% (best 95.00%); T34: W-NCM 93.00% (best 99.00%); T35: W-NCM 95.00% (best 99.50%); T36: W-NCM 94.50% (best 98.00%); T37: W-NCM 90.00% (best 93.50%); T38: W-NCM 92.00% (best 96.00%); T39: W-NCM 98.50% (best 98.50%)
2025-12-11 16:16:29,851 [trainer.py] => Average forgetting (W-NCM): 11.39% | Max forgetting (W-NCM): 65.50%
2025-12-11 16:16:30,552 [trainer.py] => All params: 125940251
2025-12-11 16:16:30,558 [trainer.py] => Trainable params: 185858
2025-12-11 16:16:30,559 [inflora.py] => Learning on 78-80
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_v.39.weight', 'image_encoder.blocks.7.attn.lora_B_k.39.weight', 'image_encoder.blocks.0.attn.lora_B_k.39.weight', 'image_encoder.blocks.11.attn.lora_B_v.39.weight', 'image_encoder.blocks.2.attn.lora_B_k.39.weight', 'image_encoder.blocks.3.attn.lora_B_v.39.weight', 'image_encoder.blocks.5.attn.lora_B_k.39.weight', 'image_encoder.blocks.3.attn.lora_B_k.39.weight', 'image_encoder.blocks.9.attn.lora_B_k.39.weight', 'image_encoder.blocks.4.attn.lora_B_k.39.weight', 'image_encoder.blocks.6.attn.lora_B_v.39.weight', 'image_encoder.blocks.1.attn.lora_B_v.39.weight', 'image_encoder.blocks.10.attn.lora_B_k.39.weight', 'image_encoder.blocks.0.attn.lora_B_v.39.weight', 'classifier_pool.39.weight', 'classifier_pool.39.bias', 'image_encoder.blocks.5.attn.lora_B_v.39.weight', 'image_encoder.blocks.7.attn.lora_B_v.39.weight', 'image_encoder.blocks.4.attn.lora_B_v.39.weight', 'image_encoder.blocks.2.attn.lora_B_v.39.weight', 'image_encoder.blocks.8.attn.lora_B_v.39.weight', 'image_encoder.blocks.10.attn.lora_B_v.39.weight', 'image_encoder.blocks.11.attn.lora_B_k.39.weight', 'image_encoder.blocks.8.attn.lora_B_k.39.weight', 'image_encoder.blocks.6.attn.lora_B_k.39.weight', 'image_encoder.blocks.1.attn.lora_B_k.39.weight'}
2025-12-11 16:18:38,212 [inflora.py] => Task 39, Epoch 20/20 => Loss 0.034, Train_accy 98.90
Threshold:  0.989
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 31/768 type remove
Layer 3 : 62/768 type remove
Layer 4 : 87/768 type remove
Layer 5 : 115/768 type remove
Layer 6 : 156/768 type remove
Layer 7 : 193/768 type remove
Layer 8 : 273/768 type remove
Layer 9 : 292/768 type remove
Layer 10 : 278/768 type remove
Layer 11 : 167/768 type remove
Layer 12 : 145/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:18:48,089 [trainer.py] => Time:137.5305781364441
8000 8000
8000 8000
2025-12-11 16:19:09,911 [trainer.py] => Time:21.821981191635132
2025-12-11 16:19:09,912 [inflora.py] => Exemplar size: 0
2025-12-11 16:19:09,912 [trainer.py] => CNN: {'total': np.float64(67.97), '00-01': np.float64(85.5), '02-03': np.float64(72.0), '04-05': np.float64(68.0), '06-07': np.float64(48.0), '08-09': np.float64(83.0), '10-11': np.float64(57.5), '12-13': np.float64(71.5), '14-15': np.float64(75.0), '16-17': np.float64(72.5), '18-19': np.float64(68.5), '20-21': np.float64(65.0), '22-23': np.float64(58.5), '24-25': np.float64(64.5), '26-27': np.float64(65.5), '28-29': np.float64(71.5), '30-31': np.float64(73.0), '32-33': np.float64(68.5), '34-35': np.float64(51.0), '36-37': np.float64(71.5), '38-39': np.float64(82.5), '40-41': np.float64(83.0), '42-43': np.float64(29.5), '44-45': np.float64(54.0), '46-47': np.float64(47.5), '48-49': np.float64(83.5), '50-51': np.float64(74.0), '52-53': np.float64(84.5), '54-55': np.float64(66.5), '56-57': np.float64(78.5), '58-59': np.float64(59.0), '60-61': np.float64(75.0), '62-63': np.float64(64.0), '64-65': np.float64(67.5), '66-67': np.float64(59.0), '68-69': np.float64(87.5), '70-71': np.float64(85.5), '72-73': np.float64(23.5), '74-75': np.float64(74.5), '76-77': np.float64(73.0), '78-79': np.float64(76.5), 'old': np.float64(67.76), 'new': np.float64(76.5)}
2025-12-11 16:19:09,912 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97)]
2025-12-11 16:19:09,912 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5)]
2025-12-11 16:19:09,912 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975]
2025-12-11 16:19:34,723 [trainer.py] => W-NCM: {'00-01': 97.0, '02-03': 82.5, '04-05': 79.0, '06-07': 90.5, '08-09': 95.5, '10-11': 35.0, '12-13': 85.5, '14-15': 95.0, '16-17': 90.5, '18-19': 92.0, '20-21': 93.0, '22-23': 76.5, '24-25': 86.0, '26-27': 82.5, '28-29': 91.0, '30-31': 91.0, '32-33': 71.0, '34-35': 88.5, '36-37': 88.0, '38-39': 93.5, '40-41': 95.5, '42-43': 86.5, '44-45': 91.0, '46-47': 73.5, '48-49': 94.5, '50-51': 87.0, '52-53': 80.0, '54-55': 84.0, '56-57': 94.0, '58-59': 91.5, '60-61': 90.5, '62-63': 84.5, '64-65': 89.0, '66-67': 94.5, '68-69': 95.0, '70-71': 91.5, '72-73': 90.0, '74-75': 89.0, '76-77': 97.0, '78-79': 98.5}
2025-12-11 16:19:34,723 [trainer.py] => Ave Acc (W-NCM): 87.51%
2025-12-11 16:19:34,723 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 97.00% (best 100.00%); T2: W-NCM 82.50% (best 100.00%); T3: W-NCM 79.00% (best 100.00%); T4: W-NCM 90.50% (best 98.50%); T5: W-NCM 95.50% (best 100.00%); T6: W-NCM 35.00% (best 100.00%); T7: W-NCM 85.50% (best 99.50%); T8: W-NCM 95.00% (best 98.50%); T9: W-NCM 90.50% (best 99.50%); T10: W-NCM 92.00% (best 99.00%); T11: W-NCM 93.00% (best 99.50%); T12: W-NCM 76.50% (best 99.00%); T13: W-NCM 86.00% (best 98.00%); T14: W-NCM 82.50% (best 99.00%); T15: W-NCM 91.00% (best 97.50%); T16: W-NCM 91.00% (best 98.50%); T17: W-NCM 71.00% (best 98.00%); T18: W-NCM 88.50% (best 99.00%); T19: W-NCM 88.00% (best 99.50%); T20: W-NCM 93.50% (best 99.00%); T21: W-NCM 95.50% (best 98.50%); T22: W-NCM 86.50% (best 96.00%); T23: W-NCM 91.00% (best 95.50%); T24: W-NCM 73.50% (best 100.00%); T25: W-NCM 94.50% (best 99.00%); T26: W-NCM 87.00% (best 99.00%); T27: W-NCM 80.00% (best 100.00%); T28: W-NCM 84.00% (best 98.50%); T29: W-NCM 94.00% (best 98.50%); T30: W-NCM 91.50% (best 96.00%); T31: W-NCM 90.50% (best 98.50%); T32: W-NCM 84.50% (best 97.00%); T33: W-NCM 89.00% (best 95.00%); T34: W-NCM 94.50% (best 99.00%); T35: W-NCM 95.00% (best 99.50%); T36: W-NCM 91.50% (best 98.00%); T37: W-NCM 90.00% (best 93.50%); T38: W-NCM 89.00% (best 96.00%); T39: W-NCM 97.00% (best 98.50%); T40: W-NCM 98.50% (best 98.50%)
2025-12-11 16:19:34,723 [trainer.py] => Average forgetting (W-NCM): 11.18% | Max forgetting (W-NCM): 65.00%
2025-12-11 16:19:35,408 [trainer.py] => All params: 125940251
2025-12-11 16:19:35,414 [trainer.py] => Trainable params: 185858
2025-12-11 16:19:35,414 [inflora.py] => Learning on 80-82
Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.40.weight', 'image_encoder.blocks.11.attn.lora_B_k.40.weight', 'image_encoder.blocks.0.attn.lora_B_v.40.weight', 'image_encoder.blocks.4.attn.lora_B_v.40.weight', 'image_encoder.blocks.7.attn.lora_B_k.40.weight', 'image_encoder.blocks.3.attn.lora_B_v.40.weight', 'image_encoder.blocks.2.attn.lora_B_k.40.weight', 'image_encoder.blocks.0.attn.lora_B_k.40.weight', 'image_encoder.blocks.7.attn.lora_B_v.40.weight', 'image_encoder.blocks.4.attn.lora_B_k.40.weight', 'image_encoder.blocks.3.attn.lora_B_k.40.weight', 'image_encoder.blocks.8.attn.lora_B_k.40.weight', 'image_encoder.blocks.6.attn.lora_B_k.40.weight', 'image_encoder.blocks.10.attn.lora_B_v.40.weight', 'image_encoder.blocks.5.attn.lora_B_v.40.weight', 'classifier_pool.40.bias', 'image_encoder.blocks.10.attn.lora_B_k.40.weight', 'image_encoder.blocks.11.attn.lora_B_v.40.weight', 'image_encoder.blocks.5.attn.lora_B_k.40.weight', 'image_encoder.blocks.9.attn.lora_B_k.40.weight', 'classifier_pool.40.weight', 'image_encoder.blocks.1.attn.lora_B_k.40.weight', 'image_encoder.blocks.1.attn.lora_B_v.40.weight', 'image_encoder.blocks.9.attn.lora_B_v.40.weight', 'image_encoder.blocks.2.attn.lora_B_v.40.weight', 'image_encoder.blocks.8.attn.lora_B_v.40.weight'}
2025-12-11 16:21:42,775 [inflora.py] => Task 40, Epoch 20/20 => Loss 0.014, Train_accy 99.50
Threshold:  0.99
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 33/768 type remove
Layer 3 : 65/768 type remove
Layer 4 : 92/768 type remove
Layer 5 : 121/768 type remove
Layer 6 : 166/768 type remove
Layer 7 : 203/768 type remove
Layer 8 : 281/768 type remove
Layer 9 : 304/768 type remove
Layer 10 : 303/768 type remove
Layer 11 : 185/768 type remove
Layer 12 : 159/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:21:53,032 [trainer.py] => Time:137.61772918701172
8200 8200
8200 8200
2025-12-11 16:22:15,341 [trainer.py] => Time:22.308326244354248
2025-12-11 16:22:15,341 [inflora.py] => Exemplar size: 0
2025-12-11 16:22:15,341 [trainer.py] => CNN: {'total': np.float64(67.4), '00-01': np.float64(87.0), '02-03': np.float64(69.0), '04-05': np.float64(68.5), '06-07': np.float64(49.0), '08-09': np.float64(89.0), '10-11': np.float64(55.0), '12-13': np.float64(76.0), '14-15': np.float64(81.5), '16-17': np.float64(62.0), '18-19': np.float64(65.5), '20-21': np.float64(72.5), '22-23': np.float64(58.5), '24-25': np.float64(64.5), '26-27': np.float64(71.5), '28-29': np.float64(67.0), '30-31': np.float64(66.0), '32-33': np.float64(60.5), '34-35': np.float64(52.5), '36-37': np.float64(66.5), '38-39': np.float64(84.5), '40-41': np.float64(83.0), '42-43': np.float64(23.5), '44-45': np.float64(53.0), '46-47': np.float64(51.0), '48-49': np.float64(67.5), '50-51': np.float64(76.0), '52-53': np.float64(83.0), '54-55': np.float64(66.5), '56-57': np.float64(80.5), '58-59': np.float64(72.5), '60-61': np.float64(79.0), '62-63': np.float64(61.5), '64-65': np.float64(68.0), '66-67': np.float64(55.5), '68-69': np.float64(89.5), '70-71': np.float64(84.0), '72-73': np.float64(27.5), '74-75': np.float64(72.0), '76-77': np.float64(70.0), '78-79': np.float64(75.0), '80-81': np.float64(58.5), 'old': np.float64(67.62), 'new': np.float64(58.5)}
2025-12-11 16:22:15,341 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4)]
2025-12-11 16:22:15,341 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56)]
2025-12-11 16:22:15,341 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025]
2025-12-11 16:22:40,530 [trainer.py] => W-NCM: {'00-01': 97.0, '02-03': 86.5, '04-05': 75.5, '06-07': 93.0, '08-09': 95.0, '10-11': 28.999999999999996, '12-13': 67.5, '14-15': 96.0, '16-17': 89.5, '18-19': 93.5, '20-21': 91.0, '22-23': 78.0, '24-25': 88.5, '26-27': 85.5, '28-29': 93.0, '30-31': 92.0, '32-33': 70.0, '34-35': 91.5, '36-37': 88.0, '38-39': 93.0, '40-41': 95.0, '42-43': 87.5, '44-45': 90.5, '46-47': 69.0, '48-49': 93.5, '50-51': 86.0, '52-53': 84.5, '54-55': 86.5, '56-57': 94.5, '58-59': 88.5, '60-61': 90.5, '62-63': 85.0, '64-65': 89.5, '66-67': 94.5, '68-69': 97.0, '70-71': 94.5, '72-73': 89.5, '74-75': 92.5, '76-77': 96.5, '78-79': 98.0, '80-81': 95.5}
2025-12-11 16:22:40,531 [trainer.py] => Ave Acc (W-NCM): 87.60%
2025-12-11 16:22:40,531 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 97.00% (best 100.00%); T2: W-NCM 86.50% (best 100.00%); T3: W-NCM 75.50% (best 100.00%); T4: W-NCM 93.00% (best 98.50%); T5: W-NCM 95.00% (best 100.00%); T6: W-NCM 29.00% (best 100.00%); T7: W-NCM 67.50% (best 99.50%); T8: W-NCM 96.00% (best 98.50%); T9: W-NCM 89.50% (best 99.50%); T10: W-NCM 93.50% (best 99.00%); T11: W-NCM 91.00% (best 99.50%); T12: W-NCM 78.00% (best 99.00%); T13: W-NCM 88.50% (best 98.00%); T14: W-NCM 85.50% (best 99.00%); T15: W-NCM 93.00% (best 97.50%); T16: W-NCM 92.00% (best 98.50%); T17: W-NCM 70.00% (best 98.00%); T18: W-NCM 91.50% (best 99.00%); T19: W-NCM 88.00% (best 99.50%); T20: W-NCM 93.00% (best 99.00%); T21: W-NCM 95.00% (best 98.50%); T22: W-NCM 87.50% (best 96.00%); T23: W-NCM 90.50% (best 95.50%); T24: W-NCM 69.00% (best 100.00%); T25: W-NCM 93.50% (best 99.00%); T26: W-NCM 86.00% (best 99.00%); T27: W-NCM 84.50% (best 100.00%); T28: W-NCM 86.50% (best 98.50%); T29: W-NCM 94.50% (best 98.50%); T30: W-NCM 88.50% (best 96.00%); T31: W-NCM 90.50% (best 98.50%); T32: W-NCM 85.00% (best 97.00%); T33: W-NCM 89.50% (best 95.00%); T34: W-NCM 94.50% (best 99.00%); T35: W-NCM 97.00% (best 99.50%); T36: W-NCM 94.50% (best 98.00%); T37: W-NCM 89.50% (best 93.50%); T38: W-NCM 92.50% (best 96.00%); T39: W-NCM 96.50% (best 98.50%); T40: W-NCM 98.00% (best 98.50%); T41: W-NCM 95.50% (best 95.50%)
2025-12-11 16:22:40,531 [trainer.py] => Average forgetting (W-NCM): 11.01% | Max forgetting (W-NCM): 71.00%
2025-12-11 16:22:41,232 [trainer.py] => All params: 125940251
2025-12-11 16:22:41,239 [trainer.py] => Trainable params: 185858
2025-12-11 16:22:41,239 [inflora.py] => Learning on 82-84
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.41.weight', 'image_encoder.blocks.9.attn.lora_B_k.41.weight', 'image_encoder.blocks.6.attn.lora_B_v.41.weight', 'image_encoder.blocks.2.attn.lora_B_v.41.weight', 'image_encoder.blocks.7.attn.lora_B_k.41.weight', 'image_encoder.blocks.0.attn.lora_B_v.41.weight', 'image_encoder.blocks.2.attn.lora_B_k.41.weight', 'image_encoder.blocks.11.attn.lora_B_k.41.weight', 'image_encoder.blocks.4.attn.lora_B_k.41.weight', 'image_encoder.blocks.9.attn.lora_B_v.41.weight', 'image_encoder.blocks.1.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_v.41.weight', 'image_encoder.blocks.3.attn.lora_B_v.41.weight', 'image_encoder.blocks.7.attn.lora_B_v.41.weight', 'image_encoder.blocks.10.attn.lora_B_v.41.weight', 'image_encoder.blocks.8.attn.lora_B_v.41.weight', 'image_encoder.blocks.8.attn.lora_B_k.41.weight', 'image_encoder.blocks.3.attn.lora_B_k.41.weight', 'classifier_pool.41.bias', 'image_encoder.blocks.1.attn.lora_B_v.41.weight', 'image_encoder.blocks.6.attn.lora_B_k.41.weight', 'classifier_pool.41.weight', 'image_encoder.blocks.11.attn.lora_B_v.41.weight', 'image_encoder.blocks.0.attn.lora_B_k.41.weight', 'image_encoder.blocks.5.attn.lora_B_k.41.weight', 'image_encoder.blocks.10.attn.lora_B_k.41.weight'}
2025-12-11 16:24:48,797 [inflora.py] => Task 41, Epoch 20/20 => Loss 0.015, Train_accy 99.30
Threshold:  0.991
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 34/768 type remove
Layer 3 : 70/768 type remove
Layer 4 : 98/768 type remove
Layer 5 : 131/768 type remove
Layer 6 : 174/768 type remove
Layer 7 : 214/768 type remove
Layer 8 : 299/768 type remove
Layer 9 : 318/768 type remove
Layer 10 : 312/768 type remove
Layer 11 : 199/768 type remove
Layer 12 : 166/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:24:58,856 [trainer.py] => Time:137.61717319488525
8400 8400
8400 8400
2025-12-11 16:25:21,515 [trainer.py] => Time:22.659159898757935
2025-12-11 16:25:21,516 [inflora.py] => Exemplar size: 0
2025-12-11 16:25:21,516 [trainer.py] => CNN: {'total': np.float64(67.21), '00-01': np.float64(87.5), '02-03': np.float64(69.5), '04-05': np.float64(66.0), '06-07': np.float64(49.0), '08-09': np.float64(89.5), '10-11': np.float64(54.5), '12-13': np.float64(75.5), '14-15': np.float64(81.5), '16-17': np.float64(62.0), '18-19': np.float64(67.5), '20-21': np.float64(72.5), '22-23': np.float64(57.5), '24-25': np.float64(64.0), '26-27': np.float64(65.5), '28-29': np.float64(69.0), '30-31': np.float64(66.0), '32-33': np.float64(59.5), '34-35': np.float64(53.5), '36-37': np.float64(64.0), '38-39': np.float64(84.0), '40-41': np.float64(84.5), '42-43': np.float64(25.0), '44-45': np.float64(54.5), '46-47': np.float64(51.0), '48-49': np.float64(59.0), '50-51': np.float64(80.0), '52-53': np.float64(82.5), '54-55': np.float64(69.5), '56-57': np.float64(80.0), '58-59': np.float64(67.5), '60-61': np.float64(78.0), '62-63': np.float64(62.0), '64-65': np.float64(67.5), '66-67': np.float64(56.0), '68-69': np.float64(87.5), '70-71': np.float64(87.0), '72-73': np.float64(22.5), '74-75': np.float64(72.5), '76-77': np.float64(68.5), '78-79': np.float64(71.5), '80-81': np.float64(58.5), '82-83': np.float64(80.0), 'old': np.float64(66.9), 'new': np.float64(80.0)}
2025-12-11 16:25:21,516 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4), np.float64(67.21)]
2025-12-11 16:25:21,516 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56), np.float64(99.58)]
2025-12-11 16:25:21,516 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025, 0.6721428571428572]
2025-12-11 16:25:47,126 [trainer.py] => W-NCM: {'00-01': 96.5, '02-03': 84.5, '04-05': 77.5, '06-07': 93.5, '08-09': 94.5, '10-11': 21.0, '12-13': 65.5, '14-15': 97.5, '16-17': 89.0, '18-19': 92.5, '20-21': 90.5, '22-23': 76.5, '24-25': 86.5, '26-27': 83.5, '28-29': 94.5, '30-31': 90.5, '32-33': 70.0, '34-35': 90.5, '36-37': 87.5, '38-39': 92.5, '40-41': 94.5, '42-43': 86.0, '44-45': 90.0, '46-47': 71.0, '48-49': 94.5, '50-51': 86.5, '52-53': 88.0, '54-55': 88.0, '56-57': 94.5, '58-59': 86.0, '60-61': 91.0, '62-63': 84.0, '64-65': 87.5, '66-67': 94.0, '68-69': 95.0, '70-71': 92.5, '72-73': 88.5, '74-75': 91.0, '76-77': 96.5, '78-79': 97.5, '80-81': 96.0, '82-83': 98.0}
2025-12-11 16:25:47,126 [trainer.py] => Ave Acc (W-NCM): 87.26%
2025-12-11 16:25:47,126 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 96.50% (best 100.00%); T2: W-NCM 84.50% (best 100.00%); T3: W-NCM 77.50% (best 100.00%); T4: W-NCM 93.50% (best 98.50%); T5: W-NCM 94.50% (best 100.00%); T6: W-NCM 21.00% (best 100.00%); T7: W-NCM 65.50% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 89.00% (best 99.50%); T10: W-NCM 92.50% (best 99.00%); T11: W-NCM 90.50% (best 99.50%); T12: W-NCM 76.50% (best 99.00%); T13: W-NCM 86.50% (best 98.00%); T14: W-NCM 83.50% (best 99.00%); T15: W-NCM 94.50% (best 97.50%); T16: W-NCM 90.50% (best 98.50%); T17: W-NCM 70.00% (best 98.00%); T18: W-NCM 90.50% (best 99.00%); T19: W-NCM 87.50% (best 99.50%); T20: W-NCM 92.50% (best 99.00%); T21: W-NCM 94.50% (best 98.50%); T22: W-NCM 86.00% (best 96.00%); T23: W-NCM 90.00% (best 95.50%); T24: W-NCM 71.00% (best 100.00%); T25: W-NCM 94.50% (best 99.00%); T26: W-NCM 86.50% (best 99.00%); T27: W-NCM 88.00% (best 100.00%); T28: W-NCM 88.00% (best 98.50%); T29: W-NCM 94.50% (best 98.50%); T30: W-NCM 86.00% (best 96.00%); T31: W-NCM 91.00% (best 98.50%); T32: W-NCM 84.00% (best 97.00%); T33: W-NCM 87.50% (best 95.00%); T34: W-NCM 94.00% (best 99.00%); T35: W-NCM 95.00% (best 99.50%); T36: W-NCM 92.50% (best 98.00%); T37: W-NCM 88.50% (best 93.50%); T38: W-NCM 91.00% (best 96.00%); T39: W-NCM 96.50% (best 98.50%); T40: W-NCM 97.50% (best 98.50%); T41: W-NCM 96.00% (best 96.00%); T42: W-NCM 98.00% (best 98.00%)
2025-12-11 16:25:47,126 [trainer.py] => Average forgetting (W-NCM): 11.35% | Max forgetting (W-NCM): 79.00%
2025-12-11 16:25:47,883 [trainer.py] => All params: 125940251
2025-12-11 16:25:47,889 [trainer.py] => Trainable params: 185858
2025-12-11 16:25:47,889 [inflora.py] => Learning on 84-86
Parameters to be updated: {'classifier_pool.42.bias', 'image_encoder.blocks.5.attn.lora_B_k.42.weight', 'image_encoder.blocks.1.attn.lora_B_v.42.weight', 'image_encoder.blocks.9.attn.lora_B_k.42.weight', 'image_encoder.blocks.11.attn.lora_B_v.42.weight', 'image_encoder.blocks.3.attn.lora_B_k.42.weight', 'image_encoder.blocks.7.attn.lora_B_k.42.weight', 'image_encoder.blocks.2.attn.lora_B_k.42.weight', 'image_encoder.blocks.0.attn.lora_B_v.42.weight', 'image_encoder.blocks.6.attn.lora_B_v.42.weight', 'image_encoder.blocks.4.attn.lora_B_v.42.weight', 'image_encoder.blocks.7.attn.lora_B_v.42.weight', 'image_encoder.blocks.4.attn.lora_B_k.42.weight', 'image_encoder.blocks.9.attn.lora_B_v.42.weight', 'image_encoder.blocks.8.attn.lora_B_k.42.weight', 'image_encoder.blocks.11.attn.lora_B_k.42.weight', 'image_encoder.blocks.1.attn.lora_B_k.42.weight', 'image_encoder.blocks.10.attn.lora_B_v.42.weight', 'image_encoder.blocks.0.attn.lora_B_k.42.weight', 'image_encoder.blocks.10.attn.lora_B_k.42.weight', 'image_encoder.blocks.5.attn.lora_B_v.42.weight', 'image_encoder.blocks.2.attn.lora_B_v.42.weight', 'image_encoder.blocks.6.attn.lora_B_k.42.weight', 'image_encoder.blocks.3.attn.lora_B_v.42.weight', 'image_encoder.blocks.8.attn.lora_B_v.42.weight', 'classifier_pool.42.weight'}
2025-12-11 16:27:54,898 [inflora.py] => Task 42, Epoch 20/20 => Loss 0.029, Train_accy 98.80
Threshold:  0.992
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 11/768 type remove
Layer 2 : 36/768 type remove
Layer 3 : 72/768 type remove
Layer 4 : 102/768 type remove
Layer 5 : 137/768 type remove
Layer 6 : 185/768 type remove
Layer 7 : 226/768 type remove
Layer 8 : 311/768 type remove
Layer 9 : 332/768 type remove
Layer 10 : 336/768 type remove
Layer 11 : 223/768 type remove
Layer 12 : 178/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:28:04,847 [trainer.py] => Time:136.95804047584534
8600 8600
8600 8600
2025-12-11 16:28:28,081 [trainer.py] => Time:23.23331093788147
2025-12-11 16:28:28,081 [inflora.py] => Exemplar size: 0
2025-12-11 16:28:28,081 [trainer.py] => CNN: {'total': np.float64(66.97), '00-01': np.float64(84.0), '02-03': np.float64(68.0), '04-05': np.float64(67.5), '06-07': np.float64(47.5), '08-09': np.float64(88.0), '10-11': np.float64(52.5), '12-13': np.float64(76.0), '14-15': np.float64(80.0), '16-17': np.float64(65.0), '18-19': np.float64(71.0), '20-21': np.float64(69.5), '22-23': np.float64(61.5), '24-25': np.float64(63.5), '26-27': np.float64(65.0), '28-29': np.float64(70.5), '30-31': np.float64(73.0), '32-33': np.float64(62.5), '34-35': np.float64(52.5), '36-37': np.float64(63.5), '38-39': np.float64(84.5), '40-41': np.float64(83.5), '42-43': np.float64(25.5), '44-45': np.float64(53.5), '46-47': np.float64(47.0), '48-49': np.float64(65.0), '50-51': np.float64(78.5), '52-53': np.float64(87.0), '54-55': np.float64(66.5), '56-57': np.float64(80.0), '58-59': np.float64(59.0), '60-61': np.float64(73.0), '62-63': np.float64(61.5), '64-65': np.float64(66.0), '66-67': np.float64(53.0), '68-69': np.float64(86.5), '70-71': np.float64(86.0), '72-73': np.float64(22.0), '74-75': np.float64(71.0), '76-77': np.float64(66.5), '78-79': np.float64(73.5), '80-81': np.float64(56.5), '82-83': np.float64(82.5), '84-85': np.float64(70.5), 'old': np.float64(66.88), 'new': np.float64(70.5)}
2025-12-11 16:28:28,081 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4), np.float64(67.21), np.float64(66.97)]
2025-12-11 16:28:28,081 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56), np.float64(99.58), np.float64(99.56)]
2025-12-11 16:28:28,081 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025, 0.6721428571428572, 0.6696511627906977]
2025-12-11 16:28:54,242 [trainer.py] => W-NCM: {'00-01': 96.5, '02-03': 86.0, '04-05': 77.0, '06-07': 93.5, '08-09': 95.0, '10-11': 28.000000000000004, '12-13': 75.0, '14-15': 97.0, '16-17': 89.0, '18-19': 93.0, '20-21': 91.0, '22-23': 77.0, '24-25': 84.5, '26-27': 84.0, '28-29': 92.0, '30-31': 92.0, '32-33': 70.5, '34-35': 89.5, '36-37': 88.5, '38-39': 93.0, '40-41': 92.5, '42-43': 87.5, '44-45': 89.5, '46-47': 70.5, '48-49': 94.5, '50-51': 86.5, '52-53': 86.0, '54-55': 86.5, '56-57': 95.0, '58-59': 87.0, '60-61': 91.0, '62-63': 84.5, '64-65': 88.5, '66-67': 94.0, '68-69': 94.0, '70-71': 92.0, '72-73': 87.5, '74-75': 88.5, '76-77': 95.5, '78-79': 98.0, '80-81': 96.0, '82-83': 98.5, '84-85': 98.0}
2025-12-11 16:28:54,243 [trainer.py] => Ave Acc (W-NCM): 87.76%
2025-12-11 16:28:54,243 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 96.50% (best 100.00%); T2: W-NCM 86.00% (best 100.00%); T3: W-NCM 77.00% (best 100.00%); T4: W-NCM 93.50% (best 98.50%); T5: W-NCM 95.00% (best 100.00%); T6: W-NCM 28.00% (best 100.00%); T7: W-NCM 75.00% (best 99.50%); T8: W-NCM 97.00% (best 98.50%); T9: W-NCM 89.00% (best 99.50%); T10: W-NCM 93.00% (best 99.00%); T11: W-NCM 91.00% (best 99.50%); T12: W-NCM 77.00% (best 99.00%); T13: W-NCM 84.50% (best 98.00%); T14: W-NCM 84.00% (best 99.00%); T15: W-NCM 92.00% (best 97.50%); T16: W-NCM 92.00% (best 98.50%); T17: W-NCM 70.50% (best 98.00%); T18: W-NCM 89.50% (best 99.00%); T19: W-NCM 88.50% (best 99.50%); T20: W-NCM 93.00% (best 99.00%); T21: W-NCM 92.50% (best 98.50%); T22: W-NCM 87.50% (best 96.00%); T23: W-NCM 89.50% (best 95.50%); T24: W-NCM 70.50% (best 100.00%); T25: W-NCM 94.50% (best 99.00%); T26: W-NCM 86.50% (best 99.00%); T27: W-NCM 86.00% (best 100.00%); T28: W-NCM 86.50% (best 98.50%); T29: W-NCM 95.00% (best 98.50%); T30: W-NCM 87.00% (best 96.00%); T31: W-NCM 91.00% (best 98.50%); T32: W-NCM 84.50% (best 97.00%); T33: W-NCM 88.50% (best 95.00%); T34: W-NCM 94.00% (best 99.00%); T35: W-NCM 94.00% (best 99.50%); T36: W-NCM 92.00% (best 98.00%); T37: W-NCM 87.50% (best 93.50%); T38: W-NCM 88.50% (best 96.00%); T39: W-NCM 95.50% (best 98.50%); T40: W-NCM 98.00% (best 98.50%); T41: W-NCM 96.00% (best 96.00%); T42: W-NCM 98.50% (best 98.50%); T43: W-NCM 98.00% (best 98.00%)
2025-12-11 16:28:54,243 [trainer.py] => Average forgetting (W-NCM): 10.85% | Max forgetting (W-NCM): 72.00%
2025-12-11 16:28:54,938 [trainer.py] => All params: 125940251
2025-12-11 16:28:54,944 [trainer.py] => Trainable params: 185858
2025-12-11 16:28:54,944 [inflora.py] => Learning on 86-88
Parameters to be updated: {'image_encoder.blocks.5.attn.lora_B_v.43.weight', 'image_encoder.blocks.4.attn.lora_B_v.43.weight', 'classifier_pool.43.bias', 'image_encoder.blocks.9.attn.lora_B_v.43.weight', 'image_encoder.blocks.8.attn.lora_B_k.43.weight', 'image_encoder.blocks.9.attn.lora_B_k.43.weight', 'image_encoder.blocks.6.attn.lora_B_v.43.weight', 'image_encoder.blocks.6.attn.lora_B_k.43.weight', 'image_encoder.blocks.0.attn.lora_B_v.43.weight', 'image_encoder.blocks.11.attn.lora_B_v.43.weight', 'image_encoder.blocks.3.attn.lora_B_v.43.weight', 'image_encoder.blocks.11.attn.lora_B_k.43.weight', 'image_encoder.blocks.1.attn.lora_B_v.43.weight', 'image_encoder.blocks.0.attn.lora_B_k.43.weight', 'classifier_pool.43.weight', 'image_encoder.blocks.7.attn.lora_B_v.43.weight', 'image_encoder.blocks.1.attn.lora_B_k.43.weight', 'image_encoder.blocks.7.attn.lora_B_k.43.weight', 'image_encoder.blocks.10.attn.lora_B_v.43.weight', 'image_encoder.blocks.4.attn.lora_B_k.43.weight', 'image_encoder.blocks.5.attn.lora_B_k.43.weight', 'image_encoder.blocks.10.attn.lora_B_k.43.weight', 'image_encoder.blocks.2.attn.lora_B_k.43.weight', 'image_encoder.blocks.2.attn.lora_B_v.43.weight', 'image_encoder.blocks.8.attn.lora_B_v.43.weight', 'image_encoder.blocks.3.attn.lora_B_k.43.weight'}
2025-12-11 16:31:02,312 [inflora.py] => Task 43, Epoch 20/20 => Loss 0.048, Train_accy 98.10
Threshold:  0.993
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 11/768 type remove
Layer 2 : 37/768 type remove
Layer 3 : 73/768 type remove
Layer 4 : 105/768 type remove
Layer 5 : 144/768 type remove
Layer 6 : 196/768 type remove
Layer 7 : 245/768 type remove
Layer 8 : 331/768 type remove
Layer 9 : 360/768 type remove
Layer 10 : 361/768 type remove
Layer 11 : 251/768 type remove
Layer 12 : 191/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:31:12,439 [trainer.py] => Time:137.4953010082245
8800 8800
8800 8800
2025-12-11 16:31:36,148 [trainer.py] => Time:23.70824360847473
2025-12-11 16:31:36,148 [inflora.py] => Exemplar size: 0
2025-12-11 16:31:36,148 [trainer.py] => CNN: {'total': np.float64(67.77), '00-01': np.float64(82.5), '02-03': np.float64(68.5), '04-05': np.float64(63.0), '06-07': np.float64(43.5), '08-09': np.float64(90.5), '10-11': np.float64(53.0), '12-13': np.float64(79.0), '14-15': np.float64(80.0), '16-17': np.float64(61.5), '18-19': np.float64(69.5), '20-21': np.float64(69.5), '22-23': np.float64(61.0), '24-25': np.float64(58.5), '26-27': np.float64(66.5), '28-29': np.float64(73.0), '30-31': np.float64(77.5), '32-33': np.float64(64.5), '34-35': np.float64(51.0), '36-37': np.float64(62.0), '38-39': np.float64(88.0), '40-41': np.float64(84.5), '42-43': np.float64(25.0), '44-45': np.float64(56.5), '46-47': np.float64(47.5), '48-49': np.float64(66.5), '50-51': np.float64(81.0), '52-53': np.float64(81.0), '54-55': np.float64(72.0), '56-57': np.float64(82.0), '58-59': np.float64(67.5), '60-61': np.float64(74.5), '62-63': np.float64(61.0), '64-65': np.float64(66.5), '66-67': np.float64(54.5), '68-69': np.float64(89.5), '70-71': np.float64(83.5), '72-73': np.float64(25.5), '74-75': np.float64(72.0), '76-77': np.float64(64.0), '78-79': np.float64(70.5), '80-81': np.float64(60.5), '82-83': np.float64(84.0), '84-85': np.float64(72.0), '86-87': np.float64(78.0), 'old': np.float64(67.53), 'new': np.float64(78.0)}
2025-12-11 16:31:36,148 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4), np.float64(67.21), np.float64(66.97), np.float64(67.77)]
2025-12-11 16:31:36,148 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56), np.float64(99.58), np.float64(99.56), np.float64(99.52)]
2025-12-11 16:31:36,149 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025, 0.6721428571428572, 0.6696511627906977, 0.6777272727272727]
2025-12-11 16:32:02,796 [trainer.py] => W-NCM: {'00-01': 95.5, '02-03': 84.5, '04-05': 75.5, '06-07': 94.5, '08-09': 95.5, '10-11': 31.5, '12-13': 77.5, '14-15': 96.0, '16-17': 88.0, '18-19': 93.5, '20-21': 92.0, '22-23': 76.0, '24-25': 85.5, '26-27': 85.5, '28-29': 93.0, '30-31': 92.5, '32-33': 70.5, '34-35': 88.5, '36-37': 89.0, '38-39': 92.5, '40-41': 91.0, '42-43': 88.0, '44-45': 91.0, '46-47': 67.5, '48-49': 94.0, '50-51': 88.0, '52-53': 88.0, '54-55': 87.0, '56-57': 96.0, '58-59': 86.5, '60-61': 91.0, '62-63': 85.5, '64-65': 89.5, '66-67': 93.5, '68-69': 94.0, '70-71': 92.5, '72-73': 87.0, '74-75': 89.0, '76-77': 95.5, '78-79': 97.0, '80-81': 94.5, '82-83': 98.0, '84-85': 97.0, '86-87': 99.5}
2025-12-11 16:32:02,797 [trainer.py] => Ave Acc (W-NCM): 88.12%
2025-12-11 16:32:02,797 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 95.50% (best 100.00%); T2: W-NCM 84.50% (best 100.00%); T3: W-NCM 75.50% (best 100.00%); T4: W-NCM 94.50% (best 98.50%); T5: W-NCM 95.50% (best 100.00%); T6: W-NCM 31.50% (best 100.00%); T7: W-NCM 77.50% (best 99.50%); T8: W-NCM 96.00% (best 98.50%); T9: W-NCM 88.00% (best 99.50%); T10: W-NCM 93.50% (best 99.00%); T11: W-NCM 92.00% (best 99.50%); T12: W-NCM 76.00% (best 99.00%); T13: W-NCM 85.50% (best 98.00%); T14: W-NCM 85.50% (best 99.00%); T15: W-NCM 93.00% (best 97.50%); T16: W-NCM 92.50% (best 98.50%); T17: W-NCM 70.50% (best 98.00%); T18: W-NCM 88.50% (best 99.00%); T19: W-NCM 89.00% (best 99.50%); T20: W-NCM 92.50% (best 99.00%); T21: W-NCM 91.00% (best 98.50%); T22: W-NCM 88.00% (best 96.00%); T23: W-NCM 91.00% (best 95.50%); T24: W-NCM 67.50% (best 100.00%); T25: W-NCM 94.00% (best 99.00%); T26: W-NCM 88.00% (best 99.00%); T27: W-NCM 88.00% (best 100.00%); T28: W-NCM 87.00% (best 98.50%); T29: W-NCM 96.00% (best 98.50%); T30: W-NCM 86.50% (best 96.00%); T31: W-NCM 91.00% (best 98.50%); T32: W-NCM 85.50% (best 97.00%); T33: W-NCM 89.50% (best 95.00%); T34: W-NCM 93.50% (best 99.00%); T35: W-NCM 94.00% (best 99.50%); T36: W-NCM 92.50% (best 98.00%); T37: W-NCM 87.00% (best 93.50%); T38: W-NCM 89.00% (best 96.00%); T39: W-NCM 95.50% (best 98.50%); T40: W-NCM 97.00% (best 98.50%); T41: W-NCM 94.50% (best 96.00%); T42: W-NCM 98.00% (best 98.50%); T43: W-NCM 97.00% (best 98.00%); T44: W-NCM 99.50% (best 99.50%)
2025-12-11 16:32:02,797 [trainer.py] => Average forgetting (W-NCM): 10.49% | Max forgetting (W-NCM): 68.50%
2025-12-11 16:32:04,527 [trainer.py] => All params: 125940251
2025-12-11 16:32:04,533 [trainer.py] => Trainable params: 185858
2025-12-11 16:32:04,533 [inflora.py] => Learning on 88-90
Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_v.44.weight', 'image_encoder.blocks.7.attn.lora_B_k.44.weight', 'image_encoder.blocks.2.attn.lora_B_k.44.weight', 'image_encoder.blocks.1.attn.lora_B_k.44.weight', 'image_encoder.blocks.4.attn.lora_B_k.44.weight', 'image_encoder.blocks.3.attn.lora_B_k.44.weight', 'image_encoder.blocks.8.attn.lora_B_v.44.weight', 'image_encoder.blocks.2.attn.lora_B_v.44.weight', 'image_encoder.blocks.6.attn.lora_B_v.44.weight', 'image_encoder.blocks.9.attn.lora_B_v.44.weight', 'image_encoder.blocks.8.attn.lora_B_k.44.weight', 'image_encoder.blocks.10.attn.lora_B_k.44.weight', 'image_encoder.blocks.6.attn.lora_B_k.44.weight', 'image_encoder.blocks.11.attn.lora_B_k.44.weight', 'image_encoder.blocks.4.attn.lora_B_v.44.weight', 'image_encoder.blocks.11.attn.lora_B_v.44.weight', 'image_encoder.blocks.3.attn.lora_B_v.44.weight', 'classifier_pool.44.bias', 'image_encoder.blocks.0.attn.lora_B_k.44.weight', 'image_encoder.blocks.7.attn.lora_B_v.44.weight', 'image_encoder.blocks.9.attn.lora_B_k.44.weight', 'image_encoder.blocks.0.attn.lora_B_v.44.weight', 'classifier_pool.44.weight', 'image_encoder.blocks.5.attn.lora_B_k.44.weight', 'image_encoder.blocks.5.attn.lora_B_v.44.weight', 'image_encoder.blocks.1.attn.lora_B_v.44.weight'}
2025-12-11 16:34:11,818 [inflora.py] => Task 44, Epoch 20/20 => Loss 0.042, Train_accy 98.20
Threshold:  0.994
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 11/768 type remove
Layer 2 : 39/768 type remove
Layer 3 : 80/768 type remove
Layer 4 : 116/768 type remove
Layer 5 : 156/768 type remove
Layer 6 : 210/768 type remove
Layer 7 : 253/768 type remove
Layer 8 : 339/768 type remove
Layer 9 : 365/768 type remove
Layer 10 : 369/768 type remove
Layer 11 : 267/768 type remove
Layer 12 : 201/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:34:21,868 [trainer.py] => Time:137.33492946624756
9000 9000
9000 9000
2025-12-11 16:34:46,226 [trainer.py] => Time:24.357091665267944
2025-12-11 16:34:46,226 [inflora.py] => Exemplar size: 0
2025-12-11 16:34:46,226 [trainer.py] => CNN: {'total': np.float64(66.22), '00-01': np.float64(77.0), '02-03': np.float64(63.0), '04-05': np.float64(64.5), '06-07': np.float64(35.5), '08-09': np.float64(86.0), '10-11': np.float64(55.0), '12-13': np.float64(79.0), '14-15': np.float64(83.0), '16-17': np.float64(62.5), '18-19': np.float64(71.0), '20-21': np.float64(72.5), '22-23': np.float64(66.0), '24-25': np.float64(61.5), '26-27': np.float64(69.5), '28-29': np.float64(68.5), '30-31': np.float64(73.5), '32-33': np.float64(60.0), '34-35': np.float64(48.5), '36-37': np.float64(58.0), '38-39': np.float64(89.5), '40-41': np.float64(83.0), '42-43': np.float64(22.0), '44-45': np.float64(54.0), '46-47': np.float64(43.5), '48-49': np.float64(57.0), '50-51': np.float64(76.5), '52-53': np.float64(85.5), '54-55': np.float64(67.5), '56-57': np.float64(79.0), '58-59': np.float64(58.0), '60-61': np.float64(71.0), '62-63': np.float64(60.5), '64-65': np.float64(66.5), '66-67': np.float64(50.5), '68-69': np.float64(87.5), '70-71': np.float64(88.0), '72-73': np.float64(22.5), '74-75': np.float64(70.0), '76-77': np.float64(60.5), '78-79': np.float64(69.5), '80-81': np.float64(56.5), '82-83': np.float64(81.0), '84-85': np.float64(74.5), '86-87': np.float64(78.5), '88-89': np.float64(73.0), 'old': np.float64(66.07), 'new': np.float64(73.0)}
2025-12-11 16:34:46,226 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4), np.float64(67.21), np.float64(66.97), np.float64(67.77), np.float64(66.22)]
2025-12-11 16:34:46,226 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56), np.float64(99.58), np.float64(99.56), np.float64(99.52), np.float64(99.49)]
2025-12-11 16:34:46,226 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025, 0.6721428571428572, 0.6696511627906977, 0.6777272727272727, 0.6622222222222223]
2025-12-11 16:35:13,454 [trainer.py] => W-NCM: {'00-01': 96.0, '02-03': 79.5, '04-05': 76.5, '06-07': 93.5, '08-09': 94.5, '10-11': 31.0, '12-13': 78.0, '14-15': 97.5, '16-17': 87.5, '18-19': 91.5, '20-21': 94.0, '22-23': 76.0, '24-25': 86.0, '26-27': 86.0, '28-29': 92.0, '30-31': 91.5, '32-33': 69.0, '34-35': 87.0, '36-37': 88.0, '38-39': 91.0, '40-41': 88.5, '42-43': 80.0, '44-45': 90.0, '46-47': 69.5, '48-49': 94.0, '50-51': 88.0, '52-53': 87.0, '54-55': 87.0, '56-57': 92.5, '58-59': 85.5, '60-61': 90.0, '62-63': 86.5, '64-65': 87.0, '66-67': 92.5, '68-69': 93.0, '70-71': 94.0, '72-73': 87.5, '74-75': 89.0, '76-77': 94.0, '78-79': 95.0, '80-81': 94.0, '82-83': 97.5, '84-85': 96.5, '86-87': 99.5, '88-89': 98.5}
2025-12-11 16:35:13,454 [trainer.py] => Ave Acc (W-NCM): 87.61%
2025-12-11 16:35:13,454 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 96.00% (best 100.00%); T2: W-NCM 79.50% (best 100.00%); T3: W-NCM 76.50% (best 100.00%); T4: W-NCM 93.50% (best 98.50%); T5: W-NCM 94.50% (best 100.00%); T6: W-NCM 31.00% (best 100.00%); T7: W-NCM 78.00% (best 99.50%); T8: W-NCM 97.50% (best 98.50%); T9: W-NCM 87.50% (best 99.50%); T10: W-NCM 91.50% (best 99.00%); T11: W-NCM 94.00% (best 99.50%); T12: W-NCM 76.00% (best 99.00%); T13: W-NCM 86.00% (best 98.00%); T14: W-NCM 86.00% (best 99.00%); T15: W-NCM 92.00% (best 97.50%); T16: W-NCM 91.50% (best 98.50%); T17: W-NCM 69.00% (best 98.00%); T18: W-NCM 87.00% (best 99.00%); T19: W-NCM 88.00% (best 99.50%); T20: W-NCM 91.00% (best 99.00%); T21: W-NCM 88.50% (best 98.50%); T22: W-NCM 80.00% (best 96.00%); T23: W-NCM 90.00% (best 95.50%); T24: W-NCM 69.50% (best 100.00%); T25: W-NCM 94.00% (best 99.00%); T26: W-NCM 88.00% (best 99.00%); T27: W-NCM 87.00% (best 100.00%); T28: W-NCM 87.00% (best 98.50%); T29: W-NCM 92.50% (best 98.50%); T30: W-NCM 85.50% (best 96.00%); T31: W-NCM 90.00% (best 98.50%); T32: W-NCM 86.50% (best 97.00%); T33: W-NCM 87.00% (best 95.00%); T34: W-NCM 92.50% (best 99.00%); T35: W-NCM 93.00% (best 99.50%); T36: W-NCM 94.00% (best 98.00%); T37: W-NCM 87.50% (best 93.50%); T38: W-NCM 89.00% (best 96.00%); T39: W-NCM 94.00% (best 98.50%); T40: W-NCM 95.00% (best 98.50%); T41: W-NCM 94.00% (best 96.00%); T42: W-NCM 97.50% (best 98.50%); T43: W-NCM 96.50% (best 98.00%); T44: W-NCM 99.50% (best 99.50%); T45: W-NCM 98.50% (best 98.50%)
2025-12-11 16:35:13,454 [trainer.py] => Average forgetting (W-NCM): 11.01% | Max forgetting (W-NCM): 69.00%
2025-12-11 16:35:14,150 [trainer.py] => All params: 125940251
2025-12-11 16:35:14,156 [trainer.py] => Trainable params: 185858
2025-12-11 16:35:14,156 [inflora.py] => Learning on 90-92
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.45.weight', 'image_encoder.blocks.10.attn.lora_B_k.45.weight', 'image_encoder.blocks.2.attn.lora_B_k.45.weight', 'image_encoder.blocks.4.attn.lora_B_k.45.weight', 'classifier_pool.45.bias', 'image_encoder.blocks.3.attn.lora_B_k.45.weight', 'image_encoder.blocks.11.attn.lora_B_k.45.weight', 'classifier_pool.45.weight', 'image_encoder.blocks.5.attn.lora_B_v.45.weight', 'image_encoder.blocks.7.attn.lora_B_k.45.weight', 'image_encoder.blocks.2.attn.lora_B_v.45.weight', 'image_encoder.blocks.11.attn.lora_B_v.45.weight', 'image_encoder.blocks.8.attn.lora_B_v.45.weight', 'image_encoder.blocks.5.attn.lora_B_k.45.weight', 'image_encoder.blocks.1.attn.lora_B_v.45.weight', 'image_encoder.blocks.7.attn.lora_B_v.45.weight', 'image_encoder.blocks.1.attn.lora_B_k.45.weight', 'image_encoder.blocks.10.attn.lora_B_v.45.weight', 'image_encoder.blocks.6.attn.lora_B_k.45.weight', 'image_encoder.blocks.0.attn.lora_B_k.45.weight', 'image_encoder.blocks.3.attn.lora_B_v.45.weight', 'image_encoder.blocks.8.attn.lora_B_k.45.weight', 'image_encoder.blocks.6.attn.lora_B_v.45.weight', 'image_encoder.blocks.9.attn.lora_B_k.45.weight', 'image_encoder.blocks.0.attn.lora_B_v.45.weight', 'image_encoder.blocks.9.attn.lora_B_v.45.weight'}
2025-12-11 16:37:21,454 [inflora.py] => Task 45, Epoch 20/20 => Loss 0.039, Train_accy 98.70
Threshold:  0.995
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 11/768 type remove
Layer 2 : 40/768 type remove
Layer 3 : 82/768 type remove
Layer 4 : 122/768 type remove
Layer 5 : 166/768 type remove
Layer 6 : 224/768 type remove
Layer 7 : 269/768 type remove
Layer 8 : 352/768 type remove
Layer 9 : 377/768 type remove
Layer 10 : 379/768 type retain
Layer 11 : 285/768 type remove
Layer 12 : 217/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:37:31,503 [trainer.py] => Time:137.34731721878052
9200 9200
9200 9200
2025-12-11 16:37:56,351 [trainer.py] => Time:24.847299575805664
2025-12-11 16:37:56,351 [inflora.py] => Exemplar size: 0
2025-12-11 16:37:56,351 [trainer.py] => CNN: {'total': np.float64(65.59), '00-01': np.float64(77.5), '02-03': np.float64(63.0), '04-05': np.float64(52.0), '06-07': np.float64(36.0), '08-09': np.float64(87.5), '10-11': np.float64(55.0), '12-13': np.float64(58.5), '14-15': np.float64(84.5), '16-17': np.float64(68.5), '18-19': np.float64(68.0), '20-21': np.float64(72.0), '22-23': np.float64(63.5), '24-25': np.float64(69.0), '26-27': np.float64(64.0), '28-29': np.float64(68.5), '30-31': np.float64(66.5), '32-33': np.float64(60.0), '34-35': np.float64(46.5), '36-37': np.float64(58.5), '38-39': np.float64(86.5), '40-41': np.float64(84.0), '42-43': np.float64(19.5), '44-45': np.float64(55.5), '46-47': np.float64(42.5), '48-49': np.float64(51.5), '50-51': np.float64(80.0), '52-53': np.float64(86.5), '54-55': np.float64(79.0), '56-57': np.float64(76.5), '58-59': np.float64(59.0), '60-61': np.float64(72.5), '62-63': np.float64(55.0), '64-65': np.float64(63.0), '66-67': np.float64(50.5), '68-69': np.float64(81.5), '70-71': np.float64(89.5), '72-73': np.float64(18.5), '74-75': np.float64(70.5), '76-77': np.float64(64.5), '78-79': np.float64(68.5), '80-81': np.float64(51.0), '82-83': np.float64(83.0), '84-85': np.float64(80.5), '86-87': np.float64(77.5), '88-89': np.float64(61.5), '90-91': np.float64(90.0), 'old': np.float64(65.04), 'new': np.float64(90.0)}
2025-12-11 16:37:56,351 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4), np.float64(67.21), np.float64(66.97), np.float64(67.77), np.float64(66.22), np.float64(65.59)]
2025-12-11 16:37:56,352 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56), np.float64(99.58), np.float64(99.56), np.float64(99.52), np.float64(99.49), np.float64(99.52)]
2025-12-11 16:37:56,352 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025, 0.6721428571428572, 0.6696511627906977, 0.6777272727272727, 0.6622222222222223, 0.6559782608695652]
2025-12-11 16:38:24,170 [trainer.py] => W-NCM: {'00-01': 93.5, '02-03': 77.5, '04-05': 77.5, '06-07': 92.0, '08-09': 93.0, '10-11': 21.5, '12-13': 67.5, '14-15': 96.0, '16-17': 86.0, '18-19': 89.0, '20-21': 91.0, '22-23': 72.5, '24-25': 88.5, '26-27': 87.5, '28-29': 93.0, '30-31': 94.0, '32-33': 61.0, '34-35': 88.0, '36-37': 84.0, '38-39': 89.0, '40-41': 85.0, '42-43': 79.5, '44-45': 89.0, '46-47': 65.0, '48-49': 93.5, '50-51': 89.5, '52-53': 89.0, '54-55': 89.0, '56-57': 92.0, '58-59': 86.0, '60-61': 90.0, '62-63': 84.0, '64-65': 84.0, '66-67': 92.0, '68-69': 88.5, '70-71': 90.0, '72-73': 82.5, '74-75': 88.5, '76-77': 94.5, '78-79': 94.0, '80-81': 83.0, '82-83': 96.5, '84-85': 96.5, '86-87': 99.5, '88-89': 97.5, '90-91': 98.5}
2025-12-11 16:38:24,170 [trainer.py] => Ave Acc (W-NCM): 86.07%
2025-12-11 16:38:24,170 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 93.50% (best 100.00%); T2: W-NCM 77.50% (best 100.00%); T3: W-NCM 77.50% (best 100.00%); T4: W-NCM 92.00% (best 98.50%); T5: W-NCM 93.00% (best 100.00%); T6: W-NCM 21.50% (best 100.00%); T7: W-NCM 67.50% (best 99.50%); T8: W-NCM 96.00% (best 98.50%); T9: W-NCM 86.00% (best 99.50%); T10: W-NCM 89.00% (best 99.00%); T11: W-NCM 91.00% (best 99.50%); T12: W-NCM 72.50% (best 99.00%); T13: W-NCM 88.50% (best 98.00%); T14: W-NCM 87.50% (best 99.00%); T15: W-NCM 93.00% (best 97.50%); T16: W-NCM 94.00% (best 98.50%); T17: W-NCM 61.00% (best 98.00%); T18: W-NCM 88.00% (best 99.00%); T19: W-NCM 84.00% (best 99.50%); T20: W-NCM 89.00% (best 99.00%); T21: W-NCM 85.00% (best 98.50%); T22: W-NCM 79.50% (best 96.00%); T23: W-NCM 89.00% (best 95.50%); T24: W-NCM 65.00% (best 100.00%); T25: W-NCM 93.50% (best 99.00%); T26: W-NCM 89.50% (best 99.00%); T27: W-NCM 89.00% (best 100.00%); T28: W-NCM 89.00% (best 98.50%); T29: W-NCM 92.00% (best 98.50%); T30: W-NCM 86.00% (best 96.00%); T31: W-NCM 90.00% (best 98.50%); T32: W-NCM 84.00% (best 97.00%); T33: W-NCM 84.00% (best 95.00%); T34: W-NCM 92.00% (best 99.00%); T35: W-NCM 88.50% (best 99.50%); T36: W-NCM 90.00% (best 98.00%); T37: W-NCM 82.50% (best 93.50%); T38: W-NCM 88.50% (best 96.00%); T39: W-NCM 94.50% (best 98.50%); T40: W-NCM 94.00% (best 98.50%); T41: W-NCM 83.00% (best 96.00%); T42: W-NCM 96.50% (best 98.50%); T43: W-NCM 96.50% (best 98.00%); T44: W-NCM 99.50% (best 99.50%); T45: W-NCM 97.50% (best 98.50%); T46: W-NCM 98.50% (best 98.50%)
2025-12-11 16:38:24,170 [trainer.py] => Average forgetting (W-NCM): 12.59% | Max forgetting (W-NCM): 78.50%
2025-12-11 16:38:24,859 [trainer.py] => All params: 125940251
2025-12-11 16:38:24,865 [trainer.py] => Trainable params: 185858
2025-12-11 16:38:24,865 [inflora.py] => Learning on 92-94
Parameters to be updated: {'classifier_pool.46.weight', 'image_encoder.blocks.6.attn.lora_B_v.46.weight', 'image_encoder.blocks.5.attn.lora_B_v.46.weight', 'image_encoder.blocks.11.attn.lora_B_v.46.weight', 'image_encoder.blocks.1.attn.lora_B_v.46.weight', 'image_encoder.blocks.1.attn.lora_B_k.46.weight', 'image_encoder.blocks.10.attn.lora_B_v.46.weight', 'image_encoder.blocks.2.attn.lora_B_v.46.weight', 'image_encoder.blocks.6.attn.lora_B_k.46.weight', 'image_encoder.blocks.8.attn.lora_B_v.46.weight', 'image_encoder.blocks.10.attn.lora_B_k.46.weight', 'image_encoder.blocks.9.attn.lora_B_v.46.weight', 'image_encoder.blocks.9.attn.lora_B_k.46.weight', 'image_encoder.blocks.4.attn.lora_B_k.46.weight', 'image_encoder.blocks.11.attn.lora_B_k.46.weight', 'classifier_pool.46.bias', 'image_encoder.blocks.3.attn.lora_B_v.46.weight', 'image_encoder.blocks.5.attn.lora_B_k.46.weight', 'image_encoder.blocks.8.attn.lora_B_k.46.weight', 'image_encoder.blocks.4.attn.lora_B_v.46.weight', 'image_encoder.blocks.7.attn.lora_B_k.46.weight', 'image_encoder.blocks.0.attn.lora_B_v.46.weight', 'image_encoder.blocks.3.attn.lora_B_k.46.weight', 'image_encoder.blocks.2.attn.lora_B_k.46.weight', 'image_encoder.blocks.7.attn.lora_B_v.46.weight', 'image_encoder.blocks.0.attn.lora_B_k.46.weight'}
2025-12-11 16:40:32,398 [inflora.py] => Task 46, Epoch 20/20 => Loss 0.012, Train_accy 99.30
Threshold:  0.996
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 44/768 type remove
Layer 3 : 88/768 type remove
Layer 4 : 133/768 type remove
Layer 5 : 182/768 type remove
Layer 6 : 243/768 type remove
Layer 7 : 295/768 type remove
Layer 8 : 383/768 type retain
Layer 9 : 354/768 type retain
Layer 10 : 333/768 type retain
Layer 11 : 338/768 type remove
Layer 12 : 268/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:40:42,645 [trainer.py] => Time:137.78052639961243
9400 9400
9400 9400
2025-12-11 16:41:08,079 [trainer.py] => Time:25.43282985687256
2025-12-11 16:41:08,079 [inflora.py] => Exemplar size: 0
2025-12-11 16:41:08,079 [trainer.py] => CNN: {'total': np.float64(65.13), '00-01': np.float64(70.0), '02-03': np.float64(66.5), '04-05': np.float64(58.5), '06-07': np.float64(38.5), '08-09': np.float64(86.0), '10-11': np.float64(54.0), '12-13': np.float64(66.5), '14-15': np.float64(78.5), '16-17': np.float64(62.0), '18-19': np.float64(68.5), '20-21': np.float64(66.5), '22-23': np.float64(67.5), '24-25': np.float64(65.0), '26-27': np.float64(67.5), '28-29': np.float64(71.0), '30-31': np.float64(72.0), '32-33': np.float64(58.0), '34-35': np.float64(46.5), '36-37': np.float64(58.0), '38-39': np.float64(89.0), '40-41': np.float64(84.5), '42-43': np.float64(17.5), '44-45': np.float64(50.5), '46-47': np.float64(45.0), '48-49': np.float64(62.0), '50-51': np.float64(74.0), '52-53': np.float64(88.0), '54-55': np.float64(68.0), '56-57': np.float64(75.5), '58-59': np.float64(51.0), '60-61': np.float64(69.5), '62-63': np.float64(59.5), '64-65': np.float64(66.5), '66-67': np.float64(45.0), '68-69': np.float64(85.5), '70-71': np.float64(84.0), '72-73': np.float64(21.5), '74-75': np.float64(68.0), '76-77': np.float64(63.5), '78-79': np.float64(68.5), '80-81': np.float64(51.5), '82-83': np.float64(80.0), '84-85': np.float64(77.5), '86-87': np.float64(80.5), '88-89': np.float64(66.0), '90-91': np.float64(89.0), '92-93': np.float64(59.0), 'old': np.float64(65.26), 'new': np.float64(59.0)}
2025-12-11 16:41:08,079 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4), np.float64(67.21), np.float64(66.97), np.float64(67.77), np.float64(66.22), np.float64(65.59), np.float64(65.13)]
2025-12-11 16:41:08,079 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56), np.float64(99.58), np.float64(99.56), np.float64(99.52), np.float64(99.49), np.float64(99.52), np.float64(99.54)]
2025-12-11 16:41:08,079 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025, 0.6721428571428572, 0.6696511627906977, 0.6777272727272727, 0.6622222222222223, 0.6559782608695652, 0.6512765957446809]
2025-12-11 16:41:36,495 [trainer.py] => W-NCM: {'00-01': 94.5, '02-03': 79.5, '04-05': 79.0, '06-07': 92.0, '08-09': 94.0, '10-11': 27.0, '12-13': 72.5, '14-15': 96.0, '16-17': 88.5, '18-19': 92.0, '20-21': 93.0, '22-23': 77.0, '24-25': 87.5, '26-27': 85.0, '28-29': 91.0, '30-31': 93.0, '32-33': 65.5, '34-35': 88.0, '36-37': 87.5, '38-39': 90.5, '40-41': 90.0, '42-43': 83.5, '44-45': 90.5, '46-47': 71.0, '48-49': 94.0, '50-51': 85.0, '52-53': 84.5, '54-55': 85.0, '56-57': 94.5, '58-59': 86.0, '60-61': 88.0, '62-63': 80.5, '64-65': 87.5, '66-67': 89.0, '68-69': 92.0, '70-71': 85.5, '72-73': 81.0, '74-75': 89.5, '76-77': 93.5, '78-79': 94.5, '80-81': 85.5, '82-83': 96.5, '84-85': 96.0, '86-87': 99.0, '88-89': 97.5, '90-91': 96.5, '92-93': 97.5}
2025-12-11 16:41:36,496 [trainer.py] => Ave Acc (W-NCM): 86.95%
2025-12-11 16:41:36,496 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 94.50% (best 100.00%); T2: W-NCM 79.50% (best 100.00%); T3: W-NCM 79.00% (best 100.00%); T4: W-NCM 92.00% (best 98.50%); T5: W-NCM 94.00% (best 100.00%); T6: W-NCM 27.00% (best 100.00%); T7: W-NCM 72.50% (best 99.50%); T8: W-NCM 96.00% (best 98.50%); T9: W-NCM 88.50% (best 99.50%); T10: W-NCM 92.00% (best 99.00%); T11: W-NCM 93.00% (best 99.50%); T12: W-NCM 77.00% (best 99.00%); T13: W-NCM 87.50% (best 98.00%); T14: W-NCM 85.00% (best 99.00%); T15: W-NCM 91.00% (best 97.50%); T16: W-NCM 93.00% (best 98.50%); T17: W-NCM 65.50% (best 98.00%); T18: W-NCM 88.00% (best 99.00%); T19: W-NCM 87.50% (best 99.50%); T20: W-NCM 90.50% (best 99.00%); T21: W-NCM 90.00% (best 98.50%); T22: W-NCM 83.50% (best 96.00%); T23: W-NCM 90.50% (best 95.50%); T24: W-NCM 71.00% (best 100.00%); T25: W-NCM 94.00% (best 99.00%); T26: W-NCM 85.00% (best 99.00%); T27: W-NCM 84.50% (best 100.00%); T28: W-NCM 85.00% (best 98.50%); T29: W-NCM 94.50% (best 98.50%); T30: W-NCM 86.00% (best 96.00%); T31: W-NCM 88.00% (best 98.50%); T32: W-NCM 80.50% (best 97.00%); T33: W-NCM 87.50% (best 95.00%); T34: W-NCM 89.00% (best 99.00%); T35: W-NCM 92.00% (best 99.50%); T36: W-NCM 85.50% (best 98.00%); T37: W-NCM 81.00% (best 93.50%); T38: W-NCM 89.50% (best 96.00%); T39: W-NCM 93.50% (best 98.50%); T40: W-NCM 94.50% (best 98.50%); T41: W-NCM 85.50% (best 96.00%); T42: W-NCM 96.50% (best 98.50%); T43: W-NCM 96.00% (best 98.00%); T44: W-NCM 99.00% (best 99.50%); T45: W-NCM 97.50% (best 98.50%); T46: W-NCM 96.50% (best 98.50%); T47: W-NCM 97.50% (best 97.50%)
2025-12-11 16:41:36,496 [trainer.py] => Average forgetting (W-NCM): 11.66% | Max forgetting (W-NCM): 73.00%
2025-12-11 16:41:37,192 [trainer.py] => All params: 125940251
2025-12-11 16:41:37,198 [trainer.py] => Trainable params: 185858
2025-12-11 16:41:37,198 [inflora.py] => Learning on 94-96
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.47.weight', 'image_encoder.blocks.6.attn.lora_B_v.47.weight', 'image_encoder.blocks.8.attn.lora_B_v.47.weight', 'image_encoder.blocks.0.attn.lora_B_v.47.weight', 'image_encoder.blocks.3.attn.lora_B_k.47.weight', 'classifier_pool.47.weight', 'image_encoder.blocks.7.attn.lora_B_k.47.weight', 'image_encoder.blocks.2.attn.lora_B_k.47.weight', 'image_encoder.blocks.3.attn.lora_B_v.47.weight', 'image_encoder.blocks.11.attn.lora_B_k.47.weight', 'image_encoder.blocks.10.attn.lora_B_k.47.weight', 'classifier_pool.47.bias', 'image_encoder.blocks.8.attn.lora_B_k.47.weight', 'image_encoder.blocks.4.attn.lora_B_k.47.weight', 'image_encoder.blocks.0.attn.lora_B_k.47.weight', 'image_encoder.blocks.10.attn.lora_B_v.47.weight', 'image_encoder.blocks.11.attn.lora_B_v.47.weight', 'image_encoder.blocks.9.attn.lora_B_k.47.weight', 'image_encoder.blocks.6.attn.lora_B_k.47.weight', 'image_encoder.blocks.2.attn.lora_B_v.47.weight', 'image_encoder.blocks.1.attn.lora_B_k.47.weight', 'image_encoder.blocks.9.attn.lora_B_v.47.weight', 'image_encoder.blocks.1.attn.lora_B_v.47.weight', 'image_encoder.blocks.5.attn.lora_B_v.47.weight', 'image_encoder.blocks.5.attn.lora_B_k.47.weight', 'image_encoder.blocks.7.attn.lora_B_v.47.weight'}
2025-12-11 16:43:44,797 [inflora.py] => Task 47, Epoch 20/20 => Loss 0.011, Train_accy 99.70
Threshold:  0.997
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 12/768 type remove
Layer 2 : 46/768 type remove
Layer 3 : 90/768 type remove
Layer 4 : 142/768 type remove
Layer 5 : 195/768 type remove
Layer 6 : 268/768 type remove
Layer 7 : 329/768 type remove
Layer 8 : 345/768 type retain
Layer 9 : 310/768 type retain
Layer 10 : 292/768 type retain
Layer 11 : 381/768 type remove
Layer 12 : 319/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:43:55,049 [trainer.py] => Time:137.85074758529663
9600 9600
9600 9600
2025-12-11 16:44:20,972 [trainer.py] => Time:25.92318344116211
2025-12-11 16:44:20,972 [inflora.py] => Exemplar size: 0
2025-12-11 16:44:20,972 [trainer.py] => CNN: {'total': np.float64(63.03), '00-01': np.float64(66.5), '02-03': np.float64(63.0), '04-05': np.float64(54.0), '06-07': np.float64(34.0), '08-09': np.float64(87.5), '10-11': np.float64(50.0), '12-13': np.float64(67.5), '14-15': np.float64(80.0), '16-17': np.float64(60.5), '18-19': np.float64(65.5), '20-21': np.float64(65.0), '22-23': np.float64(70.0), '24-25': np.float64(63.0), '26-27': np.float64(66.0), '28-29': np.float64(66.0), '30-31': np.float64(60.5), '32-33': np.float64(55.5), '34-35': np.float64(47.0), '36-37': np.float64(58.0), '38-39': np.float64(86.5), '40-41': np.float64(84.5), '42-43': np.float64(14.0), '44-45': np.float64(44.5), '46-47': np.float64(39.5), '48-49': np.float64(65.0), '50-51': np.float64(70.5), '52-53': np.float64(85.0), '54-55': np.float64(65.5), '56-57': np.float64(70.0), '58-59': np.float64(49.5), '60-61': np.float64(71.0), '62-63': np.float64(60.5), '64-65': np.float64(66.5), '66-67': np.float64(45.0), '68-69': np.float64(83.5), '70-71': np.float64(84.0), '72-73': np.float64(17.5), '74-75': np.float64(61.0), '76-77': np.float64(63.5), '78-79': np.float64(75.5), '80-81': np.float64(51.0), '82-83': np.float64(80.5), '84-85': np.float64(75.5), '86-87': np.float64(79.5), '88-89': np.float64(69.5), '90-91': np.float64(88.0), '92-93': np.float64(54.0), '94-95': np.float64(45.5), 'old': np.float64(63.4), 'new': np.float64(45.5)}
2025-12-11 16:44:20,972 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4), np.float64(67.21), np.float64(66.97), np.float64(67.77), np.float64(66.22), np.float64(65.59), np.float64(65.13), np.float64(63.03)]
2025-12-11 16:44:20,973 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56), np.float64(99.58), np.float64(99.56), np.float64(99.52), np.float64(99.49), np.float64(99.52), np.float64(99.54), np.float64(99.52)]
2025-12-11 16:44:20,973 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025, 0.6721428571428572, 0.6696511627906977, 0.6777272727272727, 0.6622222222222223, 0.6559782608695652, 0.6512765957446809, 0.6303125]
2025-12-11 16:44:49,784 [trainer.py] => W-NCM: {'00-01': 94.5, '02-03': 79.0, '04-05': 78.5, '06-07': 91.5, '08-09': 93.5, '10-11': 25.0, '12-13': 70.5, '14-15': 96.5, '16-17': 88.0, '18-19': 91.0, '20-21': 87.5, '22-23': 80.5, '24-25': 85.0, '26-27': 88.0, '28-29': 87.5, '30-31': 78.0, '32-33': 66.0, '34-35': 90.0, '36-37': 85.5, '38-39': 89.5, '40-41': 88.5, '42-43': 82.5, '44-45': 88.5, '46-47': 69.5, '48-49': 93.5, '50-51': 83.5, '52-53': 84.5, '54-55': 81.0, '56-57': 94.0, '58-59': 83.0, '60-61': 87.5, '62-63': 81.5, '64-65': 87.0, '66-67': 88.5, '68-69': 91.5, '70-71': 82.5, '72-73': 74.5, '74-75': 92.0, '76-77': 93.0, '78-79': 95.0, '80-81': 84.5, '82-83': 96.5, '84-85': 94.0, '86-87': 95.5, '88-89': 97.0, '90-91': 96.5, '92-93': 97.5, '94-95': 98.5}
2025-12-11 16:44:49,784 [trainer.py] => Ave Acc (W-NCM): 85.98%
2025-12-11 16:44:49,785 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 94.50% (best 100.00%); T2: W-NCM 79.00% (best 100.00%); T3: W-NCM 78.50% (best 100.00%); T4: W-NCM 91.50% (best 98.50%); T5: W-NCM 93.50% (best 100.00%); T6: W-NCM 25.00% (best 100.00%); T7: W-NCM 70.50% (best 99.50%); T8: W-NCM 96.50% (best 98.50%); T9: W-NCM 88.00% (best 99.50%); T10: W-NCM 91.00% (best 99.00%); T11: W-NCM 87.50% (best 99.50%); T12: W-NCM 80.50% (best 99.00%); T13: W-NCM 85.00% (best 98.00%); T14: W-NCM 88.00% (best 99.00%); T15: W-NCM 87.50% (best 97.50%); T16: W-NCM 78.00% (best 98.50%); T17: W-NCM 66.00% (best 98.00%); T18: W-NCM 90.00% (best 99.00%); T19: W-NCM 85.50% (best 99.50%); T20: W-NCM 89.50% (best 99.00%); T21: W-NCM 88.50% (best 98.50%); T22: W-NCM 82.50% (best 96.00%); T23: W-NCM 88.50% (best 95.50%); T24: W-NCM 69.50% (best 100.00%); T25: W-NCM 93.50% (best 99.00%); T26: W-NCM 83.50% (best 99.00%); T27: W-NCM 84.50% (best 100.00%); T28: W-NCM 81.00% (best 98.50%); T29: W-NCM 94.00% (best 98.50%); T30: W-NCM 83.00% (best 96.00%); T31: W-NCM 87.50% (best 98.50%); T32: W-NCM 81.50% (best 97.00%); T33: W-NCM 87.00% (best 95.00%); T34: W-NCM 88.50% (best 99.00%); T35: W-NCM 91.50% (best 99.50%); T36: W-NCM 82.50% (best 98.00%); T37: W-NCM 74.50% (best 93.50%); T38: W-NCM 92.00% (best 96.00%); T39: W-NCM 93.00% (best 98.50%); T40: W-NCM 95.00% (best 98.50%); T41: W-NCM 84.50% (best 96.00%); T42: W-NCM 96.50% (best 98.50%); T43: W-NCM 94.00% (best 98.00%); T44: W-NCM 95.50% (best 99.50%); T45: W-NCM 97.00% (best 98.50%); T46: W-NCM 96.50% (best 98.50%); T47: W-NCM 97.50% (best 97.50%); T48: W-NCM 98.50% (best 98.50%)
2025-12-11 16:44:49,785 [trainer.py] => Average forgetting (W-NCM): 12.65% | Max forgetting (W-NCM): 75.00%
2025-12-11 16:44:50,473 [trainer.py] => All params: 125940251
2025-12-11 16:44:50,479 [trainer.py] => Trainable params: 185858
2025-12-11 16:44:50,479 [inflora.py] => Learning on 96-98
Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_k.48.weight', 'image_encoder.blocks.6.attn.lora_B_v.48.weight', 'image_encoder.blocks.3.attn.lora_B_v.48.weight', 'image_encoder.blocks.10.attn.lora_B_v.48.weight', 'image_encoder.blocks.4.attn.lora_B_k.48.weight', 'image_encoder.blocks.9.attn.lora_B_v.48.weight', 'image_encoder.blocks.0.attn.lora_B_k.48.weight', 'image_encoder.blocks.8.attn.lora_B_v.48.weight', 'classifier_pool.48.bias', 'image_encoder.blocks.5.attn.lora_B_k.48.weight', 'image_encoder.blocks.1.attn.lora_B_v.48.weight', 'image_encoder.blocks.7.attn.lora_B_k.48.weight', 'classifier_pool.48.weight', 'image_encoder.blocks.0.attn.lora_B_v.48.weight', 'image_encoder.blocks.2.attn.lora_B_v.48.weight', 'image_encoder.blocks.8.attn.lora_B_k.48.weight', 'image_encoder.blocks.11.attn.lora_B_v.48.weight', 'image_encoder.blocks.6.attn.lora_B_k.48.weight', 'image_encoder.blocks.7.attn.lora_B_v.48.weight', 'image_encoder.blocks.11.attn.lora_B_k.48.weight', 'image_encoder.blocks.2.attn.lora_B_k.48.weight', 'image_encoder.blocks.3.attn.lora_B_k.48.weight', 'image_encoder.blocks.10.attn.lora_B_k.48.weight', 'image_encoder.blocks.1.attn.lora_B_k.48.weight', 'image_encoder.blocks.4.attn.lora_B_v.48.weight', 'image_encoder.blocks.5.attn.lora_B_v.48.weight'}
2025-12-11 16:46:58,002 [inflora.py] => Task 48, Epoch 20/20 => Loss 0.029, Train_accy 98.70
Threshold:  0.998
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 13/768 type remove
Layer 2 : 49/768 type remove
Layer 3 : 98/768 type remove
Layer 4 : 159/768 type remove
Layer 5 : 219/768 type remove
Layer 6 : 300/768 type remove
Layer 7 : 361/768 type remove
Layer 8 : 310/768 type retain
Layer 9 : 280/768 type retain
Layer 10 : 256/768 type retain
Layer 11 : 347/768 type retain
Layer 12 : 364/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:47:08,309 [trainer.py] => Time:137.82939338684082
9800 9800
9800 9800
2025-12-11 16:47:34,803 [trainer.py] => Time:26.493751049041748
2025-12-11 16:47:34,803 [inflora.py] => Exemplar size: 0
2025-12-11 16:47:34,803 [trainer.py] => CNN: {'total': np.float64(61.72), '00-01': np.float64(66.0), '02-03': np.float64(68.5), '04-05': np.float64(49.5), '06-07': np.float64(34.5), '08-09': np.float64(86.5), '10-11': np.float64(49.0), '12-13': np.float64(66.0), '14-15': np.float64(77.0), '16-17': np.float64(56.0), '18-19': np.float64(67.0), '20-21': np.float64(59.0), '22-23': np.float64(65.5), '24-25': np.float64(69.0), '26-27': np.float64(65.0), '28-29': np.float64(74.5), '30-31': np.float64(69.0), '32-33': np.float64(54.5), '34-35': np.float64(48.0), '36-37': np.float64(58.0), '38-39': np.float64(85.0), '40-41': np.float64(82.5), '42-43': np.float64(14.5), '44-45': np.float64(45.5), '46-47': np.float64(40.5), '48-49': np.float64(69.0), '50-51': np.float64(70.0), '52-53': np.float64(77.5), '54-55': np.float64(65.0), '56-57': np.float64(72.0), '58-59': np.float64(52.0), '60-61': np.float64(68.0), '62-63': np.float64(60.5), '64-65': np.float64(63.5), '66-67': np.float64(46.0), '68-69': np.float64(77.5), '70-71': np.float64(88.0), '72-73': np.float64(14.5), '74-75': np.float64(62.0), '76-77': np.float64(66.5), '78-79': np.float64(76.5), '80-81': np.float64(51.0), '82-83': np.float64(78.5), '84-85': np.float64(73.0), '86-87': np.float64(71.5), '88-89': np.float64(72.0), '90-91': np.float64(88.0), '92-93': np.float64(53.5), '94-95': np.float64(45.0), '96-97': np.float64(13.0), 'old': np.float64(62.74), 'new': np.float64(13.0)}
2025-12-11 16:47:34,803 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4), np.float64(67.21), np.float64(66.97), np.float64(67.77), np.float64(66.22), np.float64(65.59), np.float64(65.13), np.float64(63.03), np.float64(61.72)]
2025-12-11 16:47:34,803 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56), np.float64(99.58), np.float64(99.56), np.float64(99.52), np.float64(99.49), np.float64(99.52), np.float64(99.54), np.float64(99.52), np.float64(99.56)]
2025-12-11 16:47:34,803 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025, 0.6721428571428572, 0.6696511627906977, 0.6777272727272727, 0.6622222222222223, 0.6559782608695652, 0.6512765957446809, 0.6303125, 0.6172448979591837]
2025-12-11 16:48:04,186 [trainer.py] => W-NCM: {'00-01': 95.5, '02-03': 76.0, '04-05': 76.5, '06-07': 92.0, '08-09': 94.5, '10-11': 27.0, '12-13': 66.0, '14-15': 97.0, '16-17': 86.5, '18-19': 89.0, '20-21': 88.0, '22-23': 75.5, '24-25': 86.5, '26-27': 86.5, '28-29': 88.5, '30-31': 79.5, '32-33': 52.5, '34-35': 89.0, '36-37': 83.5, '38-39': 85.5, '40-41': 88.0, '42-43': 79.0, '44-45': 90.0, '46-47': 57.99999999999999, '48-49': 91.0, '50-51': 86.0, '52-53': 54.0, '54-55': 82.0, '56-57': 92.5, '58-59': 69.5, '60-61': 78.0, '62-63': 84.0, '64-65': 85.0, '66-67': 85.5, '68-69': 85.5, '70-71': 80.5, '72-73': 72.5, '74-75': 88.5, '76-77': 94.5, '78-79': 95.5, '80-81': 83.5, '82-83': 96.0, '84-85': 94.5, '86-87': 94.5, '88-89': 97.0, '90-91': 96.5, '92-93': 96.5, '94-95': 98.0, '96-97': 97.0}
2025-12-11 16:48:04,187 [trainer.py] => Ave Acc (W-NCM): 83.84%
2025-12-11 16:48:04,187 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 95.50% (best 100.00%); T2: W-NCM 76.00% (best 100.00%); T3: W-NCM 76.50% (best 100.00%); T4: W-NCM 92.00% (best 98.50%); T5: W-NCM 94.50% (best 100.00%); T6: W-NCM 27.00% (best 100.00%); T7: W-NCM 66.00% (best 99.50%); T8: W-NCM 97.00% (best 98.50%); T9: W-NCM 86.50% (best 99.50%); T10: W-NCM 89.00% (best 99.00%); T11: W-NCM 88.00% (best 99.50%); T12: W-NCM 75.50% (best 99.00%); T13: W-NCM 86.50% (best 98.00%); T14: W-NCM 86.50% (best 99.00%); T15: W-NCM 88.50% (best 97.50%); T16: W-NCM 79.50% (best 98.50%); T17: W-NCM 52.50% (best 98.00%); T18: W-NCM 89.00% (best 99.00%); T19: W-NCM 83.50% (best 99.50%); T20: W-NCM 85.50% (best 99.00%); T21: W-NCM 88.00% (best 98.50%); T22: W-NCM 79.00% (best 96.00%); T23: W-NCM 90.00% (best 95.50%); T24: W-NCM 58.00% (best 100.00%); T25: W-NCM 91.00% (best 99.00%); T26: W-NCM 86.00% (best 99.00%); T27: W-NCM 54.00% (best 100.00%); T28: W-NCM 82.00% (best 98.50%); T29: W-NCM 92.50% (best 98.50%); T30: W-NCM 69.50% (best 96.00%); T31: W-NCM 78.00% (best 98.50%); T32: W-NCM 84.00% (best 97.00%); T33: W-NCM 85.00% (best 95.00%); T34: W-NCM 85.50% (best 99.00%); T35: W-NCM 85.50% (best 99.50%); T36: W-NCM 80.50% (best 98.00%); T37: W-NCM 72.50% (best 93.50%); T38: W-NCM 88.50% (best 96.00%); T39: W-NCM 94.50% (best 98.50%); T40: W-NCM 95.50% (best 98.50%); T41: W-NCM 83.50% (best 96.00%); T42: W-NCM 96.00% (best 98.50%); T43: W-NCM 94.50% (best 98.00%); T44: W-NCM 94.50% (best 99.50%); T45: W-NCM 97.00% (best 98.50%); T46: W-NCM 96.50% (best 98.50%); T47: W-NCM 96.50% (best 97.50%); T48: W-NCM 98.00% (best 98.50%); T49: W-NCM 97.00% (best 97.00%)
2025-12-11 16:48:04,187 [trainer.py] => Average forgetting (W-NCM): 14.80% | Max forgetting (W-NCM): 73.00%
2025-12-11 16:48:04,903 [trainer.py] => All params: 125940251
2025-12-11 16:48:04,909 [trainer.py] => Trainable params: 185858
2025-12-11 16:48:04,910 [inflora.py] => Learning on 98-100
Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.49.weight', 'image_encoder.blocks.3.attn.lora_B_v.49.weight', 'image_encoder.blocks.2.attn.lora_B_k.49.weight', 'image_encoder.blocks.6.attn.lora_B_k.49.weight', 'image_encoder.blocks.6.attn.lora_B_v.49.weight', 'image_encoder.blocks.9.attn.lora_B_v.49.weight', 'image_encoder.blocks.11.attn.lora_B_v.49.weight', 'image_encoder.blocks.10.attn.lora_B_v.49.weight', 'image_encoder.blocks.5.attn.lora_B_k.49.weight', 'image_encoder.blocks.7.attn.lora_B_k.49.weight', 'image_encoder.blocks.0.attn.lora_B_v.49.weight', 'image_encoder.blocks.2.attn.lora_B_v.49.weight', 'image_encoder.blocks.8.attn.lora_B_v.49.weight', 'image_encoder.blocks.8.attn.lora_B_k.49.weight', 'image_encoder.blocks.3.attn.lora_B_k.49.weight', 'image_encoder.blocks.1.attn.lora_B_k.49.weight', 'image_encoder.blocks.7.attn.lora_B_v.49.weight', 'image_encoder.blocks.11.attn.lora_B_k.49.weight', 'image_encoder.blocks.9.attn.lora_B_k.49.weight', 'image_encoder.blocks.0.attn.lora_B_k.49.weight', 'classifier_pool.49.bias', 'image_encoder.blocks.5.attn.lora_B_v.49.weight', 'image_encoder.blocks.1.attn.lora_B_v.49.weight', 'image_encoder.blocks.4.attn.lora_B_k.49.weight', 'image_encoder.blocks.10.attn.lora_B_k.49.weight', 'classifier_pool.49.weight'}
2025-12-11 16:50:12,534 [inflora.py] => Task 49, Epoch 20/20 => Loss 0.031, Train_accy 99.10
Threshold:  0.999
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 14/768 type remove
Layer 2 : 53/768 type remove
Layer 3 : 108/768 type remove
Layer 4 : 182/768 type remove
Layer 5 : 257/768 type remove
Layer 6 : 357/768 type remove
Layer 7 : 338/768 type retain
Layer 8 : 232/768 type retain
Layer 9 : 189/768 type retain
Layer 10 : 161/768 type retain
Layer 11 : 231/768 type retain
Layer 12 : 247/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-12-11 16:50:23,121 [trainer.py] => Time:138.21110606193542
10000 10000
10000 10000
2025-12-11 16:50:50,196 [trainer.py] => Time:27.075358152389526
2025-12-11 16:50:50,196 [inflora.py] => Exemplar size: 0
2025-12-11 16:50:50,197 [trainer.py] => CNN: {'total': np.float64(60.55), '00-01': np.float64(69.5), '02-03': np.float64(63.0), '04-05': np.float64(47.5), '06-07': np.float64(35.0), '08-09': np.float64(83.5), '10-11': np.float64(41.0), '12-13': np.float64(61.0), '14-15': np.float64(72.5), '16-17': np.float64(59.5), '18-19': np.float64(65.0), '20-21': np.float64(58.5), '22-23': np.float64(60.5), '24-25': np.float64(64.5), '26-27': np.float64(67.0), '28-29': np.float64(68.0), '30-31': np.float64(62.0), '32-33': np.float64(53.0), '34-35': np.float64(47.5), '36-37': np.float64(60.5), '38-39': np.float64(88.5), '40-41': np.float64(85.0), '42-43': np.float64(15.0), '44-45': np.float64(44.0), '46-47': np.float64(38.0), '48-49': np.float64(69.5), '50-51': np.float64(68.5), '52-53': np.float64(75.5), '54-55': np.float64(63.0), '56-57': np.float64(77.5), '58-59': np.float64(48.5), '60-61': np.float64(67.0), '62-63': np.float64(54.5), '64-65': np.float64(64.0), '66-67': np.float64(47.0), '68-69': np.float64(73.5), '70-71': np.float64(90.5), '72-73': np.float64(16.5), '74-75': np.float64(58.5), '76-77': np.float64(68.0), '78-79': np.float64(72.5), '80-81': np.float64(52.0), '82-83': np.float64(77.0), '84-85': np.float64(62.0), '86-87': np.float64(72.5), '88-89': np.float64(73.0), '90-91': np.float64(86.0), '92-93': np.float64(55.0), '94-95': np.float64(47.0), '96-97': np.float64(14.0), '98-99': np.float64(65.0), 'old': np.float64(60.46), 'new': np.float64(65.0)}
2025-12-11 16:50:50,197 [trainer.py] => CNN top1 curve: [np.float64(100.0), np.float64(98.25), np.float64(92.83), np.float64(88.38), np.float64(91.1), np.float64(86.42), np.float64(87.57), np.float64(88.12), np.float64(87.78), np.float64(87.7), np.float64(86.64), np.float64(85.04), np.float64(83.81), np.float64(83.29), np.float64(82.87), np.float64(82.41), np.float64(81.71), np.float64(78.0), np.float64(77.58), np.float64(76.6), np.float64(76.76), np.float64(75.02), np.float64(76.54), np.float64(73.1), np.float64(73.52), np.float64(73.56), np.float64(73.89), np.float64(73.02), np.float64(73.4), np.float64(72.13), np.float64(71.19), np.float64(69.73), np.float64(70.09), np.float64(69.65), np.float64(69.11), np.float64(67.76), np.float64(65.78), np.float64(65.62), np.float64(67.79), np.float64(67.97), np.float64(67.4), np.float64(67.21), np.float64(66.97), np.float64(67.77), np.float64(66.22), np.float64(65.59), np.float64(65.13), np.float64(63.03), np.float64(61.72), np.float64(60.55)]
2025-12-11 16:50:50,197 [trainer.py] => CNN top1 with task curve: [np.float64(100.0), np.float64(100.0), np.float64(100.0), np.float64(99.5), np.float64(99.7), np.float64(99.67), np.float64(99.71), np.float64(99.75), np.float64(99.67), np.float64(99.75), np.float64(99.68), np.float64(99.58), np.float64(99.77), np.float64(99.75), np.float64(99.7), np.float64(99.78), np.float64(99.68), np.float64(99.69), np.float64(99.66), np.float64(99.65), np.float64(99.57), np.float64(99.55), np.float64(99.57), np.float64(99.54), np.float64(99.52), np.float64(99.52), np.float64(99.48), np.float64(99.5), np.float64(99.55), np.float64(99.55), np.float64(99.55), np.float64(99.59), np.float64(99.53), np.float64(99.56), np.float64(99.61), np.float64(99.56), np.float64(99.54), np.float64(99.54), np.float64(99.5), np.float64(99.5), np.float64(99.56), np.float64(99.58), np.float64(99.56), np.float64(99.52), np.float64(99.49), np.float64(99.52), np.float64(99.54), np.float64(99.52), np.float64(99.56), np.float64(99.5)]
2025-12-11 16:50:50,197 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9283333333333333, 0.88375, 0.911, 0.8641666666666666, 0.8764285714285714, 0.88125, 0.8777777777777778, 0.877, 0.8663636363636363, 0.8504166666666667, 0.838076923076923, 0.8328571428571429, 0.8286666666666667, 0.8240625, 0.8170588235294117, 0.78, 0.7757894736842105, 0.766, 0.7676190476190476, 0.7502272727272727, 0.7654347826086957, 0.7310416666666667, 0.7352, 0.7355769230769231, 0.7388888888888889, 0.7301785714285715, 0.7339655172413793, 0.7213333333333334, 0.7119354838709677, 0.69734375, 0.7009090909090909, 0.6964705882352941, 0.6911428571428572, 0.6776388888888889, 0.6578378378378379, 0.6561842105263158, 0.6779487179487179, 0.67975, 0.6740243902439025, 0.6721428571428572, 0.6696511627906977, 0.6777272727272727, 0.6622222222222223, 0.6559782608695652, 0.6512765957446809, 0.6303125, 0.6172448979591837, 0.6055]
2025-12-11 16:51:20,154 [trainer.py] => W-NCM: {'00-01': 96.0, '02-03': 70.0, '04-05': 76.0, '06-07': 91.0, '08-09': 94.5, '10-11': 23.0, '12-13': 68.0, '14-15': 95.5, '16-17': 89.5, '18-19': 85.0, '20-21': 90.5, '22-23': 75.0, '24-25': 88.0, '26-27': 85.0, '28-29': 88.5, '30-31': 85.0, '32-33': 51.0, '34-35': 47.0, '36-37': 83.5, '38-39': 85.5, '40-41': 85.0, '42-43': 80.5, '44-45': 89.5, '46-47': 42.0, '48-49': 90.5, '50-51': 86.0, '52-53': 54.0, '54-55': 81.5, '56-57': 93.5, '58-59': 72.5, '60-61': 81.5, '62-63': 83.5, '64-65': 86.5, '66-67': 87.0, '68-69': 85.0, '70-71': 80.5, '72-73': 72.5, '74-75': 85.0, '76-77': 95.5, '78-79': 83.0, '80-81': 85.5, '82-83': 95.5, '84-85': 94.0, '86-87': 94.0, '88-89': 97.5, '90-91': 96.5, '92-93': 96.5, '94-95': 97.5, '96-97': 97.5, '98-99': 98.0}
2025-12-11 16:51:20,154 [trainer.py] => Ave Acc (W-NCM): 82.70%
2025-12-11 16:51:20,154 [trainer.py] => Per-task accuracies (W-NCM): T1: W-NCM 96.00% (best 100.00%); T2: W-NCM 70.00% (best 100.00%); T3: W-NCM 76.00% (best 100.00%); T4: W-NCM 91.00% (best 98.50%); T5: W-NCM 94.50% (best 100.00%); T6: W-NCM 23.00% (best 100.00%); T7: W-NCM 68.00% (best 99.50%); T8: W-NCM 95.50% (best 98.50%); T9: W-NCM 89.50% (best 99.50%); T10: W-NCM 85.00% (best 99.00%); T11: W-NCM 90.50% (best 99.50%); T12: W-NCM 75.00% (best 99.00%); T13: W-NCM 88.00% (best 98.00%); T14: W-NCM 85.00% (best 99.00%); T15: W-NCM 88.50% (best 97.50%); T16: W-NCM 85.00% (best 98.50%); T17: W-NCM 51.00% (best 98.00%); T18: W-NCM 47.00% (best 99.00%); T19: W-NCM 83.50% (best 99.50%); T20: W-NCM 85.50% (best 99.00%); T21: W-NCM 85.00% (best 98.50%); T22: W-NCM 80.50% (best 96.00%); T23: W-NCM 89.50% (best 95.50%); T24: W-NCM 42.00% (best 100.00%); T25: W-NCM 90.50% (best 99.00%); T26: W-NCM 86.00% (best 99.00%); T27: W-NCM 54.00% (best 100.00%); T28: W-NCM 81.50% (best 98.50%); T29: W-NCM 93.50% (best 98.50%); T30: W-NCM 72.50% (best 96.00%); T31: W-NCM 81.50% (best 98.50%); T32: W-NCM 83.50% (best 97.00%); T33: W-NCM 86.50% (best 95.00%); T34: W-NCM 87.00% (best 99.00%); T35: W-NCM 85.00% (best 99.50%); T36: W-NCM 80.50% (best 98.00%); T37: W-NCM 72.50% (best 93.50%); T38: W-NCM 85.00% (best 96.00%); T39: W-NCM 95.50% (best 98.50%); T40: W-NCM 83.00% (best 98.50%); T41: W-NCM 85.50% (best 96.00%); T42: W-NCM 95.50% (best 98.50%); T43: W-NCM 94.00% (best 98.00%); T44: W-NCM 94.00% (best 99.50%); T45: W-NCM 97.50% (best 98.50%); T46: W-NCM 96.50% (best 98.50%); T47: W-NCM 96.50% (best 97.50%); T48: W-NCM 97.50% (best 98.50%); T49: W-NCM 97.50% (best 97.50%); T50: W-NCM 98.00% (best 98.00%)
2025-12-11 16:51:20,154 [trainer.py] => Average forgetting (W-NCM): 15.96% | Max forgetting (W-NCM): 77.00%
2025-12-11 16:51:24,198 [trainer.py] => 
===== Summary =====
2025-12-11 16:51:24,198 [trainer.py] => Final average accuracy: 60.55%
2025-12-11 16:51:24,198 [trainer.py] => Average accuracy over tasks: 76.07%
2025-12-11 16:51:24,199 [trainer.py] => Final average forgetting: 18.64%
2025-12-11 16:51:24,199 [trainer.py] => Final max forgetting: 47.50%
2025-12-11 16:51:24,199 [trainer.py] => W-NCM final average accuracy: 82.70%
2025-12-11 16:51:24,199 [trainer.py] => W-NCM average accuracy over tasks: 90.59%
2025-12-11 16:51:24,199 [trainer.py] => W-NCM final average forgetting: 15.96%
2025-12-11 16:51:24,199 [trainer.py] => W-NCM final max forgetting: 77.00%
